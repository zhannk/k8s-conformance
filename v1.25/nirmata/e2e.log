I0124 18:33:01.285431      22 e2e.go:116] Starting e2e run "617be119-0c88-4374-8e10-e5fff9ed44b0" on Ginkgo node 1
Jan 24 18:33:01.402: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1674585179 - will randomize all specs

Will run 362 of 7066 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Jan 24 18:33:01.934: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 18:33:01.945: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 24 18:33:01.995: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 24 18:33:02.065: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 24 18:33:02.066: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Jan 24 18:33:02.067: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 24 18:33:02.086: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Jan 24 18:33:02.086: INFO: e2e test version: v1.25.5
Jan 24 18:33:02.093: INFO: kube-apiserver version: v1.25.5
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Jan 24 18:33:02.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 18:33:02.125: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.192 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Jan 24 18:33:01.934: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 18:33:01.945: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Jan 24 18:33:01.995: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Jan 24 18:33:02.065: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Jan 24 18:33:02.066: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
    Jan 24 18:33:02.067: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Jan 24 18:33:02.086: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Jan 24 18:33:02.086: INFO: e2e test version: v1.25.5
    Jan 24 18:33:02.093: INFO: kube-apiserver version: v1.25.5
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Jan 24 18:33:02.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 18:33:02.125: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:33:02.288
Jan 24 18:33:02.289: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename job 01/24/23 18:33:02.3
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:33:02.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:33:02.49
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 01/24/23 18:33:02.518
STEP: Ensuring job reaches completions 01/24/23 18:33:02.545
STEP: Ensuring pods with index for job exist 01/24/23 18:33:18.554
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 24 18:33:18.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8635" for this suite. 01/24/23 18:33:18.576
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":1,"skipped":4,"failed":0}
------------------------------
• [SLOW TEST] [16.304 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:33:02.288
    Jan 24 18:33:02.289: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename job 01/24/23 18:33:02.3
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:33:02.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:33:02.49
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 01/24/23 18:33:02.518
    STEP: Ensuring job reaches completions 01/24/23 18:33:02.545
    STEP: Ensuring pods with index for job exist 01/24/23 18:33:18.554
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 24 18:33:18.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8635" for this suite. 01/24/23 18:33:18.576
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:33:18.596
Jan 24 18:33:18.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 18:33:18.608
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:33:18.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:33:18.7
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 01/24/23 18:33:18.713
Jan 24 18:33:18.748: INFO: Waiting up to 5m0s for pod "downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f" in namespace "downward-api-6712" to be "Succeeded or Failed"
Jan 24 18:33:18.770: INFO: Pod "downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.757271ms
Jan 24 18:33:20.779: INFO: Pod "downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031262168s
Jan 24 18:33:22.780: INFO: Pod "downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031792637s
STEP: Saw pod success 01/24/23 18:33:22.78
Jan 24 18:33:22.785: INFO: Pod "downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f" satisfied condition "Succeeded or Failed"
Jan 24 18:33:22.805: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f container dapi-container: <nil>
STEP: delete the pod 01/24/23 18:33:22.857
Jan 24 18:33:22.904: INFO: Waiting for pod downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f to disappear
Jan 24 18:33:22.916: INFO: Pod downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jan 24 18:33:22.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6712" for this suite. 01/24/23 18:33:22.942
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":2,"skipped":18,"failed":0}
------------------------------
• [4.361 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:33:18.596
    Jan 24 18:33:18.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 18:33:18.608
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:33:18.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:33:18.7
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 01/24/23 18:33:18.713
    Jan 24 18:33:18.748: INFO: Waiting up to 5m0s for pod "downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f" in namespace "downward-api-6712" to be "Succeeded or Failed"
    Jan 24 18:33:18.770: INFO: Pod "downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.757271ms
    Jan 24 18:33:20.779: INFO: Pod "downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031262168s
    Jan 24 18:33:22.780: INFO: Pod "downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031792637s
    STEP: Saw pod success 01/24/23 18:33:22.78
    Jan 24 18:33:22.785: INFO: Pod "downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f" satisfied condition "Succeeded or Failed"
    Jan 24 18:33:22.805: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f container dapi-container: <nil>
    STEP: delete the pod 01/24/23 18:33:22.857
    Jan 24 18:33:22.904: INFO: Waiting for pod downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f to disappear
    Jan 24 18:33:22.916: INFO: Pod downward-api-775f85bd-c14b-4ef2-a1b0-2f3ece01508f no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jan 24 18:33:22.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6712" for this suite. 01/24/23 18:33:22.942
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:33:22.96
Jan 24 18:33:22.967: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename taint-single-pod 01/24/23 18:33:22.984
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:33:23.024
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:33:23.035
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Jan 24 18:33:23.049: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 24 18:34:23.205: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Jan 24 18:34:23.223: INFO: Starting informer...
STEP: Starting pod... 01/24/23 18:34:23.223
Jan 24 18:34:23.542: INFO: Pod is running on vikash-v125latest-conf-71087. Tainting Node
STEP: Trying to apply a taint on the Node 01/24/23 18:34:23.542
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/24/23 18:34:23.584
STEP: Waiting short time to make sure Pod is queued for deletion 01/24/23 18:34:23.63
Jan 24 18:34:23.634: INFO: Pod wasn't evicted. Proceeding
Jan 24 18:34:23.634: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/24/23 18:34:23.837
STEP: Waiting some time to make sure that toleration time passed. 01/24/23 18:34:23.908
Jan 24 18:35:38.926: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Jan 24 18:35:38.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-9009" for this suite. 01/24/23 18:35:38.957
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":3,"skipped":18,"failed":0}
------------------------------
• [SLOW TEST] [136.029 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:33:22.96
    Jan 24 18:33:22.967: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename taint-single-pod 01/24/23 18:33:22.984
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:33:23.024
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:33:23.035
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Jan 24 18:33:23.049: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 24 18:34:23.205: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Jan 24 18:34:23.223: INFO: Starting informer...
    STEP: Starting pod... 01/24/23 18:34:23.223
    Jan 24 18:34:23.542: INFO: Pod is running on vikash-v125latest-conf-71087. Tainting Node
    STEP: Trying to apply a taint on the Node 01/24/23 18:34:23.542
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/24/23 18:34:23.584
    STEP: Waiting short time to make sure Pod is queued for deletion 01/24/23 18:34:23.63
    Jan 24 18:34:23.634: INFO: Pod wasn't evicted. Proceeding
    Jan 24 18:34:23.634: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/24/23 18:34:23.837
    STEP: Waiting some time to make sure that toleration time passed. 01/24/23 18:34:23.908
    Jan 24 18:35:38.926: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 18:35:38.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-9009" for this suite. 01/24/23 18:35:38.957
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:35:39.045
Jan 24 18:35:39.046: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 18:35:39.052
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:35:39.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:35:39.142
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 01/24/23 18:35:39.159
STEP: setting up watch 01/24/23 18:35:39.159
STEP: submitting the pod to kubernetes 01/24/23 18:35:39.276
STEP: verifying the pod is in kubernetes 01/24/23 18:35:39.324
STEP: verifying pod creation was observed 01/24/23 18:35:39.343
Jan 24 18:35:39.345: INFO: Waiting up to 5m0s for pod "pod-submit-remove-09374b4b-7517-486e-bbaf-22e39d55f391" in namespace "pods-7093" to be "running"
Jan 24 18:35:39.367: INFO: Pod "pod-submit-remove-09374b4b-7517-486e-bbaf-22e39d55f391": Phase="Pending", Reason="", readiness=false. Elapsed: 20.30047ms
Jan 24 18:35:41.382: INFO: Pod "pod-submit-remove-09374b4b-7517-486e-bbaf-22e39d55f391": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034858165s
Jan 24 18:35:43.387: INFO: Pod "pod-submit-remove-09374b4b-7517-486e-bbaf-22e39d55f391": Phase="Running", Reason="", readiness=true. Elapsed: 4.040398775s
Jan 24 18:35:43.387: INFO: Pod "pod-submit-remove-09374b4b-7517-486e-bbaf-22e39d55f391" satisfied condition "running"
STEP: deleting the pod gracefully 01/24/23 18:35:43.399
STEP: verifying pod deletion was observed 01/24/23 18:35:43.417
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 24 18:35:46.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7093" for this suite. 01/24/23 18:35:46.594
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":4,"skipped":91,"failed":0}
------------------------------
• [SLOW TEST] [7.579 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:35:39.045
    Jan 24 18:35:39.046: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 18:35:39.052
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:35:39.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:35:39.142
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 01/24/23 18:35:39.159
    STEP: setting up watch 01/24/23 18:35:39.159
    STEP: submitting the pod to kubernetes 01/24/23 18:35:39.276
    STEP: verifying the pod is in kubernetes 01/24/23 18:35:39.324
    STEP: verifying pod creation was observed 01/24/23 18:35:39.343
    Jan 24 18:35:39.345: INFO: Waiting up to 5m0s for pod "pod-submit-remove-09374b4b-7517-486e-bbaf-22e39d55f391" in namespace "pods-7093" to be "running"
    Jan 24 18:35:39.367: INFO: Pod "pod-submit-remove-09374b4b-7517-486e-bbaf-22e39d55f391": Phase="Pending", Reason="", readiness=false. Elapsed: 20.30047ms
    Jan 24 18:35:41.382: INFO: Pod "pod-submit-remove-09374b4b-7517-486e-bbaf-22e39d55f391": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034858165s
    Jan 24 18:35:43.387: INFO: Pod "pod-submit-remove-09374b4b-7517-486e-bbaf-22e39d55f391": Phase="Running", Reason="", readiness=true. Elapsed: 4.040398775s
    Jan 24 18:35:43.387: INFO: Pod "pod-submit-remove-09374b4b-7517-486e-bbaf-22e39d55f391" satisfied condition "running"
    STEP: deleting the pod gracefully 01/24/23 18:35:43.399
    STEP: verifying pod deletion was observed 01/24/23 18:35:43.417
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 24 18:35:46.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7093" for this suite. 01/24/23 18:35:46.594
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:35:46.674
Jan 24 18:35:46.690: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 18:35:46.705
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:35:46.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:35:46.793
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 01/24/23 18:35:46.799
Jan 24 18:35:46.835: INFO: Waiting up to 5m0s for pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c" in namespace "emptydir-7279" to be "Succeeded or Failed"
Jan 24 18:35:46.855: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.553868ms
Jan 24 18:35:48.864: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028790632s
Jan 24 18:35:50.865: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029992846s
Jan 24 18:35:52.868: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03259111s
Jan 24 18:35:54.922: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.08694539s
Jan 24 18:35:56.864: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.028822393s
Jan 24 18:35:58.879: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Running", Reason="", readiness=true. Elapsed: 12.043968068s
Jan 24 18:36:00.885: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Running", Reason="", readiness=false. Elapsed: 14.050074454s
Jan 24 18:36:02.869: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.034085176s
STEP: Saw pod success 01/24/23 18:36:02.869
Jan 24 18:36:02.870: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c" satisfied condition "Succeeded or Failed"
Jan 24 18:36:02.898: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c container test-container: <nil>
STEP: delete the pod 01/24/23 18:36:02.979
Jan 24 18:36:03.016: INFO: Waiting for pod pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c to disappear
Jan 24 18:36:03.031: INFO: Pod pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 18:36:03.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7279" for this suite. 01/24/23 18:36:03.054
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":5,"skipped":110,"failed":0}
------------------------------
• [SLOW TEST] [16.411 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:35:46.674
    Jan 24 18:35:46.690: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 18:35:46.705
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:35:46.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:35:46.793
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 01/24/23 18:35:46.799
    Jan 24 18:35:46.835: INFO: Waiting up to 5m0s for pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c" in namespace "emptydir-7279" to be "Succeeded or Failed"
    Jan 24 18:35:46.855: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.553868ms
    Jan 24 18:35:48.864: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028790632s
    Jan 24 18:35:50.865: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029992846s
    Jan 24 18:35:52.868: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03259111s
    Jan 24 18:35:54.922: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.08694539s
    Jan 24 18:35:56.864: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.028822393s
    Jan 24 18:35:58.879: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Running", Reason="", readiness=true. Elapsed: 12.043968068s
    Jan 24 18:36:00.885: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Running", Reason="", readiness=false. Elapsed: 14.050074454s
    Jan 24 18:36:02.869: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.034085176s
    STEP: Saw pod success 01/24/23 18:36:02.869
    Jan 24 18:36:02.870: INFO: Pod "pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c" satisfied condition "Succeeded or Failed"
    Jan 24 18:36:02.898: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c container test-container: <nil>
    STEP: delete the pod 01/24/23 18:36:02.979
    Jan 24 18:36:03.016: INFO: Waiting for pod pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c to disappear
    Jan 24 18:36:03.031: INFO: Pod pod-21bf4eb2-e7ef-40d8-bf9b-f871f9cc412c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 18:36:03.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7279" for this suite. 01/24/23 18:36:03.054
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:36:03.125
Jan 24 18:36:03.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sched-preemption 01/24/23 18:36:03.134
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:36:03.303
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:36:03.334
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jan 24 18:36:03.417: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 24 18:37:03.524: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 01/24/23 18:37:03.535
Jan 24 18:37:03.607: INFO: Created pod: pod0-0-sched-preemption-low-priority
Jan 24 18:37:03.660: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Jan 24 18:37:03.754: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Jan 24 18:37:03.801: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 01/24/23 18:37:03.801
Jan 24 18:37:03.802: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-9954" to be "running"
Jan 24 18:37:03.910: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 108.590564ms
Jan 24 18:37:05.928: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126178175s
Jan 24 18:37:07.925: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.123038188s
Jan 24 18:37:09.975: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.173796939s
Jan 24 18:37:11.945: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.143678542s
Jan 24 18:37:13.933: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.131246181s
Jan 24 18:37:15.954: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 12.151890065s
Jan 24 18:37:17.934: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 14.132520109s
Jan 24 18:37:20.039: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 16.237102998s
Jan 24 18:37:20.039: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Jan 24 18:37:20.039: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-9954" to be "running"
Jan 24 18:37:20.186: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 146.978829ms
Jan 24 18:37:20.186: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Jan 24 18:37:20.186: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-9954" to be "running"
Jan 24 18:37:20.213: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 27.269952ms
Jan 24 18:37:20.214: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Jan 24 18:37:20.252: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-9954" to be "running"
Jan 24 18:37:20.374: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 121.509315ms
Jan 24 18:37:20.374: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 01/24/23 18:37:20.374
Jan 24 18:37:20.453: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Jan 24 18:37:20.534: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 68.952753ms
Jan 24 18:37:22.670: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.205285462s
Jan 24 18:37:24.679: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.214263136s
Jan 24 18:37:26.676: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.211153095s
Jan 24 18:37:28.665: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.200062844s
Jan 24 18:37:28.665: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jan 24 18:37:28.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-9954" for this suite. 01/24/23 18:37:28.811
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":6,"skipped":139,"failed":0}
------------------------------
• [SLOW TEST] [85.890 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:36:03.125
    Jan 24 18:36:03.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sched-preemption 01/24/23 18:36:03.134
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:36:03.303
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:36:03.334
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jan 24 18:36:03.417: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 24 18:37:03.524: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 01/24/23 18:37:03.535
    Jan 24 18:37:03.607: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Jan 24 18:37:03.660: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Jan 24 18:37:03.754: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Jan 24 18:37:03.801: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 01/24/23 18:37:03.801
    Jan 24 18:37:03.802: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-9954" to be "running"
    Jan 24 18:37:03.910: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 108.590564ms
    Jan 24 18:37:05.928: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126178175s
    Jan 24 18:37:07.925: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.123038188s
    Jan 24 18:37:09.975: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.173796939s
    Jan 24 18:37:11.945: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.143678542s
    Jan 24 18:37:13.933: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.131246181s
    Jan 24 18:37:15.954: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 12.151890065s
    Jan 24 18:37:17.934: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 14.132520109s
    Jan 24 18:37:20.039: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 16.237102998s
    Jan 24 18:37:20.039: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Jan 24 18:37:20.039: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-9954" to be "running"
    Jan 24 18:37:20.186: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 146.978829ms
    Jan 24 18:37:20.186: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Jan 24 18:37:20.186: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-9954" to be "running"
    Jan 24 18:37:20.213: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 27.269952ms
    Jan 24 18:37:20.214: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Jan 24 18:37:20.252: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-9954" to be "running"
    Jan 24 18:37:20.374: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 121.509315ms
    Jan 24 18:37:20.374: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 01/24/23 18:37:20.374
    Jan 24 18:37:20.453: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Jan 24 18:37:20.534: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 68.952753ms
    Jan 24 18:37:22.670: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.205285462s
    Jan 24 18:37:24.679: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.214263136s
    Jan 24 18:37:26.676: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.211153095s
    Jan 24 18:37:28.665: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.200062844s
    Jan 24 18:37:28.665: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 18:37:28.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-9954" for this suite. 01/24/23 18:37:28.811
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:37:29.077
Jan 24 18:37:29.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 18:37:29.083
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:37:29.161
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:37:29.186
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 01/24/23 18:37:29.259
Jan 24 18:37:29.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9778 create -f -'
Jan 24 18:37:39.355: INFO: stderr: ""
Jan 24 18:37:39.356: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 01/24/23 18:37:39.356
Jan 24 18:37:40.382: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 18:37:40.382: INFO: Found 0 / 1
Jan 24 18:37:41.423: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 18:37:41.423: INFO: Found 0 / 1
Jan 24 18:37:42.391: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 18:37:42.392: INFO: Found 1 / 1
Jan 24 18:37:42.392: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 01/24/23 18:37:42.393
Jan 24 18:37:42.452: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 18:37:42.461: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 24 18:37:42.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9778 patch pod agnhost-primary-c4vjg -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 24 18:37:42.992: INFO: stderr: ""
Jan 24 18:37:42.992: INFO: stdout: "pod/agnhost-primary-c4vjg patched\n"
STEP: checking annotations 01/24/23 18:37:42.992
Jan 24 18:37:43.028: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 18:37:43.028: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 18:37:43.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9778" for this suite. 01/24/23 18:37:43.05
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":7,"skipped":176,"failed":0}
------------------------------
• [SLOW TEST] [13.997 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:37:29.077
    Jan 24 18:37:29.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 18:37:29.083
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:37:29.161
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:37:29.186
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 01/24/23 18:37:29.259
    Jan 24 18:37:29.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9778 create -f -'
    Jan 24 18:37:39.355: INFO: stderr: ""
    Jan 24 18:37:39.356: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 01/24/23 18:37:39.356
    Jan 24 18:37:40.382: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 18:37:40.382: INFO: Found 0 / 1
    Jan 24 18:37:41.423: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 18:37:41.423: INFO: Found 0 / 1
    Jan 24 18:37:42.391: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 18:37:42.392: INFO: Found 1 / 1
    Jan 24 18:37:42.392: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 01/24/23 18:37:42.393
    Jan 24 18:37:42.452: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 18:37:42.461: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Jan 24 18:37:42.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9778 patch pod agnhost-primary-c4vjg -p {"metadata":{"annotations":{"x":"y"}}}'
    Jan 24 18:37:42.992: INFO: stderr: ""
    Jan 24 18:37:42.992: INFO: stdout: "pod/agnhost-primary-c4vjg patched\n"
    STEP: checking annotations 01/24/23 18:37:42.992
    Jan 24 18:37:43.028: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 18:37:43.028: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 18:37:43.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9778" for this suite. 01/24/23 18:37:43.05
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:37:43.087
Jan 24 18:37:43.087: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename deployment 01/24/23 18:37:43.094
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:37:43.218
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:37:43.235
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Jan 24 18:37:43.265: INFO: Creating deployment "webserver-deployment"
Jan 24 18:37:43.306: INFO: Waiting for observed generation 1
Jan 24 18:37:45.866: INFO: Waiting for all required pods to come up
Jan 24 18:37:46.497: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 01/24/23 18:37:46.729
Jan 24 18:37:46.730: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-wxcvj" in namespace "deployment-5477" to be "running"
Jan 24 18:37:46.731: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2bkh4" in namespace "deployment-5477" to be "running"
Jan 24 18:37:46.731: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-57666" in namespace "deployment-5477" to be "running"
Jan 24 18:37:46.732: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-8j9k9" in namespace "deployment-5477" to be "running"
Jan 24 18:37:46.732: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-gfpgm" in namespace "deployment-5477" to be "running"
Jan 24 18:37:46.733: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-h8jmq" in namespace "deployment-5477" to be "running"
Jan 24 18:37:46.733: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-hgnnz" in namespace "deployment-5477" to be "running"
Jan 24 18:37:46.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-j9nwd" in namespace "deployment-5477" to be "running"
Jan 24 18:37:46.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-nwmz7" in namespace "deployment-5477" to be "running"
Jan 24 18:37:46.735: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vz2jn" in namespace "deployment-5477" to be "running"
Jan 24 18:37:46.992: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 261.374869ms
Jan 24 18:37:46.992: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 259.070743ms
Jan 24 18:37:46.992: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 258.907778ms
Jan 24 18:37:46.993: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 260.611946ms
Jan 24 18:37:46.993: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 258.950931ms
Jan 24 18:37:46.993: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 260.609834ms
Jan 24 18:37:46.993: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 262.099908ms
Jan 24 18:37:47.008: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 274.05301ms
Jan 24 18:37:47.009: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 277.510046ms
Jan 24 18:37:47.009: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 274.303486ms
Jan 24 18:37:49.052: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.318376212s
Jan 24 18:37:49.111: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.380376091s
Jan 24 18:37:49.125: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.394426208s
Jan 24 18:37:49.155: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.422470736s
Jan 24 18:37:49.162: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.426704659s
Jan 24 18:37:49.162: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 2.430687536s
Jan 24 18:37:49.163: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.429811989s
Jan 24 18:37:49.163: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.431098762s
Jan 24 18:37:49.472: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.738070833s
Jan 24 18:37:49.474: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.73988962s
Jan 24 18:37:51.125: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.392898329s
Jan 24 18:37:51.128: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.397660563s
Jan 24 18:37:51.128: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.397042636s
Jan 24 18:37:51.133: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.401111816s
Jan 24 18:37:51.134: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 4.402378821s
Jan 24 18:37:51.128: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.393989749s
Jan 24 18:37:51.135: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.402145693s
Jan 24 18:37:51.136: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.402768523s
Jan 24 18:37:51.121: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.387596208s
Jan 24 18:37:51.249: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.513769905s
Jan 24 18:37:53.002: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 6.269069405s
Jan 24 18:37:53.007: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 6.275051059s
Jan 24 18:37:53.008: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.277534949s
Jan 24 18:37:53.009: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.277610437s
Jan 24 18:37:53.012: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.278468257s
Jan 24 18:37:53.017: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.285058703s
Jan 24 18:37:53.021: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.286239881s
Jan 24 18:37:53.021: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.288046277s
Jan 24 18:37:53.021: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 6.289509845s
Jan 24 18:37:53.021: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.286178213s
Jan 24 18:37:55.001: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.270057415s
Jan 24 18:37:55.001: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.270981964s
Jan 24 18:37:55.001: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 8.268986663s
Jan 24 18:37:55.001: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.268270999s
Jan 24 18:37:55.016: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.282677827s
Jan 24 18:37:55.022: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.287833176s
Jan 24 18:37:55.026: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 8.294929311s
Jan 24 18:37:55.027: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.292542104s
Jan 24 18:37:55.029: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 8.295656232s
Jan 24 18:37:55.029: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.296942907s
Jan 24 18:37:57.015: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 10.281539345s
Jan 24 18:37:57.018: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.28412505s
Jan 24 18:37:57.018: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.286961689s
Jan 24 18:37:57.026: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 10.293523603s
Jan 24 18:37:57.028: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.293496062s
Jan 24 18:37:57.028: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.293021785s
Jan 24 18:37:57.028: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 10.297828323s
Jan 24 18:37:57.031: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.298619091s
Jan 24 18:37:57.032: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 10.300150249s
Jan 24 18:37:57.057: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 10.324248028s
Jan 24 18:37:59.043: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 12.309328424s
Jan 24 18:37:59.043: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 12.30824954s
Jan 24 18:37:59.044: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.312672928s
Jan 24 18:37:59.044: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 12.311906965s
Jan 24 18:37:59.045: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 12.313380814s
Jan 24 18:37:59.045: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.310699826s
Jan 24 18:37:59.045: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.31167177s
Jan 24 18:37:59.050: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 12.319245311s
Jan 24 18:37:59.050: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 12.316908855s
Jan 24 18:37:59.053: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.321195553s
Jan 24 18:38:01.005: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 14.274752196s
Jan 24 18:38:01.005: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.271671004s
Jan 24 18:38:01.006: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.273640386s
Jan 24 18:38:01.006: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 14.27249327s
Jan 24 18:38:01.006: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 14.273439065s
Jan 24 18:38:01.006: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.274893499s
Jan 24 18:38:01.006: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 14.273256704s
Jan 24 18:38:01.016: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.281165305s
Jan 24 18:38:01.016: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Running", Reason="", readiness=true. Elapsed: 14.280703223s
Jan 24 18:38:01.016: INFO: Pod "webserver-deployment-845c8977d9-vz2jn" satisfied condition "running"
Jan 24 18:38:01.020: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 14.288570725s
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Running", Reason="", readiness=true. Elapsed: 16.292009578s
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-j9nwd" satisfied condition "running"
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 16.295752826s
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 16.293685047s
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.291849365s
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Running", Reason="", readiness=true. Elapsed: 16.294321687s
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-8j9k9" satisfied condition "running"
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Running", Reason="", readiness=true. Elapsed: 16.294904458s
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 16.293604471s
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-57666" satisfied condition "running"
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Running", Reason="", readiness=true. Elapsed: 16.292567948s
Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-hgnnz" satisfied condition "running"
Jan 24 18:38:03.027: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.29546424s
Jan 24 18:38:05.006: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 18.2760442s
Jan 24 18:38:05.007: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.275891842s
Jan 24 18:38:05.040: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 18.306893324s
Jan 24 18:38:05.045: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 18.312298433s
Jan 24 18:38:05.088: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.353948693s
Jan 24 18:38:07.007: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Running", Reason="", readiness=true. Elapsed: 20.276276025s
Jan 24 18:38:07.007: INFO: Pod "webserver-deployment-845c8977d9-wxcvj" satisfied condition "running"
Jan 24 18:38:07.008: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Running", Reason="", readiness=true. Elapsed: 20.276546521s
Jan 24 18:38:07.008: INFO: Pod "webserver-deployment-845c8977d9-2bkh4" satisfied condition "running"
Jan 24 18:38:07.008: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Running", Reason="", readiness=true. Elapsed: 20.275992805s
Jan 24 18:38:07.010: INFO: Pod "webserver-deployment-845c8977d9-gfpgm" satisfied condition "running"
Jan 24 18:38:07.009: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Running", Reason="", readiness=true. Elapsed: 20.27633415s
Jan 24 18:38:07.011: INFO: Pod "webserver-deployment-845c8977d9-h8jmq" satisfied condition "running"
Jan 24 18:38:07.020: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Running", Reason="", readiness=true. Elapsed: 20.285737602s
Jan 24 18:38:07.020: INFO: Pod "webserver-deployment-845c8977d9-nwmz7" satisfied condition "running"
Jan 24 18:38:07.020: INFO: Waiting for deployment "webserver-deployment" to complete
Jan 24 18:38:07.036: INFO: Updating deployment "webserver-deployment" with a non-existent image
Jan 24 18:38:07.061: INFO: Updating deployment webserver-deployment
Jan 24 18:38:07.062: INFO: Waiting for observed generation 2
Jan 24 18:38:09.169: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 24 18:38:09.178: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 24 18:38:09.204: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jan 24 18:38:09.295: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 24 18:38:09.295: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 24 18:38:09.369: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jan 24 18:38:09.468: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Jan 24 18:38:09.468: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Jan 24 18:38:09.572: INFO: Updating deployment webserver-deployment
Jan 24 18:38:09.572: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Jan 24 18:38:09.709: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 24 18:38:11.815: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 24 18:38:12.579: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-5477  b015c5e0-acc8-4288-8ab9-058ee065b3df 14747 3 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 18:38:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002eb8758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-01-24 18:38:09 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-01-24 18:38:10 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Jan 24 18:38:12.948: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-5477  ba6237a9-7d34-4e34-987e-17026b46be87 14735 3 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment b015c5e0-acc8-4288-8ab9-058ee065b3df 0xc002eb8b67 0xc002eb8b68}] [] [{kube-controller-manager Update apps/v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b015c5e0-acc8-4288-8ab9-058ee065b3df\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002eb8c08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 24 18:38:12.948: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Jan 24 18:38:12.948: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-5477  d0948274-445b-40e6-8259-221cddcb5a6c 14742 3 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment b015c5e0-acc8-4288-8ab9-058ee065b3df 0xc002eb8c67 0xc002eb8c68}] [] [{kube-controller-manager Update apps/v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b015c5e0-acc8-4288-8ab9-058ee065b3df\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002eb8cf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Jan 24 18:38:13.520: INFO: Pod "webserver-deployment-69b7448995-2kqb9" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-2kqb9 webserver-deployment-69b7448995- deployment-5477  7f19aa5b-7ae8-406a-80ca-ee20ca1bee74 14647 0 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:0d8a9aa1d6f4a6bbcef8428708da63f8e287d8b015afcc8c336cdd610ec8b5ad cni.projectcalico.org/podIP:10.244.71.219/32 cni.projectcalico.org/podIPs:10.244.71.219/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273d387 0xc00273d388}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-24 18:38:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-642fz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-642fz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:13.550: INFO: Pod "webserver-deployment-69b7448995-dt4tw" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-dt4tw webserver-deployment-69b7448995- deployment-5477  8447fe49-128a-47e7-b8ef-acfb9b8f2f97 14749 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273d580 0xc00273d581}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-crq5b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-crq5b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:13.554: INFO: Pod "webserver-deployment-69b7448995-gsz2p" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-gsz2p webserver-deployment-69b7448995- deployment-5477  82ae6a37-c0be-4cd3-8c4b-dca2449f0d23 14642 0 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:4fde42251e82f3317b5738158c8d560ee777fc64a9f8f266c131955398ed23fc cni.projectcalico.org/podIP:10.244.71.218/32 cni.projectcalico.org/podIPs:10.244.71.218/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273d780 0xc00273d781}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-24 18:38:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-224h5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-224h5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:13.930: INFO: Pod "webserver-deployment-69b7448995-h6t6q" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-h6t6q webserver-deployment-69b7448995- deployment-5477  74a0d618-307c-48ab-a667-15f60b29fcf6 14704 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273d970 0xc00273d971}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k4xj4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k4xj4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:14.339: INFO: Pod "webserver-deployment-69b7448995-lt269" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lt269 webserver-deployment-69b7448995- deployment-5477  5d59871e-392d-4f9c-ab21-0f4460cd11a1 14771 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273db40 0xc00273db41}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hs59j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hs59j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:15.111: INFO: Pod "webserver-deployment-69b7448995-pfgnr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-pfgnr webserver-deployment-69b7448995- deployment-5477  897b6ba3-3e71-4117-8a11-760c791ae188 14729 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273dd10 0xc00273dd11}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pf77w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pf77w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:15.113: INFO: Pod "webserver-deployment-69b7448995-pzz7q" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-pzz7q webserver-deployment-69b7448995- deployment-5477  eccda26c-4d14-4c73-89b5-58310d3505af 14657 0 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:8bbe20d5848d61cf650b2d0951b1f2403c1b0f75cae5958803542fd6d511a67a cni.projectcalico.org/podIP:10.244.71.220/32 cni.projectcalico.org/podIPs:10.244.71.220/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273df00 0xc00273df01}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kxjdj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kxjdj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:15.115: INFO: Pod "webserver-deployment-69b7448995-sxhck" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-sxhck webserver-deployment-69b7448995- deployment-5477  3ca01be3-e05e-4b81-8e7b-4fceef448928 14769 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb80f0 0xc002fb80f1}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-52tsn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-52tsn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:15.116: INFO: Pod "webserver-deployment-69b7448995-wbbxx" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-wbbxx webserver-deployment-69b7448995- deployment-5477  dd828298-85e8-485e-9feb-af9d329f4043 14727 0 2023-01-24 18:38:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb82c0 0xc002fb82c1}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hwcrl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hwcrl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:15.117: INFO: Pod "webserver-deployment-69b7448995-x9gjw" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-x9gjw webserver-deployment-69b7448995- deployment-5477  4a0313fb-1d7f-4929-b51c-56d5b1dd4cb2 14773 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb8420 0xc002fb8421}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xj4jm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xj4jm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:15.120: INFO: Pod "webserver-deployment-69b7448995-z7m4f" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-z7m4f webserver-deployment-69b7448995- deployment-5477  705cda7c-8048-4782-8d2f-837cab19cd8f 14779 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb8600 0xc002fb8601}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbhx8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbhx8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:15.126: INFO: Pod "webserver-deployment-69b7448995-zb84d" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-zb84d webserver-deployment-69b7448995- deployment-5477  85241ff2-4071-4601-8dfd-2eab8b76b86a 14648 0 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:3993d4786488c77e86be3001676f323103ea1b1d33cd6e48e96a407afab569dc cni.projectcalico.org/podIP:10.244.47.87/32 cni.projectcalico.org/podIPs:10.244.47.87/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb87f0 0xc002fb87f1}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-24 18:38:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6z7p7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6z7p7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:15.151: INFO: Pod "webserver-deployment-69b7448995-zzsvv" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-zzsvv webserver-deployment-69b7448995- deployment-5477  bd6b0d91-fd1e-4a94-a1d0-02b4a4858eec 14660 0 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:f943e8fa62d6eb1bf31efeae7364cc297a055edb3a4726438e71d64d12307172 cni.projectcalico.org/podIP:10.244.47.88/32 cni.projectcalico.org/podIPs:10.244.47.88/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb8a10 0xc002fb8a11}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f4tr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f4tr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.252: INFO: Pod "webserver-deployment-845c8977d9-2bkh4" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2bkh4 webserver-deployment-845c8977d9- deployment-5477  7dc5735f-e09a-4e5f-9510-c8173f9b8867 14583 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:7e4e9408f66ad90c75b79d68044091a796c251b9db80f5b6f8fd8427a656b1ce cni.projectcalico.org/podIP:10.244.47.86/32 cni.projectcalico.org/podIPs:10.244.47.86/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb8c30 0xc002fb8c31}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.86\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zm5bd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zm5bd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.86,StartTime:2023-01-24 18:37:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://13dae19afb555f131d468147556fe347a4852e2b8c2be2fd4923c6ac9673506f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.86,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.253: INFO: Pod "webserver-deployment-845c8977d9-57666" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-57666 webserver-deployment-845c8977d9- deployment-5477  b8eb6aaf-ffd3-4076-b4b4-a086f1d43abe 14551 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8ed5039b907c738270b27813d433cee345dba1d090c0e5f0b235feeed762c43b cni.projectcalico.org/podIP:10.244.71.216/32 cni.projectcalico.org/podIPs:10.244.71.216/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb8e47 0xc002fb8e48}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.216\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z24qw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z24qw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.216,StartTime:2023-01-24 18:37:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3b0f49c6914f03bb5fce67b6bdcce726faf76f901e6c5db272e09144b5cba82d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.216,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.323: INFO: Pod "webserver-deployment-845c8977d9-8j9k9" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8j9k9 webserver-deployment-845c8977d9- deployment-5477  ab4859e9-2d25-42c9-9ceb-18056535e29f 14547 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:82d2c3869ca30127593720fe755371fc5eca5e16fa17418d1b399ddd6ca3c68f cni.projectcalico.org/podIP:10.244.71.215/32 cni.projectcalico.org/podIPs:10.244.71.215/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9067 0xc002fb9068}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.215\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8xw2m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8xw2m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.215,StartTime:2023-01-24 18:37:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://30a69af5e4f8c0b10f466a9fae2b80c22aaa5378229dc9fbdeb97592c02b5443,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.215,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.330: INFO: Pod "webserver-deployment-845c8977d9-9sh6s" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9sh6s webserver-deployment-845c8977d9- deployment-5477  c07efed9-8d3e-45f1-abdc-4f8c3bdb3e37 14701 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9267 0xc002fb9268}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tvf4z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tvf4z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.331: INFO: Pod "webserver-deployment-845c8977d9-bc6xb" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bc6xb webserver-deployment-845c8977d9- deployment-5477  c99d5dc4-edfb-4125-936a-72b1b1bd667c 14760 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9427 0xc002fb9428}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7l45r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7l45r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.332: INFO: Pod "webserver-deployment-845c8977d9-bkglx" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bkglx webserver-deployment-845c8977d9- deployment-5477  775a9704-ee66-422b-8cc4-062765320131 14681 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb95e7 0xc002fb95e8}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6k62s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6k62s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.332: INFO: Pod "webserver-deployment-845c8977d9-dvnx7" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-dvnx7 webserver-deployment-845c8977d9- deployment-5477  f2e3dd52-ca34-4cf7-bdb5-546eaeed9233 14764 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb97a7 0xc002fb97a8}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fm6cg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fm6cg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.333: INFO: Pod "webserver-deployment-845c8977d9-gfpgm" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gfpgm webserver-deployment-845c8977d9- deployment-5477  bbdbe739-7034-451b-bf9e-79aed49a8659 14575 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:39f9af4d4afbe43962d8a44525309b4c50734a2a6298f5627c8973fb3f0021c6 cni.projectcalico.org/podIP:10.244.47.83/32 cni.projectcalico.org/podIPs:10.244.47.83/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9987 0xc002fb9988}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.83\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dfqmx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dfqmx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.83,StartTime:2023-01-24 18:37:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1e1257d775bdec57a17e7c009458d71af751731a86f6c05e1922769ba9e541e9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.83,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.333: INFO: Pod "webserver-deployment-845c8977d9-h8jmq" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-h8jmq webserver-deployment-845c8977d9- deployment-5477  c9742a20-5fa3-4504-a693-4e7462d416bb 14570 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:be2a121682475eadf8ec094ada00fed26653fd0f931d08c10eeb379b23a6b130 cni.projectcalico.org/podIP:10.244.47.85/32 cni.projectcalico.org/podIPs:10.244.47.85/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9ba7 0xc002fb9ba8}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.85\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n42jm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n42jm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.85,StartTime:2023-01-24 18:37:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7492485e22f43a2ea71cab5468950048468ca713fd60812793a1d108db206e24,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.334: INFO: Pod "webserver-deployment-845c8977d9-hgnnz" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-hgnnz webserver-deployment-845c8977d9- deployment-5477  c4ae9ee3-95bf-4f6a-88db-0cf1dbb080a3 14554 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:effbd703f701c4c11b278d441e4440007b6a501738178a84e8ea1d3b6ff8d6d0 cni.projectcalico.org/podIP:10.244.71.217/32 cni.projectcalico.org/podIPs:10.244.71.217/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9dc7 0xc002fb9dc8}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.217\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hf4jl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hf4jl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.217,StartTime:2023-01-24 18:37:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://74581976e58dcd066295994bfc7ddf60dd8bfed4acf16af3d765352c3c619ca3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.217,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.334: INFO: Pod "webserver-deployment-845c8977d9-hs5pc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-hs5pc webserver-deployment-845c8977d9- deployment-5477  500204cd-d013-4cab-8b41-0bee07d81810 14778 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9fc7 0xc002fb9fc8}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2gzss,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2gzss,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.466: INFO: Pod "webserver-deployment-845c8977d9-j8c55" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-j8c55 webserver-deployment-845c8977d9- deployment-5477  ebf6d29d-85c5-418a-a843-73ed466f4290 14722 0 2023-01-24 18:38:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002210197 0xc002210198}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rvbfg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rvbfg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.472: INFO: Pod "webserver-deployment-845c8977d9-nwmz7" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-nwmz7 webserver-deployment-845c8977d9- deployment-5477  51192b51-7e80-468f-9210-0ad3ff38fbe4 14573 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:bb90c600be4992d48532797db48d04cb4ea75662876638aa443fa9067178c6b7 cni.projectcalico.org/podIP:10.244.47.82/32 cni.projectcalico.org/podIPs:10.244.47.82/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002210320 0xc002210321}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.82\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4f646,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4f646,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.82,StartTime:2023-01-24 18:37:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://654e92c2873d23b65918d29ea5093db20f4fd0bd7ac30c312ce9ebbb78d1fe91,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.478: INFO: Pod "webserver-deployment-845c8977d9-q7q7z" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-q7q7z webserver-deployment-845c8977d9- deployment-5477  d2edd869-53e3-478d-b6e1-b513ea44d724 14716 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002210517 0xc002210518}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x5fdk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x5fdk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.478: INFO: Pod "webserver-deployment-845c8977d9-vmbh5" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vmbh5 webserver-deployment-845c8977d9- deployment-5477  ab73642a-ef63-4f8c-b55e-b5e137df1f3a 14728 0 2023-01-24 18:38:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002210670 0xc002210671}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wml4f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wml4f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.479: INFO: Pod "webserver-deployment-845c8977d9-w2bll" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-w2bll webserver-deployment-845c8977d9- deployment-5477  4e67b711-0959-44eb-97c0-78d0112fcf0c 14725 0 2023-01-24 18:38:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc0022107c0 0xc0022107c1}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pr89v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pr89v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.480: INFO: Pod "webserver-deployment-845c8977d9-wc76n" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wc76n webserver-deployment-845c8977d9- deployment-5477  453dacb1-3b44-486d-a2dc-8fca1952b94b 14733 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002210910 0xc002210911}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-czqdt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-czqdt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.480: INFO: Pod "webserver-deployment-845c8977d9-wmb7r" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wmb7r webserver-deployment-845c8977d9- deployment-5477  7e0a691b-7c9f-455a-a473-762fb9e3c4fe 14759 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002b8e017 0xc002b8e018}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f9bbs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f9bbs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.482: INFO: Pod "webserver-deployment-845c8977d9-wxcvj" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wxcvj webserver-deployment-845c8977d9- deployment-5477  5985d2ee-dd23-4068-8b53-0f88712e6908 14586 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:980b2706491306c463b7af811e4b4b9989bf372c3be04ba7f1164a7ad8237d07 cni.projectcalico.org/podIP:10.244.47.84/32 cni.projectcalico.org/podIPs:10.244.47.84/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002b8e1f7 0xc002b8e1f8}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.84\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gjrh4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gjrh4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.84,StartTime:2023-01-24 18:37:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://263bbe7e8bd24b291cca8c5ab19129fbdaeaf6a44772677382199d4d093eb050,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.84,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:38:16.483: INFO: Pod "webserver-deployment-845c8977d9-x66sb" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-x66sb webserver-deployment-845c8977d9- deployment-5477  a251ddbd-a3e0-48ef-aafa-10d11cfb3b51 14783 0 2023-01-24 18:38:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002b8e3f7 0xc002b8e3f8}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wx2dn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wx2dn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 24 18:38:16.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5477" for this suite. 01/24/23 18:38:17.553
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":8,"skipped":200,"failed":0}
------------------------------
• [SLOW TEST] [34.689 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:37:43.087
    Jan 24 18:37:43.087: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename deployment 01/24/23 18:37:43.094
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:37:43.218
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:37:43.235
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Jan 24 18:37:43.265: INFO: Creating deployment "webserver-deployment"
    Jan 24 18:37:43.306: INFO: Waiting for observed generation 1
    Jan 24 18:37:45.866: INFO: Waiting for all required pods to come up
    Jan 24 18:37:46.497: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 01/24/23 18:37:46.729
    Jan 24 18:37:46.730: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-wxcvj" in namespace "deployment-5477" to be "running"
    Jan 24 18:37:46.731: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2bkh4" in namespace "deployment-5477" to be "running"
    Jan 24 18:37:46.731: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-57666" in namespace "deployment-5477" to be "running"
    Jan 24 18:37:46.732: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-8j9k9" in namespace "deployment-5477" to be "running"
    Jan 24 18:37:46.732: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-gfpgm" in namespace "deployment-5477" to be "running"
    Jan 24 18:37:46.733: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-h8jmq" in namespace "deployment-5477" to be "running"
    Jan 24 18:37:46.733: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-hgnnz" in namespace "deployment-5477" to be "running"
    Jan 24 18:37:46.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-j9nwd" in namespace "deployment-5477" to be "running"
    Jan 24 18:37:46.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-nwmz7" in namespace "deployment-5477" to be "running"
    Jan 24 18:37:46.735: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vz2jn" in namespace "deployment-5477" to be "running"
    Jan 24 18:37:46.992: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 261.374869ms
    Jan 24 18:37:46.992: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 259.070743ms
    Jan 24 18:37:46.992: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 258.907778ms
    Jan 24 18:37:46.993: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 260.611946ms
    Jan 24 18:37:46.993: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 258.950931ms
    Jan 24 18:37:46.993: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 260.609834ms
    Jan 24 18:37:46.993: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 262.099908ms
    Jan 24 18:37:47.008: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 274.05301ms
    Jan 24 18:37:47.009: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 277.510046ms
    Jan 24 18:37:47.009: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 274.303486ms
    Jan 24 18:37:49.052: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.318376212s
    Jan 24 18:37:49.111: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.380376091s
    Jan 24 18:37:49.125: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.394426208s
    Jan 24 18:37:49.155: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.422470736s
    Jan 24 18:37:49.162: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.426704659s
    Jan 24 18:37:49.162: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 2.430687536s
    Jan 24 18:37:49.163: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.429811989s
    Jan 24 18:37:49.163: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.431098762s
    Jan 24 18:37:49.472: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.738070833s
    Jan 24 18:37:49.474: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.73988962s
    Jan 24 18:37:51.125: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.392898329s
    Jan 24 18:37:51.128: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.397660563s
    Jan 24 18:37:51.128: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.397042636s
    Jan 24 18:37:51.133: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.401111816s
    Jan 24 18:37:51.134: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 4.402378821s
    Jan 24 18:37:51.128: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.393989749s
    Jan 24 18:37:51.135: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.402145693s
    Jan 24 18:37:51.136: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.402768523s
    Jan 24 18:37:51.121: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.387596208s
    Jan 24 18:37:51.249: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.513769905s
    Jan 24 18:37:53.002: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 6.269069405s
    Jan 24 18:37:53.007: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 6.275051059s
    Jan 24 18:37:53.008: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.277534949s
    Jan 24 18:37:53.009: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.277610437s
    Jan 24 18:37:53.012: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.278468257s
    Jan 24 18:37:53.017: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.285058703s
    Jan 24 18:37:53.021: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.286239881s
    Jan 24 18:37:53.021: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.288046277s
    Jan 24 18:37:53.021: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 6.289509845s
    Jan 24 18:37:53.021: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.286178213s
    Jan 24 18:37:55.001: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.270057415s
    Jan 24 18:37:55.001: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.270981964s
    Jan 24 18:37:55.001: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 8.268986663s
    Jan 24 18:37:55.001: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.268270999s
    Jan 24 18:37:55.016: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.282677827s
    Jan 24 18:37:55.022: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.287833176s
    Jan 24 18:37:55.026: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 8.294929311s
    Jan 24 18:37:55.027: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.292542104s
    Jan 24 18:37:55.029: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 8.295656232s
    Jan 24 18:37:55.029: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.296942907s
    Jan 24 18:37:57.015: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 10.281539345s
    Jan 24 18:37:57.018: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.28412505s
    Jan 24 18:37:57.018: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.286961689s
    Jan 24 18:37:57.026: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 10.293523603s
    Jan 24 18:37:57.028: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.293496062s
    Jan 24 18:37:57.028: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.293021785s
    Jan 24 18:37:57.028: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 10.297828323s
    Jan 24 18:37:57.031: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.298619091s
    Jan 24 18:37:57.032: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 10.300150249s
    Jan 24 18:37:57.057: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 10.324248028s
    Jan 24 18:37:59.043: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 12.309328424s
    Jan 24 18:37:59.043: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Pending", Reason="", readiness=false. Elapsed: 12.30824954s
    Jan 24 18:37:59.044: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.312672928s
    Jan 24 18:37:59.044: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 12.311906965s
    Jan 24 18:37:59.045: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 12.313380814s
    Jan 24 18:37:59.045: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.310699826s
    Jan 24 18:37:59.045: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.31167177s
    Jan 24 18:37:59.050: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 12.319245311s
    Jan 24 18:37:59.050: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 12.316908855s
    Jan 24 18:37:59.053: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.321195553s
    Jan 24 18:38:01.005: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 14.274752196s
    Jan 24 18:38:01.005: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.271671004s
    Jan 24 18:38:01.006: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.273640386s
    Jan 24 18:38:01.006: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Pending", Reason="", readiness=false. Elapsed: 14.27249327s
    Jan 24 18:38:01.006: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 14.273439065s
    Jan 24 18:38:01.006: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.274893499s
    Jan 24 18:38:01.006: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 14.273256704s
    Jan 24 18:38:01.016: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.281165305s
    Jan 24 18:38:01.016: INFO: Pod "webserver-deployment-845c8977d9-vz2jn": Phase="Running", Reason="", readiness=true. Elapsed: 14.280703223s
    Jan 24 18:38:01.016: INFO: Pod "webserver-deployment-845c8977d9-vz2jn" satisfied condition "running"
    Jan 24 18:38:01.020: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Pending", Reason="", readiness=false. Elapsed: 14.288570725s
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-j9nwd": Phase="Running", Reason="", readiness=true. Elapsed: 16.292009578s
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-j9nwd" satisfied condition "running"
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 16.295752826s
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 16.293685047s
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.291849365s
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-8j9k9": Phase="Running", Reason="", readiness=true. Elapsed: 16.294321687s
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-8j9k9" satisfied condition "running"
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-57666": Phase="Running", Reason="", readiness=true. Elapsed: 16.294904458s
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 16.293604471s
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-57666" satisfied condition "running"
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-hgnnz": Phase="Running", Reason="", readiness=true. Elapsed: 16.292567948s
    Jan 24 18:38:03.026: INFO: Pod "webserver-deployment-845c8977d9-hgnnz" satisfied condition "running"
    Jan 24 18:38:03.027: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.29546424s
    Jan 24 18:38:05.006: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Pending", Reason="", readiness=false. Elapsed: 18.2760442s
    Jan 24 18:38:05.007: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.275891842s
    Jan 24 18:38:05.040: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Pending", Reason="", readiness=false. Elapsed: 18.306893324s
    Jan 24 18:38:05.045: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Pending", Reason="", readiness=false. Elapsed: 18.312298433s
    Jan 24 18:38:05.088: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.353948693s
    Jan 24 18:38:07.007: INFO: Pod "webserver-deployment-845c8977d9-wxcvj": Phase="Running", Reason="", readiness=true. Elapsed: 20.276276025s
    Jan 24 18:38:07.007: INFO: Pod "webserver-deployment-845c8977d9-wxcvj" satisfied condition "running"
    Jan 24 18:38:07.008: INFO: Pod "webserver-deployment-845c8977d9-2bkh4": Phase="Running", Reason="", readiness=true. Elapsed: 20.276546521s
    Jan 24 18:38:07.008: INFO: Pod "webserver-deployment-845c8977d9-2bkh4" satisfied condition "running"
    Jan 24 18:38:07.008: INFO: Pod "webserver-deployment-845c8977d9-gfpgm": Phase="Running", Reason="", readiness=true. Elapsed: 20.275992805s
    Jan 24 18:38:07.010: INFO: Pod "webserver-deployment-845c8977d9-gfpgm" satisfied condition "running"
    Jan 24 18:38:07.009: INFO: Pod "webserver-deployment-845c8977d9-h8jmq": Phase="Running", Reason="", readiness=true. Elapsed: 20.27633415s
    Jan 24 18:38:07.011: INFO: Pod "webserver-deployment-845c8977d9-h8jmq" satisfied condition "running"
    Jan 24 18:38:07.020: INFO: Pod "webserver-deployment-845c8977d9-nwmz7": Phase="Running", Reason="", readiness=true. Elapsed: 20.285737602s
    Jan 24 18:38:07.020: INFO: Pod "webserver-deployment-845c8977d9-nwmz7" satisfied condition "running"
    Jan 24 18:38:07.020: INFO: Waiting for deployment "webserver-deployment" to complete
    Jan 24 18:38:07.036: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Jan 24 18:38:07.061: INFO: Updating deployment webserver-deployment
    Jan 24 18:38:07.062: INFO: Waiting for observed generation 2
    Jan 24 18:38:09.169: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Jan 24 18:38:09.178: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Jan 24 18:38:09.204: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Jan 24 18:38:09.295: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Jan 24 18:38:09.295: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Jan 24 18:38:09.369: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Jan 24 18:38:09.468: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Jan 24 18:38:09.468: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Jan 24 18:38:09.572: INFO: Updating deployment webserver-deployment
    Jan 24 18:38:09.572: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Jan 24 18:38:09.709: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Jan 24 18:38:11.815: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 24 18:38:12.579: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-5477  b015c5e0-acc8-4288-8ab9-058ee065b3df 14747 3 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 18:38:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002eb8758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-01-24 18:38:09 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-01-24 18:38:10 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Jan 24 18:38:12.948: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-5477  ba6237a9-7d34-4e34-987e-17026b46be87 14735 3 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment b015c5e0-acc8-4288-8ab9-058ee065b3df 0xc002eb8b67 0xc002eb8b68}] [] [{kube-controller-manager Update apps/v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b015c5e0-acc8-4288-8ab9-058ee065b3df\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002eb8c08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 18:38:12.948: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Jan 24 18:38:12.948: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-5477  d0948274-445b-40e6-8259-221cddcb5a6c 14742 3 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment b015c5e0-acc8-4288-8ab9-058ee065b3df 0xc002eb8c67 0xc002eb8c68}] [] [{kube-controller-manager Update apps/v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b015c5e0-acc8-4288-8ab9-058ee065b3df\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002eb8cf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 18:38:13.520: INFO: Pod "webserver-deployment-69b7448995-2kqb9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-2kqb9 webserver-deployment-69b7448995- deployment-5477  7f19aa5b-7ae8-406a-80ca-ee20ca1bee74 14647 0 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:0d8a9aa1d6f4a6bbcef8428708da63f8e287d8b015afcc8c336cdd610ec8b5ad cni.projectcalico.org/podIP:10.244.71.219/32 cni.projectcalico.org/podIPs:10.244.71.219/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273d387 0xc00273d388}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-24 18:38:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-642fz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-642fz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:13.550: INFO: Pod "webserver-deployment-69b7448995-dt4tw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-dt4tw webserver-deployment-69b7448995- deployment-5477  8447fe49-128a-47e7-b8ef-acfb9b8f2f97 14749 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273d580 0xc00273d581}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-crq5b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-crq5b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:13.554: INFO: Pod "webserver-deployment-69b7448995-gsz2p" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-gsz2p webserver-deployment-69b7448995- deployment-5477  82ae6a37-c0be-4cd3-8c4b-dca2449f0d23 14642 0 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:4fde42251e82f3317b5738158c8d560ee777fc64a9f8f266c131955398ed23fc cni.projectcalico.org/podIP:10.244.71.218/32 cni.projectcalico.org/podIPs:10.244.71.218/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273d780 0xc00273d781}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-24 18:38:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-224h5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-224h5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:13.930: INFO: Pod "webserver-deployment-69b7448995-h6t6q" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-h6t6q webserver-deployment-69b7448995- deployment-5477  74a0d618-307c-48ab-a667-15f60b29fcf6 14704 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273d970 0xc00273d971}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-k4xj4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-k4xj4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:14.339: INFO: Pod "webserver-deployment-69b7448995-lt269" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lt269 webserver-deployment-69b7448995- deployment-5477  5d59871e-392d-4f9c-ab21-0f4460cd11a1 14771 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273db40 0xc00273db41}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hs59j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hs59j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:15.111: INFO: Pod "webserver-deployment-69b7448995-pfgnr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-pfgnr webserver-deployment-69b7448995- deployment-5477  897b6ba3-3e71-4117-8a11-760c791ae188 14729 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273dd10 0xc00273dd11}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pf77w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pf77w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:15.113: INFO: Pod "webserver-deployment-69b7448995-pzz7q" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-pzz7q webserver-deployment-69b7448995- deployment-5477  eccda26c-4d14-4c73-89b5-58310d3505af 14657 0 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:8bbe20d5848d61cf650b2d0951b1f2403c1b0f75cae5958803542fd6d511a67a cni.projectcalico.org/podIP:10.244.71.220/32 cni.projectcalico.org/podIPs:10.244.71.220/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc00273df00 0xc00273df01}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kxjdj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kxjdj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:15.115: INFO: Pod "webserver-deployment-69b7448995-sxhck" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-sxhck webserver-deployment-69b7448995- deployment-5477  3ca01be3-e05e-4b81-8e7b-4fceef448928 14769 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb80f0 0xc002fb80f1}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-52tsn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-52tsn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:15.116: INFO: Pod "webserver-deployment-69b7448995-wbbxx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-wbbxx webserver-deployment-69b7448995- deployment-5477  dd828298-85e8-485e-9feb-af9d329f4043 14727 0 2023-01-24 18:38:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb82c0 0xc002fb82c1}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hwcrl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hwcrl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:15.117: INFO: Pod "webserver-deployment-69b7448995-x9gjw" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-x9gjw webserver-deployment-69b7448995- deployment-5477  4a0313fb-1d7f-4929-b51c-56d5b1dd4cb2 14773 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb8420 0xc002fb8421}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xj4jm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xj4jm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:15.120: INFO: Pod "webserver-deployment-69b7448995-z7m4f" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-z7m4f webserver-deployment-69b7448995- deployment-5477  705cda7c-8048-4782-8d2f-837cab19cd8f 14779 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb8600 0xc002fb8601}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbhx8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbhx8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:15.126: INFO: Pod "webserver-deployment-69b7448995-zb84d" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-zb84d webserver-deployment-69b7448995- deployment-5477  85241ff2-4071-4601-8dfd-2eab8b76b86a 14648 0 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:3993d4786488c77e86be3001676f323103ea1b1d33cd6e48e96a407afab569dc cni.projectcalico.org/podIP:10.244.47.87/32 cni.projectcalico.org/podIPs:10.244.47.87/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb87f0 0xc002fb87f1}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-24 18:38:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6z7p7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6z7p7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:15.151: INFO: Pod "webserver-deployment-69b7448995-zzsvv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-zzsvv webserver-deployment-69b7448995- deployment-5477  bd6b0d91-fd1e-4a94-a1d0-02b4a4858eec 14660 0 2023-01-24 18:38:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:f943e8fa62d6eb1bf31efeae7364cc297a055edb3a4726438e71d64d12307172 cni.projectcalico.org/podIP:10.244.47.88/32 cni.projectcalico.org/podIPs:10.244.47.88/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 ba6237a9-7d34-4e34-987e-17026b46be87 0xc002fb8a10 0xc002fb8a11}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ba6237a9-7d34-4e34-987e-17026b46be87\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f4tr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f4tr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.252: INFO: Pod "webserver-deployment-845c8977d9-2bkh4" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2bkh4 webserver-deployment-845c8977d9- deployment-5477  7dc5735f-e09a-4e5f-9510-c8173f9b8867 14583 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:7e4e9408f66ad90c75b79d68044091a796c251b9db80f5b6f8fd8427a656b1ce cni.projectcalico.org/podIP:10.244.47.86/32 cni.projectcalico.org/podIPs:10.244.47.86/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb8c30 0xc002fb8c31}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.86\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zm5bd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zm5bd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.86,StartTime:2023-01-24 18:37:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://13dae19afb555f131d468147556fe347a4852e2b8c2be2fd4923c6ac9673506f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.86,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.253: INFO: Pod "webserver-deployment-845c8977d9-57666" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-57666 webserver-deployment-845c8977d9- deployment-5477  b8eb6aaf-ffd3-4076-b4b4-a086f1d43abe 14551 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:8ed5039b907c738270b27813d433cee345dba1d090c0e5f0b235feeed762c43b cni.projectcalico.org/podIP:10.244.71.216/32 cni.projectcalico.org/podIPs:10.244.71.216/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb8e47 0xc002fb8e48}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.216\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z24qw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z24qw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.216,StartTime:2023-01-24 18:37:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3b0f49c6914f03bb5fce67b6bdcce726faf76f901e6c5db272e09144b5cba82d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.216,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.323: INFO: Pod "webserver-deployment-845c8977d9-8j9k9" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8j9k9 webserver-deployment-845c8977d9- deployment-5477  ab4859e9-2d25-42c9-9ceb-18056535e29f 14547 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:82d2c3869ca30127593720fe755371fc5eca5e16fa17418d1b399ddd6ca3c68f cni.projectcalico.org/podIP:10.244.71.215/32 cni.projectcalico.org/podIPs:10.244.71.215/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9067 0xc002fb9068}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.215\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8xw2m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8xw2m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.215,StartTime:2023-01-24 18:37:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://30a69af5e4f8c0b10f466a9fae2b80c22aaa5378229dc9fbdeb97592c02b5443,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.215,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.330: INFO: Pod "webserver-deployment-845c8977d9-9sh6s" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9sh6s webserver-deployment-845c8977d9- deployment-5477  c07efed9-8d3e-45f1-abdc-4f8c3bdb3e37 14701 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9267 0xc002fb9268}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tvf4z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tvf4z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.331: INFO: Pod "webserver-deployment-845c8977d9-bc6xb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bc6xb webserver-deployment-845c8977d9- deployment-5477  c99d5dc4-edfb-4125-936a-72b1b1bd667c 14760 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9427 0xc002fb9428}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7l45r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7l45r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.332: INFO: Pod "webserver-deployment-845c8977d9-bkglx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bkglx webserver-deployment-845c8977d9- deployment-5477  775a9704-ee66-422b-8cc4-062765320131 14681 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb95e7 0xc002fb95e8}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6k62s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6k62s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.332: INFO: Pod "webserver-deployment-845c8977d9-dvnx7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-dvnx7 webserver-deployment-845c8977d9- deployment-5477  f2e3dd52-ca34-4cf7-bdb5-546eaeed9233 14764 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb97a7 0xc002fb97a8}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fm6cg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fm6cg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.333: INFO: Pod "webserver-deployment-845c8977d9-gfpgm" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gfpgm webserver-deployment-845c8977d9- deployment-5477  bbdbe739-7034-451b-bf9e-79aed49a8659 14575 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:39f9af4d4afbe43962d8a44525309b4c50734a2a6298f5627c8973fb3f0021c6 cni.projectcalico.org/podIP:10.244.47.83/32 cni.projectcalico.org/podIPs:10.244.47.83/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9987 0xc002fb9988}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.83\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dfqmx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dfqmx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.83,StartTime:2023-01-24 18:37:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1e1257d775bdec57a17e7c009458d71af751731a86f6c05e1922769ba9e541e9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.83,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.333: INFO: Pod "webserver-deployment-845c8977d9-h8jmq" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-h8jmq webserver-deployment-845c8977d9- deployment-5477  c9742a20-5fa3-4504-a693-4e7462d416bb 14570 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:be2a121682475eadf8ec094ada00fed26653fd0f931d08c10eeb379b23a6b130 cni.projectcalico.org/podIP:10.244.47.85/32 cni.projectcalico.org/podIPs:10.244.47.85/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9ba7 0xc002fb9ba8}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.85\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n42jm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n42jm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.85,StartTime:2023-01-24 18:37:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://7492485e22f43a2ea71cab5468950048468ca713fd60812793a1d108db206e24,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.85,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.334: INFO: Pod "webserver-deployment-845c8977d9-hgnnz" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-hgnnz webserver-deployment-845c8977d9- deployment-5477  c4ae9ee3-95bf-4f6a-88db-0cf1dbb080a3 14554 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:effbd703f701c4c11b278d441e4440007b6a501738178a84e8ea1d3b6ff8d6d0 cni.projectcalico.org/podIP:10.244.71.217/32 cni.projectcalico.org/podIPs:10.244.71.217/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9dc7 0xc002fb9dc8}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.217\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hf4jl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hf4jl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.217,StartTime:2023-01-24 18:37:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://74581976e58dcd066295994bfc7ddf60dd8bfed4acf16af3d765352c3c619ca3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.217,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.334: INFO: Pod "webserver-deployment-845c8977d9-hs5pc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-hs5pc webserver-deployment-845c8977d9- deployment-5477  500204cd-d013-4cab-8b41-0bee07d81810 14778 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002fb9fc7 0xc002fb9fc8}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2gzss,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2gzss,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.466: INFO: Pod "webserver-deployment-845c8977d9-j8c55" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-j8c55 webserver-deployment-845c8977d9- deployment-5477  ebf6d29d-85c5-418a-a843-73ed466f4290 14722 0 2023-01-24 18:38:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002210197 0xc002210198}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rvbfg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rvbfg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.472: INFO: Pod "webserver-deployment-845c8977d9-nwmz7" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-nwmz7 webserver-deployment-845c8977d9- deployment-5477  51192b51-7e80-468f-9210-0ad3ff38fbe4 14573 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:bb90c600be4992d48532797db48d04cb4ea75662876638aa443fa9067178c6b7 cni.projectcalico.org/podIP:10.244.47.82/32 cni.projectcalico.org/podIPs:10.244.47.82/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002210320 0xc002210321}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:05 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.82\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4f646,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4f646,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.82,StartTime:2023-01-24 18:37:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://654e92c2873d23b65918d29ea5093db20f4fd0bd7ac30c312ce9ebbb78d1fe91,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.478: INFO: Pod "webserver-deployment-845c8977d9-q7q7z" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-q7q7z webserver-deployment-845c8977d9- deployment-5477  d2edd869-53e3-478d-b6e1-b513ea44d724 14716 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002210517 0xc002210518}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x5fdk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x5fdk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.478: INFO: Pod "webserver-deployment-845c8977d9-vmbh5" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vmbh5 webserver-deployment-845c8977d9- deployment-5477  ab73642a-ef63-4f8c-b55e-b5e137df1f3a 14728 0 2023-01-24 18:38:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002210670 0xc002210671}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wml4f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wml4f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.479: INFO: Pod "webserver-deployment-845c8977d9-w2bll" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-w2bll webserver-deployment-845c8977d9- deployment-5477  4e67b711-0959-44eb-97c0-78d0112fcf0c 14725 0 2023-01-24 18:38:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc0022107c0 0xc0022107c1}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pr89v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pr89v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.480: INFO: Pod "webserver-deployment-845c8977d9-wc76n" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wc76n webserver-deployment-845c8977d9- deployment-5477  453dacb1-3b44-486d-a2dc-8fca1952b94b 14733 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002210910 0xc002210911}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-czqdt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-czqdt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.480: INFO: Pod "webserver-deployment-845c8977d9-wmb7r" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wmb7r webserver-deployment-845c8977d9- deployment-5477  7e0a691b-7c9f-455a-a473-762fb9e3c4fe 14759 0 2023-01-24 18:38:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002b8e017 0xc002b8e018}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f9bbs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f9bbs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.482: INFO: Pod "webserver-deployment-845c8977d9-wxcvj" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wxcvj webserver-deployment-845c8977d9- deployment-5477  5985d2ee-dd23-4068-8b53-0f88712e6908 14586 0 2023-01-24 18:37:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:980b2706491306c463b7af811e4b4b9989bf372c3be04ba7f1164a7ad8237d07 cni.projectcalico.org/podIP:10.244.47.84/32 cni.projectcalico.org/podIPs:10.244.47.84/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002b8e1f7 0xc002b8e1f8}] [] [{kube-controller-manager Update v1 2023-01-24 18:37:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:37:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:38:06 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.84\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gjrh4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gjrh4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:37:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.84,StartTime:2023-01-24 18:37:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:38:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://263bbe7e8bd24b291cca8c5ab19129fbdaeaf6a44772677382199d4d093eb050,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.84,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:38:16.483: INFO: Pod "webserver-deployment-845c8977d9-x66sb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-x66sb webserver-deployment-845c8977d9- deployment-5477  a251ddbd-a3e0-48ef-aafa-10d11cfb3b51 14783 0 2023-01-24 18:38:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 d0948274-445b-40e6-8259-221cddcb5a6c 0xc002b8e3f7 0xc002b8e3f8}] [] [{kube-controller-manager Update v1 2023-01-24 18:38:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d0948274-445b-40e6-8259-221cddcb5a6c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:38:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wx2dn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wx2dn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:38:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:38:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 24 18:38:16.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5477" for this suite. 01/24/23 18:38:17.553
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:38:17.965
Jan 24 18:38:17.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 18:38:17.982
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:38:18.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:38:18.236
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 01/24/23 18:38:18.262
Jan 24 18:38:18.390: INFO: Waiting up to 5m0s for pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e" in namespace "emptydir-3853" to be "Succeeded or Failed"
Jan 24 18:38:18.415: INFO: Pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.451116ms
Jan 24 18:38:20.470: INFO: Pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079403669s
Jan 24 18:38:22.697: INFO: Pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.307176587s
Jan 24 18:38:26.227: INFO: Pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.836638002s
STEP: Saw pod success 01/24/23 18:38:26.227
Jan 24 18:38:26.227: INFO: Pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e" satisfied condition "Succeeded or Failed"
Jan 24 18:38:26.362: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e container test-container: <nil>
STEP: delete the pod 01/24/23 18:38:26.979
Jan 24 18:38:27.039: INFO: Waiting for pod pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e to disappear
Jan 24 18:38:27.084: INFO: Pod pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 18:38:27.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3853" for this suite. 01/24/23 18:38:27.14
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":9,"skipped":200,"failed":0}
------------------------------
• [SLOW TEST] [9.635 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:38:17.965
    Jan 24 18:38:17.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 18:38:17.982
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:38:18.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:38:18.236
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 01/24/23 18:38:18.262
    Jan 24 18:38:18.390: INFO: Waiting up to 5m0s for pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e" in namespace "emptydir-3853" to be "Succeeded or Failed"
    Jan 24 18:38:18.415: INFO: Pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.451116ms
    Jan 24 18:38:20.470: INFO: Pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079403669s
    Jan 24 18:38:22.697: INFO: Pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.307176587s
    Jan 24 18:38:26.227: INFO: Pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.836638002s
    STEP: Saw pod success 01/24/23 18:38:26.227
    Jan 24 18:38:26.227: INFO: Pod "pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e" satisfied condition "Succeeded or Failed"
    Jan 24 18:38:26.362: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e container test-container: <nil>
    STEP: delete the pod 01/24/23 18:38:26.979
    Jan 24 18:38:27.039: INFO: Waiting for pod pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e to disappear
    Jan 24 18:38:27.084: INFO: Pod pod-c34eb331-ab42-4fbe-8493-d35f5ff3067e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 18:38:27.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3853" for this suite. 01/24/23 18:38:27.14
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:38:27.652
Jan 24 18:38:27.652: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename disruption 01/24/23 18:38:27.656
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:38:28.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:38:28.728
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 01/24/23 18:38:28.794
STEP: Updating PodDisruptionBudget status 01/24/23 18:38:28.818
STEP: Waiting for all pods to be running 01/24/23 18:38:28.951
Jan 24 18:38:29.131: INFO: running pods: 0 < 1
Jan 24 18:38:31.251: INFO: running pods: 0 < 1
Jan 24 18:38:33.165: INFO: running pods: 0 < 1
STEP: locating a running pod 01/24/23 18:38:35.23
STEP: Waiting for the pdb to be processed 01/24/23 18:38:35.685
STEP: Patching PodDisruptionBudget status 01/24/23 18:38:36.817
STEP: Waiting for the pdb to be processed 01/24/23 18:38:36.927
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jan 24 18:38:36.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4052" for this suite. 01/24/23 18:38:37.215
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":10,"skipped":211,"failed":0}
------------------------------
• [SLOW TEST] [9.992 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:38:27.652
    Jan 24 18:38:27.652: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename disruption 01/24/23 18:38:27.656
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:38:28.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:38:28.728
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 01/24/23 18:38:28.794
    STEP: Updating PodDisruptionBudget status 01/24/23 18:38:28.818
    STEP: Waiting for all pods to be running 01/24/23 18:38:28.951
    Jan 24 18:38:29.131: INFO: running pods: 0 < 1
    Jan 24 18:38:31.251: INFO: running pods: 0 < 1
    Jan 24 18:38:33.165: INFO: running pods: 0 < 1
    STEP: locating a running pod 01/24/23 18:38:35.23
    STEP: Waiting for the pdb to be processed 01/24/23 18:38:35.685
    STEP: Patching PodDisruptionBudget status 01/24/23 18:38:36.817
    STEP: Waiting for the pdb to be processed 01/24/23 18:38:36.927
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jan 24 18:38:36.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4052" for this suite. 01/24/23 18:38:37.215
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:38:37.64
Jan 24 18:38:37.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename runtimeclass 01/24/23 18:38:37.657
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:38:37.804
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:38:37.814
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Jan 24 18:38:37.908: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-2389 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jan 24 18:38:37.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2389" for this suite. 01/24/23 18:38:38.047
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":11,"skipped":219,"failed":0}
------------------------------
• [0.434 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:38:37.64
    Jan 24 18:38:37.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename runtimeclass 01/24/23 18:38:37.657
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:38:37.804
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:38:37.814
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Jan 24 18:38:37.908: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-2389 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jan 24 18:38:37.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-2389" for this suite. 01/24/23 18:38:38.047
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:38:38.082
Jan 24 18:38:38.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename dns 01/24/23 18:38:38.088
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:38:38.165
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:38:38.218
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 01/24/23 18:38:38.547
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4829.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4829.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 16.227.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.227.16_udp@PTR;check="$$(dig +tcp +noall +answer +search 16.227.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.227.16_tcp@PTR;sleep 1; done
 01/24/23 18:38:38.86
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4829.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4829.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 16.227.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.227.16_udp@PTR;check="$$(dig +tcp +noall +answer +search 16.227.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.227.16_tcp@PTR;sleep 1; done
 01/24/23 18:38:38.861
STEP: creating a pod to probe DNS 01/24/23 18:38:38.886
STEP: submitting the pod to kubernetes 01/24/23 18:38:38.887
Jan 24 18:38:38.955: INFO: Waiting up to 15m0s for pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5" in namespace "dns-4829" to be "running"
Jan 24 18:38:38.978: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.804716ms
Jan 24 18:38:41.041: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086573562s
Jan 24 18:38:43.018: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062813517s
Jan 24 18:38:45.150: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.194819212s
Jan 24 18:38:47.006: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05159779s
Jan 24 18:38:48.993: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038023068s
Jan 24 18:38:51.015: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.0604623s
Jan 24 18:38:52.990: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.03488902s
Jan 24 18:38:54.996: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.041500527s
Jan 24 18:38:56.991: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.035916646s
Jan 24 18:38:59.004: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.049345233s
Jan 24 18:39:01.023: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.067750331s
Jan 24 18:39:03.007: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.052424328s
Jan 24 18:39:04.997: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.042568709s
Jan 24 18:39:06.993: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.038484992s
Jan 24 18:39:09.019: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.064093421s
Jan 24 18:39:10.993: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.038133953s
Jan 24 18:39:12.990: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.035226378s
Jan 24 18:39:15.128: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.172658546s
Jan 24 18:39:16.991: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Running", Reason="", readiness=true. Elapsed: 38.036492132s
Jan 24 18:39:16.992: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5" satisfied condition "running"
STEP: retrieving the pod 01/24/23 18:39:16.992
STEP: looking for the results for each expected name from probers 01/24/23 18:39:17.024
Jan 24 18:39:17.048: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:17.062: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:17.076: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:17.098: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:17.157: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:17.168: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:17.186: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:17.203: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:17.309: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

Jan 24 18:39:22.347: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:22.374: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:22.419: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:22.635: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:22.721: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:22.747: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:22.783: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:22.814: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:22.860: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

Jan 24 18:39:27.331: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:27.342: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:27.367: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:27.391: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:27.445: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:27.469: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:27.488: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:27.501: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:27.566: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

Jan 24 18:39:32.381: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:32.428: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:32.552: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:32.689: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:32.949: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:32.982: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:33.009: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:33.039: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:33.215: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

Jan 24 18:39:37.326: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:37.339: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:37.350: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:37.366: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:37.428: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:37.441: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:37.456: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:37.477: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:37.530: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

Jan 24 18:39:42.336: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:42.375: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:42.392: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:42.405: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:42.469: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:42.486: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:42.508: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:42.576: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
Jan 24 18:39:42.740: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

Jan 24 18:39:47.547: INFO: DNS probes using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 succeeded

STEP: deleting the pod 01/24/23 18:39:47.547
STEP: deleting the test service 01/24/23 18:39:47.584
STEP: deleting the test headless service 01/24/23 18:39:47.659
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 24 18:39:47.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4829" for this suite. 01/24/23 18:39:47.889
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":12,"skipped":243,"failed":0}
------------------------------
• [SLOW TEST] [69.850 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:38:38.082
    Jan 24 18:38:38.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename dns 01/24/23 18:38:38.088
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:38:38.165
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:38:38.218
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 01/24/23 18:38:38.547
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4829.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4829.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 16.227.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.227.16_udp@PTR;check="$$(dig +tcp +noall +answer +search 16.227.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.227.16_tcp@PTR;sleep 1; done
     01/24/23 18:38:38.86
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4829.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4829.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4829.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4829.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4829.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 16.227.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.227.16_udp@PTR;check="$$(dig +tcp +noall +answer +search 16.227.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.227.16_tcp@PTR;sleep 1; done
     01/24/23 18:38:38.861
    STEP: creating a pod to probe DNS 01/24/23 18:38:38.886
    STEP: submitting the pod to kubernetes 01/24/23 18:38:38.887
    Jan 24 18:38:38.955: INFO: Waiting up to 15m0s for pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5" in namespace "dns-4829" to be "running"
    Jan 24 18:38:38.978: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.804716ms
    Jan 24 18:38:41.041: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086573562s
    Jan 24 18:38:43.018: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062813517s
    Jan 24 18:38:45.150: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.194819212s
    Jan 24 18:38:47.006: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05159779s
    Jan 24 18:38:48.993: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038023068s
    Jan 24 18:38:51.015: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.0604623s
    Jan 24 18:38:52.990: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.03488902s
    Jan 24 18:38:54.996: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.041500527s
    Jan 24 18:38:56.991: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.035916646s
    Jan 24 18:38:59.004: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.049345233s
    Jan 24 18:39:01.023: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.067750331s
    Jan 24 18:39:03.007: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.052424328s
    Jan 24 18:39:04.997: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.042568709s
    Jan 24 18:39:06.993: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.038484992s
    Jan 24 18:39:09.019: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.064093421s
    Jan 24 18:39:10.993: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.038133953s
    Jan 24 18:39:12.990: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.035226378s
    Jan 24 18:39:15.128: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.172658546s
    Jan 24 18:39:16.991: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5": Phase="Running", Reason="", readiness=true. Elapsed: 38.036492132s
    Jan 24 18:39:16.992: INFO: Pod "dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5" satisfied condition "running"
    STEP: retrieving the pod 01/24/23 18:39:16.992
    STEP: looking for the results for each expected name from probers 01/24/23 18:39:17.024
    Jan 24 18:39:17.048: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:17.062: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:17.076: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:17.098: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:17.157: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:17.168: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:17.186: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:17.203: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:17.309: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

    Jan 24 18:39:22.347: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:22.374: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:22.419: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:22.635: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:22.721: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:22.747: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:22.783: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:22.814: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:22.860: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

    Jan 24 18:39:27.331: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:27.342: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:27.367: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:27.391: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:27.445: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:27.469: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:27.488: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:27.501: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:27.566: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

    Jan 24 18:39:32.381: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:32.428: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:32.552: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:32.689: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:32.949: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:32.982: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:33.009: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:33.039: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:33.215: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

    Jan 24 18:39:37.326: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:37.339: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:37.350: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:37.366: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:37.428: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:37.441: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:37.456: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:37.477: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:37.530: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

    Jan 24 18:39:42.336: INFO: Unable to read wheezy_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:42.375: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:42.392: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:42.405: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:42.469: INFO: Unable to read jessie_udp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:42.486: INFO: Unable to read jessie_tcp@dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:42.508: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:42.576: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local from pod dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5: the server could not find the requested resource (get pods dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5)
    Jan 24 18:39:42.740: INFO: Lookups using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 failed for: [wheezy_udp@dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@dns-test-service.dns-4829.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_udp@dns-test-service.dns-4829.svc.cluster.local jessie_tcp@dns-test-service.dns-4829.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4829.svc.cluster.local]

    Jan 24 18:39:47.547: INFO: DNS probes using dns-4829/dns-test-7460946d-7f04-478f-8f7f-5dff0f6cd1d5 succeeded

    STEP: deleting the pod 01/24/23 18:39:47.547
    STEP: deleting the test service 01/24/23 18:39:47.584
    STEP: deleting the test headless service 01/24/23 18:39:47.659
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 24 18:39:47.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4829" for this suite. 01/24/23 18:39:47.889
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:39:47.934
Jan 24 18:39:47.935: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename endpointslice 01/24/23 18:39:47.938
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:39:48
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:39:48.018
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Jan 24 18:39:48.084: INFO: Endpoints addresses: [10.10.1.213] , ports: [6443]
Jan 24 18:39:48.085: INFO: EndpointSlices addresses: [10.10.1.213] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jan 24 18:39:48.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9519" for this suite. 01/24/23 18:39:48.103
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":13,"skipped":249,"failed":0}
------------------------------
• [0.193 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:39:47.934
    Jan 24 18:39:47.935: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename endpointslice 01/24/23 18:39:47.938
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:39:48
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:39:48.018
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Jan 24 18:39:48.084: INFO: Endpoints addresses: [10.10.1.213] , ports: [6443]
    Jan 24 18:39:48.085: INFO: EndpointSlices addresses: [10.10.1.213] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jan 24 18:39:48.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-9519" for this suite. 01/24/23 18:39:48.103
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:39:48.15
Jan 24 18:39:48.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 18:39:48.177
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:39:48.267
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:39:48.287
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 01/24/23 18:39:48.322
Jan 24 18:39:48.345: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 18:39:56.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:40:27.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-148" for this suite. 01/24/23 18:40:27.825
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":14,"skipped":279,"failed":0}
------------------------------
• [SLOW TEST] [39.697 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:39:48.15
    Jan 24 18:39:48.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 18:39:48.177
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:39:48.267
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:39:48.287
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 01/24/23 18:39:48.322
    Jan 24 18:39:48.345: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 18:39:56.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:40:27.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-148" for this suite. 01/24/23 18:40:27.825
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:40:27.878
Jan 24 18:40:27.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename statefulset 01/24/23 18:40:27.894
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:40:27.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:40:27.988
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9834 01/24/23 18:40:27.997
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-9834 01/24/23 18:40:28.036
Jan 24 18:40:28.062: INFO: Found 0 stateful pods, waiting for 1
Jan 24 18:40:38.073: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 01/24/23 18:40:38.085
STEP: updating a scale subresource 01/24/23 18:40:38.095
STEP: verifying the statefulset Spec.Replicas was modified 01/24/23 18:40:38.113
STEP: Patch a scale subresource 01/24/23 18:40:38.157
STEP: verifying the statefulset Spec.Replicas was modified 01/24/23 18:40:38.32
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 24 18:40:38.337: INFO: Deleting all statefulset in ns statefulset-9834
Jan 24 18:40:38.344: INFO: Scaling statefulset ss to 0
Jan 24 18:40:48.388: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 18:40:48.406: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 24 18:40:48.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9834" for this suite. 01/24/23 18:40:48.568
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":15,"skipped":312,"failed":0}
------------------------------
• [SLOW TEST] [20.707 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:40:27.878
    Jan 24 18:40:27.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename statefulset 01/24/23 18:40:27.894
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:40:27.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:40:27.988
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9834 01/24/23 18:40:27.997
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-9834 01/24/23 18:40:28.036
    Jan 24 18:40:28.062: INFO: Found 0 stateful pods, waiting for 1
    Jan 24 18:40:38.073: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 01/24/23 18:40:38.085
    STEP: updating a scale subresource 01/24/23 18:40:38.095
    STEP: verifying the statefulset Spec.Replicas was modified 01/24/23 18:40:38.113
    STEP: Patch a scale subresource 01/24/23 18:40:38.157
    STEP: verifying the statefulset Spec.Replicas was modified 01/24/23 18:40:38.32
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 24 18:40:38.337: INFO: Deleting all statefulset in ns statefulset-9834
    Jan 24 18:40:38.344: INFO: Scaling statefulset ss to 0
    Jan 24 18:40:48.388: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 18:40:48.406: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 24 18:40:48.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9834" for this suite. 01/24/23 18:40:48.568
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:40:48.61
Jan 24 18:40:48.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename containers 01/24/23 18:40:48.616
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:40:48.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:40:48.728
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 01/24/23 18:40:48.767
Jan 24 18:40:48.835: INFO: Waiting up to 5m0s for pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2" in namespace "containers-7266" to be "Succeeded or Failed"
Jan 24 18:40:48.862: INFO: Pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.711073ms
Jan 24 18:40:50.877: INFO: Pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041558045s
Jan 24 18:40:52.878: INFO: Pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042898109s
Jan 24 18:40:54.917: INFO: Pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.081735002s
STEP: Saw pod success 01/24/23 18:40:54.917
Jan 24 18:40:54.918: INFO: Pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2" satisfied condition "Succeeded or Failed"
Jan 24 18:40:54.932: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 18:40:55.067
Jan 24 18:40:55.121: INFO: Waiting for pod client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2 to disappear
Jan 24 18:40:55.138: INFO: Pod client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jan 24 18:40:55.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7266" for this suite. 01/24/23 18:40:55.159
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":16,"skipped":347,"failed":0}
------------------------------
• [SLOW TEST] [6.631 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:40:48.61
    Jan 24 18:40:48.610: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename containers 01/24/23 18:40:48.616
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:40:48.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:40:48.728
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 01/24/23 18:40:48.767
    Jan 24 18:40:48.835: INFO: Waiting up to 5m0s for pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2" in namespace "containers-7266" to be "Succeeded or Failed"
    Jan 24 18:40:48.862: INFO: Pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.711073ms
    Jan 24 18:40:50.877: INFO: Pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041558045s
    Jan 24 18:40:52.878: INFO: Pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042898109s
    Jan 24 18:40:54.917: INFO: Pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.081735002s
    STEP: Saw pod success 01/24/23 18:40:54.917
    Jan 24 18:40:54.918: INFO: Pod "client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2" satisfied condition "Succeeded or Failed"
    Jan 24 18:40:54.932: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 18:40:55.067
    Jan 24 18:40:55.121: INFO: Waiting for pod client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2 to disappear
    Jan 24 18:40:55.138: INFO: Pod client-containers-d3314ada-685a-4727-a6fe-acc25d2ddde2 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jan 24 18:40:55.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7266" for this suite. 01/24/23 18:40:55.159
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:40:55.264
Jan 24 18:40:55.265: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename daemonsets 01/24/23 18:40:55.269
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:40:55.403
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:40:55.446
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 01/24/23 18:40:55.603
STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 18:40:55.62
Jan 24 18:40:55.680: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:40:55.701: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 18:40:56.753: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:40:56.753: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 18:40:57.734: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:40:57.734: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 18:40:58.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:40:58.900: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 18:40:59.745: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 24 18:40:59.745: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Getting /status 01/24/23 18:40:59.76
Jan 24 18:40:59.814: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 01/24/23 18:40:59.815
Jan 24 18:40:59.846: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 01/24/23 18:40:59.851
Jan 24 18:40:59.865: INFO: Observed &DaemonSet event: ADDED
Jan 24 18:40:59.867: INFO: Observed &DaemonSet event: MODIFIED
Jan 24 18:40:59.872: INFO: Observed &DaemonSet event: MODIFIED
Jan 24 18:40:59.877: INFO: Observed &DaemonSet event: MODIFIED
Jan 24 18:40:59.878: INFO: Found daemon set daemon-set in namespace daemonsets-1452 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jan 24 18:40:59.879: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 01/24/23 18:40:59.88
STEP: watching for the daemon set status to be patched 01/24/23 18:40:59.906
Jan 24 18:40:59.932: INFO: Observed &DaemonSet event: ADDED
Jan 24 18:40:59.933: INFO: Observed &DaemonSet event: MODIFIED
Jan 24 18:40:59.947: INFO: Observed &DaemonSet event: MODIFIED
Jan 24 18:40:59.954: INFO: Observed &DaemonSet event: MODIFIED
Jan 24 18:40:59.955: INFO: Observed daemon set daemon-set in namespace daemonsets-1452 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jan 24 18:40:59.960: INFO: Observed &DaemonSet event: MODIFIED
Jan 24 18:40:59.961: INFO: Found daemon set daemon-set in namespace daemonsets-1452 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Jan 24 18:40:59.973: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/24/23 18:40:59.987
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1452, will wait for the garbage collector to delete the pods 01/24/23 18:40:59.987
Jan 24 18:41:00.107: INFO: Deleting DaemonSet.extensions daemon-set took: 38.73627ms
Jan 24 18:41:00.813: INFO: Terminating DaemonSet.extensions daemon-set pods took: 706.284436ms
Jan 24 18:41:05.030: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:41:05.030: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 24 18:41:05.050: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"15699"},"items":null}

Jan 24 18:41:05.090: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"15699"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 24 18:41:05.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1452" for this suite. 01/24/23 18:41:05.167
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":17,"skipped":351,"failed":0}
------------------------------
• [SLOW TEST] [10.020 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:40:55.264
    Jan 24 18:40:55.265: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename daemonsets 01/24/23 18:40:55.269
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:40:55.403
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:40:55.446
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 01/24/23 18:40:55.603
    STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 18:40:55.62
    Jan 24 18:40:55.680: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:40:55.701: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 18:40:56.753: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:40:56.753: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 18:40:57.734: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:40:57.734: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 18:40:58.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:40:58.900: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 18:40:59.745: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 24 18:40:59.745: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Getting /status 01/24/23 18:40:59.76
    Jan 24 18:40:59.814: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 01/24/23 18:40:59.815
    Jan 24 18:40:59.846: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 01/24/23 18:40:59.851
    Jan 24 18:40:59.865: INFO: Observed &DaemonSet event: ADDED
    Jan 24 18:40:59.867: INFO: Observed &DaemonSet event: MODIFIED
    Jan 24 18:40:59.872: INFO: Observed &DaemonSet event: MODIFIED
    Jan 24 18:40:59.877: INFO: Observed &DaemonSet event: MODIFIED
    Jan 24 18:40:59.878: INFO: Found daemon set daemon-set in namespace daemonsets-1452 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jan 24 18:40:59.879: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 01/24/23 18:40:59.88
    STEP: watching for the daemon set status to be patched 01/24/23 18:40:59.906
    Jan 24 18:40:59.932: INFO: Observed &DaemonSet event: ADDED
    Jan 24 18:40:59.933: INFO: Observed &DaemonSet event: MODIFIED
    Jan 24 18:40:59.947: INFO: Observed &DaemonSet event: MODIFIED
    Jan 24 18:40:59.954: INFO: Observed &DaemonSet event: MODIFIED
    Jan 24 18:40:59.955: INFO: Observed daemon set daemon-set in namespace daemonsets-1452 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jan 24 18:40:59.960: INFO: Observed &DaemonSet event: MODIFIED
    Jan 24 18:40:59.961: INFO: Found daemon set daemon-set in namespace daemonsets-1452 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Jan 24 18:40:59.973: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/24/23 18:40:59.987
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1452, will wait for the garbage collector to delete the pods 01/24/23 18:40:59.987
    Jan 24 18:41:00.107: INFO: Deleting DaemonSet.extensions daemon-set took: 38.73627ms
    Jan 24 18:41:00.813: INFO: Terminating DaemonSet.extensions daemon-set pods took: 706.284436ms
    Jan 24 18:41:05.030: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:41:05.030: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 24 18:41:05.050: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"15699"},"items":null}

    Jan 24 18:41:05.090: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"15699"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 18:41:05.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1452" for this suite. 01/24/23 18:41:05.167
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:41:05.449
Jan 24 18:41:05.449: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 18:41:05.478
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:05.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:05.56
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 01/24/23 18:41:05.601
Jan 24 18:41:05.648: INFO: Waiting up to 5m0s for pod "pod-mz2bl" in namespace "pods-2308" to be "running"
Jan 24 18:41:05.673: INFO: Pod "pod-mz2bl": Phase="Pending", Reason="", readiness=false. Elapsed: 24.639291ms
Jan 24 18:41:07.758: INFO: Pod "pod-mz2bl": Phase="Running", Reason="", readiness=true. Elapsed: 2.109921373s
Jan 24 18:41:07.758: INFO: Pod "pod-mz2bl" satisfied condition "running"
STEP: patching /status 01/24/23 18:41:07.759
Jan 24 18:41:07.809: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 24 18:41:07.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2308" for this suite. 01/24/23 18:41:07.829
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":18,"skipped":384,"failed":0}
------------------------------
• [2.433 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:41:05.449
    Jan 24 18:41:05.449: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 18:41:05.478
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:05.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:05.56
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 01/24/23 18:41:05.601
    Jan 24 18:41:05.648: INFO: Waiting up to 5m0s for pod "pod-mz2bl" in namespace "pods-2308" to be "running"
    Jan 24 18:41:05.673: INFO: Pod "pod-mz2bl": Phase="Pending", Reason="", readiness=false. Elapsed: 24.639291ms
    Jan 24 18:41:07.758: INFO: Pod "pod-mz2bl": Phase="Running", Reason="", readiness=true. Elapsed: 2.109921373s
    Jan 24 18:41:07.758: INFO: Pod "pod-mz2bl" satisfied condition "running"
    STEP: patching /status 01/24/23 18:41:07.759
    Jan 24 18:41:07.809: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 24 18:41:07.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2308" for this suite. 01/24/23 18:41:07.829
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:41:07.887
Jan 24 18:41:07.888: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replication-controller 01/24/23 18:41:07.907
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:08.022
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:08.064
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 01/24/23 18:41:08.093
STEP: waiting for RC to be added 01/24/23 18:41:08.109
STEP: waiting for available Replicas 01/24/23 18:41:08.11
STEP: patching ReplicationController 01/24/23 18:41:17.603
STEP: waiting for RC to be modified 01/24/23 18:41:17.654
STEP: patching ReplicationController status 01/24/23 18:41:17.656
STEP: waiting for RC to be modified 01/24/23 18:41:17.712
STEP: waiting for available Replicas 01/24/23 18:41:17.719
STEP: fetching ReplicationController status 01/24/23 18:41:17.738
STEP: patching ReplicationController scale 01/24/23 18:41:17.786
STEP: waiting for RC to be modified 01/24/23 18:41:17.822
STEP: waiting for ReplicationController's scale to be the max amount 01/24/23 18:41:17.822
STEP: fetching ReplicationController; ensuring that it's patched 01/24/23 18:41:27.71
STEP: updating ReplicationController status 01/24/23 18:41:27.732
STEP: waiting for RC to be modified 01/24/23 18:41:27.762
STEP: listing all ReplicationControllers 01/24/23 18:41:27.786
STEP: checking that ReplicationController has expected values 01/24/23 18:41:27.827
STEP: deleting ReplicationControllers by collection 01/24/23 18:41:27.827
STEP: waiting for ReplicationController to have a DELETED watchEvent 01/24/23 18:41:27.852
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jan 24 18:41:28.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7551" for this suite. 01/24/23 18:41:28.141
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":19,"skipped":407,"failed":0}
------------------------------
• [SLOW TEST] [20.277 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:41:07.887
    Jan 24 18:41:07.888: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replication-controller 01/24/23 18:41:07.907
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:08.022
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:08.064
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 01/24/23 18:41:08.093
    STEP: waiting for RC to be added 01/24/23 18:41:08.109
    STEP: waiting for available Replicas 01/24/23 18:41:08.11
    STEP: patching ReplicationController 01/24/23 18:41:17.603
    STEP: waiting for RC to be modified 01/24/23 18:41:17.654
    STEP: patching ReplicationController status 01/24/23 18:41:17.656
    STEP: waiting for RC to be modified 01/24/23 18:41:17.712
    STEP: waiting for available Replicas 01/24/23 18:41:17.719
    STEP: fetching ReplicationController status 01/24/23 18:41:17.738
    STEP: patching ReplicationController scale 01/24/23 18:41:17.786
    STEP: waiting for RC to be modified 01/24/23 18:41:17.822
    STEP: waiting for ReplicationController's scale to be the max amount 01/24/23 18:41:17.822
    STEP: fetching ReplicationController; ensuring that it's patched 01/24/23 18:41:27.71
    STEP: updating ReplicationController status 01/24/23 18:41:27.732
    STEP: waiting for RC to be modified 01/24/23 18:41:27.762
    STEP: listing all ReplicationControllers 01/24/23 18:41:27.786
    STEP: checking that ReplicationController has expected values 01/24/23 18:41:27.827
    STEP: deleting ReplicationControllers by collection 01/24/23 18:41:27.827
    STEP: waiting for ReplicationController to have a DELETED watchEvent 01/24/23 18:41:27.852
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jan 24 18:41:28.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7551" for this suite. 01/24/23 18:41:28.141
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:41:28.219
Jan 24 18:41:28.219: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 18:41:28.225
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:28.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:28.337
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 01/24/23 18:41:28.371
Jan 24 18:41:28.407: INFO: Waiting up to 5m0s for pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706" in namespace "emptydir-7722" to be "Succeeded or Failed"
Jan 24 18:41:28.430: INFO: Pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706": Phase="Pending", Reason="", readiness=false. Elapsed: 23.501877ms
Jan 24 18:41:30.491: INFO: Pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084285462s
Jan 24 18:41:32.442: INFO: Pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706": Phase="Running", Reason="", readiness=false. Elapsed: 4.035799493s
Jan 24 18:41:34.453: INFO: Pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04641086s
STEP: Saw pod success 01/24/23 18:41:34.467
Jan 24 18:41:34.471: INFO: Pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706" satisfied condition "Succeeded or Failed"
Jan 24 18:41:34.485: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706 container test-container: <nil>
STEP: delete the pod 01/24/23 18:41:34.498
Jan 24 18:41:34.532: INFO: Waiting for pod pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706 to disappear
Jan 24 18:41:34.542: INFO: Pod pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 18:41:34.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7722" for this suite. 01/24/23 18:41:34.561
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":20,"skipped":466,"failed":0}
------------------------------
• [SLOW TEST] [6.353 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:41:28.219
    Jan 24 18:41:28.219: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 18:41:28.225
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:28.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:28.337
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 01/24/23 18:41:28.371
    Jan 24 18:41:28.407: INFO: Waiting up to 5m0s for pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706" in namespace "emptydir-7722" to be "Succeeded or Failed"
    Jan 24 18:41:28.430: INFO: Pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706": Phase="Pending", Reason="", readiness=false. Elapsed: 23.501877ms
    Jan 24 18:41:30.491: INFO: Pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084285462s
    Jan 24 18:41:32.442: INFO: Pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706": Phase="Running", Reason="", readiness=false. Elapsed: 4.035799493s
    Jan 24 18:41:34.453: INFO: Pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04641086s
    STEP: Saw pod success 01/24/23 18:41:34.467
    Jan 24 18:41:34.471: INFO: Pod "pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706" satisfied condition "Succeeded or Failed"
    Jan 24 18:41:34.485: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706 container test-container: <nil>
    STEP: delete the pod 01/24/23 18:41:34.498
    Jan 24 18:41:34.532: INFO: Waiting for pod pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706 to disappear
    Jan 24 18:41:34.542: INFO: Pod pod-dc32a23a-4a2c-4528-bfa7-f75e98a20706 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 18:41:34.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7722" for this suite. 01/24/23 18:41:34.561
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:41:34.582
Jan 24 18:41:34.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 18:41:34.584
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:34.616
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:34.622
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 01/24/23 18:41:34.628
Jan 24 18:41:34.695: INFO: created test-pod-1
Jan 24 18:41:34.765: INFO: created test-pod-2
Jan 24 18:41:34.790: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 01/24/23 18:41:34.79
Jan 24 18:41:34.793: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-5413' to be running and ready
Jan 24 18:41:34.831: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jan 24 18:41:34.832: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jan 24 18:41:34.833: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jan 24 18:41:34.836: INFO: 0 / 3 pods in namespace 'pods-5413' are running and ready (0 seconds elapsed)
Jan 24 18:41:34.836: INFO: expected 0 pod replicas in namespace 'pods-5413', 0 are Running and Ready.
Jan 24 18:41:34.837: INFO: POD         NODE                          PHASE    GRACE  CONDITIONS
Jan 24 18:41:34.839: INFO: test-pod-1  vikash-v125latest-conf-71087  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  }]
Jan 24 18:41:34.839: INFO: test-pod-2  vikash-v125latest-conf-71087  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  }]
Jan 24 18:41:34.840: INFO: test-pod-3  vikash-v125latest-conf-71087  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  }]
Jan 24 18:41:34.840: INFO: 
Jan 24 18:41:36.869: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jan 24 18:41:36.870: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jan 24 18:41:36.870: INFO: 1 / 3 pods in namespace 'pods-5413' are running and ready (2 seconds elapsed)
Jan 24 18:41:36.870: INFO: expected 0 pod replicas in namespace 'pods-5413', 0 are Running and Ready.
Jan 24 18:41:36.870: INFO: POD         NODE                          PHASE    GRACE  CONDITIONS
Jan 24 18:41:36.870: INFO: test-pod-2  vikash-v125latest-conf-71087  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  }]
Jan 24 18:41:36.870: INFO: test-pod-3  vikash-v125latest-conf-71087  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  }]
Jan 24 18:41:36.870: INFO: 
Jan 24 18:41:38.874: INFO: 3 / 3 pods in namespace 'pods-5413' are running and ready (4 seconds elapsed)
Jan 24 18:41:38.874: INFO: expected 0 pod replicas in namespace 'pods-5413', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 01/24/23 18:41:38.965
Jan 24 18:41:38.991: INFO: Pod quantity 3 is different from expected quantity 0
Jan 24 18:41:40.002: INFO: Pod quantity 3 is different from expected quantity 0
Jan 24 18:41:41.003: INFO: Pod quantity 1 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 24 18:41:42.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5413" for this suite. 01/24/23 18:41:42.013
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":21,"skipped":484,"failed":0}
------------------------------
• [SLOW TEST] [7.450 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:41:34.582
    Jan 24 18:41:34.583: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 18:41:34.584
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:34.616
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:34.622
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 01/24/23 18:41:34.628
    Jan 24 18:41:34.695: INFO: created test-pod-1
    Jan 24 18:41:34.765: INFO: created test-pod-2
    Jan 24 18:41:34.790: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 01/24/23 18:41:34.79
    Jan 24 18:41:34.793: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-5413' to be running and ready
    Jan 24 18:41:34.831: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jan 24 18:41:34.832: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jan 24 18:41:34.833: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jan 24 18:41:34.836: INFO: 0 / 3 pods in namespace 'pods-5413' are running and ready (0 seconds elapsed)
    Jan 24 18:41:34.836: INFO: expected 0 pod replicas in namespace 'pods-5413', 0 are Running and Ready.
    Jan 24 18:41:34.837: INFO: POD         NODE                          PHASE    GRACE  CONDITIONS
    Jan 24 18:41:34.839: INFO: test-pod-1  vikash-v125latest-conf-71087  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  }]
    Jan 24 18:41:34.839: INFO: test-pod-2  vikash-v125latest-conf-71087  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  }]
    Jan 24 18:41:34.840: INFO: test-pod-3  vikash-v125latest-conf-71087  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  }]
    Jan 24 18:41:34.840: INFO: 
    Jan 24 18:41:36.869: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jan 24 18:41:36.870: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Jan 24 18:41:36.870: INFO: 1 / 3 pods in namespace 'pods-5413' are running and ready (2 seconds elapsed)
    Jan 24 18:41:36.870: INFO: expected 0 pod replicas in namespace 'pods-5413', 0 are Running and Ready.
    Jan 24 18:41:36.870: INFO: POD         NODE                          PHASE    GRACE  CONDITIONS
    Jan 24 18:41:36.870: INFO: test-pod-2  vikash-v125latest-conf-71087  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  }]
    Jan 24 18:41:36.870: INFO: test-pod-3  vikash-v125latest-conf-71087  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:41:34 +0000 UTC  }]
    Jan 24 18:41:36.870: INFO: 
    Jan 24 18:41:38.874: INFO: 3 / 3 pods in namespace 'pods-5413' are running and ready (4 seconds elapsed)
    Jan 24 18:41:38.874: INFO: expected 0 pod replicas in namespace 'pods-5413', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 01/24/23 18:41:38.965
    Jan 24 18:41:38.991: INFO: Pod quantity 3 is different from expected quantity 0
    Jan 24 18:41:40.002: INFO: Pod quantity 3 is different from expected quantity 0
    Jan 24 18:41:41.003: INFO: Pod quantity 1 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 24 18:41:42.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5413" for this suite. 01/24/23 18:41:42.013
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:41:42.064
Jan 24 18:41:42.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 18:41:42.072
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:42.126
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:42.148
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 01/24/23 18:41:42.172
STEP: submitting the pod to kubernetes 01/24/23 18:41:42.174
Jan 24 18:41:42.190: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7" in namespace "pods-3434" to be "running and ready"
Jan 24 18:41:42.208: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Pending", Reason="", readiness=false. Elapsed: 17.969307ms
Jan 24 18:41:42.208: INFO: The phase of Pod pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:41:44.222: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031414296s
Jan 24 18:41:44.222: INFO: The phase of Pod pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:41:46.219: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Running", Reason="", readiness=true. Elapsed: 4.029096775s
Jan 24 18:41:46.223: INFO: The phase of Pod pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7 is Running (Ready = true)
Jan 24 18:41:46.224: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 01/24/23 18:41:46.239
STEP: updating the pod 01/24/23 18:41:46.26
Jan 24 18:41:46.829: INFO: Successfully updated pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7"
Jan 24 18:41:46.829: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7" in namespace "pods-3434" to be "terminated with reason DeadlineExceeded"
Jan 24 18:41:46.841: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Running", Reason="", readiness=true. Elapsed: 8.795465ms
Jan 24 18:41:48.850: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Running", Reason="", readiness=false. Elapsed: 2.018065204s
Jan 24 18:41:50.857: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.025155794s
Jan 24 18:41:50.862: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 24 18:41:50.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3434" for this suite. 01/24/23 18:41:50.887
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":22,"skipped":525,"failed":0}
------------------------------
• [SLOW TEST] [8.844 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:41:42.064
    Jan 24 18:41:42.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 18:41:42.072
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:42.126
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:42.148
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 01/24/23 18:41:42.172
    STEP: submitting the pod to kubernetes 01/24/23 18:41:42.174
    Jan 24 18:41:42.190: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7" in namespace "pods-3434" to be "running and ready"
    Jan 24 18:41:42.208: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Pending", Reason="", readiness=false. Elapsed: 17.969307ms
    Jan 24 18:41:42.208: INFO: The phase of Pod pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:41:44.222: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031414296s
    Jan 24 18:41:44.222: INFO: The phase of Pod pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:41:46.219: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Running", Reason="", readiness=true. Elapsed: 4.029096775s
    Jan 24 18:41:46.223: INFO: The phase of Pod pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7 is Running (Ready = true)
    Jan 24 18:41:46.224: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 01/24/23 18:41:46.239
    STEP: updating the pod 01/24/23 18:41:46.26
    Jan 24 18:41:46.829: INFO: Successfully updated pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7"
    Jan 24 18:41:46.829: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7" in namespace "pods-3434" to be "terminated with reason DeadlineExceeded"
    Jan 24 18:41:46.841: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Running", Reason="", readiness=true. Elapsed: 8.795465ms
    Jan 24 18:41:48.850: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Running", Reason="", readiness=false. Elapsed: 2.018065204s
    Jan 24 18:41:50.857: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.025155794s
    Jan 24 18:41:50.862: INFO: Pod "pod-update-activedeadlineseconds-8b00d4c5-4ff0-4ab1-bf94-d3ec692a38d7" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 24 18:41:50.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3434" for this suite. 01/24/23 18:41:50.887
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:41:50.952
Jan 24 18:41:50.957: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename security-context-test 01/24/23 18:41:50.989
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:51.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:51.093
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Jan 24 18:41:51.141: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d" in namespace "security-context-test-7893" to be "Succeeded or Failed"
Jan 24 18:41:51.178: INFO: Pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d": Phase="Pending", Reason="", readiness=false. Elapsed: 36.756421ms
Jan 24 18:41:53.238: INFO: Pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097239561s
Jan 24 18:41:55.216: INFO: Pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075235317s
Jan 24 18:41:57.194: INFO: Pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052317675s
Jan 24 18:41:57.194: INFO: Pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d" satisfied condition "Succeeded or Failed"
Jan 24 18:41:57.237: INFO: Got logs for pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 24 18:41:57.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7893" for this suite. 01/24/23 18:41:57.271
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":23,"skipped":536,"failed":0}
------------------------------
• [SLOW TEST] [6.348 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:41:50.952
    Jan 24 18:41:50.957: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename security-context-test 01/24/23 18:41:50.989
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:51.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:51.093
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Jan 24 18:41:51.141: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d" in namespace "security-context-test-7893" to be "Succeeded or Failed"
    Jan 24 18:41:51.178: INFO: Pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d": Phase="Pending", Reason="", readiness=false. Elapsed: 36.756421ms
    Jan 24 18:41:53.238: INFO: Pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097239561s
    Jan 24 18:41:55.216: INFO: Pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075235317s
    Jan 24 18:41:57.194: INFO: Pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052317675s
    Jan 24 18:41:57.194: INFO: Pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d" satisfied condition "Succeeded or Failed"
    Jan 24 18:41:57.237: INFO: Got logs for pod "busybox-privileged-false-2800bc1d-0f36-48df-b935-adcb0e82c10d": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 24 18:41:57.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7893" for this suite. 01/24/23 18:41:57.271
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:41:57.306
Jan 24 18:41:57.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-runtime 01/24/23 18:41:57.309
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:57.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:57.379
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 01/24/23 18:41:57.417
STEP: wait for the container to reach Succeeded 01/24/23 18:41:57.457
STEP: get the container status 01/24/23 18:42:04.892
STEP: the container should be terminated 01/24/23 18:42:04.904
STEP: the termination message should be set 01/24/23 18:42:04.905
Jan 24 18:42:04.905: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 01/24/23 18:42:04.905
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jan 24 18:42:04.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5154" for this suite. 01/24/23 18:42:05.013
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":24,"skipped":541,"failed":0}
------------------------------
• [SLOW TEST] [7.740 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:41:57.306
    Jan 24 18:41:57.307: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-runtime 01/24/23 18:41:57.309
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:41:57.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:41:57.379
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 01/24/23 18:41:57.417
    STEP: wait for the container to reach Succeeded 01/24/23 18:41:57.457
    STEP: get the container status 01/24/23 18:42:04.892
    STEP: the container should be terminated 01/24/23 18:42:04.904
    STEP: the termination message should be set 01/24/23 18:42:04.905
    Jan 24 18:42:04.905: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 01/24/23 18:42:04.905
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jan 24 18:42:04.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5154" for this suite. 01/24/23 18:42:05.013
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:42:05.047
Jan 24 18:42:05.048: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename daemonsets 01/24/23 18:42:05.062
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:42:05.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:42:05.206
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Jan 24 18:42:05.356: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 01/24/23 18:42:05.414
Jan 24 18:42:05.502: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:05.502: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 01/24/23 18:42:05.502
Jan 24 18:42:05.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:05.700: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 18:42:06.723: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:06.723: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 18:42:07.723: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:07.723: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 18:42:08.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 18:42:08.729: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 01/24/23 18:42:08.746
Jan 24 18:42:08.856: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:08.856: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 01/24/23 18:42:08.856
Jan 24 18:42:08.992: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:08.992: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 18:42:10.062: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:10.062: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 18:42:11.014: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:11.014: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 18:42:12.013: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:12.013: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 18:42:13.096: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:13.096: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 18:42:14.023: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:14.024: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 18:42:15.015: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:15.015: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 18:42:16.022: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 18:42:16.022: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/24/23 18:42:16.046
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5153, will wait for the garbage collector to delete the pods 01/24/23 18:42:16.047
Jan 24 18:42:16.143: INFO: Deleting DaemonSet.extensions daemon-set took: 26.771903ms
Jan 24 18:42:16.344: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.385024ms
Jan 24 18:42:19.262: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 18:42:19.262: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 24 18:42:19.274: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16151"},"items":null}

Jan 24 18:42:19.286: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16151"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 24 18:42:19.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5153" for this suite. 01/24/23 18:42:19.427
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":25,"skipped":544,"failed":0}
------------------------------
• [SLOW TEST] [14.400 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:42:05.047
    Jan 24 18:42:05.048: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename daemonsets 01/24/23 18:42:05.062
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:42:05.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:42:05.206
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Jan 24 18:42:05.356: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 01/24/23 18:42:05.414
    Jan 24 18:42:05.502: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:05.502: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 01/24/23 18:42:05.502
    Jan 24 18:42:05.696: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:05.700: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 18:42:06.723: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:06.723: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 18:42:07.723: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:07.723: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 18:42:08.729: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 18:42:08.729: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 01/24/23 18:42:08.746
    Jan 24 18:42:08.856: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:08.856: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 01/24/23 18:42:08.856
    Jan 24 18:42:08.992: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:08.992: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 18:42:10.062: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:10.062: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 18:42:11.014: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:11.014: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 18:42:12.013: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:12.013: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 18:42:13.096: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:13.096: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 18:42:14.023: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:14.024: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 18:42:15.015: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:15.015: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 18:42:16.022: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 18:42:16.022: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/24/23 18:42:16.046
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5153, will wait for the garbage collector to delete the pods 01/24/23 18:42:16.047
    Jan 24 18:42:16.143: INFO: Deleting DaemonSet.extensions daemon-set took: 26.771903ms
    Jan 24 18:42:16.344: INFO: Terminating DaemonSet.extensions daemon-set pods took: 201.385024ms
    Jan 24 18:42:19.262: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 18:42:19.262: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 24 18:42:19.274: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"16151"},"items":null}

    Jan 24 18:42:19.286: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"16151"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 18:42:19.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5153" for this suite. 01/24/23 18:42:19.427
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:42:19.483
Jan 24 18:42:19.484: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 18:42:19.5
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:42:19.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:42:19.576
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-efd46364-c18b-40ed-a375-e4e981d9f45d 01/24/23 18:42:19.599
STEP: Creating a pod to test consume secrets 01/24/23 18:42:19.699
Jan 24 18:42:19.767: INFO: Waiting up to 5m0s for pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf" in namespace "secrets-67" to be "Succeeded or Failed"
Jan 24 18:42:19.879: INFO: Pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf": Phase="Pending", Reason="", readiness=false. Elapsed: 111.791559ms
Jan 24 18:42:21.890: INFO: Pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123177605s
Jan 24 18:42:23.909: INFO: Pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.142120319s
Jan 24 18:42:25.890: INFO: Pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.12259373s
STEP: Saw pod success 01/24/23 18:42:25.896
Jan 24 18:42:25.897: INFO: Pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf" satisfied condition "Succeeded or Failed"
Jan 24 18:42:25.922: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf container secret-volume-test: <nil>
STEP: delete the pod 01/24/23 18:42:25.966
Jan 24 18:42:26.022: INFO: Waiting for pod pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf to disappear
Jan 24 18:42:26.035: INFO: Pod pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 24 18:42:26.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-67" for this suite. 01/24/23 18:42:26.053
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":26,"skipped":545,"failed":0}
------------------------------
• [SLOW TEST] [6.586 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:42:19.483
    Jan 24 18:42:19.484: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 18:42:19.5
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:42:19.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:42:19.576
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-efd46364-c18b-40ed-a375-e4e981d9f45d 01/24/23 18:42:19.599
    STEP: Creating a pod to test consume secrets 01/24/23 18:42:19.699
    Jan 24 18:42:19.767: INFO: Waiting up to 5m0s for pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf" in namespace "secrets-67" to be "Succeeded or Failed"
    Jan 24 18:42:19.879: INFO: Pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf": Phase="Pending", Reason="", readiness=false. Elapsed: 111.791559ms
    Jan 24 18:42:21.890: INFO: Pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123177605s
    Jan 24 18:42:23.909: INFO: Pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.142120319s
    Jan 24 18:42:25.890: INFO: Pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.12259373s
    STEP: Saw pod success 01/24/23 18:42:25.896
    Jan 24 18:42:25.897: INFO: Pod "pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf" satisfied condition "Succeeded or Failed"
    Jan 24 18:42:25.922: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf container secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 18:42:25.966
    Jan 24 18:42:26.022: INFO: Waiting for pod pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf to disappear
    Jan 24 18:42:26.035: INFO: Pod pod-secrets-9af332b3-702f-41a5-9d72-e372b17835cf no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 18:42:26.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-67" for this suite. 01/24/23 18:42:26.053
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:42:26.087
Jan 24 18:42:26.088: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replication-controller 01/24/23 18:42:26.101
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:42:26.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:42:26.18
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662 01/24/23 18:42:26.195
Jan 24 18:42:26.229: INFO: Pod name my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662: Found 0 pods out of 1
Jan 24 18:42:31.302: INFO: Pod name my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662: Found 1 pods out of 1
Jan 24 18:42:31.302: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662" are running
Jan 24 18:42:31.302: INFO: Waiting up to 5m0s for pod "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv" in namespace "replication-controller-1567" to be "running"
Jan 24 18:42:31.324: INFO: Pod "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv": Phase="Running", Reason="", readiness=true. Elapsed: 19.982388ms
Jan 24 18:42:31.325: INFO: Pod "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv" satisfied condition "running"
Jan 24 18:42:31.325: INFO: Pod "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-24 18:42:26 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-24 18:42:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-24 18:42:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-24 18:42:26 +0000 UTC Reason: Message:}])
Jan 24 18:42:31.325: INFO: Trying to dial the pod
Jan 24 18:42:36.387: INFO: Controller my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662: Got expected result from replica 1 [my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv]: "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jan 24 18:42:36.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1567" for this suite. 01/24/23 18:42:36.411
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":27,"skipped":575,"failed":0}
------------------------------
• [SLOW TEST] [10.347 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:42:26.087
    Jan 24 18:42:26.088: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replication-controller 01/24/23 18:42:26.101
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:42:26.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:42:26.18
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662 01/24/23 18:42:26.195
    Jan 24 18:42:26.229: INFO: Pod name my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662: Found 0 pods out of 1
    Jan 24 18:42:31.302: INFO: Pod name my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662: Found 1 pods out of 1
    Jan 24 18:42:31.302: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662" are running
    Jan 24 18:42:31.302: INFO: Waiting up to 5m0s for pod "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv" in namespace "replication-controller-1567" to be "running"
    Jan 24 18:42:31.324: INFO: Pod "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv": Phase="Running", Reason="", readiness=true. Elapsed: 19.982388ms
    Jan 24 18:42:31.325: INFO: Pod "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv" satisfied condition "running"
    Jan 24 18:42:31.325: INFO: Pod "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-24 18:42:26 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-24 18:42:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-24 18:42:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-01-24 18:42:26 +0000 UTC Reason: Message:}])
    Jan 24 18:42:31.325: INFO: Trying to dial the pod
    Jan 24 18:42:36.387: INFO: Controller my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662: Got expected result from replica 1 [my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv]: "my-hostname-basic-e2899ccf-676d-466b-95a2-47e2f3dea662-7wnkv", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jan 24 18:42:36.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1567" for this suite. 01/24/23 18:42:36.411
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:42:36.503
Jan 24 18:42:36.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pod-network-test 01/24/23 18:42:36.513
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:42:36.562
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:42:36.576
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-5465 01/24/23 18:42:36.588
STEP: creating a selector 01/24/23 18:42:36.592
STEP: Creating the service pods in kubernetes 01/24/23 18:42:36.597
Jan 24 18:42:36.599: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jan 24 18:42:36.683: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5465" to be "running and ready"
Jan 24 18:42:36.743: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 59.437095ms
Jan 24 18:42:36.743: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:42:38.822: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.13885931s
Jan 24 18:42:38.823: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:42:40.820: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.136457819s
Jan 24 18:42:40.820: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:42:42.755: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.071783896s
Jan 24 18:42:42.755: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:42:44.750: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.066541994s
Jan 24 18:42:44.750: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:42:46.772: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.088435119s
Jan 24 18:42:46.772: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:42:48.754: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.070504804s
Jan 24 18:42:48.754: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:42:50.780: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.096752078s
Jan 24 18:42:50.780: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:42:52.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.068605994s
Jan 24 18:42:52.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 18:42:54.796: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.11266852s
Jan 24 18:42:54.796: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 18:42:56.751: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.068355542s
Jan 24 18:42:56.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 18:42:58.760: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 22.076659199s
Jan 24 18:42:58.760: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 18:43:00.765: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 24.08182442s
Jan 24 18:43:00.767: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 18:43:02.771: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 26.087377403s
Jan 24 18:43:02.771: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 18:43:04.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 28.068890277s
Jan 24 18:43:04.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 18:43:06.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 30.068756517s
Jan 24 18:43:06.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 18:43:08.754: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 32.070634391s
Jan 24 18:43:08.754: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jan 24 18:43:08.754: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jan 24 18:43:08.768: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5465" to be "running and ready"
Jan 24 18:43:08.779: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.788865ms
Jan 24 18:43:08.780: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jan 24 18:43:08.780: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 01/24/23 18:43:08.791
Jan 24 18:43:08.844: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5465" to be "running"
Jan 24 18:43:08.912: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 67.148716ms
Jan 24 18:43:11.007: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.162402128s
Jan 24 18:43:12.997: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.152015244s
Jan 24 18:43:12.997: INFO: Pod "test-container-pod" satisfied condition "running"
Jan 24 18:43:13.025: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-5465" to be "running"
Jan 24 18:43:13.034: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.998187ms
Jan 24 18:43:13.034: INFO: Pod "host-test-container-pod" satisfied condition "running"
Jan 24 18:43:13.050: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Jan 24 18:43:13.050: INFO: Going to poll 10.244.47.101 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Jan 24 18:43:13.064: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.47.101:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5465 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 18:43:13.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 18:43:13.071: INFO: ExecWithOptions: Clientset creation
Jan 24 18:43:13.071: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-5465/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.47.101%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 24 18:43:13.411: INFO: Found all 1 expected endpoints: [netserver-0]
Jan 24 18:43:13.411: INFO: Going to poll 10.244.71.251 on port 8083 at least 0 times, with a maximum of 34 tries before failing
Jan 24 18:43:13.423: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.71.251:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5465 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 18:43:13.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 18:43:13.427: INFO: ExecWithOptions: Clientset creation
Jan 24 18:43:13.427: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-5465/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.71.251%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 24 18:43:13.678: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jan 24 18:43:13.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5465" for this suite. 01/24/23 18:43:13.703
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":28,"skipped":593,"failed":0}
------------------------------
• [SLOW TEST] [37.225 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:42:36.503
    Jan 24 18:42:36.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pod-network-test 01/24/23 18:42:36.513
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:42:36.562
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:42:36.576
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-5465 01/24/23 18:42:36.588
    STEP: creating a selector 01/24/23 18:42:36.592
    STEP: Creating the service pods in kubernetes 01/24/23 18:42:36.597
    Jan 24 18:42:36.599: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jan 24 18:42:36.683: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-5465" to be "running and ready"
    Jan 24 18:42:36.743: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 59.437095ms
    Jan 24 18:42:36.743: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:42:38.822: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.13885931s
    Jan 24 18:42:38.823: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:42:40.820: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.136457819s
    Jan 24 18:42:40.820: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:42:42.755: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.071783896s
    Jan 24 18:42:42.755: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:42:44.750: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.066541994s
    Jan 24 18:42:44.750: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:42:46.772: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.088435119s
    Jan 24 18:42:46.772: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:42:48.754: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.070504804s
    Jan 24 18:42:48.754: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:42:50.780: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.096752078s
    Jan 24 18:42:50.780: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:42:52.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.068605994s
    Jan 24 18:42:52.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 18:42:54.796: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.11266852s
    Jan 24 18:42:54.796: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 18:42:56.751: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.068355542s
    Jan 24 18:42:56.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 18:42:58.760: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 22.076659199s
    Jan 24 18:42:58.760: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 18:43:00.765: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 24.08182442s
    Jan 24 18:43:00.767: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 18:43:02.771: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 26.087377403s
    Jan 24 18:43:02.771: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 18:43:04.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 28.068890277s
    Jan 24 18:43:04.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 18:43:06.752: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 30.068756517s
    Jan 24 18:43:06.752: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 18:43:08.754: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 32.070634391s
    Jan 24 18:43:08.754: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jan 24 18:43:08.754: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jan 24 18:43:08.768: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-5465" to be "running and ready"
    Jan 24 18:43:08.779: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.788865ms
    Jan 24 18:43:08.780: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jan 24 18:43:08.780: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 01/24/23 18:43:08.791
    Jan 24 18:43:08.844: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-5465" to be "running"
    Jan 24 18:43:08.912: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 67.148716ms
    Jan 24 18:43:11.007: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.162402128s
    Jan 24 18:43:12.997: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.152015244s
    Jan 24 18:43:12.997: INFO: Pod "test-container-pod" satisfied condition "running"
    Jan 24 18:43:13.025: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-5465" to be "running"
    Jan 24 18:43:13.034: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.998187ms
    Jan 24 18:43:13.034: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Jan 24 18:43:13.050: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Jan 24 18:43:13.050: INFO: Going to poll 10.244.47.101 on port 8083 at least 0 times, with a maximum of 34 tries before failing
    Jan 24 18:43:13.064: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.47.101:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5465 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 18:43:13.064: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 18:43:13.071: INFO: ExecWithOptions: Clientset creation
    Jan 24 18:43:13.071: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-5465/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.47.101%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 24 18:43:13.411: INFO: Found all 1 expected endpoints: [netserver-0]
    Jan 24 18:43:13.411: INFO: Going to poll 10.244.71.251 on port 8083 at least 0 times, with a maximum of 34 tries before failing
    Jan 24 18:43:13.423: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.71.251:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5465 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 18:43:13.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 18:43:13.427: INFO: ExecWithOptions: Clientset creation
    Jan 24 18:43:13.427: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-5465/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.244.71.251%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 24 18:43:13.678: INFO: Found all 1 expected endpoints: [netserver-1]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jan 24 18:43:13.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-5465" for this suite. 01/24/23 18:43:13.703
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:43:13.763
Jan 24 18:43:13.763: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename hostport 01/24/23 18:43:13.802
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:43:13.914
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:43:13.944
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 01/24/23 18:43:14.037
Jan 24 18:43:14.088: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-4230" to be "running and ready"
Jan 24 18:43:14.123: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 34.38496ms
Jan 24 18:43:14.123: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:43:16.155: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066708123s
Jan 24 18:43:16.155: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:43:18.136: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.047507391s
Jan 24 18:43:18.136: INFO: The phase of Pod pod1 is Running (Ready = true)
Jan 24 18:43:18.136: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.10.1.127 on the node which pod1 resides and expect scheduled 01/24/23 18:43:18.136
Jan 24 18:43:18.177: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-4230" to be "running and ready"
Jan 24 18:43:18.200: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 22.118066ms
Jan 24 18:43:18.200: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:43:20.392: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.214437604s
Jan 24 18:43:20.392: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:43:22.213: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.03524574s
Jan 24 18:43:22.213: INFO: The phase of Pod pod2 is Running (Ready = true)
Jan 24 18:43:22.214: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.10.1.127 but use UDP protocol on the node which pod2 resides 01/24/23 18:43:22.215
Jan 24 18:43:22.262: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-4230" to be "running and ready"
Jan 24 18:43:22.269: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.082515ms
Jan 24 18:43:22.269: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:43:24.280: INFO: Pod "pod3": Phase="Running", Reason="", readiness=false. Elapsed: 2.017273675s
Jan 24 18:43:24.280: INFO: The phase of Pod pod3 is Running (Ready = false)
Jan 24 18:43:26.296: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.033809919s
Jan 24 18:43:26.296: INFO: The phase of Pod pod3 is Running (Ready = true)
Jan 24 18:43:26.296: INFO: Pod "pod3" satisfied condition "running and ready"
Jan 24 18:43:26.314: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-4230" to be "running and ready"
Jan 24 18:43:26.328: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 14.057382ms
Jan 24 18:43:26.328: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:43:28.356: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.041320898s
Jan 24 18:43:28.356: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Jan 24 18:43:28.356: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 01/24/23 18:43:28.366
Jan 24 18:43:28.366: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.10.1.127 http://127.0.0.1:54323/hostname] Namespace:hostport-4230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 18:43:28.367: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 18:43:28.375: INFO: ExecWithOptions: Clientset creation
Jan 24 18:43:28.375: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/hostport-4230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.10.1.127+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.10.1.127, port: 54323 01/24/23 18:43:28.598
Jan 24 18:43:28.598: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.10.1.127:54323/hostname] Namespace:hostport-4230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 18:43:28.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 18:43:28.602: INFO: ExecWithOptions: Clientset creation
Jan 24 18:43:28.602: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/hostport-4230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.10.1.127%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.10.1.127, port: 54323 UDP 01/24/23 18:43:28.785
Jan 24 18:43:28.786: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.10.1.127 54323] Namespace:hostport-4230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 18:43:28.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 18:43:28.793: INFO: ExecWithOptions: Clientset creation
Jan 24 18:43:28.793: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/hostport-4230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.10.1.127+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Jan 24 18:43:33.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-4230" for this suite. 01/24/23 18:43:34.009
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":29,"skipped":603,"failed":0}
------------------------------
• [SLOW TEST] [20.277 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:43:13.763
    Jan 24 18:43:13.763: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename hostport 01/24/23 18:43:13.802
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:43:13.914
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:43:13.944
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 01/24/23 18:43:14.037
    Jan 24 18:43:14.088: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-4230" to be "running and ready"
    Jan 24 18:43:14.123: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 34.38496ms
    Jan 24 18:43:14.123: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:43:16.155: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066708123s
    Jan 24 18:43:16.155: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:43:18.136: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.047507391s
    Jan 24 18:43:18.136: INFO: The phase of Pod pod1 is Running (Ready = true)
    Jan 24 18:43:18.136: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.10.1.127 on the node which pod1 resides and expect scheduled 01/24/23 18:43:18.136
    Jan 24 18:43:18.177: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-4230" to be "running and ready"
    Jan 24 18:43:18.200: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 22.118066ms
    Jan 24 18:43:18.200: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:43:20.392: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.214437604s
    Jan 24 18:43:20.392: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:43:22.213: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.03524574s
    Jan 24 18:43:22.213: INFO: The phase of Pod pod2 is Running (Ready = true)
    Jan 24 18:43:22.214: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.10.1.127 but use UDP protocol on the node which pod2 resides 01/24/23 18:43:22.215
    Jan 24 18:43:22.262: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-4230" to be "running and ready"
    Jan 24 18:43:22.269: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.082515ms
    Jan 24 18:43:22.269: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:43:24.280: INFO: Pod "pod3": Phase="Running", Reason="", readiness=false. Elapsed: 2.017273675s
    Jan 24 18:43:24.280: INFO: The phase of Pod pod3 is Running (Ready = false)
    Jan 24 18:43:26.296: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.033809919s
    Jan 24 18:43:26.296: INFO: The phase of Pod pod3 is Running (Ready = true)
    Jan 24 18:43:26.296: INFO: Pod "pod3" satisfied condition "running and ready"
    Jan 24 18:43:26.314: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-4230" to be "running and ready"
    Jan 24 18:43:26.328: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 14.057382ms
    Jan 24 18:43:26.328: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:43:28.356: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.041320898s
    Jan 24 18:43:28.356: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Jan 24 18:43:28.356: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 01/24/23 18:43:28.366
    Jan 24 18:43:28.366: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.10.1.127 http://127.0.0.1:54323/hostname] Namespace:hostport-4230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 18:43:28.367: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 18:43:28.375: INFO: ExecWithOptions: Clientset creation
    Jan 24 18:43:28.375: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/hostport-4230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.10.1.127+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.10.1.127, port: 54323 01/24/23 18:43:28.598
    Jan 24 18:43:28.598: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.10.1.127:54323/hostname] Namespace:hostport-4230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 18:43:28.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 18:43:28.602: INFO: ExecWithOptions: Clientset creation
    Jan 24 18:43:28.602: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/hostport-4230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.10.1.127%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.10.1.127, port: 54323 UDP 01/24/23 18:43:28.785
    Jan 24 18:43:28.786: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.10.1.127 54323] Namespace:hostport-4230 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 18:43:28.787: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 18:43:28.793: INFO: ExecWithOptions: Clientset creation
    Jan 24 18:43:28.793: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/hostport-4230/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.10.1.127+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Jan 24 18:43:33.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-4230" for this suite. 01/24/23 18:43:34.009
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:43:34.05
Jan 24 18:43:34.050: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename namespaces 01/24/23 18:43:34.08
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:43:34.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:43:34.181
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 01/24/23 18:43:34.192
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:43:34.26
STEP: Creating a pod in the namespace 01/24/23 18:43:34.279
STEP: Waiting for the pod to have running status 01/24/23 18:43:34.338
Jan 24 18:43:34.340: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-8527" to be "running"
Jan 24 18:43:34.382: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 41.270916ms
Jan 24 18:43:36.398: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057088846s
Jan 24 18:43:38.407: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.066774914s
Jan 24 18:43:38.408: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 01/24/23 18:43:38.408
STEP: Waiting for the namespace to be removed. 01/24/23 18:43:38.432
STEP: Recreating the namespace 01/24/23 18:43:50.452
STEP: Verifying there are no pods in the namespace 01/24/23 18:43:50.502
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jan 24 18:43:50.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1645" for this suite. 01/24/23 18:43:50.517
STEP: Destroying namespace "nsdeletetest-8527" for this suite. 01/24/23 18:43:50.53
Jan 24 18:43:50.540: INFO: Namespace nsdeletetest-8527 was already deleted
STEP: Destroying namespace "nsdeletetest-2508" for this suite. 01/24/23 18:43:50.54
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":30,"skipped":606,"failed":0}
------------------------------
• [SLOW TEST] [16.503 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:43:34.05
    Jan 24 18:43:34.050: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename namespaces 01/24/23 18:43:34.08
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:43:34.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:43:34.181
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 01/24/23 18:43:34.192
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:43:34.26
    STEP: Creating a pod in the namespace 01/24/23 18:43:34.279
    STEP: Waiting for the pod to have running status 01/24/23 18:43:34.338
    Jan 24 18:43:34.340: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-8527" to be "running"
    Jan 24 18:43:34.382: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 41.270916ms
    Jan 24 18:43:36.398: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057088846s
    Jan 24 18:43:38.407: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.066774914s
    Jan 24 18:43:38.408: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 01/24/23 18:43:38.408
    STEP: Waiting for the namespace to be removed. 01/24/23 18:43:38.432
    STEP: Recreating the namespace 01/24/23 18:43:50.452
    STEP: Verifying there are no pods in the namespace 01/24/23 18:43:50.502
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 18:43:50.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1645" for this suite. 01/24/23 18:43:50.517
    STEP: Destroying namespace "nsdeletetest-8527" for this suite. 01/24/23 18:43:50.53
    Jan 24 18:43:50.540: INFO: Namespace nsdeletetest-8527 was already deleted
    STEP: Destroying namespace "nsdeletetest-2508" for this suite. 01/24/23 18:43:50.54
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:43:50.612
Jan 24 18:43:50.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-webhook 01/24/23 18:43:50.618
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:43:50.7
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:43:50.75
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 01/24/23 18:43:50.827
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 01/24/23 18:43:52.915
STEP: Deploying the custom resource conversion webhook pod 01/24/23 18:43:52.956
STEP: Wait for the deployment to be ready 01/24/23 18:43:53.002
Jan 24 18:43:53.044: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Jan 24 18:43:55.103: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 43, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 43, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 43, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 43, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 18:43:57.114
STEP: Verifying the service has paired with the endpoint 01/24/23 18:43:57.18
Jan 24 18:43:58.180: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Jan 24 18:43:58.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Creating a v1 custom resource 01/24/23 18:44:01.022
STEP: Create a v2 custom resource 01/24/23 18:44:01.119
STEP: List CRs in v1 01/24/23 18:44:01.365
STEP: List CRs in v2 01/24/23 18:44:01.387
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:44:01.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5907" for this suite. 01/24/23 18:44:01.956
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":31,"skipped":671,"failed":0}
------------------------------
• [SLOW TEST] [11.655 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:43:50.612
    Jan 24 18:43:50.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-webhook 01/24/23 18:43:50.618
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:43:50.7
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:43:50.75
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 01/24/23 18:43:50.827
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 01/24/23 18:43:52.915
    STEP: Deploying the custom resource conversion webhook pod 01/24/23 18:43:52.956
    STEP: Wait for the deployment to be ready 01/24/23 18:43:53.002
    Jan 24 18:43:53.044: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Jan 24 18:43:55.103: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 43, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 43, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 43, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 43, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 18:43:57.114
    STEP: Verifying the service has paired with the endpoint 01/24/23 18:43:57.18
    Jan 24 18:43:58.180: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Jan 24 18:43:58.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Creating a v1 custom resource 01/24/23 18:44:01.022
    STEP: Create a v2 custom resource 01/24/23 18:44:01.119
    STEP: List CRs in v1 01/24/23 18:44:01.365
    STEP: List CRs in v2 01/24/23 18:44:01.387
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:44:01.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-5907" for this suite. 01/24/23 18:44:01.956
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:44:02.288
Jan 24 18:44:02.288: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sysctl 01/24/23 18:44:02.345
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:02.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:02.855
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 01/24/23 18:44:03.018
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 24 18:44:03.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-1599" for this suite. 01/24/23 18:44:03.554
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":32,"skipped":681,"failed":0}
------------------------------
• [1.732 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:44:02.288
    Jan 24 18:44:02.288: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sysctl 01/24/23 18:44:02.345
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:02.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:02.855
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 01/24/23 18:44:03.018
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 24 18:44:03.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-1599" for this suite. 01/24/23 18:44:03.554
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:44:04.235
Jan 24 18:44:04.237: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename gc 01/24/23 18:44:04.249
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:04.467
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:04.547
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Jan 24 18:44:05.066: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"1865f324-4b40-4e3f-8209-022d26676b37", Controller:(*bool)(0xc0037dc046), BlockOwnerDeletion:(*bool)(0xc0037dc047)}}
Jan 24 18:44:05.282: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"5ac1e7f0-ed6f-4b42-a822-5b6c9830daf8", Controller:(*bool)(0xc0037dc2de), BlockOwnerDeletion:(*bool)(0xc0037dc2df)}}
Jan 24 18:44:05.743: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4e2646a5-446d-4167-ae1a-56a81e9d1aba", Controller:(*bool)(0xc0037dc546), BlockOwnerDeletion:(*bool)(0xc0037dc547)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 24 18:44:10.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6700" for this suite. 01/24/23 18:44:10.884
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":33,"skipped":733,"failed":0}
------------------------------
• [SLOW TEST] [6.673 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:44:04.235
    Jan 24 18:44:04.237: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename gc 01/24/23 18:44:04.249
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:04.467
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:04.547
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Jan 24 18:44:05.066: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"1865f324-4b40-4e3f-8209-022d26676b37", Controller:(*bool)(0xc0037dc046), BlockOwnerDeletion:(*bool)(0xc0037dc047)}}
    Jan 24 18:44:05.282: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"5ac1e7f0-ed6f-4b42-a822-5b6c9830daf8", Controller:(*bool)(0xc0037dc2de), BlockOwnerDeletion:(*bool)(0xc0037dc2df)}}
    Jan 24 18:44:05.743: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"4e2646a5-446d-4167-ae1a-56a81e9d1aba", Controller:(*bool)(0xc0037dc546), BlockOwnerDeletion:(*bool)(0xc0037dc547)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 24 18:44:10.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-6700" for this suite. 01/24/23 18:44:10.884
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:44:10.913
Jan 24 18:44:10.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 18:44:10.916
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:10.978
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:11.014
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 01/24/23 18:44:11.047
Jan 24 18:44:11.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 18:44:27.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:44:52.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1443" for this suite. 01/24/23 18:44:52.364
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":34,"skipped":746,"failed":0}
------------------------------
• [SLOW TEST] [41.465 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:44:10.913
    Jan 24 18:44:10.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 18:44:10.916
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:10.978
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:11.014
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 01/24/23 18:44:11.047
    Jan 24 18:44:11.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 18:44:27.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:44:52.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1443" for this suite. 01/24/23 18:44:52.364
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:44:52.38
Jan 24 18:44:52.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename custom-resource-definition 01/24/23 18:44:52.386
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:52.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:52.416
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 01/24/23 18:44:52.426
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 01/24/23 18:44:52.429
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 01/24/23 18:44:52.43
STEP: fetching the /apis/apiextensions.k8s.io discovery document 01/24/23 18:44:52.43
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 01/24/23 18:44:52.437
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 01/24/23 18:44:52.437
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 01/24/23 18:44:52.44
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:44:52.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3366" for this suite. 01/24/23 18:44:52.456
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":35,"skipped":748,"failed":0}
------------------------------
• [0.089 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:44:52.38
    Jan 24 18:44:52.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename custom-resource-definition 01/24/23 18:44:52.386
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:52.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:52.416
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 01/24/23 18:44:52.426
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 01/24/23 18:44:52.429
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 01/24/23 18:44:52.43
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 01/24/23 18:44:52.43
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 01/24/23 18:44:52.437
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 01/24/23 18:44:52.437
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 01/24/23 18:44:52.44
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:44:52.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3366" for this suite. 01/24/23 18:44:52.456
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:44:52.475
Jan 24 18:44:52.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 18:44:52.477
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:52.508
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:52.516
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 18:44:52.555
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:44:53.49
STEP: Deploying the webhook pod 01/24/23 18:44:53.502
STEP: Wait for the deployment to be ready 01/24/23 18:44:53.519
Jan 24 18:44:53.533: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 01/24/23 18:44:55.567
STEP: Verifying the service has paired with the endpoint 01/24/23 18:44:55.595
Jan 24 18:44:56.596: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 01/24/23 18:44:56.605
STEP: create a pod that should be updated by the webhook 01/24/23 18:44:56.645
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:44:56.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4027" for this suite. 01/24/23 18:44:56.691
STEP: Destroying namespace "webhook-4027-markers" for this suite. 01/24/23 18:44:56.704
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":36,"skipped":783,"failed":0}
------------------------------
• [4.304 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:44:52.475
    Jan 24 18:44:52.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 18:44:52.477
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:52.508
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:52.516
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 18:44:52.555
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:44:53.49
    STEP: Deploying the webhook pod 01/24/23 18:44:53.502
    STEP: Wait for the deployment to be ready 01/24/23 18:44:53.519
    Jan 24 18:44:53.533: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 01/24/23 18:44:55.567
    STEP: Verifying the service has paired with the endpoint 01/24/23 18:44:55.595
    Jan 24 18:44:56.596: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 01/24/23 18:44:56.605
    STEP: create a pod that should be updated by the webhook 01/24/23 18:44:56.645
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:44:56.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4027" for this suite. 01/24/23 18:44:56.691
    STEP: Destroying namespace "webhook-4027-markers" for this suite. 01/24/23 18:44:56.704
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:44:56.796
Jan 24 18:44:56.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 18:44:56.803
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:56.845
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:56.857
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 01/24/23 18:44:56.867
Jan 24 18:44:56.880: INFO: Waiting up to 5m0s for pod "downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64" in namespace "downward-api-4662" to be "Succeeded or Failed"
Jan 24 18:44:56.902: INFO: Pod "downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64": Phase="Pending", Reason="", readiness=false. Elapsed: 21.224722ms
Jan 24 18:44:58.914: INFO: Pod "downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033541439s
Jan 24 18:45:00.910: INFO: Pod "downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029558792s
STEP: Saw pod success 01/24/23 18:45:00.91
Jan 24 18:45:00.911: INFO: Pod "downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64" satisfied condition "Succeeded or Failed"
Jan 24 18:45:00.918: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64 container dapi-container: <nil>
STEP: delete the pod 01/24/23 18:45:00.944
Jan 24 18:45:00.959: INFO: Waiting for pod downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64 to disappear
Jan 24 18:45:00.973: INFO: Pod downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jan 24 18:45:00.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4662" for this suite. 01/24/23 18:45:00.981
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":37,"skipped":805,"failed":0}
------------------------------
• [4.194 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:44:56.796
    Jan 24 18:44:56.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 18:44:56.803
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:44:56.845
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:44:56.857
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 01/24/23 18:44:56.867
    Jan 24 18:44:56.880: INFO: Waiting up to 5m0s for pod "downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64" in namespace "downward-api-4662" to be "Succeeded or Failed"
    Jan 24 18:44:56.902: INFO: Pod "downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64": Phase="Pending", Reason="", readiness=false. Elapsed: 21.224722ms
    Jan 24 18:44:58.914: INFO: Pod "downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033541439s
    Jan 24 18:45:00.910: INFO: Pod "downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029558792s
    STEP: Saw pod success 01/24/23 18:45:00.91
    Jan 24 18:45:00.911: INFO: Pod "downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64" satisfied condition "Succeeded or Failed"
    Jan 24 18:45:00.918: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64 container dapi-container: <nil>
    STEP: delete the pod 01/24/23 18:45:00.944
    Jan 24 18:45:00.959: INFO: Waiting for pod downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64 to disappear
    Jan 24 18:45:00.973: INFO: Pod downward-api-8d3c2b5d-0e99-4c98-8c8f-265b0275cc64 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jan 24 18:45:00.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4662" for this suite. 01/24/23 18:45:00.981
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:45:00.999
Jan 24 18:45:01.000: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 18:45:01.004
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:45:01.031
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:45:01.036
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-d0262dd1-5274-48e7-a85f-97195212c25c 01/24/23 18:45:01.041
STEP: Creating a pod to test consume secrets 01/24/23 18:45:01.047
Jan 24 18:45:01.070: INFO: Waiting up to 5m0s for pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4" in namespace "secrets-1878" to be "Succeeded or Failed"
Jan 24 18:45:01.076: INFO: Pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.1354ms
Jan 24 18:45:03.083: INFO: Pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4": Phase="Running", Reason="", readiness=true. Elapsed: 2.01158231s
Jan 24 18:45:05.085: INFO: Pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4": Phase="Running", Reason="", readiness=false. Elapsed: 4.013552062s
Jan 24 18:45:07.085: INFO: Pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012811873s
STEP: Saw pod success 01/24/23 18:45:07.085
Jan 24 18:45:07.085: INFO: Pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4" satisfied condition "Succeeded or Failed"
Jan 24 18:45:07.095: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4 container secret-volume-test: <nil>
STEP: delete the pod 01/24/23 18:45:07.107
Jan 24 18:45:07.133: INFO: Waiting for pod pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4 to disappear
Jan 24 18:45:07.142: INFO: Pod pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 24 18:45:07.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1878" for this suite. 01/24/23 18:45:07.154
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":38,"skipped":821,"failed":0}
------------------------------
• [SLOW TEST] [6.167 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:45:00.999
    Jan 24 18:45:01.000: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 18:45:01.004
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:45:01.031
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:45:01.036
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-d0262dd1-5274-48e7-a85f-97195212c25c 01/24/23 18:45:01.041
    STEP: Creating a pod to test consume secrets 01/24/23 18:45:01.047
    Jan 24 18:45:01.070: INFO: Waiting up to 5m0s for pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4" in namespace "secrets-1878" to be "Succeeded or Failed"
    Jan 24 18:45:01.076: INFO: Pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.1354ms
    Jan 24 18:45:03.083: INFO: Pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4": Phase="Running", Reason="", readiness=true. Elapsed: 2.01158231s
    Jan 24 18:45:05.085: INFO: Pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4": Phase="Running", Reason="", readiness=false. Elapsed: 4.013552062s
    Jan 24 18:45:07.085: INFO: Pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012811873s
    STEP: Saw pod success 01/24/23 18:45:07.085
    Jan 24 18:45:07.085: INFO: Pod "pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4" satisfied condition "Succeeded or Failed"
    Jan 24 18:45:07.095: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4 container secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 18:45:07.107
    Jan 24 18:45:07.133: INFO: Waiting for pod pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4 to disappear
    Jan 24 18:45:07.142: INFO: Pod pod-secrets-3d96ac58-636a-4e11-9498-6399c347a5c4 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 18:45:07.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1878" for this suite. 01/24/23 18:45:07.154
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:45:07.189
Jan 24 18:45:07.191: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename deployment 01/24/23 18:45:07.196
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:45:07.245
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:45:07.262
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Jan 24 18:45:07.271: INFO: Creating simple deployment test-new-deployment
Jan 24 18:45:07.329: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource 01/24/23 18:45:09.38
STEP: updating a scale subresource 01/24/23 18:45:09.394
STEP: verifying the deployment Spec.Replicas was modified 01/24/23 18:45:09.415
STEP: Patch a scale subresource 01/24/23 18:45:09.43
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 24 18:45:09.505: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-6673  7f590172-3242-4815-9637-8269b341a0e4 16869 3 2023-01-24 18:45:07 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-01-24 18:45:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00505a208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-24 18:45:09 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-01-24 18:45:09 +0000 UTC,LastTransitionTime:2023-01-24 18:45:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jan 24 18:45:09.584: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-6673  a0417850-53c0-43d1-9242-ec6ad6b90c34 16874 2 2023-01-24 18:45:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 7f590172-3242-4815-9637-8269b341a0e4 0xc004f8fb37 0xc004f8fb38}] [] [{kube-controller-manager Update apps/v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7f590172-3242-4815-9637-8269b341a0e4\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f8fbd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jan 24 18:45:09.611: INFO: Pod "test-new-deployment-845c8977d9-72c6l" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-72c6l test-new-deployment-845c8977d9- deployment-6673  8f2cb9c0-3d87-495c-b440-26fa33f71840 16864 0 2023-01-24 18:45:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:19cbe1e3f382864b7487b5bb6dad5243b1df992361ed757c2d62624af713c925 cni.projectcalico.org/podIP:10.244.71.196/32 cni.projectcalico.org/podIPs:10.244.71.196/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 a0417850-53c0-43d1-9242-ec6ad6b90c34 0xc0051700e7 0xc0051700e8}] [] [{kube-controller-manager Update v1 2023-01-24 18:45:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a0417850-53c0-43d1-9242-ec6ad6b90c34\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:45:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.196\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gqkwx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gqkwx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.196,StartTime:2023-01-24 18:45:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:45:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d8f9226fefbb7bbcccd64987f7a801b2ad9614fa146e1e61fbc30a6001f45a75,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.196,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 18:45:09.616: INFO: Pod "test-new-deployment-845c8977d9-np5wj" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-np5wj test-new-deployment-845c8977d9- deployment-6673  900f386e-cf93-4d3b-9c77-af81d7d200ea 16877 0 2023-01-24 18:45:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 a0417850-53c0-43d1-9242-ec6ad6b90c34 0xc005170397 0xc005170398}] [] [{kube-controller-manager Update v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a0417850-53c0-43d1-9242-ec6ad6b90c34\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c57w4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c57w4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:45:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 24 18:45:09.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6673" for this suite. 01/24/23 18:45:09.649
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":39,"skipped":840,"failed":0}
------------------------------
• [2.499 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:45:07.189
    Jan 24 18:45:07.191: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename deployment 01/24/23 18:45:07.196
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:45:07.245
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:45:07.262
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Jan 24 18:45:07.271: INFO: Creating simple deployment test-new-deployment
    Jan 24 18:45:07.329: INFO: deployment "test-new-deployment" doesn't have the required revision set
    STEP: getting scale subresource 01/24/23 18:45:09.38
    STEP: updating a scale subresource 01/24/23 18:45:09.394
    STEP: verifying the deployment Spec.Replicas was modified 01/24/23 18:45:09.415
    STEP: Patch a scale subresource 01/24/23 18:45:09.43
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 24 18:45:09.505: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-6673  7f590172-3242-4815-9637-8269b341a0e4 16869 3 2023-01-24 18:45:07 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-01-24 18:45:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00505a208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-24 18:45:09 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-01-24 18:45:09 +0000 UTC,LastTransitionTime:2023-01-24 18:45:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jan 24 18:45:09.584: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-6673  a0417850-53c0-43d1-9242-ec6ad6b90c34 16874 2 2023-01-24 18:45:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 7f590172-3242-4815-9637-8269b341a0e4 0xc004f8fb37 0xc004f8fb38}] [] [{kube-controller-manager Update apps/v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7f590172-3242-4815-9637-8269b341a0e4\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004f8fbd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 18:45:09.611: INFO: Pod "test-new-deployment-845c8977d9-72c6l" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-72c6l test-new-deployment-845c8977d9- deployment-6673  8f2cb9c0-3d87-495c-b440-26fa33f71840 16864 0 2023-01-24 18:45:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:19cbe1e3f382864b7487b5bb6dad5243b1df992361ed757c2d62624af713c925 cni.projectcalico.org/podIP:10.244.71.196/32 cni.projectcalico.org/podIPs:10.244.71.196/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 a0417850-53c0-43d1-9242-ec6ad6b90c34 0xc0051700e7 0xc0051700e8}] [] [{kube-controller-manager Update v1 2023-01-24 18:45:07 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a0417850-53c0-43d1-9242-ec6ad6b90c34\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 18:45:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.196\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gqkwx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gqkwx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.196,StartTime:2023-01-24 18:45:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 18:45:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://d8f9226fefbb7bbcccd64987f7a801b2ad9614fa146e1e61fbc30a6001f45a75,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.196,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 18:45:09.616: INFO: Pod "test-new-deployment-845c8977d9-np5wj" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-np5wj test-new-deployment-845c8977d9- deployment-6673  900f386e-cf93-4d3b-9c77-af81d7d200ea 16877 0 2023-01-24 18:45:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 a0417850-53c0-43d1-9242-ec6ad6b90c34 0xc005170397 0xc005170398}] [] [{kube-controller-manager Update v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a0417850-53c0-43d1-9242-ec6ad6b90c34\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 18:45:09 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c57w4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c57w4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 18:45:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:,StartTime:2023-01-24 18:45:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 24 18:45:09.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6673" for this suite. 01/24/23 18:45:09.649
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:45:09.715
Jan 24 18:45:09.716: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-watch 01/24/23 18:45:09.722
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:45:09.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:45:09.849
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Jan 24 18:45:09.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Creating first CR  01/24/23 18:45:12.687
Jan 24 18:45:12.752: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:12Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:12Z]] name:name1 resourceVersion:16912 uid:950f8d05-15e4-4b1a-a55b-76ecc27d88d2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 01/24/23 18:45:22.755
Jan 24 18:45:22.776: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:22Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:22Z]] name:name2 resourceVersion:16955 uid:fd961797-3af0-41f1-b7ed-c5316b8eae79] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 01/24/23 18:45:32.778
Jan 24 18:45:32.806: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:32Z]] name:name1 resourceVersion:16960 uid:950f8d05-15e4-4b1a-a55b-76ecc27d88d2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 01/24/23 18:45:42.822
Jan 24 18:45:42.898: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:42Z]] name:name2 resourceVersion:16966 uid:fd961797-3af0-41f1-b7ed-c5316b8eae79] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 01/24/23 18:45:52.9
Jan 24 18:45:52.913: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:32Z]] name:name1 resourceVersion:16972 uid:950f8d05-15e4-4b1a-a55b-76ecc27d88d2] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 01/24/23 18:46:02.916
Jan 24 18:46:02.930: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:42Z]] name:name2 resourceVersion:16977 uid:fd961797-3af0-41f1-b7ed-c5316b8eae79] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:46:13.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-5765" for this suite. 01/24/23 18:46:13.502
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":40,"skipped":857,"failed":0}
------------------------------
• [SLOW TEST] [63.817 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:45:09.715
    Jan 24 18:45:09.716: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-watch 01/24/23 18:45:09.722
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:45:09.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:45:09.849
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Jan 24 18:45:09.863: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Creating first CR  01/24/23 18:45:12.687
    Jan 24 18:45:12.752: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:12Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:12Z]] name:name1 resourceVersion:16912 uid:950f8d05-15e4-4b1a-a55b-76ecc27d88d2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 01/24/23 18:45:22.755
    Jan 24 18:45:22.776: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:22Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:22Z]] name:name2 resourceVersion:16955 uid:fd961797-3af0-41f1-b7ed-c5316b8eae79] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 01/24/23 18:45:32.778
    Jan 24 18:45:32.806: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:32Z]] name:name1 resourceVersion:16960 uid:950f8d05-15e4-4b1a-a55b-76ecc27d88d2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 01/24/23 18:45:42.822
    Jan 24 18:45:42.898: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:42Z]] name:name2 resourceVersion:16966 uid:fd961797-3af0-41f1-b7ed-c5316b8eae79] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 01/24/23 18:45:52.9
    Jan 24 18:45:52.913: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:12Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:32Z]] name:name1 resourceVersion:16972 uid:950f8d05-15e4-4b1a-a55b-76ecc27d88d2] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 01/24/23 18:46:02.916
    Jan 24 18:46:02.930: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-01-24T18:45:22Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-01-24T18:45:42Z]] name:name2 resourceVersion:16977 uid:fd961797-3af0-41f1-b7ed-c5316b8eae79] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:46:13.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-5765" for this suite. 01/24/23 18:46:13.502
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:46:13.533
Jan 24 18:46:13.533: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 18:46:13.545
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:46:13.608
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:46:13.628
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-d5441ad6-74bf-4a5d-9510-0c25fd06fd50 01/24/23 18:46:13.675
STEP: Creating secret with name s-test-opt-upd-a40b6f8f-13ab-437e-b628-76f8f1378c9f 01/24/23 18:46:13.695
STEP: Creating the pod 01/24/23 18:46:13.726
Jan 24 18:46:13.897: INFO: Waiting up to 5m0s for pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1" in namespace "secrets-5661" to be "running and ready"
Jan 24 18:46:14.015: INFO: Pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1": Phase="Pending", Reason="", readiness=false. Elapsed: 110.303016ms
Jan 24 18:46:14.015: INFO: The phase of Pod pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:46:16.041: INFO: Pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.13665544s
Jan 24 18:46:16.042: INFO: The phase of Pod pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:46:18.035: INFO: Pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.129808319s
Jan 24 18:46:18.035: INFO: The phase of Pod pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:46:20.030: INFO: Pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1": Phase="Running", Reason="", readiness=true. Elapsed: 6.125559475s
Jan 24 18:46:20.030: INFO: The phase of Pod pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1 is Running (Ready = true)
Jan 24 18:46:20.030: INFO: Pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-d5441ad6-74bf-4a5d-9510-0c25fd06fd50 01/24/23 18:46:20.139
STEP: Updating secret s-test-opt-upd-a40b6f8f-13ab-437e-b628-76f8f1378c9f 01/24/23 18:46:20.166
STEP: Creating secret with name s-test-opt-create-9712f0cb-b856-4b7c-a53c-c237869ace50 01/24/23 18:46:20.222
STEP: waiting to observe update in volume 01/24/23 18:46:20.245
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 24 18:47:49.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5661" for this suite. 01/24/23 18:47:49.955
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":41,"skipped":858,"failed":0}
------------------------------
• [SLOW TEST] [96.446 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:46:13.533
    Jan 24 18:46:13.533: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 18:46:13.545
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:46:13.608
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:46:13.628
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-d5441ad6-74bf-4a5d-9510-0c25fd06fd50 01/24/23 18:46:13.675
    STEP: Creating secret with name s-test-opt-upd-a40b6f8f-13ab-437e-b628-76f8f1378c9f 01/24/23 18:46:13.695
    STEP: Creating the pod 01/24/23 18:46:13.726
    Jan 24 18:46:13.897: INFO: Waiting up to 5m0s for pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1" in namespace "secrets-5661" to be "running and ready"
    Jan 24 18:46:14.015: INFO: Pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1": Phase="Pending", Reason="", readiness=false. Elapsed: 110.303016ms
    Jan 24 18:46:14.015: INFO: The phase of Pod pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:46:16.041: INFO: Pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.13665544s
    Jan 24 18:46:16.042: INFO: The phase of Pod pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:46:18.035: INFO: Pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.129808319s
    Jan 24 18:46:18.035: INFO: The phase of Pod pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:46:20.030: INFO: Pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1": Phase="Running", Reason="", readiness=true. Elapsed: 6.125559475s
    Jan 24 18:46:20.030: INFO: The phase of Pod pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1 is Running (Ready = true)
    Jan 24 18:46:20.030: INFO: Pod "pod-secrets-2d0b7366-2033-49e0-ad4d-e730d6e106a1" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-d5441ad6-74bf-4a5d-9510-0c25fd06fd50 01/24/23 18:46:20.139
    STEP: Updating secret s-test-opt-upd-a40b6f8f-13ab-437e-b628-76f8f1378c9f 01/24/23 18:46:20.166
    STEP: Creating secret with name s-test-opt-create-9712f0cb-b856-4b7c-a53c-c237869ace50 01/24/23 18:46:20.222
    STEP: waiting to observe update in volume 01/24/23 18:46:20.245
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 18:47:49.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5661" for this suite. 01/24/23 18:47:49.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:47:49.98
Jan 24 18:47:49.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename containers 01/24/23 18:47:49.983
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:47:50.06
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:47:50.081
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 01/24/23 18:47:50.099
Jan 24 18:47:50.122: INFO: Waiting up to 5m0s for pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc" in namespace "containers-9994" to be "Succeeded or Failed"
Jan 24 18:47:50.159: INFO: Pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc": Phase="Pending", Reason="", readiness=false. Elapsed: 37.626997ms
Jan 24 18:47:52.187: INFO: Pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065822886s
Jan 24 18:47:54.197: INFO: Pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075464433s
Jan 24 18:47:56.251: INFO: Pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.129036343s
STEP: Saw pod success 01/24/23 18:47:56.251
Jan 24 18:47:56.251: INFO: Pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc" satisfied condition "Succeeded or Failed"
Jan 24 18:47:56.276: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc container agnhost-container: <nil>
STEP: delete the pod 01/24/23 18:47:56.386
Jan 24 18:47:56.479: INFO: Waiting for pod client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc to disappear
Jan 24 18:47:56.518: INFO: Pod client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jan 24 18:47:56.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9994" for this suite. 01/24/23 18:47:56.572
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":42,"skipped":865,"failed":0}
------------------------------
• [SLOW TEST] [6.609 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:47:49.98
    Jan 24 18:47:49.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename containers 01/24/23 18:47:49.983
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:47:50.06
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:47:50.081
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 01/24/23 18:47:50.099
    Jan 24 18:47:50.122: INFO: Waiting up to 5m0s for pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc" in namespace "containers-9994" to be "Succeeded or Failed"
    Jan 24 18:47:50.159: INFO: Pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc": Phase="Pending", Reason="", readiness=false. Elapsed: 37.626997ms
    Jan 24 18:47:52.187: INFO: Pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065822886s
    Jan 24 18:47:54.197: INFO: Pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075464433s
    Jan 24 18:47:56.251: INFO: Pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.129036343s
    STEP: Saw pod success 01/24/23 18:47:56.251
    Jan 24 18:47:56.251: INFO: Pod "client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc" satisfied condition "Succeeded or Failed"
    Jan 24 18:47:56.276: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 18:47:56.386
    Jan 24 18:47:56.479: INFO: Waiting for pod client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc to disappear
    Jan 24 18:47:56.518: INFO: Pod client-containers-dd31ec69-c1e7-4731-9ac6-a3c6804ed5cc no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jan 24 18:47:56.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-9994" for this suite. 01/24/23 18:47:56.572
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:47:56.647
Jan 24 18:47:56.648: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename cronjob 01/24/23 18:47:56.658
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:47:56.743
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:47:56.759
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 01/24/23 18:47:56.777
STEP: Ensuring more than one job is running at a time 01/24/23 18:47:56.805
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 01/24/23 18:49:00.827
STEP: Removing cronjob 01/24/23 18:49:00.837
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jan 24 18:49:00.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9332" for this suite. 01/24/23 18:49:01.027
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":43,"skipped":885,"failed":0}
------------------------------
• [SLOW TEST] [64.422 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:47:56.647
    Jan 24 18:47:56.648: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename cronjob 01/24/23 18:47:56.658
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:47:56.743
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:47:56.759
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 01/24/23 18:47:56.777
    STEP: Ensuring more than one job is running at a time 01/24/23 18:47:56.805
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 01/24/23 18:49:00.827
    STEP: Removing cronjob 01/24/23 18:49:00.837
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jan 24 18:49:00.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9332" for this suite. 01/24/23 18:49:01.027
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:49:01.146
Jan 24 18:49:01.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 18:49:01.181
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:01.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:01.416
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 01/24/23 18:49:01.486
STEP: waiting for available Endpoint 01/24/23 18:49:01.547
STEP: listing all Endpoints 01/24/23 18:49:01.554
STEP: updating the Endpoint 01/24/23 18:49:01.586
STEP: fetching the Endpoint 01/24/23 18:49:01.618
STEP: patching the Endpoint 01/24/23 18:49:01.681
STEP: fetching the Endpoint 01/24/23 18:49:01.763
STEP: deleting the Endpoint by Collection 01/24/23 18:49:01.786
STEP: waiting for Endpoint deletion 01/24/23 18:49:01.816
STEP: fetching the Endpoint 01/24/23 18:49:01.827
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 18:49:01.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4187" for this suite. 01/24/23 18:49:01.888
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":44,"skipped":892,"failed":0}
------------------------------
• [0.759 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:49:01.146
    Jan 24 18:49:01.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 18:49:01.181
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:01.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:01.416
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 01/24/23 18:49:01.486
    STEP: waiting for available Endpoint 01/24/23 18:49:01.547
    STEP: listing all Endpoints 01/24/23 18:49:01.554
    STEP: updating the Endpoint 01/24/23 18:49:01.586
    STEP: fetching the Endpoint 01/24/23 18:49:01.618
    STEP: patching the Endpoint 01/24/23 18:49:01.681
    STEP: fetching the Endpoint 01/24/23 18:49:01.763
    STEP: deleting the Endpoint by Collection 01/24/23 18:49:01.786
    STEP: waiting for Endpoint deletion 01/24/23 18:49:01.816
    STEP: fetching the Endpoint 01/24/23 18:49:01.827
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 18:49:01.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4187" for this suite. 01/24/23 18:49:01.888
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:49:01.906
Jan 24 18:49:01.908: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 18:49:01.941
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:02
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:02.015
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-626dbf6f-3807-44c8-a7ba-3851de28a8bb 01/24/23 18:49:02.027
STEP: Creating a pod to test consume configMaps 01/24/23 18:49:02.046
Jan 24 18:49:02.100: INFO: Waiting up to 5m0s for pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384" in namespace "configmap-3612" to be "Succeeded or Failed"
Jan 24 18:49:02.159: INFO: Pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384": Phase="Pending", Reason="", readiness=false. Elapsed: 58.931731ms
Jan 24 18:49:04.183: INFO: Pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083343045s
Jan 24 18:49:06.212: INFO: Pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384": Phase="Pending", Reason="", readiness=false. Elapsed: 4.111863073s
Jan 24 18:49:08.180: INFO: Pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.080524095s
STEP: Saw pod success 01/24/23 18:49:08.181
Jan 24 18:49:08.181: INFO: Pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384" satisfied condition "Succeeded or Failed"
Jan 24 18:49:08.190: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 18:49:08.2
Jan 24 18:49:08.227: INFO: Waiting for pod pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384 to disappear
Jan 24 18:49:08.236: INFO: Pod pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 18:49:08.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3612" for this suite. 01/24/23 18:49:08.244
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":45,"skipped":896,"failed":0}
------------------------------
• [SLOW TEST] [6.354 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:49:01.906
    Jan 24 18:49:01.908: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 18:49:01.941
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:02
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:02.015
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-626dbf6f-3807-44c8-a7ba-3851de28a8bb 01/24/23 18:49:02.027
    STEP: Creating a pod to test consume configMaps 01/24/23 18:49:02.046
    Jan 24 18:49:02.100: INFO: Waiting up to 5m0s for pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384" in namespace "configmap-3612" to be "Succeeded or Failed"
    Jan 24 18:49:02.159: INFO: Pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384": Phase="Pending", Reason="", readiness=false. Elapsed: 58.931731ms
    Jan 24 18:49:04.183: INFO: Pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083343045s
    Jan 24 18:49:06.212: INFO: Pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384": Phase="Pending", Reason="", readiness=false. Elapsed: 4.111863073s
    Jan 24 18:49:08.180: INFO: Pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.080524095s
    STEP: Saw pod success 01/24/23 18:49:08.181
    Jan 24 18:49:08.181: INFO: Pod "pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384" satisfied condition "Succeeded or Failed"
    Jan 24 18:49:08.190: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 18:49:08.2
    Jan 24 18:49:08.227: INFO: Waiting for pod pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384 to disappear
    Jan 24 18:49:08.236: INFO: Pod pod-configmaps-d6e5e9ab-f3df-456d-bf2a-6e1b3b6e4384 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 18:49:08.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3612" for this suite. 01/24/23 18:49:08.244
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:49:08.272
Jan 24 18:49:08.272: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 18:49:08.276
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:08.321
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:08.328
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 01/24/23 18:49:08.339
Jan 24 18:49:08.358: INFO: Waiting up to 5m0s for pod "downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec" in namespace "projected-9742" to be "Succeeded or Failed"
Jan 24 18:49:08.368: INFO: Pod "downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec": Phase="Pending", Reason="", readiness=false. Elapsed: 10.011562ms
Jan 24 18:49:10.375: INFO: Pod "downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016701121s
Jan 24 18:49:12.376: INFO: Pod "downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017883893s
STEP: Saw pod success 01/24/23 18:49:12.377
Jan 24 18:49:12.382: INFO: Pod "downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec" satisfied condition "Succeeded or Failed"
Jan 24 18:49:12.390: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec container client-container: <nil>
STEP: delete the pod 01/24/23 18:49:12.398
Jan 24 18:49:12.417: INFO: Waiting for pod downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec to disappear
Jan 24 18:49:12.422: INFO: Pod downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 18:49:12.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9742" for this suite. 01/24/23 18:49:12.43
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":46,"skipped":913,"failed":0}
------------------------------
• [4.167 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:49:08.272
    Jan 24 18:49:08.272: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 18:49:08.276
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:08.321
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:08.328
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 01/24/23 18:49:08.339
    Jan 24 18:49:08.358: INFO: Waiting up to 5m0s for pod "downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec" in namespace "projected-9742" to be "Succeeded or Failed"
    Jan 24 18:49:08.368: INFO: Pod "downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec": Phase="Pending", Reason="", readiness=false. Elapsed: 10.011562ms
    Jan 24 18:49:10.375: INFO: Pod "downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016701121s
    Jan 24 18:49:12.376: INFO: Pod "downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017883893s
    STEP: Saw pod success 01/24/23 18:49:12.377
    Jan 24 18:49:12.382: INFO: Pod "downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec" satisfied condition "Succeeded or Failed"
    Jan 24 18:49:12.390: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec container client-container: <nil>
    STEP: delete the pod 01/24/23 18:49:12.398
    Jan 24 18:49:12.417: INFO: Waiting for pod downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec to disappear
    Jan 24 18:49:12.422: INFO: Pod downwardapi-volume-224a537d-df92-460f-b5c3-793aeab1e4ec no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 18:49:12.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9742" for this suite. 01/24/23 18:49:12.43
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:49:12.459
Jan 24 18:49:12.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replication-controller 01/24/23 18:49:12.464
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:12.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:12.496
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 01/24/23 18:49:12.503
Jan 24 18:49:12.521: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-5366" to be "running and ready"
Jan 24 18:49:12.533: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 11.877098ms
Jan 24 18:49:12.533: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:49:14.556: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.035027147s
Jan 24 18:49:14.556: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Jan 24 18:49:14.556: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 01/24/23 18:49:14.573
STEP: Then the orphan pod is adopted 01/24/23 18:49:14.599
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jan 24 18:49:14.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5366" for this suite. 01/24/23 18:49:14.634
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":47,"skipped":926,"failed":0}
------------------------------
• [2.190 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:49:12.459
    Jan 24 18:49:12.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replication-controller 01/24/23 18:49:12.464
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:12.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:12.496
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 01/24/23 18:49:12.503
    Jan 24 18:49:12.521: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-5366" to be "running and ready"
    Jan 24 18:49:12.533: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 11.877098ms
    Jan 24 18:49:12.533: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:49:14.556: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.035027147s
    Jan 24 18:49:14.556: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Jan 24 18:49:14.556: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 01/24/23 18:49:14.573
    STEP: Then the orphan pod is adopted 01/24/23 18:49:14.599
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jan 24 18:49:14.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-5366" for this suite. 01/24/23 18:49:14.634
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:49:14.653
Jan 24 18:49:14.653: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 18:49:14.659
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:14.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:14.7
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 01/24/23 18:49:14.724
STEP: Creating a ResourceQuota 01/24/23 18:49:19.731
STEP: Ensuring resource quota status is calculated 01/24/23 18:49:19.75
STEP: Creating a Pod that fits quota 01/24/23 18:49:21.759
STEP: Ensuring ResourceQuota status captures the pod usage 01/24/23 18:49:21.8
STEP: Not allowing a pod to be created that exceeds remaining quota 01/24/23 18:49:23.813
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 01/24/23 18:49:23.823
STEP: Ensuring a pod cannot update its resource requirements 01/24/23 18:49:23.834
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 01/24/23 18:49:23.846
STEP: Deleting the pod 01/24/23 18:49:25.855
STEP: Ensuring resource quota status released the pod usage 01/24/23 18:49:25.887
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 18:49:27.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2943" for this suite. 01/24/23 18:49:27.91
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":48,"skipped":957,"failed":0}
------------------------------
• [SLOW TEST] [13.270 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:49:14.653
    Jan 24 18:49:14.653: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 18:49:14.659
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:14.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:14.7
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 01/24/23 18:49:14.724
    STEP: Creating a ResourceQuota 01/24/23 18:49:19.731
    STEP: Ensuring resource quota status is calculated 01/24/23 18:49:19.75
    STEP: Creating a Pod that fits quota 01/24/23 18:49:21.759
    STEP: Ensuring ResourceQuota status captures the pod usage 01/24/23 18:49:21.8
    STEP: Not allowing a pod to be created that exceeds remaining quota 01/24/23 18:49:23.813
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 01/24/23 18:49:23.823
    STEP: Ensuring a pod cannot update its resource requirements 01/24/23 18:49:23.834
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 01/24/23 18:49:23.846
    STEP: Deleting the pod 01/24/23 18:49:25.855
    STEP: Ensuring resource quota status released the pod usage 01/24/23 18:49:25.887
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 18:49:27.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2943" for this suite. 01/24/23 18:49:27.91
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:49:27.944
Jan 24 18:49:27.947: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 18:49:27.951
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:27.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:28.006
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 18:49:28.092
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:49:31.618
STEP: Deploying the webhook pod 01/24/23 18:49:31.645
STEP: Wait for the deployment to be ready 01/24/23 18:49:31.669
Jan 24 18:49:31.683: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Jan 24 18:49:33.738: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 49, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 49, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 49, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 49, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 18:49:35.752
STEP: Verifying the service has paired with the endpoint 01/24/23 18:49:35.792
Jan 24 18:49:36.793: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 01/24/23 18:49:36.805
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 01/24/23 18:49:36.855
STEP: Creating a dummy validating-webhook-configuration object 01/24/23 18:49:36.899
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 01/24/23 18:49:36.926
STEP: Creating a dummy mutating-webhook-configuration object 01/24/23 18:49:36.96
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 01/24/23 18:49:36.998
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:49:37.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3414" for this suite. 01/24/23 18:49:37.084
STEP: Destroying namespace "webhook-3414-markers" for this suite. 01/24/23 18:49:37.11
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":49,"skipped":992,"failed":0}
------------------------------
• [SLOW TEST] [9.333 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:49:27.944
    Jan 24 18:49:27.947: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 18:49:27.951
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:27.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:28.006
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 18:49:28.092
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:49:31.618
    STEP: Deploying the webhook pod 01/24/23 18:49:31.645
    STEP: Wait for the deployment to be ready 01/24/23 18:49:31.669
    Jan 24 18:49:31.683: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Jan 24 18:49:33.738: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 49, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 49, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 49, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 49, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 18:49:35.752
    STEP: Verifying the service has paired with the endpoint 01/24/23 18:49:35.792
    Jan 24 18:49:36.793: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 01/24/23 18:49:36.805
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 01/24/23 18:49:36.855
    STEP: Creating a dummy validating-webhook-configuration object 01/24/23 18:49:36.899
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 01/24/23 18:49:36.926
    STEP: Creating a dummy mutating-webhook-configuration object 01/24/23 18:49:36.96
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 01/24/23 18:49:36.998
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:49:37.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3414" for this suite. 01/24/23 18:49:37.084
    STEP: Destroying namespace "webhook-3414-markers" for this suite. 01/24/23 18:49:37.11
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:49:37.33
Jan 24 18:49:37.330: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename security-context-test 01/24/23 18:49:37.333
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:37.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:37.396
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Jan 24 18:49:37.442: INFO: Waiting up to 5m0s for pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f" in namespace "security-context-test-8320" to be "Succeeded or Failed"
Jan 24 18:49:37.459: INFO: Pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.623866ms
Jan 24 18:49:39.469: INFO: Pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025606856s
Jan 24 18:49:41.497: INFO: Pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f": Phase="Running", Reason="", readiness=false. Elapsed: 4.053186375s
Jan 24 18:49:43.473: INFO: Pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029800944s
Jan 24 18:49:43.473: INFO: Pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 24 18:49:43.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8320" for this suite. 01/24/23 18:49:43.485
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":50,"skipped":1018,"failed":0}
------------------------------
• [SLOW TEST] [6.167 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:49:37.33
    Jan 24 18:49:37.330: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename security-context-test 01/24/23 18:49:37.333
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:37.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:37.396
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Jan 24 18:49:37.442: INFO: Waiting up to 5m0s for pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f" in namespace "security-context-test-8320" to be "Succeeded or Failed"
    Jan 24 18:49:37.459: INFO: Pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.623866ms
    Jan 24 18:49:39.469: INFO: Pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025606856s
    Jan 24 18:49:41.497: INFO: Pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f": Phase="Running", Reason="", readiness=false. Elapsed: 4.053186375s
    Jan 24 18:49:43.473: INFO: Pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029800944s
    Jan 24 18:49:43.473: INFO: Pod "busybox-user-65534-268320ec-f24b-4272-aaea-9e32039aea0f" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 24 18:49:43.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-8320" for this suite. 01/24/23 18:49:43.485
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:49:43.513
Jan 24 18:49:43.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 18:49:43.52
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:43.6
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:43.624
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 01/24/23 18:49:43.637
Jan 24 18:49:43.674: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5" in namespace "downward-api-5841" to be "Succeeded or Failed"
Jan 24 18:49:43.701: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 27.278793ms
Jan 24 18:49:45.715: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041131563s
Jan 24 18:49:47.715: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040855526s
Jan 24 18:49:49.715: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041629189s
Jan 24 18:49:51.717: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.043464431s
STEP: Saw pod success 01/24/23 18:49:51.717
Jan 24 18:49:51.718: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5" satisfied condition "Succeeded or Failed"
Jan 24 18:49:51.735: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5 container client-container: <nil>
STEP: delete the pod 01/24/23 18:49:51.778
Jan 24 18:49:51.839: INFO: Waiting for pod downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5 to disappear
Jan 24 18:49:51.851: INFO: Pod downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 18:49:51.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5841" for this suite. 01/24/23 18:49:51.865
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":51,"skipped":1029,"failed":0}
------------------------------
• [SLOW TEST] [8.391 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:49:43.513
    Jan 24 18:49:43.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 18:49:43.52
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:43.6
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:43.624
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 01/24/23 18:49:43.637
    Jan 24 18:49:43.674: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5" in namespace "downward-api-5841" to be "Succeeded or Failed"
    Jan 24 18:49:43.701: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 27.278793ms
    Jan 24 18:49:45.715: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041131563s
    Jan 24 18:49:47.715: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040855526s
    Jan 24 18:49:49.715: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041629189s
    Jan 24 18:49:51.717: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.043464431s
    STEP: Saw pod success 01/24/23 18:49:51.717
    Jan 24 18:49:51.718: INFO: Pod "downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5" satisfied condition "Succeeded or Failed"
    Jan 24 18:49:51.735: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5 container client-container: <nil>
    STEP: delete the pod 01/24/23 18:49:51.778
    Jan 24 18:49:51.839: INFO: Waiting for pod downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5 to disappear
    Jan 24 18:49:51.851: INFO: Pod downwardapi-volume-72bf0010-d596-437f-8fc6-f1df84ebdaf5 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 18:49:51.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5841" for this suite. 01/24/23 18:49:51.865
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:49:51.922
Jan 24 18:49:51.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 18:49:51.938
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:51.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:52.016
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 01/24/23 18:49:52.03
STEP: Creating a ResourceQuota 01/24/23 18:49:57.037
STEP: Ensuring resource quota status is calculated 01/24/23 18:49:57.076
STEP: Creating a ReplicationController 01/24/23 18:49:59.097
STEP: Ensuring resource quota status captures replication controller creation 01/24/23 18:49:59.226
STEP: Deleting a ReplicationController 01/24/23 18:50:01.239
STEP: Ensuring resource quota status released usage 01/24/23 18:50:01.297
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 18:50:03.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2687" for this suite. 01/24/23 18:50:03.357
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":52,"skipped":1045,"failed":0}
------------------------------
• [SLOW TEST] [11.479 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:49:51.922
    Jan 24 18:49:51.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 18:49:51.938
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:49:51.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:49:52.016
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 01/24/23 18:49:52.03
    STEP: Creating a ResourceQuota 01/24/23 18:49:57.037
    STEP: Ensuring resource quota status is calculated 01/24/23 18:49:57.076
    STEP: Creating a ReplicationController 01/24/23 18:49:59.097
    STEP: Ensuring resource quota status captures replication controller creation 01/24/23 18:49:59.226
    STEP: Deleting a ReplicationController 01/24/23 18:50:01.239
    STEP: Ensuring resource quota status released usage 01/24/23 18:50:01.297
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 18:50:03.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2687" for this suite. 01/24/23 18:50:03.357
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:50:03.402
Jan 24 18:50:03.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 18:50:03.436
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:50:03.492
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:50:03.502
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 18:50:03.58
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:50:07.334
STEP: Deploying the webhook pod 01/24/23 18:50:07.358
STEP: Wait for the deployment to be ready 01/24/23 18:50:07.407
Jan 24 18:50:07.450: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 24 18:50:09.609: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 50, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 50, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 50, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 50, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 18:50:11.619
STEP: Verifying the service has paired with the endpoint 01/24/23 18:50:11.669
Jan 24 18:50:12.682: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 01/24/23 18:50:12.77
STEP: create a pod that should be denied by the webhook 01/24/23 18:50:12.838
STEP: create a pod that causes the webhook to hang 01/24/23 18:50:12.929
STEP: create a configmap that should be denied by the webhook 01/24/23 18:50:22.988
STEP: create a configmap that should be admitted by the webhook 01/24/23 18:50:23.056
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 01/24/23 18:50:23.091
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 01/24/23 18:50:23.167
STEP: create a namespace that bypass the webhook 01/24/23 18:50:23.218
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 01/24/23 18:50:23.311
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:50:23.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8938" for this suite. 01/24/23 18:50:23.417
STEP: Destroying namespace "webhook-8938-markers" for this suite. 01/24/23 18:50:23.434
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":53,"skipped":1046,"failed":0}
------------------------------
• [SLOW TEST] [20.246 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:50:03.402
    Jan 24 18:50:03.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 18:50:03.436
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:50:03.492
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:50:03.502
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 18:50:03.58
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:50:07.334
    STEP: Deploying the webhook pod 01/24/23 18:50:07.358
    STEP: Wait for the deployment to be ready 01/24/23 18:50:07.407
    Jan 24 18:50:07.450: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 24 18:50:09.609: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 50, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 50, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 50, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 50, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 18:50:11.619
    STEP: Verifying the service has paired with the endpoint 01/24/23 18:50:11.669
    Jan 24 18:50:12.682: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 01/24/23 18:50:12.77
    STEP: create a pod that should be denied by the webhook 01/24/23 18:50:12.838
    STEP: create a pod that causes the webhook to hang 01/24/23 18:50:12.929
    STEP: create a configmap that should be denied by the webhook 01/24/23 18:50:22.988
    STEP: create a configmap that should be admitted by the webhook 01/24/23 18:50:23.056
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 01/24/23 18:50:23.091
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 01/24/23 18:50:23.167
    STEP: create a namespace that bypass the webhook 01/24/23 18:50:23.218
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 01/24/23 18:50:23.311
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:50:23.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8938" for this suite. 01/24/23 18:50:23.417
    STEP: Destroying namespace "webhook-8938-markers" for this suite. 01/24/23 18:50:23.434
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:50:23.74
Jan 24 18:50:23.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename statefulset 01/24/23 18:50:23.818
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:50:24.009
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:50:24.019
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1946 01/24/23 18:50:24.047
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 01/24/23 18:50:24.068
STEP: Creating stateful set ss in namespace statefulset-1946 01/24/23 18:50:24.127
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1946 01/24/23 18:50:24.148
Jan 24 18:50:24.175: INFO: Found 0 stateful pods, waiting for 1
Jan 24 18:50:34.198: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 01/24/23 18:50:34.198
Jan 24 18:50:34.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 24 18:50:34.992: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 24 18:50:34.992: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 24 18:50:34.992: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 24 18:50:35.008: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 24 18:50:45.035: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 24 18:50:45.038: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 18:50:45.116: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999136s
Jan 24 18:50:46.153: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.987212557s
Jan 24 18:50:47.171: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.949995687s
Jan 24 18:50:48.218: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.920697316s
Jan 24 18:50:49.229: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.885005595s
Jan 24 18:50:50.255: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.869371383s
Jan 24 18:50:51.315: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.845561078s
Jan 24 18:50:52.332: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.788299013s
Jan 24 18:50:53.348: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.766731752s
Jan 24 18:50:54.365: INFO: Verifying statefulset ss doesn't scale past 1 for another 753.980468ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1946 01/24/23 18:50:55.366
Jan 24 18:50:55.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 24 18:50:56.092: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 24 18:50:56.092: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 24 18:50:56.092: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 24 18:50:56.119: INFO: Found 1 stateful pods, waiting for 3
Jan 24 18:51:06.203: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 18:51:06.203: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 18:51:06.203: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 01/24/23 18:51:06.203
STEP: Scale down will halt with unhealthy stateful pod 01/24/23 18:51:06.239
Jan 24 18:51:06.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 24 18:51:06.838: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 24 18:51:06.838: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 24 18:51:06.838: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 24 18:51:06.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 24 18:51:07.240: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 24 18:51:07.240: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 24 18:51:07.240: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 24 18:51:07.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 24 18:51:07.585: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 24 18:51:07.585: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 24 18:51:07.585: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 24 18:51:07.585: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 18:51:07.592: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jan 24 18:51:17.628: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 24 18:51:17.628: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 24 18:51:17.629: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 24 18:51:17.730: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998976s
Jan 24 18:51:18.749: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.953667266s
Jan 24 18:51:19.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.93490711s
Jan 24 18:51:20.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.914751547s
Jan 24 18:51:21.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.881736879s
Jan 24 18:51:22.862: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.856995237s
Jan 24 18:51:23.879: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.820793342s
Jan 24 18:51:24.930: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.799101747s
Jan 24 18:51:25.960: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.752327329s
Jan 24 18:51:26.977: INFO: Verifying statefulset ss doesn't scale past 3 for another 718.228029ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1946 01/24/23 18:51:27.977
Jan 24 18:51:27.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 24 18:51:28.751: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 24 18:51:28.751: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 24 18:51:28.751: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 24 18:51:28.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 24 18:51:29.496: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 24 18:51:29.496: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 24 18:51:29.496: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 24 18:51:29.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 24 18:51:30.386: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 24 18:51:30.386: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 24 18:51:30.386: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 24 18:51:30.386: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 01/24/23 18:51:40.603
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 24 18:51:40.605: INFO: Deleting all statefulset in ns statefulset-1946
Jan 24 18:51:40.621: INFO: Scaling statefulset ss to 0
Jan 24 18:51:40.671: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 18:51:40.681: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 24 18:51:40.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1946" for this suite. 01/24/23 18:51:40.799
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":54,"skipped":1060,"failed":0}
------------------------------
• [SLOW TEST] [77.086 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:50:23.74
    Jan 24 18:50:23.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename statefulset 01/24/23 18:50:23.818
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:50:24.009
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:50:24.019
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1946 01/24/23 18:50:24.047
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 01/24/23 18:50:24.068
    STEP: Creating stateful set ss in namespace statefulset-1946 01/24/23 18:50:24.127
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1946 01/24/23 18:50:24.148
    Jan 24 18:50:24.175: INFO: Found 0 stateful pods, waiting for 1
    Jan 24 18:50:34.198: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 01/24/23 18:50:34.198
    Jan 24 18:50:34.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 24 18:50:34.992: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 24 18:50:34.992: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 24 18:50:34.992: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 24 18:50:35.008: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Jan 24 18:50:45.035: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jan 24 18:50:45.038: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 18:50:45.116: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999136s
    Jan 24 18:50:46.153: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.987212557s
    Jan 24 18:50:47.171: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.949995687s
    Jan 24 18:50:48.218: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.920697316s
    Jan 24 18:50:49.229: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.885005595s
    Jan 24 18:50:50.255: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.869371383s
    Jan 24 18:50:51.315: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.845561078s
    Jan 24 18:50:52.332: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.788299013s
    Jan 24 18:50:53.348: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.766731752s
    Jan 24 18:50:54.365: INFO: Verifying statefulset ss doesn't scale past 1 for another 753.980468ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1946 01/24/23 18:50:55.366
    Jan 24 18:50:55.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 24 18:50:56.092: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 24 18:50:56.092: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 24 18:50:56.092: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 24 18:50:56.119: INFO: Found 1 stateful pods, waiting for 3
    Jan 24 18:51:06.203: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 18:51:06.203: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 18:51:06.203: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 01/24/23 18:51:06.203
    STEP: Scale down will halt with unhealthy stateful pod 01/24/23 18:51:06.239
    Jan 24 18:51:06.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 24 18:51:06.838: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 24 18:51:06.838: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 24 18:51:06.838: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 24 18:51:06.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 24 18:51:07.240: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 24 18:51:07.240: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 24 18:51:07.240: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 24 18:51:07.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 24 18:51:07.585: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 24 18:51:07.585: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 24 18:51:07.585: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 24 18:51:07.585: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 18:51:07.592: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Jan 24 18:51:17.628: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jan 24 18:51:17.628: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Jan 24 18:51:17.629: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Jan 24 18:51:17.730: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998976s
    Jan 24 18:51:18.749: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.953667266s
    Jan 24 18:51:19.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.93490711s
    Jan 24 18:51:20.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.914751547s
    Jan 24 18:51:21.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.881736879s
    Jan 24 18:51:22.862: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.856995237s
    Jan 24 18:51:23.879: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.820793342s
    Jan 24 18:51:24.930: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.799101747s
    Jan 24 18:51:25.960: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.752327329s
    Jan 24 18:51:26.977: INFO: Verifying statefulset ss doesn't scale past 3 for another 718.228029ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1946 01/24/23 18:51:27.977
    Jan 24 18:51:27.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 24 18:51:28.751: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 24 18:51:28.751: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 24 18:51:28.751: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 24 18:51:28.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 24 18:51:29.496: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 24 18:51:29.496: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 24 18:51:29.496: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 24 18:51:29.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-1946 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 24 18:51:30.386: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 24 18:51:30.386: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 24 18:51:30.386: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 24 18:51:30.386: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 01/24/23 18:51:40.603
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 24 18:51:40.605: INFO: Deleting all statefulset in ns statefulset-1946
    Jan 24 18:51:40.621: INFO: Scaling statefulset ss to 0
    Jan 24 18:51:40.671: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 18:51:40.681: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 24 18:51:40.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1946" for this suite. 01/24/23 18:51:40.799
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:51:40.856
Jan 24 18:51:40.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 18:51:40.869
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:51:40.957
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:51:40.979
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-182e677c-5926-4dc8-8eb7-2ce61a00dda1 01/24/23 18:51:41.095
STEP: Creating secret with name s-test-opt-upd-93696dd6-b9ad-42f9-ab2d-27833ee005a7 01/24/23 18:51:41.127
STEP: Creating the pod 01/24/23 18:51:41.162
Jan 24 18:51:41.278: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d" in namespace "projected-6322" to be "running and ready"
Jan 24 18:51:41.372: INFO: Pod "pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d": Phase="Pending", Reason="", readiness=false. Elapsed: 93.997754ms
Jan 24 18:51:41.373: INFO: The phase of Pod pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:51:43.431: INFO: Pod "pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.152346162s
Jan 24 18:51:43.431: INFO: The phase of Pod pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:51:45.391: INFO: Pod "pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d": Phase="Running", Reason="", readiness=true. Elapsed: 4.112876779s
Jan 24 18:51:45.391: INFO: The phase of Pod pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d is Running (Ready = true)
Jan 24 18:51:45.391: INFO: Pod "pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-182e677c-5926-4dc8-8eb7-2ce61a00dda1 01/24/23 18:51:45.724
STEP: Updating secret s-test-opt-upd-93696dd6-b9ad-42f9-ab2d-27833ee005a7 01/24/23 18:51:45.767
STEP: Creating secret with name s-test-opt-create-67385614-9760-46bb-9c13-9b234fdd9b0e 01/24/23 18:51:45.824
STEP: waiting to observe update in volume 01/24/23 18:51:45.854
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 24 18:52:59.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6322" for this suite. 01/24/23 18:52:59.617
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":55,"skipped":1074,"failed":0}
------------------------------
• [SLOW TEST] [78.832 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:51:40.856
    Jan 24 18:51:40.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 18:51:40.869
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:51:40.957
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:51:40.979
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-182e677c-5926-4dc8-8eb7-2ce61a00dda1 01/24/23 18:51:41.095
    STEP: Creating secret with name s-test-opt-upd-93696dd6-b9ad-42f9-ab2d-27833ee005a7 01/24/23 18:51:41.127
    STEP: Creating the pod 01/24/23 18:51:41.162
    Jan 24 18:51:41.278: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d" in namespace "projected-6322" to be "running and ready"
    Jan 24 18:51:41.372: INFO: Pod "pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d": Phase="Pending", Reason="", readiness=false. Elapsed: 93.997754ms
    Jan 24 18:51:41.373: INFO: The phase of Pod pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:51:43.431: INFO: Pod "pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.152346162s
    Jan 24 18:51:43.431: INFO: The phase of Pod pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:51:45.391: INFO: Pod "pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d": Phase="Running", Reason="", readiness=true. Elapsed: 4.112876779s
    Jan 24 18:51:45.391: INFO: The phase of Pod pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d is Running (Ready = true)
    Jan 24 18:51:45.391: INFO: Pod "pod-projected-secrets-23dd951a-e577-4910-afe6-ab912228202d" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-182e677c-5926-4dc8-8eb7-2ce61a00dda1 01/24/23 18:51:45.724
    STEP: Updating secret s-test-opt-upd-93696dd6-b9ad-42f9-ab2d-27833ee005a7 01/24/23 18:51:45.767
    STEP: Creating secret with name s-test-opt-create-67385614-9760-46bb-9c13-9b234fdd9b0e 01/24/23 18:51:45.824
    STEP: waiting to observe update in volume 01/24/23 18:51:45.854
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 24 18:52:59.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6322" for this suite. 01/24/23 18:52:59.617
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:52:59.778
Jan 24 18:52:59.779: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename ingress 01/24/23 18:52:59.795
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:00.042
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:00.06
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 01/24/23 18:53:00.203
STEP: getting /apis/networking.k8s.io 01/24/23 18:53:00.228
STEP: getting /apis/networking.k8s.iov1 01/24/23 18:53:00.373
STEP: creating 01/24/23 18:53:00.551
STEP: getting 01/24/23 18:53:00.947
STEP: listing 01/24/23 18:53:00.983
STEP: watching 01/24/23 18:53:01.032
Jan 24 18:53:01.032: INFO: starting watch
STEP: cluster-wide listing 01/24/23 18:53:01.069
STEP: cluster-wide watching 01/24/23 18:53:01.176
Jan 24 18:53:01.177: INFO: starting watch
STEP: patching 01/24/23 18:53:01.195
STEP: updating 01/24/23 18:53:01.289
Jan 24 18:53:01.329: INFO: waiting for watch events with expected annotations
Jan 24 18:53:01.329: INFO: saw patched and updated annotations
STEP: patching /status 01/24/23 18:53:01.329
STEP: updating /status 01/24/23 18:53:01.404
STEP: get /status 01/24/23 18:53:01.454
STEP: deleting 01/24/23 18:53:01.559
STEP: deleting a collection 01/24/23 18:53:01.745
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Jan 24 18:53:01.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-1688" for this suite. 01/24/23 18:53:02.051
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":56,"skipped":1117,"failed":0}
------------------------------
• [2.370 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:52:59.778
    Jan 24 18:52:59.779: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename ingress 01/24/23 18:52:59.795
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:00.042
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:00.06
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 01/24/23 18:53:00.203
    STEP: getting /apis/networking.k8s.io 01/24/23 18:53:00.228
    STEP: getting /apis/networking.k8s.iov1 01/24/23 18:53:00.373
    STEP: creating 01/24/23 18:53:00.551
    STEP: getting 01/24/23 18:53:00.947
    STEP: listing 01/24/23 18:53:00.983
    STEP: watching 01/24/23 18:53:01.032
    Jan 24 18:53:01.032: INFO: starting watch
    STEP: cluster-wide listing 01/24/23 18:53:01.069
    STEP: cluster-wide watching 01/24/23 18:53:01.176
    Jan 24 18:53:01.177: INFO: starting watch
    STEP: patching 01/24/23 18:53:01.195
    STEP: updating 01/24/23 18:53:01.289
    Jan 24 18:53:01.329: INFO: waiting for watch events with expected annotations
    Jan 24 18:53:01.329: INFO: saw patched and updated annotations
    STEP: patching /status 01/24/23 18:53:01.329
    STEP: updating /status 01/24/23 18:53:01.404
    STEP: get /status 01/24/23 18:53:01.454
    STEP: deleting 01/24/23 18:53:01.559
    STEP: deleting a collection 01/24/23 18:53:01.745
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Jan 24 18:53:01.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-1688" for this suite. 01/24/23 18:53:02.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:53:02.166
Jan 24 18:53:02.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename gc 01/24/23 18:53:02.19
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:02.389
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:02.669
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 01/24/23 18:53:02.942
STEP: Wait for the Deployment to create new ReplicaSet 01/24/23 18:53:02.982
STEP: delete the deployment 01/24/23 18:53:03.985
STEP: wait for all rs to be garbage collected 01/24/23 18:53:04.04
STEP: expected 0 rs, got 1 rs 01/24/23 18:53:04.21
STEP: expected 0 pods, got 2 pods 01/24/23 18:53:04.346
STEP: Gathering metrics 01/24/23 18:53:05.068
W0124 18:53:05.321475      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 24 18:53:05.321: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 24 18:53:05.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5885" for this suite. 01/24/23 18:53:05.342
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":57,"skipped":1128,"failed":0}
------------------------------
• [3.696 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:53:02.166
    Jan 24 18:53:02.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename gc 01/24/23 18:53:02.19
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:02.389
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:02.669
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 01/24/23 18:53:02.942
    STEP: Wait for the Deployment to create new ReplicaSet 01/24/23 18:53:02.982
    STEP: delete the deployment 01/24/23 18:53:03.985
    STEP: wait for all rs to be garbage collected 01/24/23 18:53:04.04
    STEP: expected 0 rs, got 1 rs 01/24/23 18:53:04.21
    STEP: expected 0 pods, got 2 pods 01/24/23 18:53:04.346
    STEP: Gathering metrics 01/24/23 18:53:05.068
    W0124 18:53:05.321475      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 24 18:53:05.321: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 24 18:53:05.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5885" for this suite. 01/24/23 18:53:05.342
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:53:05.865
Jan 24 18:53:05.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename statefulset 01/24/23 18:53:05.869
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:06.189
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:06.243
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1632 01/24/23 18:53:06.351
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Jan 24 18:53:06.584: INFO: Found 0 stateful pods, waiting for 1
Jan 24 18:53:16.593: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 01/24/23 18:53:16.611
W0124 18:53:16.646718      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Jan 24 18:53:16.674: INFO: Found 1 stateful pods, waiting for 2
Jan 24 18:53:26.688: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jan 24 18:53:36.695: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 18:53:36.695: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 01/24/23 18:53:36.721
STEP: Delete all of the StatefulSets 01/24/23 18:53:36.734
STEP: Verify that StatefulSets have been deleted 01/24/23 18:53:36.789
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 24 18:53:36.801: INFO: Deleting all statefulset in ns statefulset-1632
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 24 18:53:36.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1632" for this suite. 01/24/23 18:53:36.921
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":58,"skipped":1128,"failed":0}
------------------------------
• [SLOW TEST] [31.102 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:53:05.865
    Jan 24 18:53:05.865: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename statefulset 01/24/23 18:53:05.869
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:06.189
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:06.243
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1632 01/24/23 18:53:06.351
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Jan 24 18:53:06.584: INFO: Found 0 stateful pods, waiting for 1
    Jan 24 18:53:16.593: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 01/24/23 18:53:16.611
    W0124 18:53:16.646718      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Jan 24 18:53:16.674: INFO: Found 1 stateful pods, waiting for 2
    Jan 24 18:53:26.688: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Jan 24 18:53:36.695: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 18:53:36.695: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 01/24/23 18:53:36.721
    STEP: Delete all of the StatefulSets 01/24/23 18:53:36.734
    STEP: Verify that StatefulSets have been deleted 01/24/23 18:53:36.789
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 24 18:53:36.801: INFO: Deleting all statefulset in ns statefulset-1632
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 24 18:53:36.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1632" for this suite. 01/24/23 18:53:36.921
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:53:36.997
Jan 24 18:53:36.998: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename custom-resource-definition 01/24/23 18:53:37.195
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:37.384
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:37.398
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Jan 24 18:53:37.420: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:53:46.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7594" for this suite. 01/24/23 18:53:46.031
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":59,"skipped":1138,"failed":0}
------------------------------
• [SLOW TEST] [9.060 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:53:36.997
    Jan 24 18:53:36.998: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename custom-resource-definition 01/24/23 18:53:37.195
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:37.384
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:37.398
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Jan 24 18:53:37.420: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:53:46.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7594" for this suite. 01/24/23 18:53:46.031
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:53:46.09
Jan 24 18:53:46.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename namespaces 01/24/23 18:53:46.1
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:46.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:46.255
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 01/24/23 18:53:46.305
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:46.4
STEP: Creating a service in the namespace 01/24/23 18:53:46.455
STEP: Deleting the namespace 01/24/23 18:53:46.6
STEP: Waiting for the namespace to be removed. 01/24/23 18:53:46.655
STEP: Recreating the namespace 01/24/23 18:53:53.678
STEP: Verifying there is no service in the namespace 01/24/23 18:53:53.729
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jan 24 18:53:53.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3223" for this suite. 01/24/23 18:53:53.773
STEP: Destroying namespace "nsdeletetest-8138" for this suite. 01/24/23 18:53:53.791
Jan 24 18:53:53.807: INFO: Namespace nsdeletetest-8138 was already deleted
STEP: Destroying namespace "nsdeletetest-7000" for this suite. 01/24/23 18:53:53.807
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":60,"skipped":1168,"failed":0}
------------------------------
• [SLOW TEST] [7.751 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:53:46.09
    Jan 24 18:53:46.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename namespaces 01/24/23 18:53:46.1
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:46.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:46.255
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 01/24/23 18:53:46.305
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:46.4
    STEP: Creating a service in the namespace 01/24/23 18:53:46.455
    STEP: Deleting the namespace 01/24/23 18:53:46.6
    STEP: Waiting for the namespace to be removed. 01/24/23 18:53:46.655
    STEP: Recreating the namespace 01/24/23 18:53:53.678
    STEP: Verifying there is no service in the namespace 01/24/23 18:53:53.729
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 18:53:53.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-3223" for this suite. 01/24/23 18:53:53.773
    STEP: Destroying namespace "nsdeletetest-8138" for this suite. 01/24/23 18:53:53.791
    Jan 24 18:53:53.807: INFO: Namespace nsdeletetest-8138 was already deleted
    STEP: Destroying namespace "nsdeletetest-7000" for this suite. 01/24/23 18:53:53.807
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:53:53.842
Jan 24 18:53:53.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 18:53:53.848
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:53.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:53.909
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 18:53:53.975
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:53:56.854
STEP: Deploying the webhook pod 01/24/23 18:53:56.9
STEP: Wait for the deployment to be ready 01/24/23 18:53:56.963
Jan 24 18:53:57.047: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 24 18:53:59.085: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 53, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 53, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 53, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 53, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 18:54:01.093
STEP: Verifying the service has paired with the endpoint 01/24/23 18:54:01.116
Jan 24 18:54:02.123: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 01/24/23 18:54:02.133
STEP: Updating a mutating webhook configuration's rules to not include the create operation 01/24/23 18:54:02.181
STEP: Creating a configMap that should not be mutated 01/24/23 18:54:02.198
STEP: Patching a mutating webhook configuration's rules to include the create operation 01/24/23 18:54:02.215
STEP: Creating a configMap that should be mutated 01/24/23 18:54:02.229
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:54:02.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3841" for this suite. 01/24/23 18:54:02.291
STEP: Destroying namespace "webhook-3841-markers" for this suite. 01/24/23 18:54:02.314
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":61,"skipped":1170,"failed":0}
------------------------------
• [SLOW TEST] [8.581 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:53:53.842
    Jan 24 18:53:53.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 18:53:53.848
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:53:53.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:53:53.909
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 18:53:53.975
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:53:56.854
    STEP: Deploying the webhook pod 01/24/23 18:53:56.9
    STEP: Wait for the deployment to be ready 01/24/23 18:53:56.963
    Jan 24 18:53:57.047: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 24 18:53:59.085: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 53, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 53, 57, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 53, 57, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 53, 57, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 18:54:01.093
    STEP: Verifying the service has paired with the endpoint 01/24/23 18:54:01.116
    Jan 24 18:54:02.123: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 01/24/23 18:54:02.133
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 01/24/23 18:54:02.181
    STEP: Creating a configMap that should not be mutated 01/24/23 18:54:02.198
    STEP: Patching a mutating webhook configuration's rules to include the create operation 01/24/23 18:54:02.215
    STEP: Creating a configMap that should be mutated 01/24/23 18:54:02.229
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:54:02.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3841" for this suite. 01/24/23 18:54:02.291
    STEP: Destroying namespace "webhook-3841-markers" for this suite. 01/24/23 18:54:02.314
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:54:02.448
Jan 24 18:54:02.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 18:54:02.452
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:54:02.484
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:54:02.495
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-2362 01/24/23 18:54:02.508
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2362 to expose endpoints map[] 01/24/23 18:54:02.548
Jan 24 18:54:02.582: INFO: successfully validated that service multi-endpoint-test in namespace services-2362 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-2362 01/24/23 18:54:02.582
Jan 24 18:54:02.602: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2362" to be "running and ready"
Jan 24 18:54:02.619: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.15687ms
Jan 24 18:54:02.619: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:54:04.627: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.024532581s
Jan 24 18:54:04.627: INFO: The phase of Pod pod1 is Running (Ready = true)
Jan 24 18:54:04.627: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2362 to expose endpoints map[pod1:[100]] 01/24/23 18:54:04.634
Jan 24 18:54:04.654: INFO: successfully validated that service multi-endpoint-test in namespace services-2362 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-2362 01/24/23 18:54:04.655
Jan 24 18:54:04.669: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2362" to be "running and ready"
Jan 24 18:54:04.683: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.62615ms
Jan 24 18:54:04.684: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:54:06.694: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024124958s
Jan 24 18:54:06.695: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 18:54:08.694: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.02419461s
Jan 24 18:54:08.695: INFO: The phase of Pod pod2 is Running (Ready = true)
Jan 24 18:54:08.695: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2362 to expose endpoints map[pod1:[100] pod2:[101]] 01/24/23 18:54:08.701
Jan 24 18:54:08.728: INFO: successfully validated that service multi-endpoint-test in namespace services-2362 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 01/24/23 18:54:08.729
Jan 24 18:54:08.729: INFO: Creating new exec pod
Jan 24 18:54:08.745: INFO: Waiting up to 5m0s for pod "execpod4lp4l" in namespace "services-2362" to be "running"
Jan 24 18:54:08.758: INFO: Pod "execpod4lp4l": Phase="Pending", Reason="", readiness=false. Elapsed: 12.54901ms
Jan 24 18:54:10.780: INFO: Pod "execpod4lp4l": Phase="Running", Reason="", readiness=true. Elapsed: 2.03516538s
Jan 24 18:54:10.781: INFO: Pod "execpod4lp4l" satisfied condition "running"
Jan 24 18:54:11.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2362 exec execpod4lp4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Jan 24 18:54:12.574: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Jan 24 18:54:12.575: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 18:54:12.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2362 exec execpod4lp4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.174.155 80'
Jan 24 18:54:16.162: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.10.174.155 80\nConnection to 10.10.174.155 80 port [tcp/http] succeeded!\n"
Jan 24 18:54:16.162: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 18:54:16.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2362 exec execpod4lp4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Jan 24 18:54:16.979: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Jan 24 18:54:16.979: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 18:54:16.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2362 exec execpod4lp4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.174.155 81'
Jan 24 18:54:17.281: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.174.155 81\nConnection to 10.10.174.155 81 port [tcp/*] succeeded!\n"
Jan 24 18:54:17.281: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-2362 01/24/23 18:54:17.281
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2362 to expose endpoints map[pod2:[101]] 01/24/23 18:54:17.334
Jan 24 18:54:17.376: INFO: successfully validated that service multi-endpoint-test in namespace services-2362 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-2362 01/24/23 18:54:17.376
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2362 to expose endpoints map[] 01/24/23 18:54:17.421
Jan 24 18:54:17.450: INFO: successfully validated that service multi-endpoint-test in namespace services-2362 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 18:54:17.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2362" for this suite. 01/24/23 18:54:17.536
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":62,"skipped":1181,"failed":0}
------------------------------
• [SLOW TEST] [15.128 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:54:02.448
    Jan 24 18:54:02.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 18:54:02.452
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:54:02.484
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:54:02.495
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-2362 01/24/23 18:54:02.508
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2362 to expose endpoints map[] 01/24/23 18:54:02.548
    Jan 24 18:54:02.582: INFO: successfully validated that service multi-endpoint-test in namespace services-2362 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-2362 01/24/23 18:54:02.582
    Jan 24 18:54:02.602: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-2362" to be "running and ready"
    Jan 24 18:54:02.619: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.15687ms
    Jan 24 18:54:02.619: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:54:04.627: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.024532581s
    Jan 24 18:54:04.627: INFO: The phase of Pod pod1 is Running (Ready = true)
    Jan 24 18:54:04.627: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2362 to expose endpoints map[pod1:[100]] 01/24/23 18:54:04.634
    Jan 24 18:54:04.654: INFO: successfully validated that service multi-endpoint-test in namespace services-2362 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-2362 01/24/23 18:54:04.655
    Jan 24 18:54:04.669: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-2362" to be "running and ready"
    Jan 24 18:54:04.683: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.62615ms
    Jan 24 18:54:04.684: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:54:06.694: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024124958s
    Jan 24 18:54:06.695: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 18:54:08.694: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.02419461s
    Jan 24 18:54:08.695: INFO: The phase of Pod pod2 is Running (Ready = true)
    Jan 24 18:54:08.695: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2362 to expose endpoints map[pod1:[100] pod2:[101]] 01/24/23 18:54:08.701
    Jan 24 18:54:08.728: INFO: successfully validated that service multi-endpoint-test in namespace services-2362 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 01/24/23 18:54:08.729
    Jan 24 18:54:08.729: INFO: Creating new exec pod
    Jan 24 18:54:08.745: INFO: Waiting up to 5m0s for pod "execpod4lp4l" in namespace "services-2362" to be "running"
    Jan 24 18:54:08.758: INFO: Pod "execpod4lp4l": Phase="Pending", Reason="", readiness=false. Elapsed: 12.54901ms
    Jan 24 18:54:10.780: INFO: Pod "execpod4lp4l": Phase="Running", Reason="", readiness=true. Elapsed: 2.03516538s
    Jan 24 18:54:10.781: INFO: Pod "execpod4lp4l" satisfied condition "running"
    Jan 24 18:54:11.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2362 exec execpod4lp4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Jan 24 18:54:12.574: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Jan 24 18:54:12.575: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 18:54:12.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2362 exec execpod4lp4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.174.155 80'
    Jan 24 18:54:16.162: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.10.174.155 80\nConnection to 10.10.174.155 80 port [tcp/http] succeeded!\n"
    Jan 24 18:54:16.162: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 18:54:16.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2362 exec execpod4lp4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Jan 24 18:54:16.979: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Jan 24 18:54:16.979: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 18:54:16.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2362 exec execpod4lp4l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.174.155 81'
    Jan 24 18:54:17.281: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.174.155 81\nConnection to 10.10.174.155 81 port [tcp/*] succeeded!\n"
    Jan 24 18:54:17.281: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-2362 01/24/23 18:54:17.281
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2362 to expose endpoints map[pod2:[101]] 01/24/23 18:54:17.334
    Jan 24 18:54:17.376: INFO: successfully validated that service multi-endpoint-test in namespace services-2362 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-2362 01/24/23 18:54:17.376
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2362 to expose endpoints map[] 01/24/23 18:54:17.421
    Jan 24 18:54:17.450: INFO: successfully validated that service multi-endpoint-test in namespace services-2362 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 18:54:17.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2362" for this suite. 01/24/23 18:54:17.536
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:54:17.636
Jan 24 18:54:17.637: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 18:54:17.64
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:54:17.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:54:17.7
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-a7a5f79a-0e37-4a52-9b29-422e0fa53a16 01/24/23 18:54:17.709
STEP: Creating a pod to test consume secrets 01/24/23 18:54:17.723
Jan 24 18:54:17.766: INFO: Waiting up to 5m0s for pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363" in namespace "secrets-2186" to be "Succeeded or Failed"
Jan 24 18:54:17.799: INFO: Pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363": Phase="Pending", Reason="", readiness=false. Elapsed: 32.835293ms
Jan 24 18:54:19.811: INFO: Pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045101836s
Jan 24 18:54:21.812: INFO: Pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045693705s
Jan 24 18:54:23.810: INFO: Pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044273736s
STEP: Saw pod success 01/24/23 18:54:23.811
Jan 24 18:54:23.811: INFO: Pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363" satisfied condition "Succeeded or Failed"
Jan 24 18:54:23.818: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-2681487b-946a-4fad-b120-96191a988363 container secret-volume-test: <nil>
STEP: delete the pod 01/24/23 18:54:23.834
Jan 24 18:54:23.868: INFO: Waiting for pod pod-secrets-2681487b-946a-4fad-b120-96191a988363 to disappear
Jan 24 18:54:23.883: INFO: Pod pod-secrets-2681487b-946a-4fad-b120-96191a988363 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 24 18:54:23.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2186" for this suite. 01/24/23 18:54:23.897
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":63,"skipped":1201,"failed":0}
------------------------------
• [SLOW TEST] [6.292 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:54:17.636
    Jan 24 18:54:17.637: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 18:54:17.64
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:54:17.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:54:17.7
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-a7a5f79a-0e37-4a52-9b29-422e0fa53a16 01/24/23 18:54:17.709
    STEP: Creating a pod to test consume secrets 01/24/23 18:54:17.723
    Jan 24 18:54:17.766: INFO: Waiting up to 5m0s for pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363" in namespace "secrets-2186" to be "Succeeded or Failed"
    Jan 24 18:54:17.799: INFO: Pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363": Phase="Pending", Reason="", readiness=false. Elapsed: 32.835293ms
    Jan 24 18:54:19.811: INFO: Pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045101836s
    Jan 24 18:54:21.812: INFO: Pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045693705s
    Jan 24 18:54:23.810: INFO: Pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044273736s
    STEP: Saw pod success 01/24/23 18:54:23.811
    Jan 24 18:54:23.811: INFO: Pod "pod-secrets-2681487b-946a-4fad-b120-96191a988363" satisfied condition "Succeeded or Failed"
    Jan 24 18:54:23.818: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-2681487b-946a-4fad-b120-96191a988363 container secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 18:54:23.834
    Jan 24 18:54:23.868: INFO: Waiting for pod pod-secrets-2681487b-946a-4fad-b120-96191a988363 to disappear
    Jan 24 18:54:23.883: INFO: Pod pod-secrets-2681487b-946a-4fad-b120-96191a988363 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 18:54:23.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2186" for this suite. 01/24/23 18:54:23.897
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:54:23.955
Jan 24 18:54:23.955: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename dns 01/24/23 18:54:23.958
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:54:24.023
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:54:24.036
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 01/24/23 18:54:24.072
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
 01/24/23 18:54:24.113
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
 01/24/23 18:54:24.114
STEP: creating a pod to probe DNS 01/24/23 18:54:24.114
STEP: submitting the pod to kubernetes 01/24/23 18:54:24.115
Jan 24 18:54:24.219: INFO: Waiting up to 15m0s for pod "dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951" in namespace "dns-9431" to be "running"
Jan 24 18:54:24.344: INFO: Pod "dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951": Phase="Pending", Reason="", readiness=false. Elapsed: 124.008043ms
Jan 24 18:54:26.396: INFO: Pod "dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951": Phase="Pending", Reason="", readiness=false. Elapsed: 2.175208028s
Jan 24 18:54:28.423: INFO: Pod "dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951": Phase="Running", Reason="", readiness=true. Elapsed: 4.202827176s
Jan 24 18:54:28.423: INFO: Pod "dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951" satisfied condition "running"
STEP: retrieving the pod 01/24/23 18:54:28.423
STEP: looking for the results for each expected name from probers 01/24/23 18:54:28.436
Jan 24 18:54:28.524: INFO: DNS probes using dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951 succeeded

STEP: deleting the pod 01/24/23 18:54:28.524
STEP: changing the externalName to bar.example.com 01/24/23 18:54:28.596
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
 01/24/23 18:54:28.67
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
 01/24/23 18:54:28.671
STEP: creating a second pod to probe DNS 01/24/23 18:54:28.672
STEP: submitting the pod to kubernetes 01/24/23 18:54:28.672
Jan 24 18:54:28.698: INFO: Waiting up to 15m0s for pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f" in namespace "dns-9431" to be "running"
Jan 24 18:54:28.715: INFO: Pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.78008ms
Jan 24 18:54:30.779: INFO: Pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081195845s
Jan 24 18:54:32.728: INFO: Pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029798821s
Jan 24 18:54:34.732: INFO: Pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f": Phase="Running", Reason="", readiness=true. Elapsed: 6.034157048s
Jan 24 18:54:34.733: INFO: Pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f" satisfied condition "running"
STEP: retrieving the pod 01/24/23 18:54:34.733
STEP: looking for the results for each expected name from probers 01/24/23 18:54:34.753
Jan 24 18:54:34.766: INFO: File wheezy_udp@dns-test-service-3.dns-9431.svc.cluster.local from pod  dns-9431/dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f contains 'foo.example.com.
' instead of 'bar.example.com.'
Jan 24 18:54:34.778: INFO: Lookups using dns-9431/dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f failed for: [wheezy_udp@dns-test-service-3.dns-9431.svc.cluster.local]

Jan 24 18:54:39.812: INFO: DNS probes using dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f succeeded

STEP: deleting the pod 01/24/23 18:54:39.813
STEP: changing the service to type=ClusterIP 01/24/23 18:54:39.928
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
 01/24/23 18:54:40.06
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
 01/24/23 18:54:40.06
STEP: creating a third pod to probe DNS 01/24/23 18:54:40.06
STEP: submitting the pod to kubernetes 01/24/23 18:54:40.089
Jan 24 18:54:40.136: INFO: Waiting up to 15m0s for pod "dns-test-86cd6054-612b-45b9-8365-0556db48b10f" in namespace "dns-9431" to be "running"
Jan 24 18:54:40.162: INFO: Pod "dns-test-86cd6054-612b-45b9-8365-0556db48b10f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.69556ms
Jan 24 18:54:42.214: INFO: Pod "dns-test-86cd6054-612b-45b9-8365-0556db48b10f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077342236s
Jan 24 18:54:44.217: INFO: Pod "dns-test-86cd6054-612b-45b9-8365-0556db48b10f": Phase="Running", Reason="", readiness=true. Elapsed: 4.080351956s
Jan 24 18:54:44.217: INFO: Pod "dns-test-86cd6054-612b-45b9-8365-0556db48b10f" satisfied condition "running"
STEP: retrieving the pod 01/24/23 18:54:44.217
STEP: looking for the results for each expected name from probers 01/24/23 18:54:44.303
Jan 24 18:54:44.422: INFO: DNS probes using dns-test-86cd6054-612b-45b9-8365-0556db48b10f succeeded

STEP: deleting the pod 01/24/23 18:54:44.422
STEP: deleting the test externalName service 01/24/23 18:54:45.135
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 24 18:54:46.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9431" for this suite. 01/24/23 18:54:46.225
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":64,"skipped":1229,"failed":0}
------------------------------
• [SLOW TEST] [22.422 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:54:23.955
    Jan 24 18:54:23.955: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename dns 01/24/23 18:54:23.958
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:54:24.023
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:54:24.036
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 01/24/23 18:54:24.072
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
     01/24/23 18:54:24.113
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
     01/24/23 18:54:24.114
    STEP: creating a pod to probe DNS 01/24/23 18:54:24.114
    STEP: submitting the pod to kubernetes 01/24/23 18:54:24.115
    Jan 24 18:54:24.219: INFO: Waiting up to 15m0s for pod "dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951" in namespace "dns-9431" to be "running"
    Jan 24 18:54:24.344: INFO: Pod "dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951": Phase="Pending", Reason="", readiness=false. Elapsed: 124.008043ms
    Jan 24 18:54:26.396: INFO: Pod "dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951": Phase="Pending", Reason="", readiness=false. Elapsed: 2.175208028s
    Jan 24 18:54:28.423: INFO: Pod "dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951": Phase="Running", Reason="", readiness=true. Elapsed: 4.202827176s
    Jan 24 18:54:28.423: INFO: Pod "dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951" satisfied condition "running"
    STEP: retrieving the pod 01/24/23 18:54:28.423
    STEP: looking for the results for each expected name from probers 01/24/23 18:54:28.436
    Jan 24 18:54:28.524: INFO: DNS probes using dns-test-5af508ee-a3c5-4e74-a09a-6c480b95b951 succeeded

    STEP: deleting the pod 01/24/23 18:54:28.524
    STEP: changing the externalName to bar.example.com 01/24/23 18:54:28.596
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
     01/24/23 18:54:28.67
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
     01/24/23 18:54:28.671
    STEP: creating a second pod to probe DNS 01/24/23 18:54:28.672
    STEP: submitting the pod to kubernetes 01/24/23 18:54:28.672
    Jan 24 18:54:28.698: INFO: Waiting up to 15m0s for pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f" in namespace "dns-9431" to be "running"
    Jan 24 18:54:28.715: INFO: Pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.78008ms
    Jan 24 18:54:30.779: INFO: Pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081195845s
    Jan 24 18:54:32.728: INFO: Pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029798821s
    Jan 24 18:54:34.732: INFO: Pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f": Phase="Running", Reason="", readiness=true. Elapsed: 6.034157048s
    Jan 24 18:54:34.733: INFO: Pod "dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f" satisfied condition "running"
    STEP: retrieving the pod 01/24/23 18:54:34.733
    STEP: looking for the results for each expected name from probers 01/24/23 18:54:34.753
    Jan 24 18:54:34.766: INFO: File wheezy_udp@dns-test-service-3.dns-9431.svc.cluster.local from pod  dns-9431/dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Jan 24 18:54:34.778: INFO: Lookups using dns-9431/dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f failed for: [wheezy_udp@dns-test-service-3.dns-9431.svc.cluster.local]

    Jan 24 18:54:39.812: INFO: DNS probes using dns-test-cd08892c-3f6f-4f8a-9d61-9447c8e7f53f succeeded

    STEP: deleting the pod 01/24/23 18:54:39.813
    STEP: changing the service to type=ClusterIP 01/24/23 18:54:39.928
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
     01/24/23 18:54:40.06
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9431.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9431.svc.cluster.local; sleep 1; done
     01/24/23 18:54:40.06
    STEP: creating a third pod to probe DNS 01/24/23 18:54:40.06
    STEP: submitting the pod to kubernetes 01/24/23 18:54:40.089
    Jan 24 18:54:40.136: INFO: Waiting up to 15m0s for pod "dns-test-86cd6054-612b-45b9-8365-0556db48b10f" in namespace "dns-9431" to be "running"
    Jan 24 18:54:40.162: INFO: Pod "dns-test-86cd6054-612b-45b9-8365-0556db48b10f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.69556ms
    Jan 24 18:54:42.214: INFO: Pod "dns-test-86cd6054-612b-45b9-8365-0556db48b10f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077342236s
    Jan 24 18:54:44.217: INFO: Pod "dns-test-86cd6054-612b-45b9-8365-0556db48b10f": Phase="Running", Reason="", readiness=true. Elapsed: 4.080351956s
    Jan 24 18:54:44.217: INFO: Pod "dns-test-86cd6054-612b-45b9-8365-0556db48b10f" satisfied condition "running"
    STEP: retrieving the pod 01/24/23 18:54:44.217
    STEP: looking for the results for each expected name from probers 01/24/23 18:54:44.303
    Jan 24 18:54:44.422: INFO: DNS probes using dns-test-86cd6054-612b-45b9-8365-0556db48b10f succeeded

    STEP: deleting the pod 01/24/23 18:54:44.422
    STEP: deleting the test externalName service 01/24/23 18:54:45.135
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 24 18:54:46.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9431" for this suite. 01/24/23 18:54:46.225
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:54:46.464
Jan 24 18:54:46.465: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 18:54:46.47
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:54:46.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:54:46.61
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 01/24/23 18:54:46.626
Jan 24 18:54:46.649: INFO: Waiting up to 5m0s for pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5" in namespace "emptydir-9921" to be "Succeeded or Failed"
Jan 24 18:54:46.661: INFO: Pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.71868ms
Jan 24 18:54:48.668: INFO: Pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019400658s
Jan 24 18:54:50.669: INFO: Pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02000339s
Jan 24 18:54:52.681: INFO: Pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032221982s
STEP: Saw pod success 01/24/23 18:54:52.681
Jan 24 18:54:52.682: INFO: Pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5" satisfied condition "Succeeded or Failed"
Jan 24 18:54:52.698: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-4caa332f-d27c-4fc1-822c-43a6997e73a5 container test-container: <nil>
STEP: delete the pod 01/24/23 18:54:52.717
Jan 24 18:54:52.760: INFO: Waiting for pod pod-4caa332f-d27c-4fc1-822c-43a6997e73a5 to disappear
Jan 24 18:54:52.770: INFO: Pod pod-4caa332f-d27c-4fc1-822c-43a6997e73a5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 18:54:52.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9921" for this suite. 01/24/23 18:54:52.808
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":65,"skipped":1244,"failed":0}
------------------------------
• [SLOW TEST] [6.413 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:54:46.464
    Jan 24 18:54:46.465: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 18:54:46.47
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:54:46.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:54:46.61
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 01/24/23 18:54:46.626
    Jan 24 18:54:46.649: INFO: Waiting up to 5m0s for pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5" in namespace "emptydir-9921" to be "Succeeded or Failed"
    Jan 24 18:54:46.661: INFO: Pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.71868ms
    Jan 24 18:54:48.668: INFO: Pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019400658s
    Jan 24 18:54:50.669: INFO: Pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02000339s
    Jan 24 18:54:52.681: INFO: Pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032221982s
    STEP: Saw pod success 01/24/23 18:54:52.681
    Jan 24 18:54:52.682: INFO: Pod "pod-4caa332f-d27c-4fc1-822c-43a6997e73a5" satisfied condition "Succeeded or Failed"
    Jan 24 18:54:52.698: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-4caa332f-d27c-4fc1-822c-43a6997e73a5 container test-container: <nil>
    STEP: delete the pod 01/24/23 18:54:52.717
    Jan 24 18:54:52.760: INFO: Waiting for pod pod-4caa332f-d27c-4fc1-822c-43a6997e73a5 to disappear
    Jan 24 18:54:52.770: INFO: Pod pod-4caa332f-d27c-4fc1-822c-43a6997e73a5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 18:54:52.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9921" for this suite. 01/24/23 18:54:52.808
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:54:52.902
Jan 24 18:54:52.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename statefulset 01/24/23 18:54:52.906
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:54:52.95
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:54:52.984
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8063 01/24/23 18:54:53.013
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-8063 01/24/23 18:54:53.039
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8063 01/24/23 18:54:53.068
Jan 24 18:54:53.079: INFO: Found 0 stateful pods, waiting for 1
Jan 24 18:55:03.091: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 01/24/23 18:55:03.091
Jan 24 18:55:03.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 24 18:55:03.910: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 24 18:55:03.910: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 24 18:55:03.910: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 24 18:55:03.939: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 24 18:55:14.089: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 24 18:55:14.090: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 18:55:14.169: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jan 24 18:55:14.169: INFO: ss-0  vikash-v125latest-conf-71087  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  }]
Jan 24 18:55:14.170: INFO: 
Jan 24 18:55:14.175: INFO: StatefulSet ss has not reached scale 3, at 1
Jan 24 18:55:15.251: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.972199311s
Jan 24 18:55:16.283: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.902502961s
Jan 24 18:55:17.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.870523525s
Jan 24 18:55:18.431: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.808135495s
Jan 24 18:55:19.464: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.721080428s
Jan 24 18:55:20.484: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.684075348s
Jan 24 18:55:21.511: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.667476222s
Jan 24 18:55:22.530: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.638516575s
Jan 24 18:55:23.597: INFO: Verifying statefulset ss doesn't scale past 3 for another 619.234325ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8063 01/24/23 18:55:24.6
Jan 24 18:55:24.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 24 18:55:26.336: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 24 18:55:26.336: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 24 18:55:26.336: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 24 18:55:26.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 24 18:55:26.819: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jan 24 18:55:26.819: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 24 18:55:26.819: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 24 18:55:26.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 24 18:55:27.170: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jan 24 18:55:27.170: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 24 18:55:27.170: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 24 18:55:27.181: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 18:55:27.181: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 18:55:27.181: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 01/24/23 18:55:27.181
Jan 24 18:55:27.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 24 18:55:27.521: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 24 18:55:27.522: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 24 18:55:27.522: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 24 18:55:27.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 24 18:55:27.974: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 24 18:55:27.974: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 24 18:55:27.974: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 24 18:55:27.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 24 18:55:28.380: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 24 18:55:28.380: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 24 18:55:28.380: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 24 18:55:28.380: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 18:55:28.389: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jan 24 18:55:38.430: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 24 18:55:38.430: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 24 18:55:38.430: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 24 18:55:38.484: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jan 24 18:55:38.489: INFO: ss-0  vikash-v125latest-conf-71087  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  }]
Jan 24 18:55:38.490: INFO: ss-1  vikash-v125latest-conf-59870  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
Jan 24 18:55:38.490: INFO: ss-2  vikash-v125latest-conf-71087  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
Jan 24 18:55:38.490: INFO: 
Jan 24 18:55:38.490: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 24 18:55:39.511: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jan 24 18:55:39.511: INFO: ss-0  vikash-v125latest-conf-71087  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  }]
Jan 24 18:55:39.511: INFO: ss-1  vikash-v125latest-conf-59870  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
Jan 24 18:55:39.512: INFO: ss-2  vikash-v125latest-conf-71087  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
Jan 24 18:55:39.512: INFO: 
Jan 24 18:55:39.512: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 24 18:55:40.616: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jan 24 18:55:40.616: INFO: ss-1  vikash-v125latest-conf-59870  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
Jan 24 18:55:40.616: INFO: 
Jan 24 18:55:40.616: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 24 18:55:41.629: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Jan 24 18:55:41.629: INFO: ss-1  vikash-v125latest-conf-59870  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
Jan 24 18:55:41.629: INFO: 
Jan 24 18:55:41.629: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 24 18:55:42.648: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.831037014s
Jan 24 18:55:43.657: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.811668767s
Jan 24 18:55:44.670: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.803055151s
Jan 24 18:55:45.679: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.78993984s
Jan 24 18:55:46.689: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.781439425s
Jan 24 18:55:47.703: INFO: Verifying statefulset ss doesn't scale past 0 for another 768.126332ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8063 01/24/23 18:55:48.704
Jan 24 18:55:48.733: INFO: Scaling statefulset ss to 0
Jan 24 18:55:48.790: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 24 18:55:48.815: INFO: Deleting all statefulset in ns statefulset-8063
Jan 24 18:55:48.834: INFO: Scaling statefulset ss to 0
Jan 24 18:55:48.872: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 18:55:48.888: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 24 18:55:48.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8063" for this suite. 01/24/23 18:55:49.02
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":66,"skipped":1311,"failed":0}
------------------------------
• [SLOW TEST] [56.158 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:54:52.902
    Jan 24 18:54:52.903: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename statefulset 01/24/23 18:54:52.906
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:54:52.95
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:54:52.984
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-8063 01/24/23 18:54:53.013
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-8063 01/24/23 18:54:53.039
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8063 01/24/23 18:54:53.068
    Jan 24 18:54:53.079: INFO: Found 0 stateful pods, waiting for 1
    Jan 24 18:55:03.091: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 01/24/23 18:55:03.091
    Jan 24 18:55:03.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 24 18:55:03.910: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 24 18:55:03.910: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 24 18:55:03.910: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 24 18:55:03.939: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Jan 24 18:55:14.089: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jan 24 18:55:14.090: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 18:55:14.169: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
    Jan 24 18:55:14.169: INFO: ss-0  vikash-v125latest-conf-71087  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  }]
    Jan 24 18:55:14.170: INFO: 
    Jan 24 18:55:14.175: INFO: StatefulSet ss has not reached scale 3, at 1
    Jan 24 18:55:15.251: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.972199311s
    Jan 24 18:55:16.283: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.902502961s
    Jan 24 18:55:17.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.870523525s
    Jan 24 18:55:18.431: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.808135495s
    Jan 24 18:55:19.464: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.721080428s
    Jan 24 18:55:20.484: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.684075348s
    Jan 24 18:55:21.511: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.667476222s
    Jan 24 18:55:22.530: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.638516575s
    Jan 24 18:55:23.597: INFO: Verifying statefulset ss doesn't scale past 3 for another 619.234325ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8063 01/24/23 18:55:24.6
    Jan 24 18:55:24.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 24 18:55:26.336: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 24 18:55:26.336: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 24 18:55:26.336: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 24 18:55:26.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 24 18:55:26.819: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Jan 24 18:55:26.819: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 24 18:55:26.819: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 24 18:55:26.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 24 18:55:27.170: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Jan 24 18:55:27.170: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 24 18:55:27.170: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 24 18:55:27.181: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 18:55:27.181: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 18:55:27.181: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 01/24/23 18:55:27.181
    Jan 24 18:55:27.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 24 18:55:27.521: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 24 18:55:27.522: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 24 18:55:27.522: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 24 18:55:27.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 24 18:55:27.974: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 24 18:55:27.974: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 24 18:55:27.974: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 24 18:55:27.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-8063 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 24 18:55:28.380: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 24 18:55:28.380: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 24 18:55:28.380: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 24 18:55:28.380: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 18:55:28.389: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
    Jan 24 18:55:38.430: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Jan 24 18:55:38.430: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Jan 24 18:55:38.430: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Jan 24 18:55:38.484: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
    Jan 24 18:55:38.489: INFO: ss-0  vikash-v125latest-conf-71087  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  }]
    Jan 24 18:55:38.490: INFO: ss-1  vikash-v125latest-conf-59870  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
    Jan 24 18:55:38.490: INFO: ss-2  vikash-v125latest-conf-71087  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
    Jan 24 18:55:38.490: INFO: 
    Jan 24 18:55:38.490: INFO: StatefulSet ss has not reached scale 0, at 3
    Jan 24 18:55:39.511: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
    Jan 24 18:55:39.511: INFO: ss-0  vikash-v125latest-conf-71087  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:54:53 +0000 UTC  }]
    Jan 24 18:55:39.511: INFO: ss-1  vikash-v125latest-conf-59870  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
    Jan 24 18:55:39.512: INFO: ss-2  vikash-v125latest-conf-71087  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
    Jan 24 18:55:39.512: INFO: 
    Jan 24 18:55:39.512: INFO: StatefulSet ss has not reached scale 0, at 3
    Jan 24 18:55:40.616: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
    Jan 24 18:55:40.616: INFO: ss-1  vikash-v125latest-conf-59870  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
    Jan 24 18:55:40.616: INFO: 
    Jan 24 18:55:40.616: INFO: StatefulSet ss has not reached scale 0, at 1
    Jan 24 18:55:41.629: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
    Jan 24 18:55:41.629: INFO: ss-1  vikash-v125latest-conf-59870  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:28 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 18:55:14 +0000 UTC  }]
    Jan 24 18:55:41.629: INFO: 
    Jan 24 18:55:41.629: INFO: StatefulSet ss has not reached scale 0, at 1
    Jan 24 18:55:42.648: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.831037014s
    Jan 24 18:55:43.657: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.811668767s
    Jan 24 18:55:44.670: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.803055151s
    Jan 24 18:55:45.679: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.78993984s
    Jan 24 18:55:46.689: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.781439425s
    Jan 24 18:55:47.703: INFO: Verifying statefulset ss doesn't scale past 0 for another 768.126332ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8063 01/24/23 18:55:48.704
    Jan 24 18:55:48.733: INFO: Scaling statefulset ss to 0
    Jan 24 18:55:48.790: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 24 18:55:48.815: INFO: Deleting all statefulset in ns statefulset-8063
    Jan 24 18:55:48.834: INFO: Scaling statefulset ss to 0
    Jan 24 18:55:48.872: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 18:55:48.888: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 24 18:55:48.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-8063" for this suite. 01/24/23 18:55:49.02
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:55:49.061
Jan 24 18:55:49.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename subpath 01/24/23 18:55:49.076
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:55:49.165
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:55:49.187
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 01/24/23 18:55:49.217
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-z7tt 01/24/23 18:55:49.289
STEP: Creating a pod to test atomic-volume-subpath 01/24/23 18:55:49.289
Jan 24 18:55:49.323: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-z7tt" in namespace "subpath-150" to be "Succeeded or Failed"
Jan 24 18:55:49.347: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Pending", Reason="", readiness=false. Elapsed: 24.117551ms
Jan 24 18:55:51.375: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051524419s
Jan 24 18:55:53.448: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 4.124477857s
Jan 24 18:55:55.379: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 6.055224669s
Jan 24 18:55:57.355: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 8.031519586s
Jan 24 18:55:59.357: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 10.033631806s
Jan 24 18:56:01.356: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 12.032677956s
Jan 24 18:56:03.357: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 14.03390246s
Jan 24 18:56:05.360: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 16.03694008s
Jan 24 18:56:07.360: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 18.036593111s
Jan 24 18:56:09.368: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 20.044681268s
Jan 24 18:56:11.377: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 22.053342175s
Jan 24 18:56:13.385: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 24.061569959s
Jan 24 18:56:15.401: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=false. Elapsed: 26.077335862s
Jan 24 18:56:17.358: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.034932387s
STEP: Saw pod success 01/24/23 18:56:17.359
Jan 24 18:56:17.359: INFO: Pod "pod-subpath-test-secret-z7tt" satisfied condition "Succeeded or Failed"
Jan 24 18:56:17.368: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-subpath-test-secret-z7tt container test-container-subpath-secret-z7tt: <nil>
STEP: delete the pod 01/24/23 18:56:17.388
Jan 24 18:56:17.413: INFO: Waiting for pod pod-subpath-test-secret-z7tt to disappear
Jan 24 18:56:17.421: INFO: Pod pod-subpath-test-secret-z7tt no longer exists
STEP: Deleting pod pod-subpath-test-secret-z7tt 01/24/23 18:56:17.422
Jan 24 18:56:17.422: INFO: Deleting pod "pod-subpath-test-secret-z7tt" in namespace "subpath-150"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jan 24 18:56:17.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-150" for this suite. 01/24/23 18:56:17.437
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":67,"skipped":1312,"failed":0}
------------------------------
• [SLOW TEST] [28.394 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:55:49.061
    Jan 24 18:55:49.062: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename subpath 01/24/23 18:55:49.076
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:55:49.165
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:55:49.187
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 01/24/23 18:55:49.217
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-z7tt 01/24/23 18:55:49.289
    STEP: Creating a pod to test atomic-volume-subpath 01/24/23 18:55:49.289
    Jan 24 18:55:49.323: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-z7tt" in namespace "subpath-150" to be "Succeeded or Failed"
    Jan 24 18:55:49.347: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Pending", Reason="", readiness=false. Elapsed: 24.117551ms
    Jan 24 18:55:51.375: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051524419s
    Jan 24 18:55:53.448: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 4.124477857s
    Jan 24 18:55:55.379: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 6.055224669s
    Jan 24 18:55:57.355: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 8.031519586s
    Jan 24 18:55:59.357: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 10.033631806s
    Jan 24 18:56:01.356: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 12.032677956s
    Jan 24 18:56:03.357: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 14.03390246s
    Jan 24 18:56:05.360: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 16.03694008s
    Jan 24 18:56:07.360: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 18.036593111s
    Jan 24 18:56:09.368: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 20.044681268s
    Jan 24 18:56:11.377: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 22.053342175s
    Jan 24 18:56:13.385: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=true. Elapsed: 24.061569959s
    Jan 24 18:56:15.401: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Running", Reason="", readiness=false. Elapsed: 26.077335862s
    Jan 24 18:56:17.358: INFO: Pod "pod-subpath-test-secret-z7tt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.034932387s
    STEP: Saw pod success 01/24/23 18:56:17.359
    Jan 24 18:56:17.359: INFO: Pod "pod-subpath-test-secret-z7tt" satisfied condition "Succeeded or Failed"
    Jan 24 18:56:17.368: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-subpath-test-secret-z7tt container test-container-subpath-secret-z7tt: <nil>
    STEP: delete the pod 01/24/23 18:56:17.388
    Jan 24 18:56:17.413: INFO: Waiting for pod pod-subpath-test-secret-z7tt to disappear
    Jan 24 18:56:17.421: INFO: Pod pod-subpath-test-secret-z7tt no longer exists
    STEP: Deleting pod pod-subpath-test-secret-z7tt 01/24/23 18:56:17.422
    Jan 24 18:56:17.422: INFO: Deleting pod "pod-subpath-test-secret-z7tt" in namespace "subpath-150"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jan 24 18:56:17.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-150" for this suite. 01/24/23 18:56:17.437
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:56:17.477
Jan 24 18:56:17.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename endpointslicemirroring 01/24/23 18:56:17.481
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:56:17.526
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:56:17.533
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 01/24/23 18:56:17.574
Jan 24 18:56:17.610: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 01/24/23 18:56:19.643
STEP: mirroring deletion of a custom Endpoint 01/24/23 18:56:19.689
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Jan 24 18:56:19.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-5682" for this suite. 01/24/23 18:56:19.826
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":68,"skipped":1347,"failed":0}
------------------------------
• [2.401 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:56:17.477
    Jan 24 18:56:17.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename endpointslicemirroring 01/24/23 18:56:17.481
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:56:17.526
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:56:17.533
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 01/24/23 18:56:17.574
    Jan 24 18:56:17.610: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 01/24/23 18:56:19.643
    STEP: mirroring deletion of a custom Endpoint 01/24/23 18:56:19.689
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Jan 24 18:56:19.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-5682" for this suite. 01/24/23 18:56:19.826
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:56:19.888
Jan 24 18:56:19.892: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 18:56:19.895
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:56:19.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:56:20.031
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-8d0a9071-2f9e-4966-8511-50963d305823 01/24/23 18:56:20.083
STEP: Creating a pod to test consume configMaps 01/24/23 18:56:20.256
Jan 24 18:56:20.294: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0" in namespace "projected-2273" to be "Succeeded or Failed"
Jan 24 18:56:20.324: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0": Phase="Pending", Reason="", readiness=false. Elapsed: 30.040238ms
Jan 24 18:56:22.358: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063167951s
Jan 24 18:56:24.664: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.369314194s
Jan 24 18:56:26.364: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.069543018s
Jan 24 18:56:28.332: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.037898722s
STEP: Saw pod success 01/24/23 18:56:28.332
Jan 24 18:56:28.333: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0" satisfied condition "Succeeded or Failed"
Jan 24 18:56:28.341: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0 container projected-configmap-volume-test: <nil>
STEP: delete the pod 01/24/23 18:56:28.35
Jan 24 18:56:28.375: INFO: Waiting for pod pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0 to disappear
Jan 24 18:56:28.382: INFO: Pod pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 24 18:56:28.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2273" for this suite. 01/24/23 18:56:28.388
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":69,"skipped":1365,"failed":0}
------------------------------
• [SLOW TEST] [8.507 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:56:19.888
    Jan 24 18:56:19.892: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 18:56:19.895
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:56:19.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:56:20.031
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-8d0a9071-2f9e-4966-8511-50963d305823 01/24/23 18:56:20.083
    STEP: Creating a pod to test consume configMaps 01/24/23 18:56:20.256
    Jan 24 18:56:20.294: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0" in namespace "projected-2273" to be "Succeeded or Failed"
    Jan 24 18:56:20.324: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0": Phase="Pending", Reason="", readiness=false. Elapsed: 30.040238ms
    Jan 24 18:56:22.358: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063167951s
    Jan 24 18:56:24.664: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.369314194s
    Jan 24 18:56:26.364: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.069543018s
    Jan 24 18:56:28.332: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.037898722s
    STEP: Saw pod success 01/24/23 18:56:28.332
    Jan 24 18:56:28.333: INFO: Pod "pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0" satisfied condition "Succeeded or Failed"
    Jan 24 18:56:28.341: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 01/24/23 18:56:28.35
    Jan 24 18:56:28.375: INFO: Waiting for pod pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0 to disappear
    Jan 24 18:56:28.382: INFO: Pod pod-projected-configmaps-00ea690a-090b-476f-8fed-345a7b8477c0 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 24 18:56:28.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2273" for this suite. 01/24/23 18:56:28.388
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:56:28.399
Jan 24 18:56:28.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 18:56:28.403
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:56:28.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:56:28.431
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 18:56:28.465
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:56:30.41
STEP: Deploying the webhook pod 01/24/23 18:56:30.418
STEP: Wait for the deployment to be ready 01/24/23 18:56:30.435
Jan 24 18:56:30.466: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 24 18:56:32.489: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 56, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 56, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 56, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 56, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 18:56:34.498
STEP: Verifying the service has paired with the endpoint 01/24/23 18:56:34.553
Jan 24 18:56:35.559: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 01/24/23 18:56:35.567
STEP: Registering slow webhook via the AdmissionRegistration API 01/24/23 18:56:35.569
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 01/24/23 18:56:35.628
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 01/24/23 18:56:36.669
STEP: Registering slow webhook via the AdmissionRegistration API 01/24/23 18:56:36.671
STEP: Having no error when timeout is longer than webhook latency 01/24/23 18:56:37.767
STEP: Registering slow webhook via the AdmissionRegistration API 01/24/23 18:56:37.768
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 01/24/23 18:56:43.035
STEP: Registering slow webhook via the AdmissionRegistration API 01/24/23 18:56:43.037
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:56:48.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2290" for this suite. 01/24/23 18:56:48.305
STEP: Destroying namespace "webhook-2290-markers" for this suite. 01/24/23 18:56:48.405
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":70,"skipped":1382,"failed":0}
------------------------------
• [SLOW TEST] [20.464 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:56:28.399
    Jan 24 18:56:28.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 18:56:28.403
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:56:28.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:56:28.431
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 18:56:28.465
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:56:30.41
    STEP: Deploying the webhook pod 01/24/23 18:56:30.418
    STEP: Wait for the deployment to be ready 01/24/23 18:56:30.435
    Jan 24 18:56:30.466: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 24 18:56:32.489: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 56, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 56, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 56, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 56, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 18:56:34.498
    STEP: Verifying the service has paired with the endpoint 01/24/23 18:56:34.553
    Jan 24 18:56:35.559: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 01/24/23 18:56:35.567
    STEP: Registering slow webhook via the AdmissionRegistration API 01/24/23 18:56:35.569
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 01/24/23 18:56:35.628
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 01/24/23 18:56:36.669
    STEP: Registering slow webhook via the AdmissionRegistration API 01/24/23 18:56:36.671
    STEP: Having no error when timeout is longer than webhook latency 01/24/23 18:56:37.767
    STEP: Registering slow webhook via the AdmissionRegistration API 01/24/23 18:56:37.768
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 01/24/23 18:56:43.035
    STEP: Registering slow webhook via the AdmissionRegistration API 01/24/23 18:56:43.037
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:56:48.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2290" for this suite. 01/24/23 18:56:48.305
    STEP: Destroying namespace "webhook-2290-markers" for this suite. 01/24/23 18:56:48.405
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:56:48.888
Jan 24 18:56:48.888: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename events 01/24/23 18:56:48.893
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:56:49.192
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:56:49.365
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 01/24/23 18:56:49.4
Jan 24 18:56:49.433: INFO: created test-event-1
Jan 24 18:56:49.478: INFO: created test-event-2
Jan 24 18:56:49.510: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 01/24/23 18:56:49.511
STEP: delete collection of events 01/24/23 18:56:49.531
Jan 24 18:56:49.531: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 01/24/23 18:56:49.763
Jan 24 18:56:49.764: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Jan 24 18:56:49.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1404" for this suite. 01/24/23 18:56:49.909
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":71,"skipped":1417,"failed":0}
------------------------------
• [1.082 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:56:48.888
    Jan 24 18:56:48.888: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename events 01/24/23 18:56:48.893
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:56:49.192
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:56:49.365
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 01/24/23 18:56:49.4
    Jan 24 18:56:49.433: INFO: created test-event-1
    Jan 24 18:56:49.478: INFO: created test-event-2
    Jan 24 18:56:49.510: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 01/24/23 18:56:49.511
    STEP: delete collection of events 01/24/23 18:56:49.531
    Jan 24 18:56:49.531: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 01/24/23 18:56:49.763
    Jan 24 18:56:49.764: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Jan 24 18:56:49.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1404" for this suite. 01/24/23 18:56:49.909
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:56:49.972
Jan 24 18:56:49.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 18:56:49.976
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:56:50.196
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:56:50.206
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-653 01/24/23 18:56:50.236
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 01/24/23 18:56:50.287
STEP: creating service externalsvc in namespace services-653 01/24/23 18:56:50.288
STEP: creating replication controller externalsvc in namespace services-653 01/24/23 18:56:50.321
I0124 18:56:50.389667      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-653, replica count: 2
I0124 18:56:53.494606      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 18:56:56.495877      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 01/24/23 18:56:56.512
Jan 24 18:56:56.593: INFO: Creating new exec pod
Jan 24 18:56:56.626: INFO: Waiting up to 5m0s for pod "execpodmk74f" in namespace "services-653" to be "running"
Jan 24 18:56:56.648: INFO: Pod "execpodmk74f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.538129ms
Jan 24 18:56:58.691: INFO: Pod "execpodmk74f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063896406s
Jan 24 18:57:00.687: INFO: Pod "execpodmk74f": Phase="Running", Reason="", readiness=true. Elapsed: 4.059711722s
Jan 24 18:57:00.687: INFO: Pod "execpodmk74f" satisfied condition "running"
Jan 24 18:57:00.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-653 exec execpodmk74f -- /bin/sh -x -c nslookup nodeport-service.services-653.svc.cluster.local'
Jan 24 18:57:01.896: INFO: stderr: "+ nslookup nodeport-service.services-653.svc.cluster.local\n"
Jan 24 18:57:01.896: INFO: stdout: "Server:\t\t10.10.0.10\nAddress:\t10.10.0.10#53\n\nnodeport-service.services-653.svc.cluster.local\tcanonical name = externalsvc.services-653.svc.cluster.local.\nName:\texternalsvc.services-653.svc.cluster.local\nAddress: 10.10.163.83\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-653, will wait for the garbage collector to delete the pods 01/24/23 18:57:01.897
Jan 24 18:57:01.986: INFO: Deleting ReplicationController externalsvc took: 19.789547ms
Jan 24 18:57:02.206: INFO: Terminating ReplicationController externalsvc pods took: 220.363353ms
Jan 24 18:57:07.459: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 18:57:07.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-653" for this suite. 01/24/23 18:57:07.542
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":72,"skipped":1421,"failed":0}
------------------------------
• [SLOW TEST] [17.612 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:56:49.972
    Jan 24 18:56:49.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 18:56:49.976
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:56:50.196
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:56:50.206
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-653 01/24/23 18:56:50.236
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 01/24/23 18:56:50.287
    STEP: creating service externalsvc in namespace services-653 01/24/23 18:56:50.288
    STEP: creating replication controller externalsvc in namespace services-653 01/24/23 18:56:50.321
    I0124 18:56:50.389667      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-653, replica count: 2
    I0124 18:56:53.494606      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 18:56:56.495877      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 01/24/23 18:56:56.512
    Jan 24 18:56:56.593: INFO: Creating new exec pod
    Jan 24 18:56:56.626: INFO: Waiting up to 5m0s for pod "execpodmk74f" in namespace "services-653" to be "running"
    Jan 24 18:56:56.648: INFO: Pod "execpodmk74f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.538129ms
    Jan 24 18:56:58.691: INFO: Pod "execpodmk74f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063896406s
    Jan 24 18:57:00.687: INFO: Pod "execpodmk74f": Phase="Running", Reason="", readiness=true. Elapsed: 4.059711722s
    Jan 24 18:57:00.687: INFO: Pod "execpodmk74f" satisfied condition "running"
    Jan 24 18:57:00.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-653 exec execpodmk74f -- /bin/sh -x -c nslookup nodeport-service.services-653.svc.cluster.local'
    Jan 24 18:57:01.896: INFO: stderr: "+ nslookup nodeport-service.services-653.svc.cluster.local\n"
    Jan 24 18:57:01.896: INFO: stdout: "Server:\t\t10.10.0.10\nAddress:\t10.10.0.10#53\n\nnodeport-service.services-653.svc.cluster.local\tcanonical name = externalsvc.services-653.svc.cluster.local.\nName:\texternalsvc.services-653.svc.cluster.local\nAddress: 10.10.163.83\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-653, will wait for the garbage collector to delete the pods 01/24/23 18:57:01.897
    Jan 24 18:57:01.986: INFO: Deleting ReplicationController externalsvc took: 19.789547ms
    Jan 24 18:57:02.206: INFO: Terminating ReplicationController externalsvc pods took: 220.363353ms
    Jan 24 18:57:07.459: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 18:57:07.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-653" for this suite. 01/24/23 18:57:07.542
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:57:07.602
Jan 24 18:57:07.602: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-runtime 01/24/23 18:57:07.612
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:07.821
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:07.863
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 01/24/23 18:57:07.878
STEP: wait for the container to reach Succeeded 01/24/23 18:57:07.939
STEP: get the container status 01/24/23 18:57:14.113
STEP: the container should be terminated 01/24/23 18:57:14.13
STEP: the termination message should be set 01/24/23 18:57:14.131
Jan 24 18:57:14.131: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 01/24/23 18:57:14.131
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jan 24 18:57:14.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1734" for this suite. 01/24/23 18:57:14.819
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":73,"skipped":1484,"failed":0}
------------------------------
• [SLOW TEST] [7.326 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:57:07.602
    Jan 24 18:57:07.602: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-runtime 01/24/23 18:57:07.612
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:07.821
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:07.863
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 01/24/23 18:57:07.878
    STEP: wait for the container to reach Succeeded 01/24/23 18:57:07.939
    STEP: get the container status 01/24/23 18:57:14.113
    STEP: the container should be terminated 01/24/23 18:57:14.13
    STEP: the termination message should be set 01/24/23 18:57:14.131
    Jan 24 18:57:14.131: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 01/24/23 18:57:14.131
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jan 24 18:57:14.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1734" for this suite. 01/24/23 18:57:14.819
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:57:14.95
Jan 24 18:57:14.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 18:57:14.997
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:15.281
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:15.456
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 18:57:15.881
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:57:19.334
STEP: Deploying the webhook pod 01/24/23 18:57:19.403
STEP: Wait for the deployment to be ready 01/24/23 18:57:19.471
Jan 24 18:57:19.506: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 24 18:57:21.586: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 18:57:23.598: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 18:57:25.611
STEP: Verifying the service has paired with the endpoint 01/24/23 18:57:25.787
Jan 24 18:57:26.798: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 01/24/23 18:57:26.81
STEP: create a pod 01/24/23 18:57:26.856
Jan 24 18:57:26.874: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-4972" to be "running"
Jan 24 18:57:26.888: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.125419ms
Jan 24 18:57:28.904: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02900701s
Jan 24 18:57:30.920: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.045077875s
Jan 24 18:57:30.920: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 01/24/23 18:57:30.921
Jan 24 18:57:30.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=webhook-4972 attach --namespace=webhook-4972 to-be-attached-pod -i -c=container1'
Jan 24 18:57:32.197: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 18:57:32.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4972" for this suite. 01/24/23 18:57:32.265
STEP: Destroying namespace "webhook-4972-markers" for this suite. 01/24/23 18:57:32.301
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":74,"skipped":1485,"failed":0}
------------------------------
• [SLOW TEST] [17.920 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:57:14.95
    Jan 24 18:57:14.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 18:57:14.997
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:15.281
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:15.456
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 18:57:15.881
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 18:57:19.334
    STEP: Deploying the webhook pod 01/24/23 18:57:19.403
    STEP: Wait for the deployment to be ready 01/24/23 18:57:19.471
    Jan 24 18:57:19.506: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 24 18:57:21.586: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 18:57:23.598: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 18, 57, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 18:57:25.611
    STEP: Verifying the service has paired with the endpoint 01/24/23 18:57:25.787
    Jan 24 18:57:26.798: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 01/24/23 18:57:26.81
    STEP: create a pod 01/24/23 18:57:26.856
    Jan 24 18:57:26.874: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-4972" to be "running"
    Jan 24 18:57:26.888: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 13.125419ms
    Jan 24 18:57:28.904: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02900701s
    Jan 24 18:57:30.920: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.045077875s
    Jan 24 18:57:30.920: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 01/24/23 18:57:30.921
    Jan 24 18:57:30.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=webhook-4972 attach --namespace=webhook-4972 to-be-attached-pod -i -c=container1'
    Jan 24 18:57:32.197: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 18:57:32.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4972" for this suite. 01/24/23 18:57:32.265
    STEP: Destroying namespace "webhook-4972-markers" for this suite. 01/24/23 18:57:32.301
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:57:32.943
Jan 24 18:57:32.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 18:57:32.948
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:33.25
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:33.291
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-8506/configmap-test-1d1eaccd-5fa8-480e-9bf1-438c9447352d 01/24/23 18:57:33.308
STEP: Creating a pod to test consume configMaps 01/24/23 18:57:33.324
Jan 24 18:57:33.386: INFO: Waiting up to 5m0s for pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1" in namespace "configmap-8506" to be "Succeeded or Failed"
Jan 24 18:57:33.400: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.22462ms
Jan 24 18:57:35.421: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035404846s
Jan 24 18:57:37.416: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1": Phase="Running", Reason="", readiness=false. Elapsed: 4.030229581s
Jan 24 18:57:39.559: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1": Phase="Running", Reason="", readiness=false. Elapsed: 6.173287417s
Jan 24 18:57:41.410: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023553401s
STEP: Saw pod success 01/24/23 18:57:41.41
Jan 24 18:57:41.412: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1" satisfied condition "Succeeded or Failed"
Jan 24 18:57:41.423: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1 container env-test: <nil>
STEP: delete the pod 01/24/23 18:57:41.618
Jan 24 18:57:41.689: INFO: Waiting for pod pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1 to disappear
Jan 24 18:57:41.704: INFO: Pod pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 18:57:41.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8506" for this suite. 01/24/23 18:57:41.751
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":75,"skipped":1506,"failed":0}
------------------------------
• [SLOW TEST] [8.855 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:57:32.943
    Jan 24 18:57:32.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 18:57:32.948
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:33.25
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:33.291
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-8506/configmap-test-1d1eaccd-5fa8-480e-9bf1-438c9447352d 01/24/23 18:57:33.308
    STEP: Creating a pod to test consume configMaps 01/24/23 18:57:33.324
    Jan 24 18:57:33.386: INFO: Waiting up to 5m0s for pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1" in namespace "configmap-8506" to be "Succeeded or Failed"
    Jan 24 18:57:33.400: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.22462ms
    Jan 24 18:57:35.421: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035404846s
    Jan 24 18:57:37.416: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1": Phase="Running", Reason="", readiness=false. Elapsed: 4.030229581s
    Jan 24 18:57:39.559: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1": Phase="Running", Reason="", readiness=false. Elapsed: 6.173287417s
    Jan 24 18:57:41.410: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023553401s
    STEP: Saw pod success 01/24/23 18:57:41.41
    Jan 24 18:57:41.412: INFO: Pod "pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1" satisfied condition "Succeeded or Failed"
    Jan 24 18:57:41.423: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1 container env-test: <nil>
    STEP: delete the pod 01/24/23 18:57:41.618
    Jan 24 18:57:41.689: INFO: Waiting for pod pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1 to disappear
    Jan 24 18:57:41.704: INFO: Pod pod-configmaps-f7fd1804-aa40-4877-85fa-cd0e80b12fe1 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 18:57:41.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8506" for this suite. 01/24/23 18:57:41.751
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:57:41.813
Jan 24 18:57:41.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 18:57:41.818
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:41.884
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:41.905
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 01/24/23 18:57:41.924
Jan 24 18:57:41.926: INFO: namespace kubectl-9666
Jan 24 18:57:41.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9666 create -f -'
Jan 24 18:57:47.858: INFO: stderr: ""
Jan 24 18:57:47.858: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 01/24/23 18:57:47.858
Jan 24 18:57:48.873: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 18:57:48.873: INFO: Found 0 / 1
Jan 24 18:57:49.870: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 18:57:49.870: INFO: Found 0 / 1
Jan 24 18:57:50.896: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 18:57:50.896: INFO: Found 1 / 1
Jan 24 18:57:50.896: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 24 18:57:50.924: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 18:57:50.924: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 24 18:57:50.924: INFO: wait on agnhost-primary startup in kubectl-9666 
Jan 24 18:57:50.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9666 logs agnhost-primary-jd6mq agnhost-primary'
Jan 24 18:57:51.427: INFO: stderr: ""
Jan 24 18:57:51.427: INFO: stdout: "Paused\n"
STEP: exposing RC 01/24/23 18:57:51.427
Jan 24 18:57:51.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9666 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Jan 24 18:57:52.000: INFO: stderr: ""
Jan 24 18:57:52.000: INFO: stdout: "service/rm2 exposed\n"
Jan 24 18:57:52.021: INFO: Service rm2 in namespace kubectl-9666 found.
STEP: exposing service 01/24/23 18:57:54.074
Jan 24 18:57:54.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9666 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Jan 24 18:57:55.173: INFO: stderr: ""
Jan 24 18:57:55.173: INFO: stdout: "service/rm3 exposed\n"
Jan 24 18:57:55.235: INFO: Service rm3 in namespace kubectl-9666 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 18:57:57.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9666" for this suite. 01/24/23 18:57:57.294
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":76,"skipped":1518,"failed":0}
------------------------------
• [SLOW TEST] [15.502 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:57:41.813
    Jan 24 18:57:41.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 18:57:41.818
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:41.884
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:41.905
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 01/24/23 18:57:41.924
    Jan 24 18:57:41.926: INFO: namespace kubectl-9666
    Jan 24 18:57:41.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9666 create -f -'
    Jan 24 18:57:47.858: INFO: stderr: ""
    Jan 24 18:57:47.858: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 01/24/23 18:57:47.858
    Jan 24 18:57:48.873: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 18:57:48.873: INFO: Found 0 / 1
    Jan 24 18:57:49.870: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 18:57:49.870: INFO: Found 0 / 1
    Jan 24 18:57:50.896: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 18:57:50.896: INFO: Found 1 / 1
    Jan 24 18:57:50.896: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Jan 24 18:57:50.924: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 18:57:50.924: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Jan 24 18:57:50.924: INFO: wait on agnhost-primary startup in kubectl-9666 
    Jan 24 18:57:50.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9666 logs agnhost-primary-jd6mq agnhost-primary'
    Jan 24 18:57:51.427: INFO: stderr: ""
    Jan 24 18:57:51.427: INFO: stdout: "Paused\n"
    STEP: exposing RC 01/24/23 18:57:51.427
    Jan 24 18:57:51.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9666 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Jan 24 18:57:52.000: INFO: stderr: ""
    Jan 24 18:57:52.000: INFO: stdout: "service/rm2 exposed\n"
    Jan 24 18:57:52.021: INFO: Service rm2 in namespace kubectl-9666 found.
    STEP: exposing service 01/24/23 18:57:54.074
    Jan 24 18:57:54.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9666 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Jan 24 18:57:55.173: INFO: stderr: ""
    Jan 24 18:57:55.173: INFO: stdout: "service/rm3 exposed\n"
    Jan 24 18:57:55.235: INFO: Service rm3 in namespace kubectl-9666 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 18:57:57.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9666" for this suite. 01/24/23 18:57:57.294
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:57:57.322
Jan 24 18:57:57.323: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename watch 01/24/23 18:57:57.326
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:57.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:57.395
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 01/24/23 18:57:57.412
STEP: modifying the configmap once 01/24/23 18:57:57.43
STEP: modifying the configmap a second time 01/24/23 18:57:57.458
STEP: deleting the configmap 01/24/23 18:57:57.482
STEP: creating a watch on configmaps from the resource version returned by the first update 01/24/23 18:57:57.508
STEP: Expecting to observe notifications for all changes to the configmap after the first update 01/24/23 18:57:57.528
Jan 24 18:57:57.529: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3028  5c2e2ca8-0349-41ee-bcbd-f23efcc3305d 19500 0 2023-01-24 18:57:57 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-01-24 18:57:57 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 18:57:57.532: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3028  5c2e2ca8-0349-41ee-bcbd-f23efcc3305d 19501 0 2023-01-24 18:57:57 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-01-24 18:57:57 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jan 24 18:57:57.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3028" for this suite. 01/24/23 18:57:57.546
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":77,"skipped":1530,"failed":0}
------------------------------
• [0.245 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:57:57.322
    Jan 24 18:57:57.323: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename watch 01/24/23 18:57:57.326
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:57.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:57.395
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 01/24/23 18:57:57.412
    STEP: modifying the configmap once 01/24/23 18:57:57.43
    STEP: modifying the configmap a second time 01/24/23 18:57:57.458
    STEP: deleting the configmap 01/24/23 18:57:57.482
    STEP: creating a watch on configmaps from the resource version returned by the first update 01/24/23 18:57:57.508
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 01/24/23 18:57:57.528
    Jan 24 18:57:57.529: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3028  5c2e2ca8-0349-41ee-bcbd-f23efcc3305d 19500 0 2023-01-24 18:57:57 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-01-24 18:57:57 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 18:57:57.532: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3028  5c2e2ca8-0349-41ee-bcbd-f23efcc3305d 19501 0 2023-01-24 18:57:57 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-01-24 18:57:57 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jan 24 18:57:57.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3028" for this suite. 01/24/23 18:57:57.546
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:57:57.577
Jan 24 18:57:57.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-runtime 01/24/23 18:57:57.581
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:57.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:57.667
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 01/24/23 18:57:57.685
STEP: wait for the container to reach Failed 01/24/23 18:57:57.758
STEP: get the container status 01/24/23 18:58:05.488
STEP: the container should be terminated 01/24/23 18:58:05.856
STEP: the termination message should be set 01/24/23 18:58:05.856
Jan 24 18:58:05.856: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 01/24/23 18:58:05.856
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jan 24 18:58:06.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1501" for this suite. 01/24/23 18:58:06.564
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":78,"skipped":1546,"failed":0}
------------------------------
• [SLOW TEST] [9.003 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:57:57.577
    Jan 24 18:57:57.578: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-runtime 01/24/23 18:57:57.581
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:57:57.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:57:57.667
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 01/24/23 18:57:57.685
    STEP: wait for the container to reach Failed 01/24/23 18:57:57.758
    STEP: get the container status 01/24/23 18:58:05.488
    STEP: the container should be terminated 01/24/23 18:58:05.856
    STEP: the termination message should be set 01/24/23 18:58:05.856
    Jan 24 18:58:05.856: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 01/24/23 18:58:05.856
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jan 24 18:58:06.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1501" for this suite. 01/24/23 18:58:06.564
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:58:06.59
Jan 24 18:58:06.590: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 18:58:06.594
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:58:06.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:58:06.699
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7658 01/24/23 18:58:06.714
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 01/24/23 18:58:06.738
STEP: creating service externalsvc in namespace services-7658 01/24/23 18:58:06.74
STEP: creating replication controller externalsvc in namespace services-7658 01/24/23 18:58:06.781
I0124 18:58:06.806391      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7658, replica count: 2
I0124 18:58:09.859039      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 01/24/23 18:58:09.866
Jan 24 18:58:09.888: INFO: Creating new exec pod
Jan 24 18:58:09.894: INFO: Waiting up to 5m0s for pod "execpoddx9nq" in namespace "services-7658" to be "running"
Jan 24 18:58:09.898: INFO: Pod "execpoddx9nq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.109944ms
Jan 24 18:58:11.915: INFO: Pod "execpoddx9nq": Phase="Running", Reason="", readiness=true. Elapsed: 2.020841024s
Jan 24 18:58:11.916: INFO: Pod "execpoddx9nq" satisfied condition "running"
Jan 24 18:58:11.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-7658 exec execpoddx9nq -- /bin/sh -x -c nslookup clusterip-service.services-7658.svc.cluster.local'
Jan 24 18:58:12.643: INFO: stderr: "+ nslookup clusterip-service.services-7658.svc.cluster.local\n"
Jan 24 18:58:12.643: INFO: stdout: "Server:\t\t10.10.0.10\nAddress:\t10.10.0.10#53\n\nclusterip-service.services-7658.svc.cluster.local\tcanonical name = externalsvc.services-7658.svc.cluster.local.\nName:\texternalsvc.services-7658.svc.cluster.local\nAddress: 10.10.53.63\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7658, will wait for the garbage collector to delete the pods 01/24/23 18:58:12.643
Jan 24 18:58:12.728: INFO: Deleting ReplicationController externalsvc took: 26.180045ms
Jan 24 18:58:12.852: INFO: Terminating ReplicationController externalsvc pods took: 123.278004ms
Jan 24 18:58:16.384: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 18:58:16.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7658" for this suite. 01/24/23 18:58:16.44
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":79,"skipped":1566,"failed":0}
------------------------------
• [SLOW TEST] [9.865 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:58:06.59
    Jan 24 18:58:06.590: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 18:58:06.594
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:58:06.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:58:06.699
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7658 01/24/23 18:58:06.714
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 01/24/23 18:58:06.738
    STEP: creating service externalsvc in namespace services-7658 01/24/23 18:58:06.74
    STEP: creating replication controller externalsvc in namespace services-7658 01/24/23 18:58:06.781
    I0124 18:58:06.806391      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7658, replica count: 2
    I0124 18:58:09.859039      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 01/24/23 18:58:09.866
    Jan 24 18:58:09.888: INFO: Creating new exec pod
    Jan 24 18:58:09.894: INFO: Waiting up to 5m0s for pod "execpoddx9nq" in namespace "services-7658" to be "running"
    Jan 24 18:58:09.898: INFO: Pod "execpoddx9nq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.109944ms
    Jan 24 18:58:11.915: INFO: Pod "execpoddx9nq": Phase="Running", Reason="", readiness=true. Elapsed: 2.020841024s
    Jan 24 18:58:11.916: INFO: Pod "execpoddx9nq" satisfied condition "running"
    Jan 24 18:58:11.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-7658 exec execpoddx9nq -- /bin/sh -x -c nslookup clusterip-service.services-7658.svc.cluster.local'
    Jan 24 18:58:12.643: INFO: stderr: "+ nslookup clusterip-service.services-7658.svc.cluster.local\n"
    Jan 24 18:58:12.643: INFO: stdout: "Server:\t\t10.10.0.10\nAddress:\t10.10.0.10#53\n\nclusterip-service.services-7658.svc.cluster.local\tcanonical name = externalsvc.services-7658.svc.cluster.local.\nName:\texternalsvc.services-7658.svc.cluster.local\nAddress: 10.10.53.63\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-7658, will wait for the garbage collector to delete the pods 01/24/23 18:58:12.643
    Jan 24 18:58:12.728: INFO: Deleting ReplicationController externalsvc took: 26.180045ms
    Jan 24 18:58:12.852: INFO: Terminating ReplicationController externalsvc pods took: 123.278004ms
    Jan 24 18:58:16.384: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 18:58:16.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7658" for this suite. 01/24/23 18:58:16.44
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:58:16.463
Jan 24 18:58:16.464: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 18:58:16.468
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:58:16.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:58:16.515
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/24/23 18:58:16.524
Jan 24 18:58:16.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3093 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Jan 24 18:58:16.835: INFO: stderr: ""
Jan 24 18:58:16.835: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 01/24/23 18:58:16.835
STEP: verifying the pod e2e-test-httpd-pod was created 01/24/23 18:58:21.887
Jan 24 18:58:21.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3093 get pod e2e-test-httpd-pod -o json'
Jan 24 18:58:22.583: INFO: stderr: ""
Jan 24 18:58:22.584: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"0eab2c7ff82ac6e0117758849f0b1e9211facd94e2f243c870b7d079c134888b\",\n            \"cni.projectcalico.org/podIP\": \"10.244.71.244/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.244.71.244/32\"\n        },\n        \"creationTimestamp\": \"2023-01-24T18:58:16Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3093\",\n        \"resourceVersion\": \"19688\",\n        \"uid\": \"fc9a6dce-95c8-409f-a43e-4dca3f2b784d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-stts5\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"vikash-v125latest-conf-71087\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-stts5\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-24T18:58:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-24T18:58:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-24T18:58:19Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-24T18:58:16Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://4bf85a53cb684c682e4494abdddcdb4375fdda60d475b019081a455167a5685b\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-01-24T18:58:18Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.1.127\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.71.244\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.71.244\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-01-24T18:58:16Z\"\n    }\n}\n"
STEP: replace the image in the pod 01/24/23 18:58:22.584
Jan 24 18:58:22.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3093 replace -f -'
Jan 24 18:58:23.990: INFO: stderr: ""
Jan 24 18:58:23.990: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 01/24/23 18:58:23.99
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Jan 24 18:58:24.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3093 delete pods e2e-test-httpd-pod'
Jan 24 18:58:28.134: INFO: stderr: ""
Jan 24 18:58:28.134: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 18:58:28.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3093" for this suite. 01/24/23 18:58:28.149
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":80,"skipped":1586,"failed":0}
------------------------------
• [SLOW TEST] [11.718 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:58:16.463
    Jan 24 18:58:16.464: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 18:58:16.468
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:58:16.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:58:16.515
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/24/23 18:58:16.524
    Jan 24 18:58:16.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3093 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Jan 24 18:58:16.835: INFO: stderr: ""
    Jan 24 18:58:16.835: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 01/24/23 18:58:16.835
    STEP: verifying the pod e2e-test-httpd-pod was created 01/24/23 18:58:21.887
    Jan 24 18:58:21.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3093 get pod e2e-test-httpd-pod -o json'
    Jan 24 18:58:22.583: INFO: stderr: ""
    Jan 24 18:58:22.584: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"0eab2c7ff82ac6e0117758849f0b1e9211facd94e2f243c870b7d079c134888b\",\n            \"cni.projectcalico.org/podIP\": \"10.244.71.244/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.244.71.244/32\"\n        },\n        \"creationTimestamp\": \"2023-01-24T18:58:16Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3093\",\n        \"resourceVersion\": \"19688\",\n        \"uid\": \"fc9a6dce-95c8-409f-a43e-4dca3f2b784d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-stts5\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"vikash-v125latest-conf-71087\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-stts5\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-24T18:58:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-24T18:58:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-24T18:58:19Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-01-24T18:58:16Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://4bf85a53cb684c682e4494abdddcdb4375fdda60d475b019081a455167a5685b\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-01-24T18:58:18Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.1.127\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.71.244\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.71.244\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-01-24T18:58:16Z\"\n    }\n}\n"
    STEP: replace the image in the pod 01/24/23 18:58:22.584
    Jan 24 18:58:22.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3093 replace -f -'
    Jan 24 18:58:23.990: INFO: stderr: ""
    Jan 24 18:58:23.990: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 01/24/23 18:58:23.99
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Jan 24 18:58:24.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3093 delete pods e2e-test-httpd-pod'
    Jan 24 18:58:28.134: INFO: stderr: ""
    Jan 24 18:58:28.134: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 18:58:28.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3093" for this suite. 01/24/23 18:58:28.149
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:58:28.183
Jan 24 18:58:28.183: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename endpointslice 01/24/23 18:58:28.2
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:58:28.346
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:58:28.386
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jan 24 18:58:30.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5542" for this suite. 01/24/23 18:58:30.844
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":81,"skipped":1589,"failed":0}
------------------------------
• [2.690 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:58:28.183
    Jan 24 18:58:28.183: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename endpointslice 01/24/23 18:58:28.2
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:58:28.346
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:58:28.386
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jan 24 18:58:30.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-5542" for this suite. 01/24/23 18:58:30.844
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:58:30.911
Jan 24 18:58:30.911: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 18:58:30.914
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:58:30.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:58:31.035
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-d0579337-d6ed-468a-97a2-2c3ed8cb6948 01/24/23 18:58:31.051
STEP: Creating a pod to test consume configMaps 01/24/23 18:58:31.073
Jan 24 18:58:31.123: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0" in namespace "projected-4729" to be "Succeeded or Failed"
Jan 24 18:58:31.161: INFO: Pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0": Phase="Pending", Reason="", readiness=false. Elapsed: 36.932321ms
Jan 24 18:58:33.227: INFO: Pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103686585s
Jan 24 18:58:35.181: INFO: Pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056835803s
Jan 24 18:58:37.179: INFO: Pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.055111699s
STEP: Saw pod success 01/24/23 18:58:37.179
Jan 24 18:58:37.179: INFO: Pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0" satisfied condition "Succeeded or Failed"
Jan 24 18:58:37.187: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 18:58:37.201
Jan 24 18:58:37.240: INFO: Waiting for pod pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0 to disappear
Jan 24 18:58:37.249: INFO: Pod pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 24 18:58:37.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4729" for this suite. 01/24/23 18:58:37.26
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":82,"skipped":1612,"failed":0}
------------------------------
• [SLOW TEST] [6.363 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:58:30.911
    Jan 24 18:58:30.911: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 18:58:30.914
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:58:30.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:58:31.035
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-d0579337-d6ed-468a-97a2-2c3ed8cb6948 01/24/23 18:58:31.051
    STEP: Creating a pod to test consume configMaps 01/24/23 18:58:31.073
    Jan 24 18:58:31.123: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0" in namespace "projected-4729" to be "Succeeded or Failed"
    Jan 24 18:58:31.161: INFO: Pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0": Phase="Pending", Reason="", readiness=false. Elapsed: 36.932321ms
    Jan 24 18:58:33.227: INFO: Pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103686585s
    Jan 24 18:58:35.181: INFO: Pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056835803s
    Jan 24 18:58:37.179: INFO: Pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.055111699s
    STEP: Saw pod success 01/24/23 18:58:37.179
    Jan 24 18:58:37.179: INFO: Pod "pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0" satisfied condition "Succeeded or Failed"
    Jan 24 18:58:37.187: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 18:58:37.201
    Jan 24 18:58:37.240: INFO: Waiting for pod pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0 to disappear
    Jan 24 18:58:37.249: INFO: Pod pod-projected-configmaps-c33a08c5-b897-4963-911c-5e7979e30ac0 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 24 18:58:37.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4729" for this suite. 01/24/23 18:58:37.26
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 18:58:37.278
Jan 24 18:58:37.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 18:58:37.284
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:58:37.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:58:37.339
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 01/24/23 18:58:37.346
Jan 24 18:58:37.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 01/24/23 18:59:31.493
Jan 24 18:59:31.498: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 18:59:49.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:00:28.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8431" for this suite. 01/24/23 19:00:28.868
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":83,"skipped":1618,"failed":0}
------------------------------
• [SLOW TEST] [111.609 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 18:58:37.278
    Jan 24 18:58:37.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 18:58:37.284
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 18:58:37.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 18:58:37.339
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 01/24/23 18:58:37.346
    Jan 24 18:58:37.348: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 01/24/23 18:59:31.493
    Jan 24 18:59:31.498: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 18:59:49.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:00:28.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8431" for this suite. 01/24/23 19:00:28.868
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:00:28.897
Jan 24 19:00:28.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:00:28.901
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:00:28.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:00:29.004
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-88ee315a-e290-42d6-9ba7-a60d7e6f09eb 01/24/23 19:00:29.02
STEP: Creating a pod to test consume configMaps 01/24/23 19:00:29.04
Jan 24 19:00:29.107: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4" in namespace "projected-2804" to be "Succeeded or Failed"
Jan 24 19:00:29.160: INFO: Pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4": Phase="Pending", Reason="", readiness=false. Elapsed: 53.472793ms
Jan 24 19:00:31.178: INFO: Pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070836849s
Jan 24 19:00:33.179: INFO: Pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072338303s
Jan 24 19:00:35.221: INFO: Pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.113741491s
STEP: Saw pod success 01/24/23 19:00:35.221
Jan 24 19:00:35.226: INFO: Pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4" satisfied condition "Succeeded or Failed"
Jan 24 19:00:35.239: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 19:00:35.305
Jan 24 19:00:35.342: INFO: Waiting for pod pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4 to disappear
Jan 24 19:00:35.350: INFO: Pod pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 24 19:00:35.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2804" for this suite. 01/24/23 19:00:35.362
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":84,"skipped":1627,"failed":0}
------------------------------
• [SLOW TEST] [6.483 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:00:28.897
    Jan 24 19:00:28.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:00:28.901
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:00:28.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:00:29.004
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-88ee315a-e290-42d6-9ba7-a60d7e6f09eb 01/24/23 19:00:29.02
    STEP: Creating a pod to test consume configMaps 01/24/23 19:00:29.04
    Jan 24 19:00:29.107: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4" in namespace "projected-2804" to be "Succeeded or Failed"
    Jan 24 19:00:29.160: INFO: Pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4": Phase="Pending", Reason="", readiness=false. Elapsed: 53.472793ms
    Jan 24 19:00:31.178: INFO: Pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070836849s
    Jan 24 19:00:33.179: INFO: Pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072338303s
    Jan 24 19:00:35.221: INFO: Pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.113741491s
    STEP: Saw pod success 01/24/23 19:00:35.221
    Jan 24 19:00:35.226: INFO: Pod "pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4" satisfied condition "Succeeded or Failed"
    Jan 24 19:00:35.239: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 19:00:35.305
    Jan 24 19:00:35.342: INFO: Waiting for pod pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4 to disappear
    Jan 24 19:00:35.350: INFO: Pod pod-projected-configmaps-e6d26d2f-8e2d-4a5e-9a47-be8af4d959e4 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 24 19:00:35.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2804" for this suite. 01/24/23 19:00:35.362
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:00:35.382
Jan 24 19:00:35.383: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:00:35.409
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:00:35.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:00:35.488
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 01/24/23 19:00:35.508
Jan 24 19:00:35.561: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8" in namespace "projected-3168" to be "Succeeded or Failed"
Jan 24 19:00:35.575: INFO: Pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.745533ms
Jan 24 19:00:37.590: INFO: Pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028797994s
Jan 24 19:00:39.595: INFO: Pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033835563s
Jan 24 19:00:41.583: INFO: Pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022022374s
STEP: Saw pod success 01/24/23 19:00:41.583
Jan 24 19:00:41.584: INFO: Pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8" satisfied condition "Succeeded or Failed"
Jan 24 19:00:41.590: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8 container client-container: <nil>
STEP: delete the pod 01/24/23 19:00:41.61
Jan 24 19:00:41.659: INFO: Waiting for pod downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8 to disappear
Jan 24 19:00:41.675: INFO: Pod downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 19:00:41.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3168" for this suite. 01/24/23 19:00:41.686
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":85,"skipped":1633,"failed":0}
------------------------------
• [SLOW TEST] [6.321 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:00:35.382
    Jan 24 19:00:35.383: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:00:35.409
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:00:35.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:00:35.488
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 01/24/23 19:00:35.508
    Jan 24 19:00:35.561: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8" in namespace "projected-3168" to be "Succeeded or Failed"
    Jan 24 19:00:35.575: INFO: Pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.745533ms
    Jan 24 19:00:37.590: INFO: Pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028797994s
    Jan 24 19:00:39.595: INFO: Pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033835563s
    Jan 24 19:00:41.583: INFO: Pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022022374s
    STEP: Saw pod success 01/24/23 19:00:41.583
    Jan 24 19:00:41.584: INFO: Pod "downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8" satisfied condition "Succeeded or Failed"
    Jan 24 19:00:41.590: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8 container client-container: <nil>
    STEP: delete the pod 01/24/23 19:00:41.61
    Jan 24 19:00:41.659: INFO: Waiting for pod downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8 to disappear
    Jan 24 19:00:41.675: INFO: Pod downwardapi-volume-e8ec4f77-bcc7-43f2-aa7e-c38822f84bb8 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 19:00:41.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3168" for this suite. 01/24/23 19:00:41.686
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:00:41.712
Jan 24 19:00:41.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-probe 01/24/23 19:00:41.717
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:00:41.765
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:00:41.776
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-831c900d-7320-4362-b89e-33a6aacf6867 in namespace container-probe-4095 01/24/23 19:00:41.793
Jan 24 19:00:41.853: INFO: Waiting up to 5m0s for pod "liveness-831c900d-7320-4362-b89e-33a6aacf6867" in namespace "container-probe-4095" to be "not pending"
Jan 24 19:00:41.867: INFO: Pod "liveness-831c900d-7320-4362-b89e-33a6aacf6867": Phase="Pending", Reason="", readiness=false. Elapsed: 13.541397ms
Jan 24 19:00:43.888: INFO: Pod "liveness-831c900d-7320-4362-b89e-33a6aacf6867": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034401798s
Jan 24 19:00:45.881: INFO: Pod "liveness-831c900d-7320-4362-b89e-33a6aacf6867": Phase="Running", Reason="", readiness=true. Elapsed: 4.026868574s
Jan 24 19:00:45.881: INFO: Pod "liveness-831c900d-7320-4362-b89e-33a6aacf6867" satisfied condition "not pending"
Jan 24 19:00:45.881: INFO: Started pod liveness-831c900d-7320-4362-b89e-33a6aacf6867 in namespace container-probe-4095
STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:00:45.882
Jan 24 19:00:45.891: INFO: Initial restart count of pod liveness-831c900d-7320-4362-b89e-33a6aacf6867 is 0
STEP: deleting the pod 01/24/23 19:04:47.668
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 24 19:04:47.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4095" for this suite. 01/24/23 19:04:47.751
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":86,"skipped":1638,"failed":0}
------------------------------
• [SLOW TEST] [246.063 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:00:41.712
    Jan 24 19:00:41.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-probe 01/24/23 19:00:41.717
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:00:41.765
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:00:41.776
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-831c900d-7320-4362-b89e-33a6aacf6867 in namespace container-probe-4095 01/24/23 19:00:41.793
    Jan 24 19:00:41.853: INFO: Waiting up to 5m0s for pod "liveness-831c900d-7320-4362-b89e-33a6aacf6867" in namespace "container-probe-4095" to be "not pending"
    Jan 24 19:00:41.867: INFO: Pod "liveness-831c900d-7320-4362-b89e-33a6aacf6867": Phase="Pending", Reason="", readiness=false. Elapsed: 13.541397ms
    Jan 24 19:00:43.888: INFO: Pod "liveness-831c900d-7320-4362-b89e-33a6aacf6867": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034401798s
    Jan 24 19:00:45.881: INFO: Pod "liveness-831c900d-7320-4362-b89e-33a6aacf6867": Phase="Running", Reason="", readiness=true. Elapsed: 4.026868574s
    Jan 24 19:00:45.881: INFO: Pod "liveness-831c900d-7320-4362-b89e-33a6aacf6867" satisfied condition "not pending"
    Jan 24 19:00:45.881: INFO: Started pod liveness-831c900d-7320-4362-b89e-33a6aacf6867 in namespace container-probe-4095
    STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:00:45.882
    Jan 24 19:00:45.891: INFO: Initial restart count of pod liveness-831c900d-7320-4362-b89e-33a6aacf6867 is 0
    STEP: deleting the pod 01/24/23 19:04:47.668
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 24 19:04:47.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4095" for this suite. 01/24/23 19:04:47.751
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:04:47.823
Jan 24 19:04:47.823: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 19:04:47.827
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:47.889
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:47.903
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 01/24/23 19:04:47.926
STEP: Getting a ResourceQuota 01/24/23 19:04:47.948
STEP: Updating a ResourceQuota 01/24/23 19:04:47.956
STEP: Verifying a ResourceQuota was modified 01/24/23 19:04:47.99
STEP: Deleting a ResourceQuota 01/24/23 19:04:48.003
STEP: Verifying the deleted ResourceQuota 01/24/23 19:04:48.026
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 19:04:48.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4396" for this suite. 01/24/23 19:04:48.06
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":87,"skipped":1727,"failed":0}
------------------------------
• [0.287 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:04:47.823
    Jan 24 19:04:47.823: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 19:04:47.827
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:47.889
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:47.903
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 01/24/23 19:04:47.926
    STEP: Getting a ResourceQuota 01/24/23 19:04:47.948
    STEP: Updating a ResourceQuota 01/24/23 19:04:47.956
    STEP: Verifying a ResourceQuota was modified 01/24/23 19:04:47.99
    STEP: Deleting a ResourceQuota 01/24/23 19:04:48.003
    STEP: Verifying the deleted ResourceQuota 01/24/23 19:04:48.026
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 19:04:48.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4396" for this suite. 01/24/23 19:04:48.06
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:04:48.137
Jan 24 19:04:48.137: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-runtime 01/24/23 19:04:48.143
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:48.228
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:48.245
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 01/24/23 19:04:48.258
STEP: wait for the container to reach Succeeded 01/24/23 19:04:48.3
STEP: get the container status 01/24/23 19:04:54.474
STEP: the container should be terminated 01/24/23 19:04:54.499
STEP: the termination message should be set 01/24/23 19:04:54.499
Jan 24 19:04:54.501: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 01/24/23 19:04:54.501
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jan 24 19:04:54.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7191" for this suite. 01/24/23 19:04:54.616
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":88,"skipped":1749,"failed":0}
------------------------------
• [SLOW TEST] [6.508 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:04:48.137
    Jan 24 19:04:48.137: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-runtime 01/24/23 19:04:48.143
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:48.228
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:48.245
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 01/24/23 19:04:48.258
    STEP: wait for the container to reach Succeeded 01/24/23 19:04:48.3
    STEP: get the container status 01/24/23 19:04:54.474
    STEP: the container should be terminated 01/24/23 19:04:54.499
    STEP: the termination message should be set 01/24/23 19:04:54.499
    Jan 24 19:04:54.501: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 01/24/23 19:04:54.501
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jan 24 19:04:54.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7191" for this suite. 01/24/23 19:04:54.616
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:04:54.648
Jan 24 19:04:54.649: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename disruption 01/24/23 19:04:54.653
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:54.73
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:54.779
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 01/24/23 19:04:54.8
STEP: Waiting for the pdb to be processed 01/24/23 19:04:54.818
STEP: updating the pdb 01/24/23 19:04:56.847
STEP: Waiting for the pdb to be processed 01/24/23 19:04:56.876
STEP: patching the pdb 01/24/23 19:04:56.892
STEP: Waiting for the pdb to be processed 01/24/23 19:04:56.92
STEP: Waiting for the pdb to be deleted 01/24/23 19:04:56.955
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jan 24 19:04:56.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-541" for this suite. 01/24/23 19:04:56.981
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":89,"skipped":1759,"failed":0}
------------------------------
• [2.353 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:04:54.648
    Jan 24 19:04:54.649: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename disruption 01/24/23 19:04:54.653
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:54.73
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:54.779
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 01/24/23 19:04:54.8
    STEP: Waiting for the pdb to be processed 01/24/23 19:04:54.818
    STEP: updating the pdb 01/24/23 19:04:56.847
    STEP: Waiting for the pdb to be processed 01/24/23 19:04:56.876
    STEP: patching the pdb 01/24/23 19:04:56.892
    STEP: Waiting for the pdb to be processed 01/24/23 19:04:56.92
    STEP: Waiting for the pdb to be deleted 01/24/23 19:04:56.955
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jan 24 19:04:56.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-541" for this suite. 01/24/23 19:04:56.981
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:04:57.014
Jan 24 19:04:57.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 19:04:57.017
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:57.076
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:57.095
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 01/24/23 19:04:57.107
STEP: submitting the pod to kubernetes 01/24/23 19:04:57.107
STEP: verifying QOS class is set on the pod 01/24/23 19:04:57.129
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Jan 24 19:04:57.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5644" for this suite. 01/24/23 19:04:57.192
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":90,"skipped":1770,"failed":0}
------------------------------
• [0.216 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:04:57.014
    Jan 24 19:04:57.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 19:04:57.017
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:57.076
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:57.095
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 01/24/23 19:04:57.107
    STEP: submitting the pod to kubernetes 01/24/23 19:04:57.107
    STEP: verifying QOS class is set on the pod 01/24/23 19:04:57.129
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Jan 24 19:04:57.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5644" for this suite. 01/24/23 19:04:57.192
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:04:57.243
Jan 24 19:04:57.244: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename gc 01/24/23 19:04:57.25
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:57.307
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:57.32
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 01/24/23 19:04:57.332
STEP: Wait for the Deployment to create new ReplicaSet 01/24/23 19:04:57.349
STEP: delete the deployment 01/24/23 19:04:57.928
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 01/24/23 19:04:57.973
STEP: Gathering metrics 01/24/23 19:04:58.921
W0124 19:04:58.970757      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 24 19:04:58.996: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 24 19:04:58.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9491" for this suite. 01/24/23 19:04:59.026
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":91,"skipped":1770,"failed":0}
------------------------------
• [1.928 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:04:57.243
    Jan 24 19:04:57.244: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename gc 01/24/23 19:04:57.25
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:57.307
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:57.32
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 01/24/23 19:04:57.332
    STEP: Wait for the Deployment to create new ReplicaSet 01/24/23 19:04:57.349
    STEP: delete the deployment 01/24/23 19:04:57.928
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 01/24/23 19:04:57.973
    STEP: Gathering metrics 01/24/23 19:04:58.921
    W0124 19:04:58.970757      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 24 19:04:58.996: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 24 19:04:58.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9491" for this suite. 01/24/23 19:04:59.026
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:04:59.233
Jan 24 19:04:59.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 19:04:59.259
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:59.362
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:59.382
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 19:04:59.552
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:05:07.419
STEP: Deploying the webhook pod 01/24/23 19:05:07.437
STEP: Wait for the deployment to be ready 01/24/23 19:05:07.451
Jan 24 19:05:07.499: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/24/23 19:05:09.514
STEP: Verifying the service has paired with the endpoint 01/24/23 19:05:09.53
Jan 24 19:05:10.533: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 01/24/23 19:05:10.542
STEP: create a namespace for the webhook 01/24/23 19:05:10.572
STEP: create a configmap should be unconditionally rejected by the webhook 01/24/23 19:05:10.589
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:05:10.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-271" for this suite. 01/24/23 19:05:10.658
STEP: Destroying namespace "webhook-271-markers" for this suite. 01/24/23 19:05:10.669
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":92,"skipped":1772,"failed":0}
------------------------------
• [SLOW TEST] [11.510 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:04:59.233
    Jan 24 19:04:59.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 19:04:59.259
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:04:59.362
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:04:59.382
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 19:04:59.552
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:05:07.419
    STEP: Deploying the webhook pod 01/24/23 19:05:07.437
    STEP: Wait for the deployment to be ready 01/24/23 19:05:07.451
    Jan 24 19:05:07.499: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/24/23 19:05:09.514
    STEP: Verifying the service has paired with the endpoint 01/24/23 19:05:09.53
    Jan 24 19:05:10.533: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 01/24/23 19:05:10.542
    STEP: create a namespace for the webhook 01/24/23 19:05:10.572
    STEP: create a configmap should be unconditionally rejected by the webhook 01/24/23 19:05:10.589
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:05:10.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-271" for this suite. 01/24/23 19:05:10.658
    STEP: Destroying namespace "webhook-271-markers" for this suite. 01/24/23 19:05:10.669
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:05:10.745
Jan 24 19:05:10.745: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename events 01/24/23 19:05:10.751
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:05:10.801
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:05:10.812
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 01/24/23 19:05:10.819
STEP: listing events in all namespaces 01/24/23 19:05:10.828
STEP: listing events in test namespace 01/24/23 19:05:10.841
STEP: listing events with field selection filtering on source 01/24/23 19:05:10.847
STEP: listing events with field selection filtering on reportingController 01/24/23 19:05:10.853
STEP: getting the test event 01/24/23 19:05:10.857
STEP: patching the test event 01/24/23 19:05:10.867
STEP: getting the test event 01/24/23 19:05:10.887
STEP: updating the test event 01/24/23 19:05:10.896
STEP: getting the test event 01/24/23 19:05:10.91
STEP: deleting the test event 01/24/23 19:05:10.915
STEP: listing events in all namespaces 01/24/23 19:05:10.925
STEP: listing events in test namespace 01/24/23 19:05:10.939
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Jan 24 19:05:10.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4740" for this suite. 01/24/23 19:05:10.952
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":93,"skipped":1787,"failed":0}
------------------------------
• [0.213 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:05:10.745
    Jan 24 19:05:10.745: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename events 01/24/23 19:05:10.751
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:05:10.801
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:05:10.812
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 01/24/23 19:05:10.819
    STEP: listing events in all namespaces 01/24/23 19:05:10.828
    STEP: listing events in test namespace 01/24/23 19:05:10.841
    STEP: listing events with field selection filtering on source 01/24/23 19:05:10.847
    STEP: listing events with field selection filtering on reportingController 01/24/23 19:05:10.853
    STEP: getting the test event 01/24/23 19:05:10.857
    STEP: patching the test event 01/24/23 19:05:10.867
    STEP: getting the test event 01/24/23 19:05:10.887
    STEP: updating the test event 01/24/23 19:05:10.896
    STEP: getting the test event 01/24/23 19:05:10.91
    STEP: deleting the test event 01/24/23 19:05:10.915
    STEP: listing events in all namespaces 01/24/23 19:05:10.925
    STEP: listing events in test namespace 01/24/23 19:05:10.939
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Jan 24 19:05:10.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-4740" for this suite. 01/24/23 19:05:10.952
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:05:10.961
Jan 24 19:05:10.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:05:10.964
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:05:11.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:05:11.011
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-801a2fd3-0c50-4d96-aa0c-5ae402c1aa39 01/24/23 19:05:11.025
STEP: Creating a pod to test consume secrets 01/24/23 19:05:11.035
Jan 24 19:05:11.053: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab" in namespace "projected-5748" to be "Succeeded or Failed"
Jan 24 19:05:11.070: INFO: Pod "pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab": Phase="Pending", Reason="", readiness=false. Elapsed: 16.620434ms
Jan 24 19:05:13.094: INFO: Pod "pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03975194s
Jan 24 19:05:15.090: INFO: Pod "pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035732389s
STEP: Saw pod success 01/24/23 19:05:15.09
Jan 24 19:05:15.090: INFO: Pod "pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab" satisfied condition "Succeeded or Failed"
Jan 24 19:05:15.101: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab container projected-secret-volume-test: <nil>
STEP: delete the pod 01/24/23 19:05:15.167
Jan 24 19:05:15.217: INFO: Waiting for pod pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab to disappear
Jan 24 19:05:15.231: INFO: Pod pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 24 19:05:15.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5748" for this suite. 01/24/23 19:05:15.247
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":94,"skipped":1790,"failed":0}
------------------------------
• [4.303 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:05:10.961
    Jan 24 19:05:10.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:05:10.964
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:05:11.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:05:11.011
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-801a2fd3-0c50-4d96-aa0c-5ae402c1aa39 01/24/23 19:05:11.025
    STEP: Creating a pod to test consume secrets 01/24/23 19:05:11.035
    Jan 24 19:05:11.053: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab" in namespace "projected-5748" to be "Succeeded or Failed"
    Jan 24 19:05:11.070: INFO: Pod "pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab": Phase="Pending", Reason="", readiness=false. Elapsed: 16.620434ms
    Jan 24 19:05:13.094: INFO: Pod "pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03975194s
    Jan 24 19:05:15.090: INFO: Pod "pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035732389s
    STEP: Saw pod success 01/24/23 19:05:15.09
    Jan 24 19:05:15.090: INFO: Pod "pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab" satisfied condition "Succeeded or Failed"
    Jan 24 19:05:15.101: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab container projected-secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 19:05:15.167
    Jan 24 19:05:15.217: INFO: Waiting for pod pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab to disappear
    Jan 24 19:05:15.231: INFO: Pod pod-projected-secrets-44d865ce-13d3-4ef6-841d-f1e806d0b8ab no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 24 19:05:15.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5748" for this suite. 01/24/23 19:05:15.247
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:05:15.277
Jan 24 19:05:15.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-probe 01/24/23 19:05:15.28
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:05:15.316
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:05:15.327
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea in namespace container-probe-6129 01/24/23 19:05:15.332
Jan 24 19:05:15.357: INFO: Waiting up to 5m0s for pod "busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea" in namespace "container-probe-6129" to be "not pending"
Jan 24 19:05:15.399: INFO: Pod "busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea": Phase="Pending", Reason="", readiness=false. Elapsed: 41.430811ms
Jan 24 19:05:17.409: INFO: Pod "busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051885595s
Jan 24 19:05:19.409: INFO: Pod "busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea": Phase="Running", Reason="", readiness=true. Elapsed: 4.051800804s
Jan 24 19:05:19.409: INFO: Pod "busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea" satisfied condition "not pending"
Jan 24 19:05:19.409: INFO: Started pod busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea in namespace container-probe-6129
STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:05:19.409
Jan 24 19:05:19.414: INFO: Initial restart count of pod busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea is 0
Jan 24 19:06:07.903: INFO: Restart count of pod container-probe-6129/busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea is now 1 (48.488342663s elapsed)
STEP: deleting the pod 01/24/23 19:06:07.903
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 24 19:06:07.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6129" for this suite. 01/24/23 19:06:08.021
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":95,"skipped":1833,"failed":0}
------------------------------
• [SLOW TEST] [52.830 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:05:15.277
    Jan 24 19:05:15.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-probe 01/24/23 19:05:15.28
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:05:15.316
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:05:15.327
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea in namespace container-probe-6129 01/24/23 19:05:15.332
    Jan 24 19:05:15.357: INFO: Waiting up to 5m0s for pod "busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea" in namespace "container-probe-6129" to be "not pending"
    Jan 24 19:05:15.399: INFO: Pod "busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea": Phase="Pending", Reason="", readiness=false. Elapsed: 41.430811ms
    Jan 24 19:05:17.409: INFO: Pod "busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051885595s
    Jan 24 19:05:19.409: INFO: Pod "busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea": Phase="Running", Reason="", readiness=true. Elapsed: 4.051800804s
    Jan 24 19:05:19.409: INFO: Pod "busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea" satisfied condition "not pending"
    Jan 24 19:05:19.409: INFO: Started pod busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea in namespace container-probe-6129
    STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:05:19.409
    Jan 24 19:05:19.414: INFO: Initial restart count of pod busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea is 0
    Jan 24 19:06:07.903: INFO: Restart count of pod container-probe-6129/busybox-916e623e-c14a-46c6-b71d-4dc4093c22ea is now 1 (48.488342663s elapsed)
    STEP: deleting the pod 01/24/23 19:06:07.903
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 24 19:06:07.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6129" for this suite. 01/24/23 19:06:08.021
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:06:08.308
Jan 24 19:06:08.309: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replicaset 01/24/23 19:06:08.313
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:06:08.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:06:08.542
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Jan 24 19:06:08.611: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 24 19:06:13.640: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/24/23 19:06:13.641
STEP: Scaling up "test-rs" replicaset  01/24/23 19:06:13.641
Jan 24 19:06:13.724: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 01/24/23 19:06:13.724
W0124 19:06:13.970063      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Jan 24 19:06:13.995: INFO: observed ReplicaSet test-rs in namespace replicaset-4529 with ReadyReplicas 1, AvailableReplicas 1
Jan 24 19:06:14.110: INFO: observed ReplicaSet test-rs in namespace replicaset-4529 with ReadyReplicas 1, AvailableReplicas 1
Jan 24 19:06:14.741: INFO: observed ReplicaSet test-rs in namespace replicaset-4529 with ReadyReplicas 1, AvailableReplicas 1
Jan 24 19:06:14.897: INFO: observed ReplicaSet test-rs in namespace replicaset-4529 with ReadyReplicas 1, AvailableReplicas 1
Jan 24 19:06:17.350: INFO: observed ReplicaSet test-rs in namespace replicaset-4529 with ReadyReplicas 2, AvailableReplicas 2
Jan 24 19:06:18.115: INFO: observed Replicaset test-rs in namespace replicaset-4529 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 24 19:06:18.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4529" for this suite. 01/24/23 19:06:18.159
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":96,"skipped":1860,"failed":0}
------------------------------
• [SLOW TEST] [9.874 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:06:08.308
    Jan 24 19:06:08.309: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replicaset 01/24/23 19:06:08.313
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:06:08.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:06:08.542
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Jan 24 19:06:08.611: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jan 24 19:06:13.640: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/24/23 19:06:13.641
    STEP: Scaling up "test-rs" replicaset  01/24/23 19:06:13.641
    Jan 24 19:06:13.724: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 01/24/23 19:06:13.724
    W0124 19:06:13.970063      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Jan 24 19:06:13.995: INFO: observed ReplicaSet test-rs in namespace replicaset-4529 with ReadyReplicas 1, AvailableReplicas 1
    Jan 24 19:06:14.110: INFO: observed ReplicaSet test-rs in namespace replicaset-4529 with ReadyReplicas 1, AvailableReplicas 1
    Jan 24 19:06:14.741: INFO: observed ReplicaSet test-rs in namespace replicaset-4529 with ReadyReplicas 1, AvailableReplicas 1
    Jan 24 19:06:14.897: INFO: observed ReplicaSet test-rs in namespace replicaset-4529 with ReadyReplicas 1, AvailableReplicas 1
    Jan 24 19:06:17.350: INFO: observed ReplicaSet test-rs in namespace replicaset-4529 with ReadyReplicas 2, AvailableReplicas 2
    Jan 24 19:06:18.115: INFO: observed Replicaset test-rs in namespace replicaset-4529 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 24 19:06:18.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4529" for this suite. 01/24/23 19:06:18.159
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:06:18.186
Jan 24 19:06:18.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename namespaces 01/24/23 19:06:18.194
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:06:18.302
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:06:18.322
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 01/24/23 19:06:18.331
Jan 24 19:06:18.338: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 01/24/23 19:06:18.338
Jan 24 19:06:18.355: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 01/24/23 19:06:18.355
Jan 24 19:06:18.376: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jan 24 19:06:18.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8434" for this suite. 01/24/23 19:06:18.399
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":97,"skipped":1863,"failed":0}
------------------------------
• [0.236 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:06:18.186
    Jan 24 19:06:18.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename namespaces 01/24/23 19:06:18.194
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:06:18.302
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:06:18.322
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 01/24/23 19:06:18.331
    Jan 24 19:06:18.338: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 01/24/23 19:06:18.338
    Jan 24 19:06:18.355: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 01/24/23 19:06:18.355
    Jan 24 19:06:18.376: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 19:06:18.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8434" for this suite. 01/24/23 19:06:18.399
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:06:18.428
Jan 24 19:06:18.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 19:06:18.432
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:06:18.482
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:06:18.495
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/24/23 19:06:18.505
Jan 24 19:06:18.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-8006 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Jan 24 19:06:18.747: INFO: stderr: ""
Jan 24 19:06:18.747: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 01/24/23 19:06:18.747
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Jan 24 19:06:18.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-8006 delete pods e2e-test-httpd-pod'
Jan 24 19:06:21.410: INFO: stderr: ""
Jan 24 19:06:21.410: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 19:06:21.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8006" for this suite. 01/24/23 19:06:21.421
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":98,"skipped":1877,"failed":0}
------------------------------
• [3.000 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:06:18.428
    Jan 24 19:06:18.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 19:06:18.432
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:06:18.482
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:06:18.495
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/24/23 19:06:18.505
    Jan 24 19:06:18.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-8006 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Jan 24 19:06:18.747: INFO: stderr: ""
    Jan 24 19:06:18.747: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 01/24/23 19:06:18.747
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Jan 24 19:06:18.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-8006 delete pods e2e-test-httpd-pod'
    Jan 24 19:06:21.410: INFO: stderr: ""
    Jan 24 19:06:21.410: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 19:06:21.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8006" for this suite. 01/24/23 19:06:21.421
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:06:21.429
Jan 24 19:06:21.429: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename endpointslice 01/24/23 19:06:21.431
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:06:21.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:06:21.481
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 01/24/23 19:06:21.489
STEP: getting /apis/discovery.k8s.io 01/24/23 19:06:21.493
STEP: getting /apis/discovery.k8s.iov1 01/24/23 19:06:21.495
STEP: creating 01/24/23 19:06:21.496
STEP: getting 01/24/23 19:06:21.526
STEP: listing 01/24/23 19:06:21.537
STEP: watching 01/24/23 19:06:21.544
Jan 24 19:06:21.544: INFO: starting watch
STEP: cluster-wide listing 01/24/23 19:06:21.547
STEP: cluster-wide watching 01/24/23 19:06:21.554
Jan 24 19:06:21.555: INFO: starting watch
STEP: patching 01/24/23 19:06:21.557
STEP: updating 01/24/23 19:06:21.57
Jan 24 19:06:21.586: INFO: waiting for watch events with expected annotations
Jan 24 19:06:21.586: INFO: saw patched and updated annotations
STEP: deleting 01/24/23 19:06:21.587
STEP: deleting a collection 01/24/23 19:06:21.617
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jan 24 19:06:21.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2223" for this suite. 01/24/23 19:06:21.671
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":99,"skipped":1896,"failed":0}
------------------------------
• [0.268 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:06:21.429
    Jan 24 19:06:21.429: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename endpointslice 01/24/23 19:06:21.431
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:06:21.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:06:21.481
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 01/24/23 19:06:21.489
    STEP: getting /apis/discovery.k8s.io 01/24/23 19:06:21.493
    STEP: getting /apis/discovery.k8s.iov1 01/24/23 19:06:21.495
    STEP: creating 01/24/23 19:06:21.496
    STEP: getting 01/24/23 19:06:21.526
    STEP: listing 01/24/23 19:06:21.537
    STEP: watching 01/24/23 19:06:21.544
    Jan 24 19:06:21.544: INFO: starting watch
    STEP: cluster-wide listing 01/24/23 19:06:21.547
    STEP: cluster-wide watching 01/24/23 19:06:21.554
    Jan 24 19:06:21.555: INFO: starting watch
    STEP: patching 01/24/23 19:06:21.557
    STEP: updating 01/24/23 19:06:21.57
    Jan 24 19:06:21.586: INFO: waiting for watch events with expected annotations
    Jan 24 19:06:21.586: INFO: saw patched and updated annotations
    STEP: deleting 01/24/23 19:06:21.587
    STEP: deleting a collection 01/24/23 19:06:21.617
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jan 24 19:06:21.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-2223" for this suite. 01/24/23 19:06:21.671
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:06:21.701
Jan 24 19:06:21.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 19:06:21.707
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:06:21.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:06:21.779
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-989a7a5f-92ca-45eb-878d-81d3f2e34846 01/24/23 19:06:21.81
STEP: Creating configMap with name cm-test-opt-upd-18aa0395-942a-48ae-9791-1ddd0a147fdb 01/24/23 19:06:21.824
STEP: Creating the pod 01/24/23 19:06:21.839
Jan 24 19:06:21.867: INFO: Waiting up to 5m0s for pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69" in namespace "configmap-1331" to be "running and ready"
Jan 24 19:06:21.880: INFO: Pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69": Phase="Pending", Reason="", readiness=false. Elapsed: 13.053447ms
Jan 24 19:06:21.880: INFO: The phase of Pod pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:06:24.040: INFO: Pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.172815576s
Jan 24 19:06:24.040: INFO: The phase of Pod pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:06:25.915: INFO: Pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047484936s
Jan 24 19:06:25.915: INFO: The phase of Pod pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:06:27.908: INFO: Pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69": Phase="Running", Reason="", readiness=true. Elapsed: 6.040716788s
Jan 24 19:06:27.908: INFO: The phase of Pod pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69 is Running (Ready = true)
Jan 24 19:06:27.909: INFO: Pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-989a7a5f-92ca-45eb-878d-81d3f2e34846 01/24/23 19:06:27.991
STEP: Updating configmap cm-test-opt-upd-18aa0395-942a-48ae-9791-1ddd0a147fdb 01/24/23 19:06:28.013
STEP: Creating configMap with name cm-test-opt-create-8618989f-e81d-46b5-b617-c7683cd36f6d 01/24/23 19:06:28.027
STEP: waiting to observe update in volume 01/24/23 19:06:28.044
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 19:07:52.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1331" for this suite. 01/24/23 19:07:52.33
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":100,"skipped":1899,"failed":0}
------------------------------
• [SLOW TEST] [90.647 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:06:21.701
    Jan 24 19:06:21.702: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 19:06:21.707
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:06:21.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:06:21.779
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-989a7a5f-92ca-45eb-878d-81d3f2e34846 01/24/23 19:06:21.81
    STEP: Creating configMap with name cm-test-opt-upd-18aa0395-942a-48ae-9791-1ddd0a147fdb 01/24/23 19:06:21.824
    STEP: Creating the pod 01/24/23 19:06:21.839
    Jan 24 19:06:21.867: INFO: Waiting up to 5m0s for pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69" in namespace "configmap-1331" to be "running and ready"
    Jan 24 19:06:21.880: INFO: Pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69": Phase="Pending", Reason="", readiness=false. Elapsed: 13.053447ms
    Jan 24 19:06:21.880: INFO: The phase of Pod pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:06:24.040: INFO: Pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.172815576s
    Jan 24 19:06:24.040: INFO: The phase of Pod pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:06:25.915: INFO: Pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047484936s
    Jan 24 19:06:25.915: INFO: The phase of Pod pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:06:27.908: INFO: Pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69": Phase="Running", Reason="", readiness=true. Elapsed: 6.040716788s
    Jan 24 19:06:27.908: INFO: The phase of Pod pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69 is Running (Ready = true)
    Jan 24 19:06:27.909: INFO: Pod "pod-configmaps-4a87da54-cc41-4ecd-83c4-8cb74f9bfa69" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-989a7a5f-92ca-45eb-878d-81d3f2e34846 01/24/23 19:06:27.991
    STEP: Updating configmap cm-test-opt-upd-18aa0395-942a-48ae-9791-1ddd0a147fdb 01/24/23 19:06:28.013
    STEP: Creating configMap with name cm-test-opt-create-8618989f-e81d-46b5-b617-c7683cd36f6d 01/24/23 19:06:28.027
    STEP: waiting to observe update in volume 01/24/23 19:06:28.044
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 19:07:52.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1331" for this suite. 01/24/23 19:07:52.33
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:07:52.349
Jan 24 19:07:52.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 19:07:52.356
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:07:52.415
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:07:52.43
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Jan 24 19:07:52.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5528 version'
Jan 24 19:07:52.903: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Jan 24 19:07:52.903: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:15:02Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:08:09Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 19:07:52.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5528" for this suite. 01/24/23 19:07:52.918
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":101,"skipped":1899,"failed":0}
------------------------------
• [0.587 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:07:52.349
    Jan 24 19:07:52.352: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 19:07:52.356
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:07:52.415
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:07:52.43
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Jan 24 19:07:52.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5528 version'
    Jan 24 19:07:52.903: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Jan 24 19:07:52.903: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:15:02Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.5\", GitCommit:\"804d6167111f6858541cef440ccc53887fbbc96a\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T10:08:09Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 19:07:52.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5528" for this suite. 01/24/23 19:07:52.918
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:07:52.959
Jan 24 19:07:52.959: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:07:52.963
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:07:53.019
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:07:53.03
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-3770d049-62ae-45a8-9e78-4458fe955942 01/24/23 19:07:53.07
STEP: Creating a pod to test consume secrets 01/24/23 19:07:53.083
Jan 24 19:07:53.120: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af" in namespace "projected-1932" to be "Succeeded or Failed"
Jan 24 19:07:53.253: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Pending", Reason="", readiness=false. Elapsed: 132.660524ms
Jan 24 19:07:55.321: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.200541173s
Jan 24 19:07:57.271: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Running", Reason="", readiness=true. Elapsed: 4.151101049s
Jan 24 19:07:59.312: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Running", Reason="", readiness=false. Elapsed: 6.192022363s
Jan 24 19:08:01.294: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Running", Reason="", readiness=false. Elapsed: 8.173321907s
Jan 24 19:08:03.275: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.154527661s
STEP: Saw pod success 01/24/23 19:08:03.275
Jan 24 19:08:03.276: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af" satisfied condition "Succeeded or Failed"
Jan 24 19:08:03.289: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af container projected-secret-volume-test: <nil>
STEP: delete the pod 01/24/23 19:08:03.318
Jan 24 19:08:03.440: INFO: Waiting for pod pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af to disappear
Jan 24 19:08:03.456: INFO: Pod pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 24 19:08:03.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1932" for this suite. 01/24/23 19:08:03.484
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":102,"skipped":1948,"failed":0}
------------------------------
• [SLOW TEST] [10.556 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:07:52.959
    Jan 24 19:07:52.959: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:07:52.963
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:07:53.019
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:07:53.03
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-3770d049-62ae-45a8-9e78-4458fe955942 01/24/23 19:07:53.07
    STEP: Creating a pod to test consume secrets 01/24/23 19:07:53.083
    Jan 24 19:07:53.120: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af" in namespace "projected-1932" to be "Succeeded or Failed"
    Jan 24 19:07:53.253: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Pending", Reason="", readiness=false. Elapsed: 132.660524ms
    Jan 24 19:07:55.321: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.200541173s
    Jan 24 19:07:57.271: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Running", Reason="", readiness=true. Elapsed: 4.151101049s
    Jan 24 19:07:59.312: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Running", Reason="", readiness=false. Elapsed: 6.192022363s
    Jan 24 19:08:01.294: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Running", Reason="", readiness=false. Elapsed: 8.173321907s
    Jan 24 19:08:03.275: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.154527661s
    STEP: Saw pod success 01/24/23 19:08:03.275
    Jan 24 19:08:03.276: INFO: Pod "pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af" satisfied condition "Succeeded or Failed"
    Jan 24 19:08:03.289: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af container projected-secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 19:08:03.318
    Jan 24 19:08:03.440: INFO: Waiting for pod pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af to disappear
    Jan 24 19:08:03.456: INFO: Pod pod-projected-secrets-5ad5a24f-9435-4c7b-965e-fe6d1730d3af no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 24 19:08:03.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1932" for this suite. 01/24/23 19:08:03.484
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:08:03.529
Jan 24 19:08:03.529: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename deployment 01/24/23 19:08:03.533
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:08:03.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:08:03.633
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 01/24/23 19:08:03.695
STEP: waiting for Deployment to be created 01/24/23 19:08:03.714
STEP: waiting for all Replicas to be Ready 01/24/23 19:08:03.735
Jan 24 19:08:03.753: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 24 19:08:03.755: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 24 19:08:03.770: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 24 19:08:03.770: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 24 19:08:03.867: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 24 19:08:03.875: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 24 19:08:04.124: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 24 19:08:04.124: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jan 24 19:08:08.431: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Jan 24 19:08:08.431: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Jan 24 19:08:08.534: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 01/24/23 19:08:08.535
W0124 19:08:08.630160      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Jan 24 19:08:08.674: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 01/24/23 19:08:08.674
Jan 24 19:08:08.738: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
Jan 24 19:08:08.739: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
Jan 24 19:08:08.739: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
Jan 24 19:08:08.740: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
Jan 24 19:08:08.746: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
Jan 24 19:08:08.746: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
Jan 24 19:08:08.749: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
Jan 24 19:08:08.749: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
Jan 24 19:08:08.750: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
Jan 24 19:08:08.751: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
Jan 24 19:08:08.751: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:08.752: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:08.752: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:08.753: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:08.829: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:08.830: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:09.225: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:09.225: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:09.406: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
Jan 24 19:08:09.406: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
Jan 24 19:08:09.428: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
Jan 24 19:08:09.428: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
Jan 24 19:08:13.546: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:13.546: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:13.724: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
STEP: listing Deployments 01/24/23 19:08:13.724
Jan 24 19:08:14.041: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 01/24/23 19:08:14.041
Jan 24 19:08:14.241: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 01/24/23 19:08:14.242
Jan 24 19:08:15.083: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jan 24 19:08:15.174: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jan 24 19:08:15.174: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jan 24 19:08:15.599: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jan 24 19:08:18.635: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jan 24 19:08:18.922: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jan 24 19:08:19.275: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jan 24 19:08:22.438: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 01/24/23 19:08:22.601
STEP: fetching the DeploymentStatus 01/24/23 19:08:22.708
Jan 24 19:08:22.769: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
Jan 24 19:08:22.769: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
Jan 24 19:08:22.769: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
Jan 24 19:08:22.770: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
Jan 24 19:08:22.770: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:22.771: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:22.773: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
Jan 24 19:08:22.773: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 3
STEP: deleting the Deployment 01/24/23 19:08:22.773
Jan 24 19:08:22.929: INFO: observed event type MODIFIED
Jan 24 19:08:22.929: INFO: observed event type MODIFIED
Jan 24 19:08:22.930: INFO: observed event type MODIFIED
Jan 24 19:08:22.935: INFO: observed event type MODIFIED
Jan 24 19:08:22.936: INFO: observed event type MODIFIED
Jan 24 19:08:22.937: INFO: observed event type MODIFIED
Jan 24 19:08:22.938: INFO: observed event type MODIFIED
Jan 24 19:08:22.939: INFO: observed event type MODIFIED
Jan 24 19:08:22.940: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 24 19:08:22.971: INFO: Log out all the ReplicaSets if there is no deployment created
Jan 24 19:08:23.010: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-4155  95de8717-2a9c-48f3-b41b-7e5ef036c9bb 20912 4 2023-01-24 19:08:08 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 8e5b59b0-f626-4857-8309-2f0650a81ecd 0xc004a8d4d7 0xc004a8d4d8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:08:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8e5b59b0-f626-4857-8309-2f0650a81ecd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:08:22 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a8d560 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Jan 24 19:08:23.050: INFO: pod: "test-deployment-54cc775c4b-l2fwl":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-l2fwl test-deployment-54cc775c4b- deployment-4155  dc28683d-be75-430c-a282-c3bf1132dd79 20906 0 2023-01-24 19:08:09 +0000 UTC 2023-01-24 19:08:23 +0000 UTC 0xc004a8d9f8 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:f1dbccd7d06ebd966c41e2e3ad34091db5a52912c3493fe37721133b7d020713 cni.projectcalico.org/podIP:10.244.71.202/32 cni.projectcalico.org/podIPs:10.244.71.202/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 95de8717-2a9c-48f3-b41b-7e5ef036c9bb 0xc004a8da47 0xc004a8da48}] [] [{kube-controller-manager Update v1 2023-01-24 19:08:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"95de8717-2a9c-48f3-b41b-7e5ef036c9bb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 19:08:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 19:08:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.202\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4rkbx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4rkbx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.202,StartTime:2023-01-24 19:08:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 19:08:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://4aecdff58257b9f1adc6353787bf9271282a70b8126ccbd16fe15a07111364a0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.202,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jan 24 19:08:23.051: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-4155  f189571f-b86c-4e2e-be2c-9340c663a117 20901 2 2023-01-24 19:08:14 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 8e5b59b0-f626-4857-8309-2f0650a81ecd 0xc004a8d5c7 0xc004a8d5c8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:08:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8e5b59b0-f626-4857-8309-2f0650a81ecd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:08:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a8d650 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Jan 24 19:08:23.113: INFO: pod: "test-deployment-7c7d8d58c8-6l9gh":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-6l9gh test-deployment-7c7d8d58c8- deployment-4155  2725eb53-4bcc-4d51-86ba-fc289ec6f03f 20861 0 2023-01-24 19:08:14 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:ed353f6d3efa1d988f85a7e3e372a564feafc90b797431e7b0c8086149e64528 cni.projectcalico.org/podIP:10.244.71.203/32 cni.projectcalico.org/podIPs:10.244.71.203/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 f189571f-b86c-4e2e-be2c-9340c663a117 0xc002e50397 0xc002e50398}] [] [{kube-controller-manager Update v1 2023-01-24 19:08:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f189571f-b86c-4e2e-be2c-9340c663a117\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 19:08:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 19:08:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.203\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8zb2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8zb2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.203,StartTime:2023-01-24 19:08:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 19:08:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6e9b4545d4c4ae68973bc2ed15163663765ca35a285c21da07239e3d83995486,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.203,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jan 24 19:08:23.121: INFO: pod: "test-deployment-7c7d8d58c8-qx6bk":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-qx6bk test-deployment-7c7d8d58c8- deployment-4155  946e0f6c-58d9-46de-80ab-c2a70e8de03b 20900 0 2023-01-24 19:08:18 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:0230ddfa5e7d6a62e488997f4c97f85262fbf30e7139b4574537fb6d94711d88 cni.projectcalico.org/podIP:10.244.47.113/32 cni.projectcalico.org/podIPs:10.244.47.113/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 f189571f-b86c-4e2e-be2c-9340c663a117 0xc002e505b7 0xc002e505b8}] [] [{kube-controller-manager Update v1 2023-01-24 19:08:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f189571f-b86c-4e2e-be2c-9340c663a117\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 19:08:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 19:08:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lx42k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lx42k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.113,StartTime:2023-01-24 19:08:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 19:08:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://143e33d968832737a91f984879ebea4ffb8bf1636bc4aae179bb30bf7c8232bd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jan 24 19:08:23.162: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-4155  251fa5f6-3311-4b9e-9562-ed3c46feecc4 20818 3 2023-01-24 19:08:03 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 8e5b59b0-f626-4857-8309-2f0650a81ecd 0xc004a8d6b7 0xc004a8d6b8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:08:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8e5b59b0-f626-4857-8309-2f0650a81ecd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:08:13 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a8d750 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 24 19:08:23.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4155" for this suite. 01/24/23 19:08:23.384
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":103,"skipped":1983,"failed":0}
------------------------------
• [SLOW TEST] [19.940 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:08:03.529
    Jan 24 19:08:03.529: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename deployment 01/24/23 19:08:03.533
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:08:03.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:08:03.633
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 01/24/23 19:08:03.695
    STEP: waiting for Deployment to be created 01/24/23 19:08:03.714
    STEP: waiting for all Replicas to be Ready 01/24/23 19:08:03.735
    Jan 24 19:08:03.753: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 24 19:08:03.755: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 24 19:08:03.770: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 24 19:08:03.770: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 24 19:08:03.867: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 24 19:08:03.875: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 24 19:08:04.124: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 24 19:08:04.124: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Jan 24 19:08:08.431: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Jan 24 19:08:08.431: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Jan 24 19:08:08.534: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 01/24/23 19:08:08.535
    W0124 19:08:08.630160      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Jan 24 19:08:08.674: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 01/24/23 19:08:08.674
    Jan 24 19:08:08.738: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
    Jan 24 19:08:08.739: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
    Jan 24 19:08:08.739: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
    Jan 24 19:08:08.740: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
    Jan 24 19:08:08.746: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
    Jan 24 19:08:08.746: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
    Jan 24 19:08:08.749: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
    Jan 24 19:08:08.749: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 0
    Jan 24 19:08:08.750: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    Jan 24 19:08:08.751: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    Jan 24 19:08:08.751: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:08.752: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:08.752: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:08.753: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:08.829: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:08.830: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:09.225: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:09.225: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:09.406: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    Jan 24 19:08:09.406: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    Jan 24 19:08:09.428: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    Jan 24 19:08:09.428: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    Jan 24 19:08:13.546: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:13.546: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:13.724: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    STEP: listing Deployments 01/24/23 19:08:13.724
    Jan 24 19:08:14.041: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 01/24/23 19:08:14.041
    Jan 24 19:08:14.241: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 01/24/23 19:08:14.242
    Jan 24 19:08:15.083: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 24 19:08:15.174: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 24 19:08:15.174: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 24 19:08:15.599: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 24 19:08:18.635: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 24 19:08:18.922: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 24 19:08:19.275: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Jan 24 19:08:22.438: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 01/24/23 19:08:22.601
    STEP: fetching the DeploymentStatus 01/24/23 19:08:22.708
    Jan 24 19:08:22.769: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    Jan 24 19:08:22.769: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    Jan 24 19:08:22.769: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    Jan 24 19:08:22.770: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 1
    Jan 24 19:08:22.770: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:22.771: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:22.773: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 2
    Jan 24 19:08:22.773: INFO: observed Deployment test-deployment in namespace deployment-4155 with ReadyReplicas 3
    STEP: deleting the Deployment 01/24/23 19:08:22.773
    Jan 24 19:08:22.929: INFO: observed event type MODIFIED
    Jan 24 19:08:22.929: INFO: observed event type MODIFIED
    Jan 24 19:08:22.930: INFO: observed event type MODIFIED
    Jan 24 19:08:22.935: INFO: observed event type MODIFIED
    Jan 24 19:08:22.936: INFO: observed event type MODIFIED
    Jan 24 19:08:22.937: INFO: observed event type MODIFIED
    Jan 24 19:08:22.938: INFO: observed event type MODIFIED
    Jan 24 19:08:22.939: INFO: observed event type MODIFIED
    Jan 24 19:08:22.940: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 24 19:08:22.971: INFO: Log out all the ReplicaSets if there is no deployment created
    Jan 24 19:08:23.010: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-4155  95de8717-2a9c-48f3-b41b-7e5ef036c9bb 20912 4 2023-01-24 19:08:08 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 8e5b59b0-f626-4857-8309-2f0650a81ecd 0xc004a8d4d7 0xc004a8d4d8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:08:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8e5b59b0-f626-4857-8309-2f0650a81ecd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:08:22 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a8d560 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Jan 24 19:08:23.050: INFO: pod: "test-deployment-54cc775c4b-l2fwl":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-l2fwl test-deployment-54cc775c4b- deployment-4155  dc28683d-be75-430c-a282-c3bf1132dd79 20906 0 2023-01-24 19:08:09 +0000 UTC 2023-01-24 19:08:23 +0000 UTC 0xc004a8d9f8 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:f1dbccd7d06ebd966c41e2e3ad34091db5a52912c3493fe37721133b7d020713 cni.projectcalico.org/podIP:10.244.71.202/32 cni.projectcalico.org/podIPs:10.244.71.202/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 95de8717-2a9c-48f3-b41b-7e5ef036c9bb 0xc004a8da47 0xc004a8da48}] [] [{kube-controller-manager Update v1 2023-01-24 19:08:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"95de8717-2a9c-48f3-b41b-7e5ef036c9bb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 19:08:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 19:08:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.202\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4rkbx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4rkbx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.202,StartTime:2023-01-24 19:08:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 19:08:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://4aecdff58257b9f1adc6353787bf9271282a70b8126ccbd16fe15a07111364a0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.202,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Jan 24 19:08:23.051: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-4155  f189571f-b86c-4e2e-be2c-9340c663a117 20901 2 2023-01-24 19:08:14 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 8e5b59b0-f626-4857-8309-2f0650a81ecd 0xc004a8d5c7 0xc004a8d5c8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:08:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8e5b59b0-f626-4857-8309-2f0650a81ecd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:08:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a8d650 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Jan 24 19:08:23.113: INFO: pod: "test-deployment-7c7d8d58c8-6l9gh":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-6l9gh test-deployment-7c7d8d58c8- deployment-4155  2725eb53-4bcc-4d51-86ba-fc289ec6f03f 20861 0 2023-01-24 19:08:14 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:ed353f6d3efa1d988f85a7e3e372a564feafc90b797431e7b0c8086149e64528 cni.projectcalico.org/podIP:10.244.71.203/32 cni.projectcalico.org/podIPs:10.244.71.203/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 f189571f-b86c-4e2e-be2c-9340c663a117 0xc002e50397 0xc002e50398}] [] [{kube-controller-manager Update v1 2023-01-24 19:08:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f189571f-b86c-4e2e-be2c-9340c663a117\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 19:08:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 19:08:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.203\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8zb2r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8zb2r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.203,StartTime:2023-01-24 19:08:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 19:08:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6e9b4545d4c4ae68973bc2ed15163663765ca35a285c21da07239e3d83995486,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.203,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Jan 24 19:08:23.121: INFO: pod: "test-deployment-7c7d8d58c8-qx6bk":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-qx6bk test-deployment-7c7d8d58c8- deployment-4155  946e0f6c-58d9-46de-80ab-c2a70e8de03b 20900 0 2023-01-24 19:08:18 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:0230ddfa5e7d6a62e488997f4c97f85262fbf30e7139b4574537fb6d94711d88 cni.projectcalico.org/podIP:10.244.47.113/32 cni.projectcalico.org/podIPs:10.244.47.113/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 f189571f-b86c-4e2e-be2c-9340c663a117 0xc002e505b7 0xc002e505b8}] [] [{kube-controller-manager Update v1 2023-01-24 19:08:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f189571f-b86c-4e2e-be2c-9340c663a117\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 19:08:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 19:08:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lx42k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lx42k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-59870,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:08:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.213,PodIP:10.244.47.113,StartTime:2023-01-24 19:08:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 19:08:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://143e33d968832737a91f984879ebea4ffb8bf1636bc4aae179bb30bf7c8232bd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.47.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Jan 24 19:08:23.162: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-4155  251fa5f6-3311-4b9e-9562-ed3c46feecc4 20818 3 2023-01-24 19:08:03 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 8e5b59b0-f626-4857-8309-2f0650a81ecd 0xc004a8d6b7 0xc004a8d6b8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:08:13 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8e5b59b0-f626-4857-8309-2f0650a81ecd\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:08:13 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004a8d750 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 24 19:08:23.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4155" for this suite. 01/24/23 19:08:23.384
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:08:23.566
Jan 24 19:08:23.566: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 19:08:23.569
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:08:23.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:08:23.66
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-2418 01/24/23 19:08:23.672
STEP: creating service affinity-clusterip-transition in namespace services-2418 01/24/23 19:08:23.674
STEP: creating replication controller affinity-clusterip-transition in namespace services-2418 01/24/23 19:08:23.742
I0124 19:08:23.820879      22 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2418, replica count: 3
I0124 19:08:26.996458      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:08:30.001077      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:08:33.002143      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:08:36.015098      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 19:08:36.054: INFO: Creating new exec pod
Jan 24 19:08:36.137: INFO: Waiting up to 5m0s for pod "execpod-affinitylggh2" in namespace "services-2418" to be "running"
Jan 24 19:08:36.181: INFO: Pod "execpod-affinitylggh2": Phase="Pending", Reason="", readiness=false. Elapsed: 43.885212ms
Jan 24 19:08:38.228: INFO: Pod "execpod-affinitylggh2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090224748s
Jan 24 19:08:40.225: INFO: Pod "execpod-affinitylggh2": Phase="Running", Reason="", readiness=true. Elapsed: 4.088016154s
Jan 24 19:08:40.226: INFO: Pod "execpod-affinitylggh2" satisfied condition "running"
Jan 24 19:08:41.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2418 exec execpod-affinitylggh2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Jan 24 19:08:42.597: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Jan 24 19:08:42.597: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:08:42.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2418 exec execpod-affinitylggh2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.165.164 80'
Jan 24 19:08:43.419: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.165.164 80\nConnection to 10.10.165.164 80 port [tcp/http] succeeded!\n"
Jan 24 19:08:43.419: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:08:43.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2418 exec execpod-affinitylggh2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.165.164:80/ ; done'
Jan 24 19:08:45.497: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n"
Jan 24 19:08:45.497: INFO: stdout: "\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-wd6xk\naffinity-clusterip-transition-wd6xk\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-wd6xk\naffinity-clusterip-transition-29l89\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-wd6xk\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-29l89\naffinity-clusterip-transition-wd6xk\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-wd6xk"
Jan 24 19:08:45.497: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:45.497: INFO: Received response from host: affinity-clusterip-transition-wd6xk
Jan 24 19:08:45.497: INFO: Received response from host: affinity-clusterip-transition-wd6xk
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-wd6xk
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-29l89
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-wd6xk
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-29l89
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-wd6xk
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-wd6xk
Jan 24 19:08:45.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2418 exec execpod-affinitylggh2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.165.164:80/ ; done'
Jan 24 19:08:47.005: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n"
Jan 24 19:08:47.005: INFO: stdout: "\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z"
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
Jan 24 19:08:47.005: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2418, will wait for the garbage collector to delete the pods 01/24/23 19:08:47.036
Jan 24 19:08:47.102: INFO: Deleting ReplicationController affinity-clusterip-transition took: 8.376415ms
Jan 24 19:08:47.304: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 201.85276ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 19:08:50.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2418" for this suite. 01/24/23 19:08:50.14
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":104,"skipped":2031,"failed":0}
------------------------------
• [SLOW TEST] [26.584 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:08:23.566
    Jan 24 19:08:23.566: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 19:08:23.569
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:08:23.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:08:23.66
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-2418 01/24/23 19:08:23.672
    STEP: creating service affinity-clusterip-transition in namespace services-2418 01/24/23 19:08:23.674
    STEP: creating replication controller affinity-clusterip-transition in namespace services-2418 01/24/23 19:08:23.742
    I0124 19:08:23.820879      22 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2418, replica count: 3
    I0124 19:08:26.996458      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:08:30.001077      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:08:33.002143      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:08:36.015098      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 19:08:36.054: INFO: Creating new exec pod
    Jan 24 19:08:36.137: INFO: Waiting up to 5m0s for pod "execpod-affinitylggh2" in namespace "services-2418" to be "running"
    Jan 24 19:08:36.181: INFO: Pod "execpod-affinitylggh2": Phase="Pending", Reason="", readiness=false. Elapsed: 43.885212ms
    Jan 24 19:08:38.228: INFO: Pod "execpod-affinitylggh2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090224748s
    Jan 24 19:08:40.225: INFO: Pod "execpod-affinitylggh2": Phase="Running", Reason="", readiness=true. Elapsed: 4.088016154s
    Jan 24 19:08:40.226: INFO: Pod "execpod-affinitylggh2" satisfied condition "running"
    Jan 24 19:08:41.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2418 exec execpod-affinitylggh2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Jan 24 19:08:42.597: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Jan 24 19:08:42.597: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:08:42.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2418 exec execpod-affinitylggh2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.165.164 80'
    Jan 24 19:08:43.419: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.165.164 80\nConnection to 10.10.165.164 80 port [tcp/http] succeeded!\n"
    Jan 24 19:08:43.419: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:08:43.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2418 exec execpod-affinitylggh2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.165.164:80/ ; done'
    Jan 24 19:08:45.497: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n"
    Jan 24 19:08:45.497: INFO: stdout: "\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-wd6xk\naffinity-clusterip-transition-wd6xk\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-wd6xk\naffinity-clusterip-transition-29l89\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-wd6xk\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-29l89\naffinity-clusterip-transition-wd6xk\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-wd6xk"
    Jan 24 19:08:45.497: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:45.497: INFO: Received response from host: affinity-clusterip-transition-wd6xk
    Jan 24 19:08:45.497: INFO: Received response from host: affinity-clusterip-transition-wd6xk
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-wd6xk
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-29l89
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-wd6xk
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-29l89
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-wd6xk
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:45.498: INFO: Received response from host: affinity-clusterip-transition-wd6xk
    Jan 24 19:08:45.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2418 exec execpod-affinitylggh2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.165.164:80/ ; done'
    Jan 24 19:08:47.005: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.165.164:80/\n"
    Jan 24 19:08:47.005: INFO: stdout: "\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z\naffinity-clusterip-transition-8gl8z"
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Received response from host: affinity-clusterip-transition-8gl8z
    Jan 24 19:08:47.005: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2418, will wait for the garbage collector to delete the pods 01/24/23 19:08:47.036
    Jan 24 19:08:47.102: INFO: Deleting ReplicationController affinity-clusterip-transition took: 8.376415ms
    Jan 24 19:08:47.304: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 201.85276ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 19:08:50.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2418" for this suite. 01/24/23 19:08:50.14
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:08:50.152
Jan 24 19:08:50.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:08:50.154
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:08:50.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:08:50.19
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-28db4bee-0a09-40a5-a3a8-c4e2ed0ffeb3 01/24/23 19:08:50.196
STEP: Creating secret with name secret-projected-all-test-volume-d275ee77-0123-423d-8215-6a6266bb7882 01/24/23 19:08:50.204
STEP: Creating a pod to test Check all projections for projected volume plugin 01/24/23 19:08:50.217
Jan 24 19:08:50.235: INFO: Waiting up to 5m0s for pod "projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87" in namespace "projected-191" to be "Succeeded or Failed"
Jan 24 19:08:50.286: INFO: Pod "projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87": Phase="Pending", Reason="", readiness=false. Elapsed: 30.870179ms
Jan 24 19:08:52.300: INFO: Pod "projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044766879s
Jan 24 19:08:54.304: INFO: Pod "projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048904611s
STEP: Saw pod success 01/24/23 19:08:54.304
Jan 24 19:08:54.305: INFO: Pod "projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87" satisfied condition "Succeeded or Failed"
Jan 24 19:08:54.317: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87 container projected-all-volume-test: <nil>
STEP: delete the pod 01/24/23 19:08:54.341
Jan 24 19:08:54.403: INFO: Waiting for pod projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87 to disappear
Jan 24 19:08:54.410: INFO: Pod projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Jan 24 19:08:54.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-191" for this suite. 01/24/23 19:08:54.426
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":105,"skipped":2051,"failed":0}
------------------------------
• [4.289 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:08:50.152
    Jan 24 19:08:50.152: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:08:50.154
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:08:50.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:08:50.19
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-28db4bee-0a09-40a5-a3a8-c4e2ed0ffeb3 01/24/23 19:08:50.196
    STEP: Creating secret with name secret-projected-all-test-volume-d275ee77-0123-423d-8215-6a6266bb7882 01/24/23 19:08:50.204
    STEP: Creating a pod to test Check all projections for projected volume plugin 01/24/23 19:08:50.217
    Jan 24 19:08:50.235: INFO: Waiting up to 5m0s for pod "projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87" in namespace "projected-191" to be "Succeeded or Failed"
    Jan 24 19:08:50.286: INFO: Pod "projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87": Phase="Pending", Reason="", readiness=false. Elapsed: 30.870179ms
    Jan 24 19:08:52.300: INFO: Pod "projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044766879s
    Jan 24 19:08:54.304: INFO: Pod "projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048904611s
    STEP: Saw pod success 01/24/23 19:08:54.304
    Jan 24 19:08:54.305: INFO: Pod "projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87" satisfied condition "Succeeded or Failed"
    Jan 24 19:08:54.317: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87 container projected-all-volume-test: <nil>
    STEP: delete the pod 01/24/23 19:08:54.341
    Jan 24 19:08:54.403: INFO: Waiting for pod projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87 to disappear
    Jan 24 19:08:54.410: INFO: Pod projected-volume-5cd7623e-13fb-4cbd-9407-faf31b3cfc87 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Jan 24 19:08:54.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-191" for this suite. 01/24/23 19:08:54.426
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:08:54.449
Jan 24 19:08:54.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename var-expansion 01/24/23 19:08:54.453
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:08:54.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:08:54.5
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 01/24/23 19:08:54.508
Jan 24 19:08:54.530: INFO: Waiting up to 5m0s for pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127" in namespace "var-expansion-6014" to be "Succeeded or Failed"
Jan 24 19:08:54.549: INFO: Pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127": Phase="Pending", Reason="", readiness=false. Elapsed: 18.274653ms
Jan 24 19:08:56.560: INFO: Pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028613443s
Jan 24 19:08:58.583: INFO: Pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05176142s
Jan 24 19:09:00.561: INFO: Pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02983432s
STEP: Saw pod success 01/24/23 19:09:00.601
Jan 24 19:09:00.602: INFO: Pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127" satisfied condition "Succeeded or Failed"
Jan 24 19:09:00.662: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127 container dapi-container: <nil>
STEP: delete the pod 01/24/23 19:09:00.85
Jan 24 19:09:01.121: INFO: Waiting for pod var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127 to disappear
Jan 24 19:09:01.234: INFO: Pod var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 24 19:09:01.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6014" for this suite. 01/24/23 19:09:01.298
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":106,"skipped":2091,"failed":0}
------------------------------
• [SLOW TEST] [6.894 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:08:54.449
    Jan 24 19:08:54.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename var-expansion 01/24/23 19:08:54.453
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:08:54.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:08:54.5
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 01/24/23 19:08:54.508
    Jan 24 19:08:54.530: INFO: Waiting up to 5m0s for pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127" in namespace "var-expansion-6014" to be "Succeeded or Failed"
    Jan 24 19:08:54.549: INFO: Pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127": Phase="Pending", Reason="", readiness=false. Elapsed: 18.274653ms
    Jan 24 19:08:56.560: INFO: Pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028613443s
    Jan 24 19:08:58.583: INFO: Pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05176142s
    Jan 24 19:09:00.561: INFO: Pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02983432s
    STEP: Saw pod success 01/24/23 19:09:00.601
    Jan 24 19:09:00.602: INFO: Pod "var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127" satisfied condition "Succeeded or Failed"
    Jan 24 19:09:00.662: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127 container dapi-container: <nil>
    STEP: delete the pod 01/24/23 19:09:00.85
    Jan 24 19:09:01.121: INFO: Waiting for pod var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127 to disappear
    Jan 24 19:09:01.234: INFO: Pod var-expansion-cc7304cb-46d0-4088-aa1a-dd152e75a127 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 24 19:09:01.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6014" for this suite. 01/24/23 19:09:01.298
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:09:01.455
Jan 24 19:09:01.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename runtimeclass 01/24/23 19:09:01.459
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:01.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:01.517
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Jan 24 19:09:01.617: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7736 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jan 24 19:09:01.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7736" for this suite. 01/24/23 19:09:01.727
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":107,"skipped":2113,"failed":0}
------------------------------
• [0.333 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:09:01.455
    Jan 24 19:09:01.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename runtimeclass 01/24/23 19:09:01.459
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:01.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:01.517
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Jan 24 19:09:01.617: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7736 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jan 24 19:09:01.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7736" for this suite. 01/24/23 19:09:01.727
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:09:01.791
Jan 24 19:09:01.791: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 19:09:01.807
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:01.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:01.919
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 01/24/23 19:09:01.969
STEP: watching for the Service to be added 01/24/23 19:09:02.006
Jan 24 19:09:02.019: INFO: Found Service test-service-d4ljt in namespace services-9612 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Jan 24 19:09:02.020: INFO: Service test-service-d4ljt created
STEP: Getting /status 01/24/23 19:09:02.02
Jan 24 19:09:02.053: INFO: Service test-service-d4ljt has LoadBalancer: {[]}
STEP: patching the ServiceStatus 01/24/23 19:09:02.053
STEP: watching for the Service to be patched 01/24/23 19:09:02.094
Jan 24 19:09:02.132: INFO: observed Service test-service-d4ljt in namespace services-9612 with annotations: map[] & LoadBalancer: {[]}
Jan 24 19:09:02.132: INFO: Found Service test-service-d4ljt in namespace services-9612 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Jan 24 19:09:02.135: INFO: Service test-service-d4ljt has service status patched
STEP: updating the ServiceStatus 01/24/23 19:09:02.136
Jan 24 19:09:02.403: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 01/24/23 19:09:02.403
Jan 24 19:09:02.411: INFO: Observed Service test-service-d4ljt in namespace services-9612 with annotations: map[] & Conditions: {[]}
Jan 24 19:09:02.411: INFO: Observed event: &Service{ObjectMeta:{test-service-d4ljt  services-9612  92070519-f4bf-4e8b-b300-4fd9acd05ebd 21232 0 2023-01-24 19:09:01 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-01-24 19:09:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-01-24 19:09:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.10.111.104,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.10.111.104],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Jan 24 19:09:02.412: INFO: Found Service test-service-d4ljt in namespace services-9612 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jan 24 19:09:02.412: INFO: Service test-service-d4ljt has service status updated
STEP: patching the service 01/24/23 19:09:02.412
STEP: watching for the Service to be patched 01/24/23 19:09:02.511
Jan 24 19:09:02.556: INFO: observed Service test-service-d4ljt in namespace services-9612 with labels: map[test-service-static:true]
Jan 24 19:09:02.569: INFO: observed Service test-service-d4ljt in namespace services-9612 with labels: map[test-service-static:true]
Jan 24 19:09:02.569: INFO: observed Service test-service-d4ljt in namespace services-9612 with labels: map[test-service-static:true]
Jan 24 19:09:02.569: INFO: Found Service test-service-d4ljt in namespace services-9612 with labels: map[test-service:patched test-service-static:true]
Jan 24 19:09:02.569: INFO: Service test-service-d4ljt patched
STEP: deleting the service 01/24/23 19:09:02.575
STEP: watching for the Service to be deleted 01/24/23 19:09:02.664
Jan 24 19:09:02.669: INFO: Observed event: ADDED
Jan 24 19:09:02.669: INFO: Observed event: MODIFIED
Jan 24 19:09:02.669: INFO: Observed event: MODIFIED
Jan 24 19:09:02.669: INFO: Observed event: MODIFIED
Jan 24 19:09:02.670: INFO: Found Service test-service-d4ljt in namespace services-9612 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Jan 24 19:09:02.670: INFO: Service test-service-d4ljt deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 19:09:02.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9612" for this suite. 01/24/23 19:09:02.695
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":108,"skipped":2114,"failed":0}
------------------------------
• [0.940 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:09:01.791
    Jan 24 19:09:01.791: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 19:09:01.807
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:01.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:01.919
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 01/24/23 19:09:01.969
    STEP: watching for the Service to be added 01/24/23 19:09:02.006
    Jan 24 19:09:02.019: INFO: Found Service test-service-d4ljt in namespace services-9612 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Jan 24 19:09:02.020: INFO: Service test-service-d4ljt created
    STEP: Getting /status 01/24/23 19:09:02.02
    Jan 24 19:09:02.053: INFO: Service test-service-d4ljt has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 01/24/23 19:09:02.053
    STEP: watching for the Service to be patched 01/24/23 19:09:02.094
    Jan 24 19:09:02.132: INFO: observed Service test-service-d4ljt in namespace services-9612 with annotations: map[] & LoadBalancer: {[]}
    Jan 24 19:09:02.132: INFO: Found Service test-service-d4ljt in namespace services-9612 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Jan 24 19:09:02.135: INFO: Service test-service-d4ljt has service status patched
    STEP: updating the ServiceStatus 01/24/23 19:09:02.136
    Jan 24 19:09:02.403: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 01/24/23 19:09:02.403
    Jan 24 19:09:02.411: INFO: Observed Service test-service-d4ljt in namespace services-9612 with annotations: map[] & Conditions: {[]}
    Jan 24 19:09:02.411: INFO: Observed event: &Service{ObjectMeta:{test-service-d4ljt  services-9612  92070519-f4bf-4e8b-b300-4fd9acd05ebd 21232 0 2023-01-24 19:09:01 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-01-24 19:09:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-01-24 19:09:02 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.10.111.104,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.10.111.104],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Jan 24 19:09:02.412: INFO: Found Service test-service-d4ljt in namespace services-9612 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jan 24 19:09:02.412: INFO: Service test-service-d4ljt has service status updated
    STEP: patching the service 01/24/23 19:09:02.412
    STEP: watching for the Service to be patched 01/24/23 19:09:02.511
    Jan 24 19:09:02.556: INFO: observed Service test-service-d4ljt in namespace services-9612 with labels: map[test-service-static:true]
    Jan 24 19:09:02.569: INFO: observed Service test-service-d4ljt in namespace services-9612 with labels: map[test-service-static:true]
    Jan 24 19:09:02.569: INFO: observed Service test-service-d4ljt in namespace services-9612 with labels: map[test-service-static:true]
    Jan 24 19:09:02.569: INFO: Found Service test-service-d4ljt in namespace services-9612 with labels: map[test-service:patched test-service-static:true]
    Jan 24 19:09:02.569: INFO: Service test-service-d4ljt patched
    STEP: deleting the service 01/24/23 19:09:02.575
    STEP: watching for the Service to be deleted 01/24/23 19:09:02.664
    Jan 24 19:09:02.669: INFO: Observed event: ADDED
    Jan 24 19:09:02.669: INFO: Observed event: MODIFIED
    Jan 24 19:09:02.669: INFO: Observed event: MODIFIED
    Jan 24 19:09:02.669: INFO: Observed event: MODIFIED
    Jan 24 19:09:02.670: INFO: Found Service test-service-d4ljt in namespace services-9612 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Jan 24 19:09:02.670: INFO: Service test-service-d4ljt deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 19:09:02.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9612" for this suite. 01/24/23 19:09:02.695
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:09:02.74
Jan 24 19:09:02.740: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 19:09:02.743
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:02.949
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:02.966
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 24 19:09:03.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4596" for this suite. 01/24/23 19:09:03.406
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":109,"skipped":2134,"failed":0}
------------------------------
• [0.690 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:09:02.74
    Jan 24 19:09:02.740: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 19:09:02.743
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:02.949
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:02.966
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 19:09:03.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4596" for this suite. 01/24/23 19:09:03.406
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:09:03.445
Jan 24 19:09:03.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:09:03.448
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:03.53
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:03.572
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 01/24/23 19:09:03.598
Jan 24 19:09:03.665: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d" in namespace "projected-7182" to be "Succeeded or Failed"
Jan 24 19:09:03.687: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 21.558683ms
Jan 24 19:09:05.701: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035262483s
Jan 24 19:09:07.709: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043545192s
Jan 24 19:09:09.707: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04152908s
Jan 24 19:09:11.708: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042342141s
STEP: Saw pod success 01/24/23 19:09:11.708
Jan 24 19:09:11.710: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d" satisfied condition "Succeeded or Failed"
Jan 24 19:09:11.720: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d container client-container: <nil>
STEP: delete the pod 01/24/23 19:09:11.74
Jan 24 19:09:11.766: INFO: Waiting for pod downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d to disappear
Jan 24 19:09:11.775: INFO: Pod downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 19:09:11.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7182" for this suite. 01/24/23 19:09:11.787
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":110,"skipped":2175,"failed":0}
------------------------------
• [SLOW TEST] [8.355 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:09:03.445
    Jan 24 19:09:03.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:09:03.448
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:03.53
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:03.572
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 01/24/23 19:09:03.598
    Jan 24 19:09:03.665: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d" in namespace "projected-7182" to be "Succeeded or Failed"
    Jan 24 19:09:03.687: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 21.558683ms
    Jan 24 19:09:05.701: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035262483s
    Jan 24 19:09:07.709: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043545192s
    Jan 24 19:09:09.707: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04152908s
    Jan 24 19:09:11.708: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042342141s
    STEP: Saw pod success 01/24/23 19:09:11.708
    Jan 24 19:09:11.710: INFO: Pod "downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d" satisfied condition "Succeeded or Failed"
    Jan 24 19:09:11.720: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d container client-container: <nil>
    STEP: delete the pod 01/24/23 19:09:11.74
    Jan 24 19:09:11.766: INFO: Waiting for pod downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d to disappear
    Jan 24 19:09:11.775: INFO: Pod downwardapi-volume-af78edad-2152-44c7-8321-3deabd7b9f6d no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 19:09:11.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7182" for this suite. 01/24/23 19:09:11.787
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:09:11.801
Jan 24 19:09:11.802: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubelet-test 01/24/23 19:09:11.807
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:11.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:11.856
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Jan 24 19:09:11.884: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b" in namespace "kubelet-test-2554" to be "running and ready"
Jan 24 19:09:11.904: INFO: Pod "busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.948475ms
Jan 24 19:09:11.904: INFO: The phase of Pod busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:09:13.918: INFO: Pod "busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034174296s
Jan 24 19:09:13.918: INFO: The phase of Pod busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:09:15.916: INFO: Pod "busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b": Phase="Running", Reason="", readiness=true. Elapsed: 4.031861109s
Jan 24 19:09:15.916: INFO: The phase of Pod busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b is Running (Ready = true)
Jan 24 19:09:15.916: INFO: Pod "busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jan 24 19:09:15.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2554" for this suite. 01/24/23 19:09:15.955
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":111,"skipped":2175,"failed":0}
------------------------------
• [4.177 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:09:11.801
    Jan 24 19:09:11.802: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubelet-test 01/24/23 19:09:11.807
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:11.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:11.856
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Jan 24 19:09:11.884: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b" in namespace "kubelet-test-2554" to be "running and ready"
    Jan 24 19:09:11.904: INFO: Pod "busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.948475ms
    Jan 24 19:09:11.904: INFO: The phase of Pod busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:09:13.918: INFO: Pod "busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034174296s
    Jan 24 19:09:13.918: INFO: The phase of Pod busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:09:15.916: INFO: Pod "busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b": Phase="Running", Reason="", readiness=true. Elapsed: 4.031861109s
    Jan 24 19:09:15.916: INFO: The phase of Pod busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b is Running (Ready = true)
    Jan 24 19:09:15.916: INFO: Pod "busybox-readonly-fs97b6b936-59e2-41ef-af65-5f95e287085b" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jan 24 19:09:15.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2554" for this suite. 01/24/23 19:09:15.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:09:15.992
Jan 24 19:09:15.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 19:09:15.998
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:16.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:16.066
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 19:09:16.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9272" for this suite. 01/24/23 19:09:16.203
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":112,"skipped":2188,"failed":0}
------------------------------
• [0.252 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:09:15.992
    Jan 24 19:09:15.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 19:09:15.998
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:16.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:16.066
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 19:09:16.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9272" for this suite. 01/24/23 19:09:16.203
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:09:16.256
Jan 24 19:09:16.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-lifecycle-hook 01/24/23 19:09:16.259
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:16.295
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:16.308
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 01/24/23 19:09:16.33
Jan 24 19:09:16.367: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5515" to be "running and ready"
Jan 24 19:09:16.397: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 29.374211ms
Jan 24 19:09:16.400: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:09:18.444: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076822344s
Jan 24 19:09:18.446: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:09:20.440: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.072712508s
Jan 24 19:09:20.441: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jan 24 19:09:20.441: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 01/24/23 19:09:20.455
Jan 24 19:09:20.529: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-5515" to be "running and ready"
Jan 24 19:09:20.640: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 77.292415ms
Jan 24 19:09:20.641: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:09:22.761: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.19818157s
Jan 24 19:09:22.761: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:09:24.665: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.101788387s
Jan 24 19:09:24.665: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Jan 24 19:09:24.665: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 01/24/23 19:09:24.699
STEP: delete the pod with lifecycle hook 01/24/23 19:09:24.763
Jan 24 19:09:24.803: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 24 19:09:24.871: INFO: Pod pod-with-poststart-http-hook still exists
Jan 24 19:09:26.873: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 24 19:09:26.884: INFO: Pod pod-with-poststart-http-hook still exists
Jan 24 19:09:28.874: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 24 19:09:28.886: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jan 24 19:09:28.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5515" for this suite. 01/24/23 19:09:28.9
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":113,"skipped":2196,"failed":0}
------------------------------
• [SLOW TEST] [12.670 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:09:16.256
    Jan 24 19:09:16.256: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-lifecycle-hook 01/24/23 19:09:16.259
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:16.295
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:16.308
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 01/24/23 19:09:16.33
    Jan 24 19:09:16.367: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5515" to be "running and ready"
    Jan 24 19:09:16.397: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 29.374211ms
    Jan 24 19:09:16.400: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:09:18.444: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076822344s
    Jan 24 19:09:18.446: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:09:20.440: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.072712508s
    Jan 24 19:09:20.441: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jan 24 19:09:20.441: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 01/24/23 19:09:20.455
    Jan 24 19:09:20.529: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-5515" to be "running and ready"
    Jan 24 19:09:20.640: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 77.292415ms
    Jan 24 19:09:20.641: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:09:22.761: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.19818157s
    Jan 24 19:09:22.761: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:09:24.665: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.101788387s
    Jan 24 19:09:24.665: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Jan 24 19:09:24.665: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 01/24/23 19:09:24.699
    STEP: delete the pod with lifecycle hook 01/24/23 19:09:24.763
    Jan 24 19:09:24.803: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Jan 24 19:09:24.871: INFO: Pod pod-with-poststart-http-hook still exists
    Jan 24 19:09:26.873: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Jan 24 19:09:26.884: INFO: Pod pod-with-poststart-http-hook still exists
    Jan 24 19:09:28.874: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Jan 24 19:09:28.886: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jan 24 19:09:28.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-5515" for this suite. 01/24/23 19:09:28.9
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:09:28.94
Jan 24 19:09:28.946: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:09:28.95
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:29.016
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:29.03
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 01/24/23 19:09:29.046
Jan 24 19:09:29.087: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f" in namespace "projected-4939" to be "Succeeded or Failed"
Jan 24 19:09:29.113: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.224022ms
Jan 24 19:09:31.138: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051113155s
Jan 24 19:09:33.125: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038167108s
Jan 24 19:09:35.585: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.498417281s
Jan 24 19:09:37.128: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.040879166s
STEP: Saw pod success 01/24/23 19:09:37.128
Jan 24 19:09:37.128: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f" satisfied condition "Succeeded or Failed"
Jan 24 19:09:37.163: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f container client-container: <nil>
STEP: delete the pod 01/24/23 19:09:37.197
Jan 24 19:09:37.248: INFO: Waiting for pod downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f to disappear
Jan 24 19:09:37.262: INFO: Pod downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 19:09:37.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4939" for this suite. 01/24/23 19:09:37.275
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":114,"skipped":2238,"failed":0}
------------------------------
• [SLOW TEST] [8.358 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:09:28.94
    Jan 24 19:09:28.946: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:09:28.95
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:29.016
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:29.03
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 01/24/23 19:09:29.046
    Jan 24 19:09:29.087: INFO: Waiting up to 5m0s for pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f" in namespace "projected-4939" to be "Succeeded or Failed"
    Jan 24 19:09:29.113: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.224022ms
    Jan 24 19:09:31.138: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051113155s
    Jan 24 19:09:33.125: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038167108s
    Jan 24 19:09:35.585: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.498417281s
    Jan 24 19:09:37.128: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.040879166s
    STEP: Saw pod success 01/24/23 19:09:37.128
    Jan 24 19:09:37.128: INFO: Pod "downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f" satisfied condition "Succeeded or Failed"
    Jan 24 19:09:37.163: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f container client-container: <nil>
    STEP: delete the pod 01/24/23 19:09:37.197
    Jan 24 19:09:37.248: INFO: Waiting for pod downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f to disappear
    Jan 24 19:09:37.262: INFO: Pod downwardapi-volume-aa08f8fc-1897-4157-a07a-1dd4cbf4fc0f no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 19:09:37.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4939" for this suite. 01/24/23 19:09:37.275
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:09:37.3
Jan 24 19:09:37.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-probe 01/24/23 19:09:37.324
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:37.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:37.425
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 in namespace container-probe-8559 01/24/23 19:09:37.443
Jan 24 19:09:37.487: INFO: Waiting up to 5m0s for pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952" in namespace "container-probe-8559" to be "not pending"
Jan 24 19:09:37.522: INFO: Pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952": Phase="Pending", Reason="", readiness=false. Elapsed: 33.470611ms
Jan 24 19:09:39.540: INFO: Pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051316217s
Jan 24 19:09:41.628: INFO: Pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952": Phase="Pending", Reason="", readiness=false. Elapsed: 4.139766065s
Jan 24 19:09:43.572: INFO: Pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952": Phase="Running", Reason="", readiness=true. Elapsed: 6.084112747s
Jan 24 19:09:43.572: INFO: Pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952" satisfied condition "not pending"
Jan 24 19:09:43.573: INFO: Started pod liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 in namespace container-probe-8559
STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:09:43.573
Jan 24 19:09:43.588: INFO: Initial restart count of pod liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is 0
Jan 24 19:09:59.802: INFO: Restart count of pod container-probe-8559/liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is now 1 (16.212888147s elapsed)
Jan 24 19:10:20.127: INFO: Restart count of pod container-probe-8559/liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is now 2 (36.538333201s elapsed)
Jan 24 19:10:40.596: INFO: Restart count of pod container-probe-8559/liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is now 3 (57.006642236s elapsed)
Jan 24 19:11:00.898: INFO: Restart count of pod container-probe-8559/liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is now 4 (1m17.30926489s elapsed)
Jan 24 19:12:09.929: INFO: Restart count of pod container-probe-8559/liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is now 5 (2m26.339735076s elapsed)
STEP: deleting the pod 01/24/23 19:12:09.929
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 24 19:12:09.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8559" for this suite. 01/24/23 19:12:09.959
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":115,"skipped":2247,"failed":0}
------------------------------
• [SLOW TEST] [152.671 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:09:37.3
    Jan 24 19:09:37.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-probe 01/24/23 19:09:37.324
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:09:37.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:09:37.425
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 in namespace container-probe-8559 01/24/23 19:09:37.443
    Jan 24 19:09:37.487: INFO: Waiting up to 5m0s for pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952" in namespace "container-probe-8559" to be "not pending"
    Jan 24 19:09:37.522: INFO: Pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952": Phase="Pending", Reason="", readiness=false. Elapsed: 33.470611ms
    Jan 24 19:09:39.540: INFO: Pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051316217s
    Jan 24 19:09:41.628: INFO: Pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952": Phase="Pending", Reason="", readiness=false. Elapsed: 4.139766065s
    Jan 24 19:09:43.572: INFO: Pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952": Phase="Running", Reason="", readiness=true. Elapsed: 6.084112747s
    Jan 24 19:09:43.572: INFO: Pod "liveness-6ca9fb42-6d19-43bc-9809-6286624c3952" satisfied condition "not pending"
    Jan 24 19:09:43.573: INFO: Started pod liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 in namespace container-probe-8559
    STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:09:43.573
    Jan 24 19:09:43.588: INFO: Initial restart count of pod liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is 0
    Jan 24 19:09:59.802: INFO: Restart count of pod container-probe-8559/liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is now 1 (16.212888147s elapsed)
    Jan 24 19:10:20.127: INFO: Restart count of pod container-probe-8559/liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is now 2 (36.538333201s elapsed)
    Jan 24 19:10:40.596: INFO: Restart count of pod container-probe-8559/liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is now 3 (57.006642236s elapsed)
    Jan 24 19:11:00.898: INFO: Restart count of pod container-probe-8559/liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is now 4 (1m17.30926489s elapsed)
    Jan 24 19:12:09.929: INFO: Restart count of pod container-probe-8559/liveness-6ca9fb42-6d19-43bc-9809-6286624c3952 is now 5 (2m26.339735076s elapsed)
    STEP: deleting the pod 01/24/23 19:12:09.929
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 24 19:12:09.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8559" for this suite. 01/24/23 19:12:09.959
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:12:09.971
Jan 24 19:12:09.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename limitrange 01/24/23 19:12:09.973
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:12:10.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:12:10.025
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 01/24/23 19:12:10.029
STEP: Setting up watch 01/24/23 19:12:10.03
STEP: Submitting a LimitRange 01/24/23 19:12:10.146
STEP: Verifying LimitRange creation was observed 01/24/23 19:12:10.159
STEP: Fetching the LimitRange to ensure it has proper values 01/24/23 19:12:10.16
Jan 24 19:12:10.169: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jan 24 19:12:10.169: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 01/24/23 19:12:10.169
STEP: Ensuring Pod has resource requirements applied from LimitRange 01/24/23 19:12:10.182
Jan 24 19:12:10.202: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jan 24 19:12:10.202: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 01/24/23 19:12:10.203
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 01/24/23 19:12:10.232
Jan 24 19:12:10.242: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Jan 24 19:12:10.242: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 01/24/23 19:12:10.29
STEP: Failing to create a Pod with more than max resources 01/24/23 19:12:10.299
STEP: Updating a LimitRange 01/24/23 19:12:10.328
STEP: Verifying LimitRange updating is effective 01/24/23 19:12:10.351
STEP: Creating a Pod with less than former min resources 01/24/23 19:12:12.367
STEP: Failing to create a Pod with more than max resources 01/24/23 19:12:12.398
STEP: Deleting a LimitRange 01/24/23 19:12:12.41
STEP: Verifying the LimitRange was deleted 01/24/23 19:12:12.449
Jan 24 19:12:17.472: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 01/24/23 19:12:17.473
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Jan 24 19:12:17.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-3304" for this suite. 01/24/23 19:12:17.559
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":116,"skipped":2250,"failed":0}
------------------------------
• [SLOW TEST] [7.625 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:12:09.971
    Jan 24 19:12:09.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename limitrange 01/24/23 19:12:09.973
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:12:10.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:12:10.025
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 01/24/23 19:12:10.029
    STEP: Setting up watch 01/24/23 19:12:10.03
    STEP: Submitting a LimitRange 01/24/23 19:12:10.146
    STEP: Verifying LimitRange creation was observed 01/24/23 19:12:10.159
    STEP: Fetching the LimitRange to ensure it has proper values 01/24/23 19:12:10.16
    Jan 24 19:12:10.169: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Jan 24 19:12:10.169: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 01/24/23 19:12:10.169
    STEP: Ensuring Pod has resource requirements applied from LimitRange 01/24/23 19:12:10.182
    Jan 24 19:12:10.202: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Jan 24 19:12:10.202: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 01/24/23 19:12:10.203
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 01/24/23 19:12:10.232
    Jan 24 19:12:10.242: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Jan 24 19:12:10.242: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 01/24/23 19:12:10.29
    STEP: Failing to create a Pod with more than max resources 01/24/23 19:12:10.299
    STEP: Updating a LimitRange 01/24/23 19:12:10.328
    STEP: Verifying LimitRange updating is effective 01/24/23 19:12:10.351
    STEP: Creating a Pod with less than former min resources 01/24/23 19:12:12.367
    STEP: Failing to create a Pod with more than max resources 01/24/23 19:12:12.398
    STEP: Deleting a LimitRange 01/24/23 19:12:12.41
    STEP: Verifying the LimitRange was deleted 01/24/23 19:12:12.449
    Jan 24 19:12:17.472: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 01/24/23 19:12:17.473
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Jan 24 19:12:17.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-3304" for this suite. 01/24/23 19:12:17.559
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:12:17.666
Jan 24 19:12:17.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replicaset 01/24/23 19:12:17.681
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:12:17.877
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:12:17.899
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 01/24/23 19:12:17.924
Jan 24 19:12:18.004: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-8492" to be "running and ready"
Jan 24 19:12:18.051: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 47.518778ms
Jan 24 19:12:18.051: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:12:20.067: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063717539s
Jan 24 19:12:20.068: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:12:22.061: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.057263303s
Jan 24 19:12:22.061: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Jan 24 19:12:22.061: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 01/24/23 19:12:22.068
STEP: Then the orphan pod is adopted 01/24/23 19:12:22.082
STEP: When the matched label of one of its pods change 01/24/23 19:12:23.117
Jan 24 19:12:23.132: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 01/24/23 19:12:23.254
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 24 19:12:24.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8492" for this suite. 01/24/23 19:12:24.4
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":117,"skipped":2313,"failed":0}
------------------------------
• [SLOW TEST] [6.800 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:12:17.666
    Jan 24 19:12:17.667: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replicaset 01/24/23 19:12:17.681
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:12:17.877
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:12:17.899
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 01/24/23 19:12:17.924
    Jan 24 19:12:18.004: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-8492" to be "running and ready"
    Jan 24 19:12:18.051: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 47.518778ms
    Jan 24 19:12:18.051: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:12:20.067: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063717539s
    Jan 24 19:12:20.068: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:12:22.061: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.057263303s
    Jan 24 19:12:22.061: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Jan 24 19:12:22.061: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 01/24/23 19:12:22.068
    STEP: Then the orphan pod is adopted 01/24/23 19:12:22.082
    STEP: When the matched label of one of its pods change 01/24/23 19:12:23.117
    Jan 24 19:12:23.132: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 01/24/23 19:12:23.254
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 24 19:12:24.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-8492" for this suite. 01/24/23 19:12:24.4
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:12:24.468
Jan 24 19:12:24.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename init-container 01/24/23 19:12:24.477
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:12:24.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:12:24.673
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 01/24/23 19:12:24.766
Jan 24 19:12:24.767: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 24 19:12:32.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8770" for this suite. 01/24/23 19:12:32.998
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":118,"skipped":2318,"failed":0}
------------------------------
• [SLOW TEST] [8.593 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:12:24.468
    Jan 24 19:12:24.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename init-container 01/24/23 19:12:24.477
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:12:24.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:12:24.673
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 01/24/23 19:12:24.766
    Jan 24 19:12:24.767: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 24 19:12:32.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8770" for this suite. 01/24/23 19:12:32.998
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:12:33.083
Jan 24 19:12:33.084: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 19:12:33.087
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:12:33.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:12:33.241
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 01/24/23 19:12:50.323
STEP: Creating a ResourceQuota 01/24/23 19:12:55.346
STEP: Ensuring resource quota status is calculated 01/24/23 19:12:55.364
STEP: Creating a ConfigMap 01/24/23 19:12:57.379
STEP: Ensuring resource quota status captures configMap creation 01/24/23 19:12:57.417
STEP: Deleting a ConfigMap 01/24/23 19:12:59.426
STEP: Ensuring resource quota status released usage 01/24/23 19:12:59.439
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 19:13:01.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5903" for this suite. 01/24/23 19:13:01.467
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":119,"skipped":2352,"failed":0}
------------------------------
• [SLOW TEST] [28.413 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:12:33.083
    Jan 24 19:12:33.084: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 19:12:33.087
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:12:33.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:12:33.241
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 01/24/23 19:12:50.323
    STEP: Creating a ResourceQuota 01/24/23 19:12:55.346
    STEP: Ensuring resource quota status is calculated 01/24/23 19:12:55.364
    STEP: Creating a ConfigMap 01/24/23 19:12:57.379
    STEP: Ensuring resource quota status captures configMap creation 01/24/23 19:12:57.417
    STEP: Deleting a ConfigMap 01/24/23 19:12:59.426
    STEP: Ensuring resource quota status released usage 01/24/23 19:12:59.439
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 19:13:01.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5903" for this suite. 01/24/23 19:13:01.467
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:13:01.512
Jan 24 19:13:01.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename svcaccounts 01/24/23 19:13:01.515
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:13:01.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:13:01.637
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 01/24/23 19:13:01.657
STEP: watching for the ServiceAccount to be added 01/24/23 19:13:01.717
STEP: patching the ServiceAccount 01/24/23 19:13:01.736
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 01/24/23 19:13:01.775
STEP: deleting the ServiceAccount 01/24/23 19:13:01.798
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 24 19:13:01.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9694" for this suite. 01/24/23 19:13:01.897
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":120,"skipped":2387,"failed":0}
------------------------------
• [0.436 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:13:01.512
    Jan 24 19:13:01.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename svcaccounts 01/24/23 19:13:01.515
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:13:01.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:13:01.637
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 01/24/23 19:13:01.657
    STEP: watching for the ServiceAccount to be added 01/24/23 19:13:01.717
    STEP: patching the ServiceAccount 01/24/23 19:13:01.736
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 01/24/23 19:13:01.775
    STEP: deleting the ServiceAccount 01/24/23 19:13:01.798
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 24 19:13:01.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9694" for this suite. 01/24/23 19:13:01.897
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:13:01.955
Jan 24 19:13:01.956: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename svcaccounts 01/24/23 19:13:01.965
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:13:02.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:13:02.08
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Jan 24 19:13:02.189: INFO: created pod
Jan 24 19:13:02.189: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-3003" to be "Succeeded or Failed"
Jan 24 19:13:02.265: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 76.425221ms
Jan 24 19:13:04.303: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114008753s
Jan 24 19:13:06.294: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=false. Elapsed: 4.105374126s
Jan 24 19:13:08.274: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.084775198s
STEP: Saw pod success 01/24/23 19:13:08.274
Jan 24 19:13:08.274: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Jan 24 19:13:38.276: INFO: polling logs
Jan 24 19:13:38.346: INFO: Pod logs: 
I0124 19:13:04.850589       1 log.go:195] OK: Got token
I0124 19:13:04.850784       1 log.go:195] validating with in-cluster discovery
I0124 19:13:04.855062       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I0124 19:13:04.855420       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-3003:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1674588182, NotBefore:1674587582, IssuedAt:1674587582, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-3003", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"560c5700-2b1b-4baf-bcfc-718d66f76ca4"}}}
I0124 19:13:04.958565       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0124 19:13:05.037397       1 log.go:195] OK: Validated signature on JWT
I0124 19:13:05.037808       1 log.go:195] OK: Got valid claims from token!
I0124 19:13:05.038257       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-3003:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1674588182, NotBefore:1674587582, IssuedAt:1674587582, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-3003", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"560c5700-2b1b-4baf-bcfc-718d66f76ca4"}}}

Jan 24 19:13:38.346: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 24 19:13:38.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3003" for this suite. 01/24/23 19:13:38.393
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":121,"skipped":2409,"failed":0}
------------------------------
• [SLOW TEST] [36.467 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:13:01.955
    Jan 24 19:13:01.956: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename svcaccounts 01/24/23 19:13:01.965
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:13:02.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:13:02.08
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Jan 24 19:13:02.189: INFO: created pod
    Jan 24 19:13:02.189: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-3003" to be "Succeeded or Failed"
    Jan 24 19:13:02.265: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 76.425221ms
    Jan 24 19:13:04.303: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114008753s
    Jan 24 19:13:06.294: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=false. Elapsed: 4.105374126s
    Jan 24 19:13:08.274: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.084775198s
    STEP: Saw pod success 01/24/23 19:13:08.274
    Jan 24 19:13:08.274: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Jan 24 19:13:38.276: INFO: polling logs
    Jan 24 19:13:38.346: INFO: Pod logs: 
    I0124 19:13:04.850589       1 log.go:195] OK: Got token
    I0124 19:13:04.850784       1 log.go:195] validating with in-cluster discovery
    I0124 19:13:04.855062       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
    I0124 19:13:04.855420       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-3003:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1674588182, NotBefore:1674587582, IssuedAt:1674587582, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-3003", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"560c5700-2b1b-4baf-bcfc-718d66f76ca4"}}}
    I0124 19:13:04.958565       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
    I0124 19:13:05.037397       1 log.go:195] OK: Validated signature on JWT
    I0124 19:13:05.037808       1 log.go:195] OK: Got valid claims from token!
    I0124 19:13:05.038257       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-3003:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1674588182, NotBefore:1674587582, IssuedAt:1674587582, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-3003", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"560c5700-2b1b-4baf-bcfc-718d66f76ca4"}}}

    Jan 24 19:13:38.346: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 24 19:13:38.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-3003" for this suite. 01/24/23 19:13:38.393
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:13:38.431
Jan 24 19:13:38.432: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename daemonsets 01/24/23 19:13:38.438
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:13:38.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:13:38.523
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Jan 24 19:13:38.607: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 19:13:38.631
Jan 24 19:13:38.650: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:13:38.650: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:13:39.720: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:13:39.728: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:13:40.843: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:13:40.843: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:13:41.702: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:13:41.702: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:13:42.727: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:13:42.729: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:13:43.713: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 24 19:13:43.713: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Update daemon pods image. 01/24/23 19:13:43.814
STEP: Check that daemon pods images are updated. 01/24/23 19:13:43.879
Jan 24 19:13:43.908: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 24 19:13:44.957: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 24 19:13:45.953: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 24 19:13:46.951: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 24 19:13:47.941: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 24 19:13:47.941: INFO: Pod daemon-set-2c2pb is not available
Jan 24 19:13:48.960: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 24 19:13:48.960: INFO: Pod daemon-set-2c2pb is not available
Jan 24 19:13:49.951: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Jan 24 19:13:49.951: INFO: Pod daemon-set-2c2pb is not available
Jan 24 19:13:53.955: INFO: Pod daemon-set-n4wrx is not available
STEP: Check that daemon pods are still running on every node of the cluster. 01/24/23 19:13:53.985
Jan 24 19:13:54.060: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:13:54.060: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 19:13:55.119: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:13:55.119: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 19:13:56.092: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:13:56.092: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 19:13:57.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 24 19:13:57.096: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/24/23 19:13:57.175
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8250, will wait for the garbage collector to delete the pods 01/24/23 19:13:57.176
Jan 24 19:13:57.297: INFO: Deleting DaemonSet.extensions daemon-set took: 56.650106ms
Jan 24 19:13:57.513: INFO: Terminating DaemonSet.extensions daemon-set pods took: 216.598618ms
Jan 24 19:14:00.484: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:14:00.484: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 24 19:14:00.516: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"21938"},"items":null}

Jan 24 19:14:00.546: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"21938"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 24 19:14:00.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8250" for this suite. 01/24/23 19:14:00.667
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":122,"skipped":2441,"failed":0}
------------------------------
• [SLOW TEST] [22.262 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:13:38.431
    Jan 24 19:13:38.432: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename daemonsets 01/24/23 19:13:38.438
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:13:38.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:13:38.523
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Jan 24 19:13:38.607: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 19:13:38.631
    Jan 24 19:13:38.650: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:13:38.650: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:13:39.720: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:13:39.728: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:13:40.843: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:13:40.843: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:13:41.702: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:13:41.702: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:13:42.727: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:13:42.729: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:13:43.713: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 24 19:13:43.713: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Update daemon pods image. 01/24/23 19:13:43.814
    STEP: Check that daemon pods images are updated. 01/24/23 19:13:43.879
    Jan 24 19:13:43.908: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 24 19:13:44.957: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 24 19:13:45.953: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 24 19:13:46.951: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 24 19:13:47.941: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 24 19:13:47.941: INFO: Pod daemon-set-2c2pb is not available
    Jan 24 19:13:48.960: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 24 19:13:48.960: INFO: Pod daemon-set-2c2pb is not available
    Jan 24 19:13:49.951: INFO: Wrong image for pod: daemon-set-25jlj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Jan 24 19:13:49.951: INFO: Pod daemon-set-2c2pb is not available
    Jan 24 19:13:53.955: INFO: Pod daemon-set-n4wrx is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 01/24/23 19:13:53.985
    Jan 24 19:13:54.060: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:13:54.060: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 19:13:55.119: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:13:55.119: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 19:13:56.092: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:13:56.092: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 19:13:57.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 24 19:13:57.096: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/24/23 19:13:57.175
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8250, will wait for the garbage collector to delete the pods 01/24/23 19:13:57.176
    Jan 24 19:13:57.297: INFO: Deleting DaemonSet.extensions daemon-set took: 56.650106ms
    Jan 24 19:13:57.513: INFO: Terminating DaemonSet.extensions daemon-set pods took: 216.598618ms
    Jan 24 19:14:00.484: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:14:00.484: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 24 19:14:00.516: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"21938"},"items":null}

    Jan 24 19:14:00.546: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"21938"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 19:14:00.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8250" for this suite. 01/24/23 19:14:00.667
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:14:00.707
Jan 24 19:14:00.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-probe 01/24/23 19:14:00.713
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:14:00.787
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:14:00.802
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849 in namespace container-probe-6381 01/24/23 19:14:00.81
Jan 24 19:14:00.840: INFO: Waiting up to 5m0s for pod "test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849" in namespace "container-probe-6381" to be "not pending"
Jan 24 19:14:00.983: INFO: Pod "test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849": Phase="Pending", Reason="", readiness=false. Elapsed: 142.483899ms
Jan 24 19:14:03.337: INFO: Pod "test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849": Phase="Pending", Reason="", readiness=false. Elapsed: 2.497125109s
Jan 24 19:14:04.998: INFO: Pod "test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849": Phase="Running", Reason="", readiness=true. Elapsed: 4.157705249s
Jan 24 19:14:04.998: INFO: Pod "test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849" satisfied condition "not pending"
Jan 24 19:14:04.999: INFO: Started pod test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849 in namespace container-probe-6381
STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:14:04.999
Jan 24 19:14:05.010: INFO: Initial restart count of pod test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849 is 0
STEP: deleting the pod 01/24/23 19:18:05.071
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 24 19:18:05.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6381" for this suite. 01/24/23 19:18:05.184
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":123,"skipped":2451,"failed":0}
------------------------------
• [SLOW TEST] [244.521 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:14:00.707
    Jan 24 19:14:00.707: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-probe 01/24/23 19:14:00.713
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:14:00.787
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:14:00.802
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849 in namespace container-probe-6381 01/24/23 19:14:00.81
    Jan 24 19:14:00.840: INFO: Waiting up to 5m0s for pod "test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849" in namespace "container-probe-6381" to be "not pending"
    Jan 24 19:14:00.983: INFO: Pod "test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849": Phase="Pending", Reason="", readiness=false. Elapsed: 142.483899ms
    Jan 24 19:14:03.337: INFO: Pod "test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849": Phase="Pending", Reason="", readiness=false. Elapsed: 2.497125109s
    Jan 24 19:14:04.998: INFO: Pod "test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849": Phase="Running", Reason="", readiness=true. Elapsed: 4.157705249s
    Jan 24 19:14:04.998: INFO: Pod "test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849" satisfied condition "not pending"
    Jan 24 19:14:04.999: INFO: Started pod test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849 in namespace container-probe-6381
    STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:14:04.999
    Jan 24 19:14:05.010: INFO: Initial restart count of pod test-webserver-31a888f7-6f42-40b7-a15a-fc391b426849 is 0
    STEP: deleting the pod 01/24/23 19:18:05.071
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 24 19:18:05.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6381" for this suite. 01/24/23 19:18:05.184
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:18:05.276
Jan 24 19:18:05.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-probe 01/24/23 19:18:05.285
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:18:05.36
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:18:05.386
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1 in namespace container-probe-3245 01/24/23 19:18:05.399
Jan 24 19:18:05.482: INFO: Waiting up to 5m0s for pod "liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1" in namespace "container-probe-3245" to be "not pending"
Jan 24 19:18:05.505: INFO: Pod "liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.715018ms
Jan 24 19:18:07.523: INFO: Pod "liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041295316s
Jan 24 19:18:09.515: INFO: Pod "liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1": Phase="Running", Reason="", readiness=true. Elapsed: 4.033506554s
Jan 24 19:18:09.515: INFO: Pod "liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1" satisfied condition "not pending"
Jan 24 19:18:09.516: INFO: Started pod liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1 in namespace container-probe-3245
STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:18:09.516
Jan 24 19:18:09.522: INFO: Initial restart count of pod liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1 is 0
Jan 24 19:18:27.768: INFO: Restart count of pod container-probe-3245/liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1 is now 1 (18.245938176s elapsed)
STEP: deleting the pod 01/24/23 19:18:27.768
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 24 19:18:27.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3245" for this suite. 01/24/23 19:18:27.839
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":124,"skipped":2454,"failed":0}
------------------------------
• [SLOW TEST] [22.594 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:18:05.276
    Jan 24 19:18:05.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-probe 01/24/23 19:18:05.285
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:18:05.36
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:18:05.386
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1 in namespace container-probe-3245 01/24/23 19:18:05.399
    Jan 24 19:18:05.482: INFO: Waiting up to 5m0s for pod "liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1" in namespace "container-probe-3245" to be "not pending"
    Jan 24 19:18:05.505: INFO: Pod "liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.715018ms
    Jan 24 19:18:07.523: INFO: Pod "liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041295316s
    Jan 24 19:18:09.515: INFO: Pod "liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1": Phase="Running", Reason="", readiness=true. Elapsed: 4.033506554s
    Jan 24 19:18:09.515: INFO: Pod "liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1" satisfied condition "not pending"
    Jan 24 19:18:09.516: INFO: Started pod liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1 in namespace container-probe-3245
    STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:18:09.516
    Jan 24 19:18:09.522: INFO: Initial restart count of pod liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1 is 0
    Jan 24 19:18:27.768: INFO: Restart count of pod container-probe-3245/liveness-c33f8d60-830f-4ca7-9e1d-fa7590e316a1 is now 1 (18.245938176s elapsed)
    STEP: deleting the pod 01/24/23 19:18:27.768
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 24 19:18:27.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3245" for this suite. 01/24/23 19:18:27.839
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:18:27.915
Jan 24 19:18:27.916: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename custom-resource-definition 01/24/23 19:18:27.92
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:18:28.004
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:18:28.014
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Jan 24 19:18:28.024: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:18:29.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-378" for this suite. 01/24/23 19:18:29.655
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":125,"skipped":2475,"failed":0}
------------------------------
• [1.777 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:18:27.915
    Jan 24 19:18:27.916: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename custom-resource-definition 01/24/23 19:18:27.92
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:18:28.004
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:18:28.014
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Jan 24 19:18:28.024: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:18:29.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-378" for this suite. 01/24/23 19:18:29.655
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:18:29.708
Jan 24 19:18:29.708: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 19:18:29.731
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:18:29.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:18:29.947
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 01/24/23 19:18:29.96
Jan 24 19:18:30.273: INFO: Waiting up to 5m0s for pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9" in namespace "downward-api-5572" to be "Succeeded or Failed"
Jan 24 19:18:30.296: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9": Phase="Pending", Reason="", readiness=false. Elapsed: 23.234383ms
Jan 24 19:18:32.326: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053080041s
Jan 24 19:18:34.312: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038871983s
Jan 24 19:18:36.316: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042476459s
Jan 24 19:18:38.330: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.056676919s
STEP: Saw pod success 01/24/23 19:18:38.331
Jan 24 19:18:38.332: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9" satisfied condition "Succeeded or Failed"
Jan 24 19:18:38.352: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9 container dapi-container: <nil>
STEP: delete the pod 01/24/23 19:18:38.441
Jan 24 19:18:38.507: INFO: Waiting for pod downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9 to disappear
Jan 24 19:18:38.548: INFO: Pod downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jan 24 19:18:38.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5572" for this suite. 01/24/23 19:18:38.588
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":126,"skipped":2478,"failed":0}
------------------------------
• [SLOW TEST] [8.909 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:18:29.708
    Jan 24 19:18:29.708: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 19:18:29.731
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:18:29.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:18:29.947
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 01/24/23 19:18:29.96
    Jan 24 19:18:30.273: INFO: Waiting up to 5m0s for pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9" in namespace "downward-api-5572" to be "Succeeded or Failed"
    Jan 24 19:18:30.296: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9": Phase="Pending", Reason="", readiness=false. Elapsed: 23.234383ms
    Jan 24 19:18:32.326: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053080041s
    Jan 24 19:18:34.312: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038871983s
    Jan 24 19:18:36.316: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042476459s
    Jan 24 19:18:38.330: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.056676919s
    STEP: Saw pod success 01/24/23 19:18:38.331
    Jan 24 19:18:38.332: INFO: Pod "downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9" satisfied condition "Succeeded or Failed"
    Jan 24 19:18:38.352: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9 container dapi-container: <nil>
    STEP: delete the pod 01/24/23 19:18:38.441
    Jan 24 19:18:38.507: INFO: Waiting for pod downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9 to disappear
    Jan 24 19:18:38.548: INFO: Pod downward-api-7bb88247-925d-4506-b629-7a3bec9c12e9 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jan 24 19:18:38.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5572" for this suite. 01/24/23 19:18:38.588
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:18:38.666
Jan 24 19:18:38.666: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename subpath 01/24/23 19:18:38.67
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:18:38.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:18:38.773
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 01/24/23 19:18:38.786
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-qxdl 01/24/23 19:18:38.838
STEP: Creating a pod to test atomic-volume-subpath 01/24/23 19:18:38.838
Jan 24 19:18:38.870: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qxdl" in namespace "subpath-98" to be "Succeeded or Failed"
Jan 24 19:18:38.882: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Pending", Reason="", readiness=false. Elapsed: 11.655583ms
Jan 24 19:18:40.973: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103444427s
Jan 24 19:18:43.162: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.291683359s
Jan 24 19:18:44.935: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 6.065277999s
Jan 24 19:18:46.893: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 8.023445382s
Jan 24 19:18:48.904: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 10.033952865s
Jan 24 19:18:50.893: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 12.023465538s
Jan 24 19:18:52.914: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 14.043667013s
Jan 24 19:18:54.896: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 16.02568053s
Jan 24 19:18:56.906: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 18.036071488s
Jan 24 19:18:59.100: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 20.230326705s
Jan 24 19:19:00.926: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 22.055827632s
Jan 24 19:19:02.907: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 24.036558709s
Jan 24 19:19:04.973: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=false. Elapsed: 26.103109756s
Jan 24 19:19:06.891: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.021164145s
STEP: Saw pod success 01/24/23 19:19:06.891
Jan 24 19:19:06.892: INFO: Pod "pod-subpath-test-configmap-qxdl" satisfied condition "Succeeded or Failed"
Jan 24 19:19:06.900: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-subpath-test-configmap-qxdl container test-container-subpath-configmap-qxdl: <nil>
STEP: delete the pod 01/24/23 19:19:06.92
Jan 24 19:19:06.952: INFO: Waiting for pod pod-subpath-test-configmap-qxdl to disappear
Jan 24 19:19:06.959: INFO: Pod pod-subpath-test-configmap-qxdl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-qxdl 01/24/23 19:19:06.959
Jan 24 19:19:06.960: INFO: Deleting pod "pod-subpath-test-configmap-qxdl" in namespace "subpath-98"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jan 24 19:19:06.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-98" for this suite. 01/24/23 19:19:06.981
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":127,"skipped":2513,"failed":0}
------------------------------
• [SLOW TEST] [28.331 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:18:38.666
    Jan 24 19:18:38.666: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename subpath 01/24/23 19:18:38.67
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:18:38.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:18:38.773
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 01/24/23 19:18:38.786
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-qxdl 01/24/23 19:18:38.838
    STEP: Creating a pod to test atomic-volume-subpath 01/24/23 19:18:38.838
    Jan 24 19:18:38.870: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qxdl" in namespace "subpath-98" to be "Succeeded or Failed"
    Jan 24 19:18:38.882: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Pending", Reason="", readiness=false. Elapsed: 11.655583ms
    Jan 24 19:18:40.973: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103444427s
    Jan 24 19:18:43.162: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.291683359s
    Jan 24 19:18:44.935: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 6.065277999s
    Jan 24 19:18:46.893: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 8.023445382s
    Jan 24 19:18:48.904: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 10.033952865s
    Jan 24 19:18:50.893: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 12.023465538s
    Jan 24 19:18:52.914: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 14.043667013s
    Jan 24 19:18:54.896: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 16.02568053s
    Jan 24 19:18:56.906: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 18.036071488s
    Jan 24 19:18:59.100: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 20.230326705s
    Jan 24 19:19:00.926: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 22.055827632s
    Jan 24 19:19:02.907: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=true. Elapsed: 24.036558709s
    Jan 24 19:19:04.973: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Running", Reason="", readiness=false. Elapsed: 26.103109756s
    Jan 24 19:19:06.891: INFO: Pod "pod-subpath-test-configmap-qxdl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.021164145s
    STEP: Saw pod success 01/24/23 19:19:06.891
    Jan 24 19:19:06.892: INFO: Pod "pod-subpath-test-configmap-qxdl" satisfied condition "Succeeded or Failed"
    Jan 24 19:19:06.900: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-subpath-test-configmap-qxdl container test-container-subpath-configmap-qxdl: <nil>
    STEP: delete the pod 01/24/23 19:19:06.92
    Jan 24 19:19:06.952: INFO: Waiting for pod pod-subpath-test-configmap-qxdl to disappear
    Jan 24 19:19:06.959: INFO: Pod pod-subpath-test-configmap-qxdl no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-qxdl 01/24/23 19:19:06.959
    Jan 24 19:19:06.960: INFO: Deleting pod "pod-subpath-test-configmap-qxdl" in namespace "subpath-98"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jan 24 19:19:06.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-98" for this suite. 01/24/23 19:19:06.981
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:19:07.025
Jan 24 19:19:07.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 19:19:07.034
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:19:07.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:19:07.094
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 01/24/23 19:19:07.103
Jan 24 19:19:07.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Jan 24 19:19:07.455: INFO: stderr: ""
Jan 24 19:19:07.455: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 01/24/23 19:19:07.455
Jan 24 19:19:07.455: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Jan 24 19:19:07.455: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1063" to be "running and ready, or succeeded"
Jan 24 19:19:07.470: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 14.625749ms
Jan 24 19:19:07.470: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'vikash-v125latest-conf-71087' to be 'Running' but was 'Pending'
Jan 24 19:19:09.481: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025666478s
Jan 24 19:19:09.481: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'vikash-v125latest-conf-71087' to be 'Running' but was 'Pending'
Jan 24 19:19:11.541: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.085958133s
Jan 24 19:19:11.542: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Jan 24 19:19:11.542: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 01/24/23 19:19:11.542
Jan 24 19:19:11.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator'
Jan 24 19:19:12.081: INFO: stderr: ""
Jan 24 19:19:12.081: INFO: stdout: "I0124 19:19:09.395363       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/5cl 232\nI0124 19:19:09.596104       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/drl 320\nI0124 19:19:09.795376       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/pxjt 322\nI0124 19:19:09.995955       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/z7d 512\nI0124 19:19:10.195405       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/qm6m 506\nI0124 19:19:10.395409       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/kh42 447\nI0124 19:19:10.595990       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/hsft 272\nI0124 19:19:10.795419       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/4s7 216\nI0124 19:19:10.995418       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/r6z 275\nI0124 19:19:11.196176       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/9bq 486\nI0124 19:19:11.396017       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/dpdm 210\nI0124 19:19:11.595673       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/lxfm 360\nI0124 19:19:11.796175       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/vjk 357\nI0124 19:19:11.995463       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/vq7z 413\n"
STEP: limiting log lines 01/24/23 19:19:12.081
Jan 24 19:19:12.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator --tail=1'
Jan 24 19:19:13.563: INFO: stderr: ""
Jan 24 19:19:13.563: INFO: stdout: "I0124 19:19:13.396371       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/8q8m 384\n"
Jan 24 19:19:13.563: INFO: got output "I0124 19:19:13.396371       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/8q8m 384\n"
STEP: limiting log bytes 01/24/23 19:19:13.563
Jan 24 19:19:13.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator --limit-bytes=1'
Jan 24 19:19:14.351: INFO: stderr: ""
Jan 24 19:19:14.351: INFO: stdout: "I"
Jan 24 19:19:14.351: INFO: got output "I"
STEP: exposing timestamps 01/24/23 19:19:14.352
Jan 24 19:19:14.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator --tail=1 --timestamps'
Jan 24 19:19:16.349: INFO: stderr: ""
Jan 24 19:19:16.350: INFO: stdout: "2023-01-24T11:19:16.197186649-08:00 I0124 19:19:16.196881       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/default/pods/6cd 314\n"
Jan 24 19:19:16.350: INFO: got output "2023-01-24T11:19:16.197186649-08:00 I0124 19:19:16.196881       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/default/pods/6cd 314\n"
STEP: restricting to a time range 01/24/23 19:19:16.35
Jan 24 19:19:18.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator --since=1s'
Jan 24 19:19:19.297: INFO: stderr: ""
Jan 24 19:19:19.297: INFO: stdout: "I0124 19:19:18.400669       1 logs_generator.go:76] 45 POST /api/v1/namespaces/default/pods/plp 434\nI0124 19:19:18.596190       1 logs_generator.go:76] 46 POST /api/v1/namespaces/default/pods/lz8 365\nI0124 19:19:18.795587       1 logs_generator.go:76] 47 GET /api/v1/namespaces/kube-system/pods/srmg 338\nI0124 19:19:18.996306       1 logs_generator.go:76] 48 GET /api/v1/namespaces/kube-system/pods/4jkx 535\nI0124 19:19:19.200585       1 logs_generator.go:76] 49 POST /api/v1/namespaces/ns/pods/rcx 400\n"
Jan 24 19:19:19.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator --since=24h'
Jan 24 19:19:19.690: INFO: stderr: ""
Jan 24 19:19:19.690: INFO: stdout: "I0124 19:19:09.395363       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/5cl 232\nI0124 19:19:09.596104       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/drl 320\nI0124 19:19:09.795376       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/pxjt 322\nI0124 19:19:09.995955       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/z7d 512\nI0124 19:19:10.195405       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/qm6m 506\nI0124 19:19:10.395409       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/kh42 447\nI0124 19:19:10.595990       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/hsft 272\nI0124 19:19:10.795419       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/4s7 216\nI0124 19:19:10.995418       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/r6z 275\nI0124 19:19:11.196176       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/9bq 486\nI0124 19:19:11.396017       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/dpdm 210\nI0124 19:19:11.595673       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/lxfm 360\nI0124 19:19:11.796175       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/vjk 357\nI0124 19:19:11.995463       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/vq7z 413\nI0124 19:19:12.196351       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/5m74 322\nI0124 19:19:12.399633       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/fn5z 512\nI0124 19:19:12.596374       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/d8c 581\nI0124 19:19:12.796393       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/nwjl 596\nI0124 19:19:12.996088       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/v5bx 509\nI0124 19:19:13.199339       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/b4jn 287\nI0124 19:19:13.396371       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/8q8m 384\nI0124 19:19:13.596337       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/7vz5 382\nI0124 19:19:13.795790       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/xbw 534\nI0124 19:19:13.996885       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/flw7 380\nI0124 19:19:14.195364       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/ns/pods/hcl 203\nI0124 19:19:14.396054       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/vhtr 554\nI0124 19:19:14.595491       1 logs_generator.go:76] 26 POST /api/v1/namespaces/kube-system/pods/rjj 356\nI0124 19:19:14.796095       1 logs_generator.go:76] 27 POST /api/v1/namespaces/ns/pods/jdps 575\nI0124 19:19:14.995423       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/kube-system/pods/nx2r 273\nI0124 19:19:15.195968       1 logs_generator.go:76] 29 GET /api/v1/namespaces/kube-system/pods/hmvs 467\nI0124 19:19:15.395412       1 logs_generator.go:76] 30 POST /api/v1/namespaces/default/pods/rgth 564\nI0124 19:19:15.596012       1 logs_generator.go:76] 31 PUT /api/v1/namespaces/ns/pods/svcw 360\nI0124 19:19:15.796092       1 logs_generator.go:76] 32 PUT /api/v1/namespaces/ns/pods/7wjx 404\nI0124 19:19:15.996629       1 logs_generator.go:76] 33 GET /api/v1/namespaces/ns/pods/sqpx 522\nI0124 19:19:16.196881       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/default/pods/6cd 314\nI0124 19:19:16.396355       1 logs_generator.go:76] 35 GET /api/v1/namespaces/kube-system/pods/57pf 213\nI0124 19:19:16.596019       1 logs_generator.go:76] 36 POST /api/v1/namespaces/ns/pods/hqp 242\nI0124 19:19:16.796106       1 logs_generator.go:76] 37 PUT /api/v1/namespaces/kube-system/pods/dhp 303\nI0124 19:19:16.995855       1 logs_generator.go:76] 38 PUT /api/v1/namespaces/ns/pods/65g 549\nI0124 19:19:17.197485       1 logs_generator.go:76] 39 POST /api/v1/namespaces/default/pods/848 205\nI0124 19:19:17.396114       1 logs_generator.go:76] 40 PUT /api/v1/namespaces/default/pods/dd6m 497\nI0124 19:19:17.595506       1 logs_generator.go:76] 41 PUT /api/v1/namespaces/ns/pods/rg8j 228\nI0124 19:19:17.796008       1 logs_generator.go:76] 42 GET /api/v1/namespaces/default/pods/nqj 584\nI0124 19:19:17.995642       1 logs_generator.go:76] 43 GET /api/v1/namespaces/ns/pods/8ks 497\nI0124 19:19:18.195943       1 logs_generator.go:76] 44 GET /api/v1/namespaces/ns/pods/t29t 437\nI0124 19:19:18.400669       1 logs_generator.go:76] 45 POST /api/v1/namespaces/default/pods/plp 434\nI0124 19:19:18.596190       1 logs_generator.go:76] 46 POST /api/v1/namespaces/default/pods/lz8 365\nI0124 19:19:18.795587       1 logs_generator.go:76] 47 GET /api/v1/namespaces/kube-system/pods/srmg 338\nI0124 19:19:18.996306       1 logs_generator.go:76] 48 GET /api/v1/namespaces/kube-system/pods/4jkx 535\nI0124 19:19:19.200585       1 logs_generator.go:76] 49 POST /api/v1/namespaces/ns/pods/rcx 400\nI0124 19:19:19.396416       1 logs_generator.go:76] 50 PUT /api/v1/namespaces/default/pods/gjv 361\nI0124 19:19:19.596092       1 logs_generator.go:76] 51 PUT /api/v1/namespaces/kube-system/pods/thgl 384\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Jan 24 19:19:19.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 delete pod logs-generator'
Jan 24 19:19:22.330: INFO: stderr: ""
Jan 24 19:19:22.331: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 19:19:22.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1063" for this suite. 01/24/23 19:19:22.345
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":128,"skipped":2540,"failed":0}
------------------------------
• [SLOW TEST] [15.346 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:19:07.025
    Jan 24 19:19:07.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 19:19:07.034
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:19:07.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:19:07.094
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 01/24/23 19:19:07.103
    Jan 24 19:19:07.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Jan 24 19:19:07.455: INFO: stderr: ""
    Jan 24 19:19:07.455: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 01/24/23 19:19:07.455
    Jan 24 19:19:07.455: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Jan 24 19:19:07.455: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1063" to be "running and ready, or succeeded"
    Jan 24 19:19:07.470: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 14.625749ms
    Jan 24 19:19:07.470: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'vikash-v125latest-conf-71087' to be 'Running' but was 'Pending'
    Jan 24 19:19:09.481: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025666478s
    Jan 24 19:19:09.481: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'vikash-v125latest-conf-71087' to be 'Running' but was 'Pending'
    Jan 24 19:19:11.541: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.085958133s
    Jan 24 19:19:11.542: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Jan 24 19:19:11.542: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 01/24/23 19:19:11.542
    Jan 24 19:19:11.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator'
    Jan 24 19:19:12.081: INFO: stderr: ""
    Jan 24 19:19:12.081: INFO: stdout: "I0124 19:19:09.395363       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/5cl 232\nI0124 19:19:09.596104       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/drl 320\nI0124 19:19:09.795376       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/pxjt 322\nI0124 19:19:09.995955       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/z7d 512\nI0124 19:19:10.195405       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/qm6m 506\nI0124 19:19:10.395409       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/kh42 447\nI0124 19:19:10.595990       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/hsft 272\nI0124 19:19:10.795419       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/4s7 216\nI0124 19:19:10.995418       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/r6z 275\nI0124 19:19:11.196176       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/9bq 486\nI0124 19:19:11.396017       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/dpdm 210\nI0124 19:19:11.595673       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/lxfm 360\nI0124 19:19:11.796175       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/vjk 357\nI0124 19:19:11.995463       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/vq7z 413\n"
    STEP: limiting log lines 01/24/23 19:19:12.081
    Jan 24 19:19:12.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator --tail=1'
    Jan 24 19:19:13.563: INFO: stderr: ""
    Jan 24 19:19:13.563: INFO: stdout: "I0124 19:19:13.396371       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/8q8m 384\n"
    Jan 24 19:19:13.563: INFO: got output "I0124 19:19:13.396371       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/8q8m 384\n"
    STEP: limiting log bytes 01/24/23 19:19:13.563
    Jan 24 19:19:13.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator --limit-bytes=1'
    Jan 24 19:19:14.351: INFO: stderr: ""
    Jan 24 19:19:14.351: INFO: stdout: "I"
    Jan 24 19:19:14.351: INFO: got output "I"
    STEP: exposing timestamps 01/24/23 19:19:14.352
    Jan 24 19:19:14.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator --tail=1 --timestamps'
    Jan 24 19:19:16.349: INFO: stderr: ""
    Jan 24 19:19:16.350: INFO: stdout: "2023-01-24T11:19:16.197186649-08:00 I0124 19:19:16.196881       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/default/pods/6cd 314\n"
    Jan 24 19:19:16.350: INFO: got output "2023-01-24T11:19:16.197186649-08:00 I0124 19:19:16.196881       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/default/pods/6cd 314\n"
    STEP: restricting to a time range 01/24/23 19:19:16.35
    Jan 24 19:19:18.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator --since=1s'
    Jan 24 19:19:19.297: INFO: stderr: ""
    Jan 24 19:19:19.297: INFO: stdout: "I0124 19:19:18.400669       1 logs_generator.go:76] 45 POST /api/v1/namespaces/default/pods/plp 434\nI0124 19:19:18.596190       1 logs_generator.go:76] 46 POST /api/v1/namespaces/default/pods/lz8 365\nI0124 19:19:18.795587       1 logs_generator.go:76] 47 GET /api/v1/namespaces/kube-system/pods/srmg 338\nI0124 19:19:18.996306       1 logs_generator.go:76] 48 GET /api/v1/namespaces/kube-system/pods/4jkx 535\nI0124 19:19:19.200585       1 logs_generator.go:76] 49 POST /api/v1/namespaces/ns/pods/rcx 400\n"
    Jan 24 19:19:19.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 logs logs-generator logs-generator --since=24h'
    Jan 24 19:19:19.690: INFO: stderr: ""
    Jan 24 19:19:19.690: INFO: stdout: "I0124 19:19:09.395363       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/5cl 232\nI0124 19:19:09.596104       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/drl 320\nI0124 19:19:09.795376       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/pxjt 322\nI0124 19:19:09.995955       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/z7d 512\nI0124 19:19:10.195405       1 logs_generator.go:76] 4 GET /api/v1/namespaces/kube-system/pods/qm6m 506\nI0124 19:19:10.395409       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/kh42 447\nI0124 19:19:10.595990       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/hsft 272\nI0124 19:19:10.795419       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/4s7 216\nI0124 19:19:10.995418       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/r6z 275\nI0124 19:19:11.196176       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/9bq 486\nI0124 19:19:11.396017       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/dpdm 210\nI0124 19:19:11.595673       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/lxfm 360\nI0124 19:19:11.796175       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/vjk 357\nI0124 19:19:11.995463       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/vq7z 413\nI0124 19:19:12.196351       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/5m74 322\nI0124 19:19:12.399633       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/fn5z 512\nI0124 19:19:12.596374       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/d8c 581\nI0124 19:19:12.796393       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/nwjl 596\nI0124 19:19:12.996088       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/v5bx 509\nI0124 19:19:13.199339       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/b4jn 287\nI0124 19:19:13.396371       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/8q8m 384\nI0124 19:19:13.596337       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/7vz5 382\nI0124 19:19:13.795790       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/xbw 534\nI0124 19:19:13.996885       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/flw7 380\nI0124 19:19:14.195364       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/ns/pods/hcl 203\nI0124 19:19:14.396054       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/vhtr 554\nI0124 19:19:14.595491       1 logs_generator.go:76] 26 POST /api/v1/namespaces/kube-system/pods/rjj 356\nI0124 19:19:14.796095       1 logs_generator.go:76] 27 POST /api/v1/namespaces/ns/pods/jdps 575\nI0124 19:19:14.995423       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/kube-system/pods/nx2r 273\nI0124 19:19:15.195968       1 logs_generator.go:76] 29 GET /api/v1/namespaces/kube-system/pods/hmvs 467\nI0124 19:19:15.395412       1 logs_generator.go:76] 30 POST /api/v1/namespaces/default/pods/rgth 564\nI0124 19:19:15.596012       1 logs_generator.go:76] 31 PUT /api/v1/namespaces/ns/pods/svcw 360\nI0124 19:19:15.796092       1 logs_generator.go:76] 32 PUT /api/v1/namespaces/ns/pods/7wjx 404\nI0124 19:19:15.996629       1 logs_generator.go:76] 33 GET /api/v1/namespaces/ns/pods/sqpx 522\nI0124 19:19:16.196881       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/default/pods/6cd 314\nI0124 19:19:16.396355       1 logs_generator.go:76] 35 GET /api/v1/namespaces/kube-system/pods/57pf 213\nI0124 19:19:16.596019       1 logs_generator.go:76] 36 POST /api/v1/namespaces/ns/pods/hqp 242\nI0124 19:19:16.796106       1 logs_generator.go:76] 37 PUT /api/v1/namespaces/kube-system/pods/dhp 303\nI0124 19:19:16.995855       1 logs_generator.go:76] 38 PUT /api/v1/namespaces/ns/pods/65g 549\nI0124 19:19:17.197485       1 logs_generator.go:76] 39 POST /api/v1/namespaces/default/pods/848 205\nI0124 19:19:17.396114       1 logs_generator.go:76] 40 PUT /api/v1/namespaces/default/pods/dd6m 497\nI0124 19:19:17.595506       1 logs_generator.go:76] 41 PUT /api/v1/namespaces/ns/pods/rg8j 228\nI0124 19:19:17.796008       1 logs_generator.go:76] 42 GET /api/v1/namespaces/default/pods/nqj 584\nI0124 19:19:17.995642       1 logs_generator.go:76] 43 GET /api/v1/namespaces/ns/pods/8ks 497\nI0124 19:19:18.195943       1 logs_generator.go:76] 44 GET /api/v1/namespaces/ns/pods/t29t 437\nI0124 19:19:18.400669       1 logs_generator.go:76] 45 POST /api/v1/namespaces/default/pods/plp 434\nI0124 19:19:18.596190       1 logs_generator.go:76] 46 POST /api/v1/namespaces/default/pods/lz8 365\nI0124 19:19:18.795587       1 logs_generator.go:76] 47 GET /api/v1/namespaces/kube-system/pods/srmg 338\nI0124 19:19:18.996306       1 logs_generator.go:76] 48 GET /api/v1/namespaces/kube-system/pods/4jkx 535\nI0124 19:19:19.200585       1 logs_generator.go:76] 49 POST /api/v1/namespaces/ns/pods/rcx 400\nI0124 19:19:19.396416       1 logs_generator.go:76] 50 PUT /api/v1/namespaces/default/pods/gjv 361\nI0124 19:19:19.596092       1 logs_generator.go:76] 51 PUT /api/v1/namespaces/kube-system/pods/thgl 384\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Jan 24 19:19:19.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1063 delete pod logs-generator'
    Jan 24 19:19:22.330: INFO: stderr: ""
    Jan 24 19:19:22.331: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 19:19:22.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1063" for this suite. 01/24/23 19:19:22.345
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:19:22.373
Jan 24 19:19:22.373: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename cronjob 01/24/23 19:19:22.387
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:19:22.477
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:19:22.505
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 01/24/23 19:19:22.527
STEP: creating 01/24/23 19:19:22.528
STEP: getting 01/24/23 19:19:22.575
STEP: listing 01/24/23 19:19:22.59
STEP: watching 01/24/23 19:19:22.618
Jan 24 19:19:22.620: INFO: starting watch
STEP: cluster-wide listing 01/24/23 19:19:22.632
STEP: cluster-wide watching 01/24/23 19:19:22.645
Jan 24 19:19:22.647: INFO: starting watch
STEP: patching 01/24/23 19:19:22.656
STEP: updating 01/24/23 19:19:22.696
Jan 24 19:19:22.746: INFO: waiting for watch events with expected annotations
Jan 24 19:19:22.746: INFO: saw patched and updated annotations
STEP: patching /status 01/24/23 19:19:22.747
STEP: updating /status 01/24/23 19:19:22.802
STEP: get /status 01/24/23 19:19:22.857
STEP: deleting 01/24/23 19:19:22.877
STEP: deleting a collection 01/24/23 19:19:22.984
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jan 24 19:19:23.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5016" for this suite. 01/24/23 19:19:23.084
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":129,"skipped":2546,"failed":0}
------------------------------
• [0.761 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:19:22.373
    Jan 24 19:19:22.373: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename cronjob 01/24/23 19:19:22.387
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:19:22.477
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:19:22.505
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 01/24/23 19:19:22.527
    STEP: creating 01/24/23 19:19:22.528
    STEP: getting 01/24/23 19:19:22.575
    STEP: listing 01/24/23 19:19:22.59
    STEP: watching 01/24/23 19:19:22.618
    Jan 24 19:19:22.620: INFO: starting watch
    STEP: cluster-wide listing 01/24/23 19:19:22.632
    STEP: cluster-wide watching 01/24/23 19:19:22.645
    Jan 24 19:19:22.647: INFO: starting watch
    STEP: patching 01/24/23 19:19:22.656
    STEP: updating 01/24/23 19:19:22.696
    Jan 24 19:19:22.746: INFO: waiting for watch events with expected annotations
    Jan 24 19:19:22.746: INFO: saw patched and updated annotations
    STEP: patching /status 01/24/23 19:19:22.747
    STEP: updating /status 01/24/23 19:19:22.802
    STEP: get /status 01/24/23 19:19:22.857
    STEP: deleting 01/24/23 19:19:22.877
    STEP: deleting a collection 01/24/23 19:19:22.984
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jan 24 19:19:23.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5016" for this suite. 01/24/23 19:19:23.084
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:19:23.163
Jan 24 19:19:23.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename var-expansion 01/24/23 19:19:23.172
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:19:23.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:19:23.285
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 01/24/23 19:19:23.308
Jan 24 19:19:23.342: INFO: Waiting up to 2m0s for pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218" in namespace "var-expansion-3031" to be "running"
Jan 24 19:19:23.351: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 8.885836ms
Jan 24 19:19:25.411: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069374441s
Jan 24 19:19:27.361: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01955155s
Jan 24 19:19:29.374: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031812632s
Jan 24 19:19:31.445: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 8.1033449s
Jan 24 19:19:33.453: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 10.11092926s
Jan 24 19:19:35.367: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 12.025473235s
Jan 24 19:19:37.364: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 14.022333739s
Jan 24 19:19:39.377: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 16.035609252s
Jan 24 19:19:41.372: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 18.029913386s
Jan 24 19:19:43.379: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 20.037373235s
Jan 24 19:19:45.418: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 22.076514793s
Jan 24 19:19:47.365: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 24.023066223s
Jan 24 19:19:49.364: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 26.022711955s
Jan 24 19:19:51.398: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 28.056509457s
Jan 24 19:19:53.362: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 30.020319854s
Jan 24 19:19:55.457: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 32.114860271s
Jan 24 19:19:57.371: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 34.029331821s
Jan 24 19:19:59.368: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 36.025778167s
Jan 24 19:20:01.371: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 38.029620473s
Jan 24 19:20:03.370: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 40.027858873s
Jan 24 19:20:05.436: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 42.094420495s
Jan 24 19:20:07.370: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 44.028336525s
Jan 24 19:20:09.411: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 46.069309346s
Jan 24 19:20:11.393: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 48.051316414s
Jan 24 19:20:13.368: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 50.026115508s
Jan 24 19:20:15.410: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 52.068325196s
Jan 24 19:20:17.362: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 54.020558316s
Jan 24 19:20:19.363: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 56.021391782s
Jan 24 19:20:21.363: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 58.02094467s
Jan 24 19:20:23.368: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.026005921s
Jan 24 19:20:25.390: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.048261438s
Jan 24 19:20:27.374: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.032343401s
Jan 24 19:20:29.395: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.0529052s
Jan 24 19:20:31.364: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.022228954s
Jan 24 19:20:33.372: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.030607701s
Jan 24 19:20:35.373: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.030964556s
Jan 24 19:20:37.367: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.025230324s
Jan 24 19:20:39.363: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.021506112s
Jan 24 19:20:41.367: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.025389756s
Jan 24 19:20:43.584: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.242352476s
Jan 24 19:20:46.151: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.808947766s
Jan 24 19:20:47.362: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.020594472s
Jan 24 19:20:49.363: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.021512318s
Jan 24 19:20:51.361: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.019702386s
Jan 24 19:20:53.365: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.023206815s
Jan 24 19:20:55.373: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.030914689s
Jan 24 19:20:57.390: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.048425284s
Jan 24 19:20:59.372: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.030273194s
Jan 24 19:21:01.385: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.043173085s
Jan 24 19:21:03.378: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.036270838s
Jan 24 19:21:05.394: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.051996223s
Jan 24 19:21:07.359: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.016937265s
Jan 24 19:21:09.359: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.017007282s
Jan 24 19:21:11.358: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.016689515s
Jan 24 19:21:13.362: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.020172753s
Jan 24 19:21:15.366: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.023951589s
Jan 24 19:21:17.434: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.09180483s
Jan 24 19:21:19.423: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.081370508s
Jan 24 19:21:21.369: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.027133347s
Jan 24 19:21:23.362: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.020675181s
Jan 24 19:21:23.368: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.026741302s
STEP: updating the pod 01/24/23 19:21:23.369
Jan 24 19:21:23.907: INFO: Successfully updated pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218"
STEP: waiting for pod running 01/24/23 19:21:23.909
Jan 24 19:21:23.913: INFO: Waiting up to 2m0s for pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218" in namespace "var-expansion-3031" to be "running"
Jan 24 19:21:23.944: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 30.905567ms
Jan 24 19:21:25.957: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Running", Reason="", readiness=true. Elapsed: 2.043708256s
Jan 24 19:21:25.957: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218" satisfied condition "running"
STEP: deleting the pod gracefully 01/24/23 19:21:25.957
Jan 24 19:21:25.958: INFO: Deleting pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218" in namespace "var-expansion-3031"
Jan 24 19:21:25.967: INFO: Wait up to 5m0s for pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 24 19:21:57.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3031" for this suite. 01/24/23 19:21:58.012
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":130,"skipped":2577,"failed":0}
------------------------------
• [SLOW TEST] [154.888 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:19:23.163
    Jan 24 19:19:23.166: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename var-expansion 01/24/23 19:19:23.172
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:19:23.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:19:23.285
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 01/24/23 19:19:23.308
    Jan 24 19:19:23.342: INFO: Waiting up to 2m0s for pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218" in namespace "var-expansion-3031" to be "running"
    Jan 24 19:19:23.351: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 8.885836ms
    Jan 24 19:19:25.411: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069374441s
    Jan 24 19:19:27.361: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01955155s
    Jan 24 19:19:29.374: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031812632s
    Jan 24 19:19:31.445: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 8.1033449s
    Jan 24 19:19:33.453: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 10.11092926s
    Jan 24 19:19:35.367: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 12.025473235s
    Jan 24 19:19:37.364: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 14.022333739s
    Jan 24 19:19:39.377: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 16.035609252s
    Jan 24 19:19:41.372: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 18.029913386s
    Jan 24 19:19:43.379: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 20.037373235s
    Jan 24 19:19:45.418: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 22.076514793s
    Jan 24 19:19:47.365: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 24.023066223s
    Jan 24 19:19:49.364: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 26.022711955s
    Jan 24 19:19:51.398: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 28.056509457s
    Jan 24 19:19:53.362: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 30.020319854s
    Jan 24 19:19:55.457: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 32.114860271s
    Jan 24 19:19:57.371: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 34.029331821s
    Jan 24 19:19:59.368: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 36.025778167s
    Jan 24 19:20:01.371: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 38.029620473s
    Jan 24 19:20:03.370: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 40.027858873s
    Jan 24 19:20:05.436: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 42.094420495s
    Jan 24 19:20:07.370: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 44.028336525s
    Jan 24 19:20:09.411: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 46.069309346s
    Jan 24 19:20:11.393: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 48.051316414s
    Jan 24 19:20:13.368: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 50.026115508s
    Jan 24 19:20:15.410: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 52.068325196s
    Jan 24 19:20:17.362: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 54.020558316s
    Jan 24 19:20:19.363: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 56.021391782s
    Jan 24 19:20:21.363: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 58.02094467s
    Jan 24 19:20:23.368: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.026005921s
    Jan 24 19:20:25.390: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.048261438s
    Jan 24 19:20:27.374: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.032343401s
    Jan 24 19:20:29.395: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.0529052s
    Jan 24 19:20:31.364: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.022228954s
    Jan 24 19:20:33.372: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.030607701s
    Jan 24 19:20:35.373: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.030964556s
    Jan 24 19:20:37.367: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.025230324s
    Jan 24 19:20:39.363: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.021506112s
    Jan 24 19:20:41.367: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.025389756s
    Jan 24 19:20:43.584: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.242352476s
    Jan 24 19:20:46.151: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.808947766s
    Jan 24 19:20:47.362: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.020594472s
    Jan 24 19:20:49.363: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.021512318s
    Jan 24 19:20:51.361: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.019702386s
    Jan 24 19:20:53.365: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.023206815s
    Jan 24 19:20:55.373: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.030914689s
    Jan 24 19:20:57.390: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.048425284s
    Jan 24 19:20:59.372: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.030273194s
    Jan 24 19:21:01.385: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.043173085s
    Jan 24 19:21:03.378: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.036270838s
    Jan 24 19:21:05.394: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.051996223s
    Jan 24 19:21:07.359: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.016937265s
    Jan 24 19:21:09.359: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.017007282s
    Jan 24 19:21:11.358: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.016689515s
    Jan 24 19:21:13.362: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.020172753s
    Jan 24 19:21:15.366: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.023951589s
    Jan 24 19:21:17.434: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.09180483s
    Jan 24 19:21:19.423: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.081370508s
    Jan 24 19:21:21.369: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.027133347s
    Jan 24 19:21:23.362: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.020675181s
    Jan 24 19:21:23.368: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.026741302s
    STEP: updating the pod 01/24/23 19:21:23.369
    Jan 24 19:21:23.907: INFO: Successfully updated pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218"
    STEP: waiting for pod running 01/24/23 19:21:23.909
    Jan 24 19:21:23.913: INFO: Waiting up to 2m0s for pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218" in namespace "var-expansion-3031" to be "running"
    Jan 24 19:21:23.944: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Pending", Reason="", readiness=false. Elapsed: 30.905567ms
    Jan 24 19:21:25.957: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218": Phase="Running", Reason="", readiness=true. Elapsed: 2.043708256s
    Jan 24 19:21:25.957: INFO: Pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218" satisfied condition "running"
    STEP: deleting the pod gracefully 01/24/23 19:21:25.957
    Jan 24 19:21:25.958: INFO: Deleting pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218" in namespace "var-expansion-3031"
    Jan 24 19:21:25.967: INFO: Wait up to 5m0s for pod "var-expansion-e5b7b884-7d27-4f74-8139-d2c1c32be218" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 24 19:21:57.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3031" for this suite. 01/24/23 19:21:58.012
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:21:58.059
Jan 24 19:21:58.060: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replicaset 01/24/23 19:21:58.065
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:21:58.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:21:58.13
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 01/24/23 19:21:58.144
Jan 24 19:21:58.189: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 24 19:22:03.364: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/24/23 19:22:03.364
STEP: getting scale subresource 01/24/23 19:22:03.364
STEP: updating a scale subresource 01/24/23 19:22:03.384
STEP: verifying the replicaset Spec.Replicas was modified 01/24/23 19:22:03.423
STEP: Patch a scale subresource 01/24/23 19:22:03.459
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 24 19:22:03.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8832" for this suite. 01/24/23 19:22:03.586
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":131,"skipped":2588,"failed":0}
------------------------------
• [SLOW TEST] [5.587 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:21:58.059
    Jan 24 19:21:58.060: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replicaset 01/24/23 19:21:58.065
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:21:58.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:21:58.13
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 01/24/23 19:21:58.144
    Jan 24 19:21:58.189: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jan 24 19:22:03.364: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/24/23 19:22:03.364
    STEP: getting scale subresource 01/24/23 19:22:03.364
    STEP: updating a scale subresource 01/24/23 19:22:03.384
    STEP: verifying the replicaset Spec.Replicas was modified 01/24/23 19:22:03.423
    STEP: Patch a scale subresource 01/24/23 19:22:03.459
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 24 19:22:03.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-8832" for this suite. 01/24/23 19:22:03.586
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:22:03.664
Jan 24 19:22:03.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-probe 01/24/23 19:22:03.694
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:22:03.788
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:22:03.845
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Jan 24 19:22:03.931: INFO: Waiting up to 5m0s for pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab" in namespace "container-probe-5664" to be "running and ready"
Jan 24 19:22:03.946: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Pending", Reason="", readiness=false. Elapsed: 15.377198ms
Jan 24 19:22:03.947: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:22:05.974: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042954739s
Jan 24 19:22:05.974: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:22:07.959: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 4.027566074s
Jan 24 19:22:07.959: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
Jan 24 19:22:09.960: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 6.029499859s
Jan 24 19:22:09.961: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
Jan 24 19:22:11.963: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 8.03247231s
Jan 24 19:22:11.964: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
Jan 24 19:22:13.969: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 10.037540774s
Jan 24 19:22:13.969: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
Jan 24 19:22:15.973: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 12.04188323s
Jan 24 19:22:15.973: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
Jan 24 19:22:17.999: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 14.068396254s
Jan 24 19:22:18.000: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
Jan 24 19:22:19.975: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 16.044029671s
Jan 24 19:22:19.975: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
Jan 24 19:22:21.966: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 18.034967101s
Jan 24 19:22:21.966: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
Jan 24 19:22:23.974: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 20.043256106s
Jan 24 19:22:23.974: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
Jan 24 19:22:25.975: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=true. Elapsed: 22.044036122s
Jan 24 19:22:25.975: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = true)
Jan 24 19:22:25.975: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab" satisfied condition "running and ready"
Jan 24 19:22:25.999: INFO: Container started at 2023-01-24 19:22:06 +0000 UTC, pod became ready at 2023-01-24 19:22:24 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 24 19:22:26.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5664" for this suite. 01/24/23 19:22:26.066
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":132,"skipped":2595,"failed":0}
------------------------------
• [SLOW TEST] [22.479 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:22:03.664
    Jan 24 19:22:03.664: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-probe 01/24/23 19:22:03.694
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:22:03.788
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:22:03.845
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Jan 24 19:22:03.931: INFO: Waiting up to 5m0s for pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab" in namespace "container-probe-5664" to be "running and ready"
    Jan 24 19:22:03.946: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Pending", Reason="", readiness=false. Elapsed: 15.377198ms
    Jan 24 19:22:03.947: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:22:05.974: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042954739s
    Jan 24 19:22:05.974: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:22:07.959: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 4.027566074s
    Jan 24 19:22:07.959: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
    Jan 24 19:22:09.960: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 6.029499859s
    Jan 24 19:22:09.961: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
    Jan 24 19:22:11.963: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 8.03247231s
    Jan 24 19:22:11.964: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
    Jan 24 19:22:13.969: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 10.037540774s
    Jan 24 19:22:13.969: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
    Jan 24 19:22:15.973: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 12.04188323s
    Jan 24 19:22:15.973: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
    Jan 24 19:22:17.999: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 14.068396254s
    Jan 24 19:22:18.000: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
    Jan 24 19:22:19.975: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 16.044029671s
    Jan 24 19:22:19.975: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
    Jan 24 19:22:21.966: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 18.034967101s
    Jan 24 19:22:21.966: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
    Jan 24 19:22:23.974: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=false. Elapsed: 20.043256106s
    Jan 24 19:22:23.974: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = false)
    Jan 24 19:22:25.975: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab": Phase="Running", Reason="", readiness=true. Elapsed: 22.044036122s
    Jan 24 19:22:25.975: INFO: The phase of Pod test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab is Running (Ready = true)
    Jan 24 19:22:25.975: INFO: Pod "test-webserver-160b0960-e33e-42df-b930-4d4444e9f1ab" satisfied condition "running and ready"
    Jan 24 19:22:25.999: INFO: Container started at 2023-01-24 19:22:06 +0000 UTC, pod became ready at 2023-01-24 19:22:24 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 24 19:22:26.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5664" for this suite. 01/24/23 19:22:26.066
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:22:26.187
Jan 24 19:22:26.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename events 01/24/23 19:22:26.2
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:22:26.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:22:26.311
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 01/24/23 19:22:26.373
STEP: get a list of Events with a label in the current namespace 01/24/23 19:22:26.558
STEP: delete a list of events 01/24/23 19:22:26.596
Jan 24 19:22:26.597: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 01/24/23 19:22:26.687
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Jan 24 19:22:26.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9211" for this suite. 01/24/23 19:22:26.726
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":133,"skipped":2633,"failed":0}
------------------------------
• [0.566 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:22:26.187
    Jan 24 19:22:26.187: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename events 01/24/23 19:22:26.2
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:22:26.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:22:26.311
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 01/24/23 19:22:26.373
    STEP: get a list of Events with a label in the current namespace 01/24/23 19:22:26.558
    STEP: delete a list of events 01/24/23 19:22:26.596
    Jan 24 19:22:26.597: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 01/24/23 19:22:26.687
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Jan 24 19:22:26.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-9211" for this suite. 01/24/23 19:22:26.726
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:22:26.754
Jan 24 19:22:26.754: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename svc-latency 01/24/23 19:22:26.758
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:22:26.829
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:22:26.872
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Jan 24 19:22:26.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1596 01/24/23 19:22:26.917
I0124 19:22:26.950193      22 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1596, replica count: 1
I0124 19:22:28.002589      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:22:29.003941      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:22:30.005241      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:22:31.052464      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:22:32.053990      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 19:22:32.521: INFO: Created: latency-svc-vzfkg
Jan 24 19:22:32.822: INFO: Got endpoints: latency-svc-vzfkg [501.662601ms]
Jan 24 19:22:33.237: INFO: Created: latency-svc-th7tx
Jan 24 19:22:33.270: INFO: Created: latency-svc-nxzjz
Jan 24 19:22:33.273: INFO: Got endpoints: latency-svc-nxzjz [441.052201ms]
Jan 24 19:22:33.395: INFO: Got endpoints: latency-svc-th7tx [463.492992ms]
Jan 24 19:22:33.693: INFO: Created: latency-svc-qmhxz
Jan 24 19:22:33.724: INFO: Created: latency-svc-9knpx
Jan 24 19:22:33.725: INFO: Got endpoints: latency-svc-qmhxz [329.658019ms]
Jan 24 19:22:34.176: INFO: Created: latency-svc-zhn7q
Jan 24 19:22:34.219: INFO: Created: latency-svc-47rwq
Jan 24 19:22:34.223: INFO: Created: latency-svc-9tcqb
Jan 24 19:22:34.224: INFO: Created: latency-svc-8md4r
Jan 24 19:22:34.224: INFO: Created: latency-svc-fv97p
Jan 24 19:22:34.230: INFO: Created: latency-svc-vt6xh
Jan 24 19:22:34.234: INFO: Created: latency-svc-bmpgh
Jan 24 19:22:34.235: INFO: Created: latency-svc-n4d8r
Jan 24 19:22:34.237: INFO: Created: latency-svc-8mq92
Jan 24 19:22:34.263: INFO: Created: latency-svc-qt686
Jan 24 19:22:34.264: INFO: Got endpoints: latency-svc-vt6xh [538.279246ms]
Jan 24 19:22:34.265: INFO: Created: latency-svc-9q5jp
Jan 24 19:22:34.265: INFO: Got endpoints: latency-svc-9q5jp [1.430235474s]
Jan 24 19:22:34.267: INFO: Got endpoints: latency-svc-8mq92 [1.440350639s]
Jan 24 19:22:34.267: INFO: Got endpoints: latency-svc-zhn7q [1.326405822s]
Jan 24 19:22:34.268: INFO: Got endpoints: latency-svc-9knpx [1.431279607s]
Jan 24 19:22:34.268: INFO: Got endpoints: latency-svc-9tcqb [1.326837415s]
Jan 24 19:22:34.274: INFO: Got endpoints: latency-svc-bmpgh [1.332719194s]
Jan 24 19:22:34.275: INFO: Created: latency-svc-fcn82
Jan 24 19:22:34.275: INFO: Got endpoints: latency-svc-fcn82 [1.341876098s]
Jan 24 19:22:34.276: INFO: Got endpoints: latency-svc-47rwq [1.002246932s]
Jan 24 19:22:34.276: INFO: Got endpoints: latency-svc-8md4r [1.335551371s]
Jan 24 19:22:34.276: INFO: Got endpoints: latency-svc-qt686 [1.335384846s]
Jan 24 19:22:34.277: INFO: Got endpoints: latency-svc-fv97p [1.442904815s]
Jan 24 19:22:34.281: INFO: Got endpoints: latency-svc-n4d8r [1.341048263s]
Jan 24 19:22:34.283: INFO: Created: latency-svc-2bh6t
Jan 24 19:22:34.283: INFO: Got endpoints: latency-svc-2bh6t [1.340927465s]
Jan 24 19:22:34.284: INFO: Created: latency-svc-dpdgs
Jan 24 19:22:34.284: INFO: Got endpoints: latency-svc-dpdgs [1.448395596s]
Jan 24 19:22:34.341: INFO: Created: latency-svc-fb2lj
Jan 24 19:22:34.392: INFO: Got endpoints: latency-svc-fb2lj [128.327787ms]
Jan 24 19:22:34.775: INFO: Created: latency-svc-v6vmd
Jan 24 19:22:34.802: INFO: Created: latency-svc-fg2v7
Jan 24 19:22:34.819: INFO: Created: latency-svc-8vlgx
Jan 24 19:22:34.949: INFO: Created: latency-svc-j8d4j
Jan 24 19:22:34.965: INFO: Created: latency-svc-vxv9c
Jan 24 19:22:34.970: INFO: Created: latency-svc-chwf8
Jan 24 19:22:34.970: INFO: Created: latency-svc-nfpbs
Jan 24 19:22:34.972: INFO: Got endpoints: latency-svc-v6vmd [697.47303ms]
Jan 24 19:22:35.017: INFO: Created: latency-svc-n6cpk
Jan 24 19:22:35.017: INFO: Created: latency-svc-q9p92
Jan 24 19:22:35.024: INFO: Created: latency-svc-t2gtk
Jan 24 19:22:35.026: INFO: Created: latency-svc-pbxqh
Jan 24 19:22:35.027: INFO: Created: latency-svc-x58cr
Jan 24 19:22:35.033: INFO: Created: latency-svc-sm755
Jan 24 19:22:35.034: INFO: Created: latency-svc-zv522
Jan 24 19:22:35.035: INFO: Got endpoints: latency-svc-zv522 [759.441059ms]
Jan 24 19:22:35.035: INFO: Got endpoints: latency-svc-x58cr [768.281611ms]
Jan 24 19:22:35.047: INFO: Created: latency-svc-kv6sn
Jan 24 19:22:35.049: INFO: Got endpoints: latency-svc-sm755 [783.847244ms]
Jan 24 19:22:35.051: INFO: Got endpoints: latency-svc-t2gtk [774.210868ms]
Jan 24 19:22:35.058: INFO: Got endpoints: latency-svc-n6cpk [773.64239ms]
Jan 24 19:22:35.058: INFO: Got endpoints: latency-svc-chwf8 [777.470557ms]
Jan 24 19:22:35.048: INFO: Got endpoints: latency-svc-q9p92 [767.844445ms]
Jan 24 19:22:35.160: INFO: Got endpoints: latency-svc-nfpbs [767.203567ms]
Jan 24 19:22:35.170: INFO: Created: latency-svc-pfm5t
Jan 24 19:22:35.202: INFO: Created: latency-svc-lf6js
Jan 24 19:22:35.248: INFO: Got endpoints: latency-svc-vxv9c [965.263427ms]
Jan 24 19:22:35.302: INFO: Got endpoints: latency-svc-8vlgx [1.026468782s]
Jan 24 19:22:35.308: INFO: Got endpoints: latency-svc-j8d4j [1.03967154s]
Jan 24 19:22:35.310: INFO: Got endpoints: latency-svc-fg2v7 [1.042052482s]
Jan 24 19:22:35.311: INFO: Got endpoints: latency-svc-pbxqh [1.035435303s]
Jan 24 19:22:35.322: INFO: Got endpoints: latency-svc-kv6sn [1.055868694s]
Jan 24 19:22:35.353: INFO: Created: latency-svc-gjjcx
Jan 24 19:22:35.363: INFO: Created: latency-svc-rl9mm
Jan 24 19:22:35.393: INFO: Got endpoints: latency-svc-pfm5t [410.210311ms]
Jan 24 19:22:35.424: INFO: Got endpoints: latency-svc-rl9mm [365.339172ms]
Jan 24 19:22:35.454: INFO: Got endpoints: latency-svc-lf6js [390.220208ms]
Jan 24 19:22:35.530: INFO: Created: latency-svc-88x4k
Jan 24 19:22:35.590: INFO: Got endpoints: latency-svc-gjjcx [555.61959ms]
Jan 24 19:22:35.599: INFO: Created: latency-svc-b9b4f
Jan 24 19:22:35.743: INFO: Got endpoints: latency-svc-88x4k [694.321877ms]
Jan 24 19:22:35.758: INFO: Got endpoints: latency-svc-b9b4f [722.966663ms]
Jan 24 19:22:35.785: INFO: Created: latency-svc-l64c4
Jan 24 19:22:35.859: INFO: Created: latency-svc-ztp96
Jan 24 19:22:35.934: INFO: Created: latency-svc-smxp7
Jan 24 19:22:35.953: INFO: Created: latency-svc-zwb6m
Jan 24 19:22:36.034: INFO: Created: latency-svc-svkhl
Jan 24 19:22:36.064: INFO: Created: latency-svc-lcl54
Jan 24 19:22:36.225: INFO: Got endpoints: latency-svc-l64c4 [1.174483334s]
Jan 24 19:22:36.481: INFO: Got endpoints: latency-svc-ztp96 [1.319723892s]
Jan 24 19:22:36.483: INFO: Created: latency-svc-pxhwj
Jan 24 19:22:36.508: INFO: Got endpoints: latency-svc-zwb6m [1.206242091s]
Jan 24 19:22:36.509: INFO: Got endpoints: latency-svc-svkhl [1.186734254s]
Jan 24 19:22:36.509: INFO: Got endpoints: latency-svc-lcl54 [1.201558012s]
Jan 24 19:22:36.509: INFO: Got endpoints: latency-svc-smxp7 [1.261249138s]
Jan 24 19:22:36.575: INFO: Created: latency-svc-prw9z
Jan 24 19:22:36.576: INFO: Got endpoints: latency-svc-prw9z [1.26617059s]
Jan 24 19:22:36.577: INFO: Got endpoints: latency-svc-pxhwj [1.265735769s]
Jan 24 19:22:36.668: INFO: Created: latency-svc-v8rxt
Jan 24 19:22:36.772: INFO: Created: latency-svc-54567
Jan 24 19:22:36.772: INFO: Got endpoints: latency-svc-v8rxt [1.348359856s]
Jan 24 19:22:36.802: INFO: Created: latency-svc-4fwg2
Jan 24 19:22:36.848: INFO: Created: latency-svc-dnh5s
Jan 24 19:22:36.848: INFO: Got endpoints: latency-svc-dnh5s [1.452614264s]
Jan 24 19:22:36.996: INFO: Created: latency-svc-cs6bt
Jan 24 19:22:37.036: INFO: Created: latency-svc-5k492
Jan 24 19:22:37.129: INFO: Created: latency-svc-v6tkr
Jan 24 19:22:37.131: INFO: Created: latency-svc-mll47
Jan 24 19:22:37.132: INFO: Got endpoints: latency-svc-54567 [1.677555844s]
Jan 24 19:22:37.132: INFO: Created: latency-svc-98vfv
Jan 24 19:22:37.135: INFO: Got endpoints: latency-svc-5k492 [1.543522387s]
Jan 24 19:22:37.135: INFO: Got endpoints: latency-svc-4fwg2 [2.076909277s]
Jan 24 19:22:37.138: INFO: Got endpoints: latency-svc-v6tkr [656.171053ms]
Jan 24 19:22:37.138: INFO: Got endpoints: latency-svc-cs6bt [1.379727352s]
Jan 24 19:22:37.139: INFO: Got endpoints: latency-svc-98vfv [1.386514119s]
Jan 24 19:22:37.159: INFO: Created: latency-svc-tqw55
Jan 24 19:22:37.173: INFO: Got endpoints: latency-svc-mll47 [947.601127ms]
Jan 24 19:22:37.190: INFO: Got endpoints: latency-svc-tqw55 [680.920126ms]
Jan 24 19:22:37.210: INFO: Created: latency-svc-c8sml
Jan 24 19:22:37.224: INFO: Created: latency-svc-nvthw
Jan 24 19:22:37.246: INFO: Got endpoints: latency-svc-c8sml [731.663973ms]
Jan 24 19:22:37.256: INFO: Got endpoints: latency-svc-nvthw [680.113878ms]
Jan 24 19:22:37.452: INFO: Created: latency-svc-zw76p
Jan 24 19:22:37.486: INFO: Created: latency-svc-rmhds
Jan 24 19:22:37.491: INFO: Created: latency-svc-z558q
Jan 24 19:22:37.493: INFO: Created: latency-svc-5s4dj
Jan 24 19:22:37.515: INFO: Created: latency-svc-tgmh6
Jan 24 19:22:37.515: INFO: Created: latency-svc-rr9vw
Jan 24 19:22:37.533: INFO: Created: latency-svc-5bpvt
Jan 24 19:22:37.554: INFO: Created: latency-svc-dfqtm
Jan 24 19:22:37.556: INFO: Created: latency-svc-ztx5l
Jan 24 19:22:37.556: INFO: Created: latency-svc-rbh6b
Jan 24 19:22:37.557: INFO: Created: latency-svc-s6w97
Jan 24 19:22:37.557: INFO: Got endpoints: latency-svc-s6w97 [310.733297ms]
Jan 24 19:22:37.558: INFO: Created: latency-svc-8pzbm
Jan 24 19:22:37.559: INFO: Created: latency-svc-24dmx
Jan 24 19:22:37.559: INFO: Got endpoints: latency-svc-24dmx [302.049056ms]
Jan 24 19:22:37.559: INFO: Created: latency-svc-mhz8v
Jan 24 19:22:37.561: INFO: Created: latency-svc-45p2g
Jan 24 19:22:37.566: INFO: Got endpoints: latency-svc-rbh6b [392.649161ms]
Jan 24 19:22:37.655: INFO: Got endpoints: latency-svc-5bpvt [1.078220262s]
Jan 24 19:22:37.656: INFO: Got endpoints: latency-svc-8pzbm [515.037242ms]
Jan 24 19:22:37.657: INFO: Got endpoints: latency-svc-zw76p [519.117103ms]
Jan 24 19:22:37.675: INFO: Got endpoints: latency-svc-ztx5l [539.789649ms]
Jan 24 19:22:37.675: INFO: Got endpoints: latency-svc-tgmh6 [902.608059ms]
Jan 24 19:22:37.728: INFO: Created: latency-svc-xpstq
Jan 24 19:22:37.750: INFO: Created: latency-svc-8r65x
Jan 24 19:22:37.797: INFO: Got endpoints: latency-svc-z558q [658.812057ms]
Jan 24 19:22:37.812: INFO: Got endpoints: latency-svc-dfqtm [1.298645968s]
Jan 24 19:22:37.812: INFO: Got endpoints: latency-svc-rmhds [676.842191ms]
Jan 24 19:22:37.814: INFO: Created: latency-svc-2p6hn
Jan 24 19:22:37.825: INFO: Got endpoints: latency-svc-mhz8v [693.00185ms]
Jan 24 19:22:37.828: INFO: Got endpoints: latency-svc-rr9vw [1.317191542s]
Jan 24 19:22:37.833: INFO: Got endpoints: latency-svc-5s4dj [985.214957ms]
Jan 24 19:22:37.844: INFO: Got endpoints: latency-svc-8r65x [284.949901ms]
Jan 24 19:22:37.857: INFO: Got endpoints: latency-svc-45p2g [666.06385ms]
Jan 24 19:22:37.870: INFO: Got endpoints: latency-svc-xpstq [303.796579ms]
Jan 24 19:22:37.988: INFO: Created: latency-svc-q7bkf
Jan 24 19:22:38.029: INFO: Created: latency-svc-2lgj8
Jan 24 19:22:38.035: INFO: Created: latency-svc-7tbhx
Jan 24 19:22:38.036: INFO: Got endpoints: latency-svc-7tbhx [479.095337ms]
Jan 24 19:22:38.037: INFO: Got endpoints: latency-svc-q7bkf [380.487705ms]
Jan 24 19:22:38.038: INFO: Created: latency-svc-4mbhz
Jan 24 19:22:38.038: INFO: Got endpoints: latency-svc-2lgj8 [382.72141ms]
Jan 24 19:22:38.039: INFO: Got endpoints: latency-svc-2p6hn [381.718332ms]
Jan 24 19:22:38.040: INFO: Created: latency-svc-mvdvl
Jan 24 19:22:38.121: INFO: Created: latency-svc-vj56v
Jan 24 19:22:38.133: INFO: Created: latency-svc-6jvm8
Jan 24 19:22:38.134: INFO: Got endpoints: latency-svc-4mbhz [459.47899ms]
Jan 24 19:22:38.171: INFO: Created: latency-svc-dssvc
Jan 24 19:22:38.186: INFO: Created: latency-svc-9ck4p
Jan 24 19:22:38.204: INFO: Created: latency-svc-7pvzr
Jan 24 19:22:38.205: INFO: Got endpoints: latency-svc-mvdvl [530.54146ms]
Jan 24 19:22:38.214: INFO: Got endpoints: latency-svc-vj56v [416.532ms]
Jan 24 19:22:38.234: INFO: Got endpoints: latency-svc-6jvm8 [422.015386ms]
Jan 24 19:22:38.240: INFO: Got endpoints: latency-svc-dssvc [428.667134ms]
Jan 24 19:22:38.279: INFO: Created: latency-svc-zx8kn
Jan 24 19:22:38.279: INFO: Got endpoints: latency-svc-7pvzr [409.5825ms]
Jan 24 19:22:38.280: INFO: Got endpoints: latency-svc-9ck4p [455.187006ms]
Jan 24 19:22:38.334: INFO: Created: latency-svc-swn96
Jan 24 19:22:38.336: INFO: Got endpoints: latency-svc-zx8kn [499.411334ms]
Jan 24 19:22:38.363: INFO: Got endpoints: latency-svc-swn96 [518.866647ms]
Jan 24 19:22:38.365: INFO: Created: latency-svc-9rv9z
Jan 24 19:22:38.381: INFO: Got endpoints: latency-svc-9rv9z [524.389183ms]
Jan 24 19:22:38.384: INFO: Created: latency-svc-q4b88
Jan 24 19:22:38.433: INFO: Created: latency-svc-shspz
Jan 24 19:22:38.436: INFO: Got endpoints: latency-svc-q4b88 [608.605907ms]
Jan 24 19:22:38.462: INFO: Got endpoints: latency-svc-shspz [425.962731ms]
Jan 24 19:22:38.476: INFO: Created: latency-svc-49mxt
Jan 24 19:22:38.598: INFO: Got endpoints: latency-svc-49mxt [560.750217ms]
Jan 24 19:22:38.681: INFO: Created: latency-svc-7tgl5
Jan 24 19:22:38.786: INFO: Got endpoints: latency-svc-7tgl5 [747.765726ms]
Jan 24 19:22:38.894: INFO: Created: latency-svc-rhc66
Jan 24 19:22:38.955: INFO: Got endpoints: latency-svc-rhc66 [813.361115ms]
Jan 24 19:22:38.971: INFO: Created: latency-svc-qnxtc
Jan 24 19:22:39.019: INFO: Created: latency-svc-xzntz
Jan 24 19:22:39.047: INFO: Created: latency-svc-dhs9b
Jan 24 19:22:39.053: INFO: Got endpoints: latency-svc-xzntz [838.842137ms]
Jan 24 19:22:39.081: INFO: Created: latency-svc-xdr4m
Jan 24 19:22:39.147: INFO: Created: latency-svc-wrgcz
Jan 24 19:22:39.165: INFO: Created: latency-svc-t6j6d
Jan 24 19:22:39.231: INFO: Got endpoints: latency-svc-xdr4m [951.349164ms]
Jan 24 19:22:39.235: INFO: Got endpoints: latency-svc-dhs9b [1.000548802s]
Jan 24 19:22:39.251: INFO: Created: latency-svc-q9x67
Jan 24 19:22:39.269: INFO: Got endpoints: latency-svc-qnxtc [1.064049232s]
Jan 24 19:22:39.304: INFO: Got endpoints: latency-svc-t6j6d [1.063352502s]
Jan 24 19:22:39.391: INFO: Got endpoints: latency-svc-wrgcz [1.110336529s]
Jan 24 19:22:39.413: INFO: Created: latency-svc-xcjdv
Jan 24 19:22:39.414: INFO: Created: latency-svc-p2kgh
Jan 24 19:22:39.427: INFO: Got endpoints: latency-svc-q9x67 [1.090622921s]
Jan 24 19:22:39.428: INFO: Got endpoints: latency-svc-p2kgh [1.064947098s]
Jan 24 19:22:39.460: INFO: Got endpoints: latency-svc-xcjdv [1.078152149s]
Jan 24 19:22:39.461: INFO: Created: latency-svc-btlqh
Jan 24 19:22:39.484: INFO: Got endpoints: latency-svc-btlqh [1.445541431s]
Jan 24 19:22:39.666: INFO: Created: latency-svc-xl97c
Jan 24 19:22:39.687: INFO: Created: latency-svc-hcpls
Jan 24 19:22:39.692: INFO: Created: latency-svc-ms7kh
Jan 24 19:22:39.692: INFO: Created: latency-svc-qdlnc
Jan 24 19:22:39.761: INFO: Created: latency-svc-rckp8
Jan 24 19:22:39.761: INFO: Created: latency-svc-tkv5w
Jan 24 19:22:39.781: INFO: Created: latency-svc-klg65
Jan 24 19:22:39.791: INFO: Created: latency-svc-dgcfk
Jan 24 19:22:39.800: INFO: Created: latency-svc-26mmn
Jan 24 19:22:39.828: INFO: Created: latency-svc-dwkz6
Jan 24 19:22:39.824: INFO: Created: latency-svc-7pk9h
Jan 24 19:22:39.837: INFO: Created: latency-svc-xz67v
Jan 24 19:22:39.854: INFO: Created: latency-svc-4sqmq
Jan 24 19:22:39.866: INFO: Got endpoints: latency-svc-xl97c [596.497385ms]
Jan 24 19:22:39.868: INFO: Created: latency-svc-zwdjw
Jan 24 19:22:39.886: INFO: Created: latency-svc-99l89
Jan 24 19:22:40.037: INFO: Got endpoints: latency-svc-hcpls [984.328257ms]
Jan 24 19:22:40.043: INFO: Got endpoints: latency-svc-qdlnc [652.003857ms]
Jan 24 19:22:40.047: INFO: Got endpoints: latency-svc-ms7kh [1.610378032s]
Jan 24 19:22:40.062: INFO: Got endpoints: latency-svc-xz67v [633.327752ms]
Jan 24 19:22:40.121: INFO: Got endpoints: latency-svc-tkv5w [817.357299ms]
Jan 24 19:22:40.144: INFO: Got endpoints: latency-svc-99l89 [1.545687458s]
Jan 24 19:22:40.178: INFO: Got endpoints: latency-svc-4sqmq [750.649346ms]
Jan 24 19:22:40.339: INFO: Created: latency-svc-kgx6v
Jan 24 19:22:40.404: INFO: Got endpoints: latency-svc-dwkz6 [1.940916967s]
Jan 24 19:22:40.406: INFO: Got endpoints: latency-svc-rckp8 [946.060571ms]
Jan 24 19:22:40.407: INFO: Created: latency-svc-qthx5
Jan 24 19:22:40.411: INFO: Got endpoints: latency-svc-klg65 [1.175638995s]
Jan 24 19:22:40.413: INFO: Created: latency-svc-ph67d
Jan 24 19:22:40.415: INFO: Created: latency-svc-272gc
Jan 24 19:22:40.431: INFO: Got endpoints: latency-svc-dgcfk [1.199757895s]
Jan 24 19:22:40.431: INFO: Got endpoints: latency-svc-26mmn [1.475256032s]
Jan 24 19:22:40.437: INFO: Got endpoints: latency-svc-kgx6v [571.123902ms]
Jan 24 19:22:40.437: INFO: Got endpoints: latency-svc-7pk9h [1.650892269s]
Jan 24 19:22:40.437: INFO: Got endpoints: latency-svc-zwdjw [952.867704ms]
Jan 24 19:22:40.497: INFO: Got endpoints: latency-svc-qthx5 [450.082928ms]
Jan 24 19:22:40.665: INFO: Got endpoints: latency-svc-272gc [619.483662ms]
Jan 24 19:22:40.707: INFO: Created: latency-svc-pw2q6
Jan 24 19:22:40.805: INFO: Got endpoints: latency-svc-pw2q6 [683.89978ms]
Jan 24 19:22:40.781: INFO: Got endpoints: latency-svc-ph67d [719.404769ms]
Jan 24 19:22:40.797: INFO: Created: latency-svc-cndjs
Jan 24 19:22:40.797: INFO: Created: latency-svc-fvkrq
Jan 24 19:22:40.807: INFO: Got endpoints: latency-svc-fvkrq [662.996055ms]
Jan 24 19:22:40.798: INFO: Created: latency-svc-v4w7b
Jan 24 19:22:40.808: INFO: Got endpoints: latency-svc-v4w7b [760.034533ms]
Jan 24 19:22:40.825: INFO: Created: latency-svc-vncg2
Jan 24 19:22:40.839: INFO: Got endpoints: latency-svc-cndjs [434.305401ms]
Jan 24 19:22:40.940: INFO: Got endpoints: latency-svc-vncg2 [494.254905ms]
Jan 24 19:22:40.942: INFO: Created: latency-svc-qzwhw
Jan 24 19:22:40.942: INFO: Created: latency-svc-s29sh
Jan 24 19:22:41.000: INFO: Created: latency-svc-npzww
Jan 24 19:22:41.035: INFO: Got endpoints: latency-svc-s29sh [619.098152ms]
Jan 24 19:22:41.063: INFO: Got endpoints: latency-svc-qzwhw [601.03109ms]
Jan 24 19:22:41.068: INFO: Created: latency-svc-qhp22
Jan 24 19:22:41.398: INFO: Created: latency-svc-mz9vg
Jan 24 19:22:41.608: INFO: Created: latency-svc-m7g2m
Jan 24 19:22:41.613: INFO: Created: latency-svc-mtccn
Jan 24 19:22:41.614: INFO: Created: latency-svc-t7s27
Jan 24 19:22:41.615: INFO: Created: latency-svc-fzfjl
Jan 24 19:22:41.614: INFO: Created: latency-svc-ncn2h
Jan 24 19:22:41.623: INFO: Got endpoints: latency-svc-qhp22 [1.178547123s]
Jan 24 19:22:41.688: INFO: Got endpoints: latency-svc-npzww [1.254126837s]
Jan 24 19:22:41.727: INFO: Got endpoints: latency-svc-m7g2m [1.280055822s]
Jan 24 19:22:41.730: INFO: Created: latency-svc-4vnrq
Jan 24 19:22:41.730: INFO: Got endpoints: latency-svc-ncn2h [1.552468014s]
Jan 24 19:22:41.731: INFO: Got endpoints: latency-svc-mz9vg [1.266225881s]
Jan 24 19:22:41.865: INFO: Created: latency-svc-gjzc5
Jan 24 19:22:41.865: INFO: Got endpoints: latency-svc-gjzc5 [1.056899714s]
Jan 24 19:22:41.877: INFO: Created: latency-svc-pwxsb
Jan 24 19:22:41.877: INFO: Got endpoints: latency-svc-fzfjl [1.070597229s]
Jan 24 19:22:41.877: INFO: Got endpoints: latency-svc-mtccn [1.071237893s]
Jan 24 19:22:41.882: INFO: Got endpoints: latency-svc-4vnrq [1.217779435s]
Jan 24 19:22:41.883: INFO: Got endpoints: latency-svc-t7s27 [1.219190382s]
Jan 24 19:22:41.884: INFO: Created: latency-svc-std4p
Jan 24 19:22:41.884: INFO: Created: latency-svc-n6qbw
Jan 24 19:22:41.884: INFO: Got endpoints: latency-svc-n6qbw [1.045031197s]
Jan 24 19:22:41.891: INFO: Created: latency-svc-75htm
Jan 24 19:22:41.894: INFO: Got endpoints: latency-svc-75htm [953.461554ms]
Jan 24 19:22:41.975: INFO: Created: latency-svc-jh6d7
Jan 24 19:22:41.987: INFO: Got endpoints: latency-svc-jh6d7 [1.179166032s]
Jan 24 19:22:42.148: INFO: Got endpoints: latency-svc-pwxsb [1.112635755s]
Jan 24 19:22:42.159: INFO: Got endpoints: latency-svc-std4p [1.096297424s]
Jan 24 19:22:42.203: INFO: Created: latency-svc-p9xw7
Jan 24 19:22:42.203: INFO: Got endpoints: latency-svc-p9xw7 [579.662216ms]
Jan 24 19:22:42.274: INFO: Created: latency-svc-qqznx
Jan 24 19:22:42.300: INFO: Created: latency-svc-srfqs
Jan 24 19:22:42.305: INFO: Created: latency-svc-564xb
Jan 24 19:22:42.307: INFO: Created: latency-svc-4mjnp
Jan 24 19:22:43.063: INFO: Got endpoints: latency-svc-564xb [1.3339914s]
Jan 24 19:22:43.066: INFO: Got endpoints: latency-svc-srfqs [1.264043868s]
Jan 24 19:22:43.067: INFO: Got endpoints: latency-svc-qqznx [1.378438197s]
Jan 24 19:22:43.200: INFO: Created: latency-svc-h6qlm
Jan 24 19:22:43.201: INFO: Created: latency-svc-pmjh8
Jan 24 19:22:43.201: INFO: Created: latency-svc-cgvlm
Jan 24 19:22:43.202: INFO: Created: latency-svc-ksk22
Jan 24 19:22:43.203: INFO: Created: latency-svc-kpslr
Jan 24 19:22:43.203: INFO: Created: latency-svc-jwtn6
Jan 24 19:22:43.204: INFO: Created: latency-svc-t6tjq
Jan 24 19:22:43.204: INFO: Created: latency-svc-94nzg
Jan 24 19:22:43.205: INFO: Created: latency-svc-jhd7l
Jan 24 19:22:43.205: INFO: Got endpoints: latency-svc-4mjnp [1.33967927s]
Jan 24 19:22:43.206: INFO: Created: latency-svc-tnszs
Jan 24 19:22:43.247: INFO: Got endpoints: latency-svc-pmjh8 [1.36964907s]
Jan 24 19:22:43.704: INFO: Created: latency-svc-qcnbf
Jan 24 19:22:43.706: INFO: Created: latency-svc-b79zl
Jan 24 19:22:43.728: INFO: Created: latency-svc-p466v
Jan 24 19:22:43.736: INFO: Got endpoints: latency-svc-h6qlm [1.842023982s]
Jan 24 19:22:44.446: INFO: Created: latency-svc-j7b9q
Jan 24 19:22:44.468: INFO: Got endpoints: latency-svc-j7b9q [2.586775623s]
Jan 24 19:22:43.737: INFO: Got endpoints: latency-svc-tnszs [1.853824375s]
Jan 24 19:22:44.403: INFO: Got endpoints: latency-svc-kpslr [2.243959555s]
Jan 24 19:22:44.403: INFO: Got endpoints: latency-svc-cgvlm [2.518895607s]
Jan 24 19:22:44.403: INFO: Got endpoints: latency-svc-ksk22 [2.25548329s]
Jan 24 19:22:44.403: INFO: Got endpoints: latency-svc-jwtn6 [2.602524438s]
Jan 24 19:22:44.442: INFO: Got endpoints: latency-svc-94nzg [2.559278556s]
Jan 24 19:22:44.539: INFO: Created: latency-svc-d545v
Jan 24 19:22:44.801: INFO: Got endpoints: latency-svc-t6tjq [2.597708229s]
Jan 24 19:22:44.810: INFO: Got endpoints: latency-svc-jhd7l [2.819613451s]
Jan 24 19:22:45.079: INFO: Created: latency-svc-pc828
Jan 24 19:22:45.128: INFO: Created: latency-svc-sqb9x
Jan 24 19:22:45.129: INFO: Got endpoints: latency-svc-pc828 [571.095945ms]
Jan 24 19:22:45.136: INFO: Got endpoints: latency-svc-b79zl [2.072824627s]
Jan 24 19:22:45.139: INFO: Got endpoints: latency-svc-qcnbf [2.071537691s]
Jan 24 19:22:45.176: INFO: Got endpoints: latency-svc-p466v [1.971615257s]
Jan 24 19:22:45.203: INFO: Got endpoints: latency-svc-d545v [2.136728518s]
Jan 24 19:22:45.230: INFO: Got endpoints: latency-svc-sqb9x [1.98253914s]
Jan 24 19:22:45.239: INFO: Created: latency-svc-4fr9w
Jan 24 19:22:45.885: INFO: Created: latency-svc-sxzsn
Jan 24 19:22:45.885: INFO: Created: latency-svc-4c855
Jan 24 19:22:45.885: INFO: Created: latency-svc-hkkp5
Jan 24 19:22:45.886: INFO: Got endpoints: latency-svc-hkkp5 [1.231180548s]
Jan 24 19:22:45.887: INFO: Got endpoints: latency-svc-4fr9w [1.414636208s]
Jan 24 19:22:46.463: INFO: Created: latency-svc-p9q8r
Jan 24 19:22:46.463: INFO: Got endpoints: latency-svc-sxzsn [1.805684692s]
Jan 24 19:22:46.475: INFO: Got endpoints: latency-svc-4c855 [1.863072567s]
Jan 24 19:22:46.487: INFO: Created: latency-svc-x5jj6
Jan 24 19:22:46.489: INFO: Created: latency-svc-hdcth
Jan 24 19:22:46.489: INFO: Got endpoints: latency-svc-p9q8r [2.047297746s]
Jan 24 19:22:46.608: INFO: Created: latency-svc-s7kfx
Jan 24 19:22:46.608: INFO: Created: latency-svc-84gk2
Jan 24 19:22:46.609: INFO: Created: latency-svc-jtgf2
Jan 24 19:22:46.609: INFO: Created: latency-svc-9jsqf
Jan 24 19:22:46.610: INFO: Created: latency-svc-p4gzm
Jan 24 19:22:46.610: INFO: Created: latency-svc-7z4k2
Jan 24 19:22:46.611: INFO: Created: latency-svc-cvjgw
Jan 24 19:22:46.611: INFO: Created: latency-svc-dqz4g
Jan 24 19:22:46.624: INFO: Created: latency-svc-lxd5q
Jan 24 19:22:46.640: INFO: Created: latency-svc-blkkz
Jan 24 19:22:46.651: INFO: Got endpoints: latency-svc-84gk2 [1.84001041s]
Jan 24 19:22:46.653: INFO: Got endpoints: latency-svc-x5jj6 [1.843124259s]
Jan 24 19:22:46.676: INFO: Got endpoints: latency-svc-s7kfx [1.451105688s]
Jan 24 19:22:46.681: INFO: Got endpoints: latency-svc-9jsqf [1.552007975s]
Jan 24 19:22:46.683: INFO: Got endpoints: latency-svc-p4gzm [1.497926891s]
Jan 24 19:22:46.819: INFO: Got endpoints: latency-svc-7z4k2 [1.682346138s]
Jan 24 19:22:47.095: INFO: Created: latency-svc-cv8v6
Jan 24 19:22:47.095: INFO: Created: latency-svc-hhrhm
Jan 24 19:22:47.096: INFO: Created: latency-svc-6s6nz
Jan 24 19:22:47.103: INFO: Got endpoints: latency-svc-blkkz [2.629664126s]
Jan 24 19:22:47.103: INFO: Got endpoints: latency-svc-hdcth [1.873630801s]
Jan 24 19:22:47.111: INFO: Created: latency-svc-khpln
Jan 24 19:22:47.111: INFO: Created: latency-svc-4jpfh
Jan 24 19:22:47.111: INFO: Got endpoints: latency-svc-4jpfh [647.877497ms]
Jan 24 19:22:47.117: INFO: Created: latency-svc-lwssw
Jan 24 19:22:47.117: INFO: Got endpoints: latency-svc-lwssw [520.74426ms]
Jan 24 19:22:47.118: INFO: Got endpoints: latency-svc-dqz4g [1.945408914s]
Jan 24 19:22:47.121: INFO: Got endpoints: latency-svc-jtgf2 [1.234037098s]
Jan 24 19:22:47.121: INFO: Got endpoints: latency-svc-lxd5q [2.459410257s]
Jan 24 19:22:47.121: INFO: Got endpoints: latency-svc-cvjgw [1.234593884s]
Jan 24 19:22:47.122: INFO: Created: latency-svc-ghzzc
Jan 24 19:22:47.122: INFO: Created: latency-svc-qghdg
Jan 24 19:22:47.123: INFO: Created: latency-svc-q4sz6
Jan 24 19:22:47.126: INFO: Got endpoints: latency-svc-qghdg [649.596409ms]
Jan 24 19:22:47.129: INFO: Got endpoints: latency-svc-ghzzc [448.162956ms]
Jan 24 19:22:47.129: INFO: Got endpoints: latency-svc-q4sz6 [477.127894ms]
Jan 24 19:22:47.129: INFO: Got endpoints: latency-svc-khpln [465.594283ms]
Jan 24 19:22:47.129: INFO: Got endpoints: latency-svc-cv8v6 [436.475339ms]
Jan 24 19:22:47.129: INFO: Got endpoints: latency-svc-hhrhm [447.62118ms]
Jan 24 19:22:47.132: INFO: Got endpoints: latency-svc-6s6nz [313.321867ms]
Jan 24 19:22:47.162: INFO: Created: latency-svc-dd9qc
Jan 24 19:22:47.188: INFO: Created: latency-svc-vvlsk
Jan 24 19:22:47.200: INFO: Got endpoints: latency-svc-dd9qc [97.449798ms]
Jan 24 19:22:47.218: INFO: Created: latency-svc-h8zcd
Jan 24 19:22:47.231: INFO: Got endpoints: latency-svc-vvlsk [127.754176ms]
Jan 24 19:22:47.332: INFO: Created: latency-svc-6dp5r
Jan 24 19:22:47.338: INFO: Got endpoints: latency-svc-h8zcd [220.240529ms]
Jan 24 19:22:47.339: INFO: Created: latency-svc-4jr9g
Jan 24 19:22:47.341: INFO: Got endpoints: latency-svc-4jr9g [223.976109ms]
Jan 24 19:22:47.369: INFO: Got endpoints: latency-svc-6dp5r [257.775937ms]
Jan 24 19:22:47.369: INFO: Latencies: [97.449798ms 127.754176ms 128.327787ms 220.240529ms 223.976109ms 257.775937ms 284.949901ms 302.049056ms 303.796579ms 310.733297ms 313.321867ms 329.658019ms 365.339172ms 380.487705ms 381.718332ms 382.72141ms 390.220208ms 392.649161ms 409.5825ms 410.210311ms 416.532ms 422.015386ms 425.962731ms 428.667134ms 434.305401ms 436.475339ms 441.052201ms 447.62118ms 448.162956ms 450.082928ms 455.187006ms 459.47899ms 463.492992ms 465.594283ms 477.127894ms 479.095337ms 494.254905ms 499.411334ms 515.037242ms 518.866647ms 519.117103ms 520.74426ms 524.389183ms 530.54146ms 538.279246ms 539.789649ms 555.61959ms 560.750217ms 571.095945ms 571.123902ms 579.662216ms 596.497385ms 601.03109ms 608.605907ms 619.098152ms 619.483662ms 633.327752ms 647.877497ms 649.596409ms 652.003857ms 656.171053ms 658.812057ms 662.996055ms 666.06385ms 676.842191ms 680.113878ms 680.920126ms 683.89978ms 693.00185ms 694.321877ms 697.47303ms 719.404769ms 722.966663ms 731.663973ms 747.765726ms 750.649346ms 759.441059ms 760.034533ms 767.203567ms 767.844445ms 768.281611ms 773.64239ms 774.210868ms 777.470557ms 783.847244ms 813.361115ms 817.357299ms 838.842137ms 902.608059ms 946.060571ms 947.601127ms 951.349164ms 952.867704ms 953.461554ms 965.263427ms 984.328257ms 985.214957ms 1.000548802s 1.002246932s 1.026468782s 1.035435303s 1.03967154s 1.042052482s 1.045031197s 1.055868694s 1.056899714s 1.063352502s 1.064049232s 1.064947098s 1.070597229s 1.071237893s 1.078152149s 1.078220262s 1.090622921s 1.096297424s 1.110336529s 1.112635755s 1.174483334s 1.175638995s 1.178547123s 1.179166032s 1.186734254s 1.199757895s 1.201558012s 1.206242091s 1.217779435s 1.219190382s 1.231180548s 1.234037098s 1.234593884s 1.254126837s 1.261249138s 1.264043868s 1.265735769s 1.26617059s 1.266225881s 1.280055822s 1.298645968s 1.317191542s 1.319723892s 1.326405822s 1.326837415s 1.332719194s 1.3339914s 1.335384846s 1.335551371s 1.33967927s 1.340927465s 1.341048263s 1.341876098s 1.348359856s 1.36964907s 1.378438197s 1.379727352s 1.386514119s 1.414636208s 1.430235474s 1.431279607s 1.440350639s 1.442904815s 1.445541431s 1.448395596s 1.451105688s 1.452614264s 1.475256032s 1.497926891s 1.543522387s 1.545687458s 1.552007975s 1.552468014s 1.610378032s 1.650892269s 1.677555844s 1.682346138s 1.805684692s 1.84001041s 1.842023982s 1.843124259s 1.853824375s 1.863072567s 1.873630801s 1.940916967s 1.945408914s 1.971615257s 1.98253914s 2.047297746s 2.071537691s 2.072824627s 2.076909277s 2.136728518s 2.243959555s 2.25548329s 2.459410257s 2.518895607s 2.559278556s 2.586775623s 2.597708229s 2.602524438s 2.629664126s 2.819613451s]
Jan 24 19:22:47.370: INFO: 50 %ile: 1.035435303s
Jan 24 19:22:47.371: INFO: 90 %ile: 1.873630801s
Jan 24 19:22:47.371: INFO: 99 %ile: 2.629664126s
Jan 24 19:22:47.371: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Jan 24 19:22:47.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1596" for this suite. 01/24/23 19:22:47.399
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":134,"skipped":2633,"failed":0}
------------------------------
• [SLOW TEST] [20.677 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:22:26.754
    Jan 24 19:22:26.754: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename svc-latency 01/24/23 19:22:26.758
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:22:26.829
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:22:26.872
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Jan 24 19:22:26.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-1596 01/24/23 19:22:26.917
    I0124 19:22:26.950193      22 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1596, replica count: 1
    I0124 19:22:28.002589      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:22:29.003941      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:22:30.005241      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:22:31.052464      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:22:32.053990      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 19:22:32.521: INFO: Created: latency-svc-vzfkg
    Jan 24 19:22:32.822: INFO: Got endpoints: latency-svc-vzfkg [501.662601ms]
    Jan 24 19:22:33.237: INFO: Created: latency-svc-th7tx
    Jan 24 19:22:33.270: INFO: Created: latency-svc-nxzjz
    Jan 24 19:22:33.273: INFO: Got endpoints: latency-svc-nxzjz [441.052201ms]
    Jan 24 19:22:33.395: INFO: Got endpoints: latency-svc-th7tx [463.492992ms]
    Jan 24 19:22:33.693: INFO: Created: latency-svc-qmhxz
    Jan 24 19:22:33.724: INFO: Created: latency-svc-9knpx
    Jan 24 19:22:33.725: INFO: Got endpoints: latency-svc-qmhxz [329.658019ms]
    Jan 24 19:22:34.176: INFO: Created: latency-svc-zhn7q
    Jan 24 19:22:34.219: INFO: Created: latency-svc-47rwq
    Jan 24 19:22:34.223: INFO: Created: latency-svc-9tcqb
    Jan 24 19:22:34.224: INFO: Created: latency-svc-8md4r
    Jan 24 19:22:34.224: INFO: Created: latency-svc-fv97p
    Jan 24 19:22:34.230: INFO: Created: latency-svc-vt6xh
    Jan 24 19:22:34.234: INFO: Created: latency-svc-bmpgh
    Jan 24 19:22:34.235: INFO: Created: latency-svc-n4d8r
    Jan 24 19:22:34.237: INFO: Created: latency-svc-8mq92
    Jan 24 19:22:34.263: INFO: Created: latency-svc-qt686
    Jan 24 19:22:34.264: INFO: Got endpoints: latency-svc-vt6xh [538.279246ms]
    Jan 24 19:22:34.265: INFO: Created: latency-svc-9q5jp
    Jan 24 19:22:34.265: INFO: Got endpoints: latency-svc-9q5jp [1.430235474s]
    Jan 24 19:22:34.267: INFO: Got endpoints: latency-svc-8mq92 [1.440350639s]
    Jan 24 19:22:34.267: INFO: Got endpoints: latency-svc-zhn7q [1.326405822s]
    Jan 24 19:22:34.268: INFO: Got endpoints: latency-svc-9knpx [1.431279607s]
    Jan 24 19:22:34.268: INFO: Got endpoints: latency-svc-9tcqb [1.326837415s]
    Jan 24 19:22:34.274: INFO: Got endpoints: latency-svc-bmpgh [1.332719194s]
    Jan 24 19:22:34.275: INFO: Created: latency-svc-fcn82
    Jan 24 19:22:34.275: INFO: Got endpoints: latency-svc-fcn82 [1.341876098s]
    Jan 24 19:22:34.276: INFO: Got endpoints: latency-svc-47rwq [1.002246932s]
    Jan 24 19:22:34.276: INFO: Got endpoints: latency-svc-8md4r [1.335551371s]
    Jan 24 19:22:34.276: INFO: Got endpoints: latency-svc-qt686 [1.335384846s]
    Jan 24 19:22:34.277: INFO: Got endpoints: latency-svc-fv97p [1.442904815s]
    Jan 24 19:22:34.281: INFO: Got endpoints: latency-svc-n4d8r [1.341048263s]
    Jan 24 19:22:34.283: INFO: Created: latency-svc-2bh6t
    Jan 24 19:22:34.283: INFO: Got endpoints: latency-svc-2bh6t [1.340927465s]
    Jan 24 19:22:34.284: INFO: Created: latency-svc-dpdgs
    Jan 24 19:22:34.284: INFO: Got endpoints: latency-svc-dpdgs [1.448395596s]
    Jan 24 19:22:34.341: INFO: Created: latency-svc-fb2lj
    Jan 24 19:22:34.392: INFO: Got endpoints: latency-svc-fb2lj [128.327787ms]
    Jan 24 19:22:34.775: INFO: Created: latency-svc-v6vmd
    Jan 24 19:22:34.802: INFO: Created: latency-svc-fg2v7
    Jan 24 19:22:34.819: INFO: Created: latency-svc-8vlgx
    Jan 24 19:22:34.949: INFO: Created: latency-svc-j8d4j
    Jan 24 19:22:34.965: INFO: Created: latency-svc-vxv9c
    Jan 24 19:22:34.970: INFO: Created: latency-svc-chwf8
    Jan 24 19:22:34.970: INFO: Created: latency-svc-nfpbs
    Jan 24 19:22:34.972: INFO: Got endpoints: latency-svc-v6vmd [697.47303ms]
    Jan 24 19:22:35.017: INFO: Created: latency-svc-n6cpk
    Jan 24 19:22:35.017: INFO: Created: latency-svc-q9p92
    Jan 24 19:22:35.024: INFO: Created: latency-svc-t2gtk
    Jan 24 19:22:35.026: INFO: Created: latency-svc-pbxqh
    Jan 24 19:22:35.027: INFO: Created: latency-svc-x58cr
    Jan 24 19:22:35.033: INFO: Created: latency-svc-sm755
    Jan 24 19:22:35.034: INFO: Created: latency-svc-zv522
    Jan 24 19:22:35.035: INFO: Got endpoints: latency-svc-zv522 [759.441059ms]
    Jan 24 19:22:35.035: INFO: Got endpoints: latency-svc-x58cr [768.281611ms]
    Jan 24 19:22:35.047: INFO: Created: latency-svc-kv6sn
    Jan 24 19:22:35.049: INFO: Got endpoints: latency-svc-sm755 [783.847244ms]
    Jan 24 19:22:35.051: INFO: Got endpoints: latency-svc-t2gtk [774.210868ms]
    Jan 24 19:22:35.058: INFO: Got endpoints: latency-svc-n6cpk [773.64239ms]
    Jan 24 19:22:35.058: INFO: Got endpoints: latency-svc-chwf8 [777.470557ms]
    Jan 24 19:22:35.048: INFO: Got endpoints: latency-svc-q9p92 [767.844445ms]
    Jan 24 19:22:35.160: INFO: Got endpoints: latency-svc-nfpbs [767.203567ms]
    Jan 24 19:22:35.170: INFO: Created: latency-svc-pfm5t
    Jan 24 19:22:35.202: INFO: Created: latency-svc-lf6js
    Jan 24 19:22:35.248: INFO: Got endpoints: latency-svc-vxv9c [965.263427ms]
    Jan 24 19:22:35.302: INFO: Got endpoints: latency-svc-8vlgx [1.026468782s]
    Jan 24 19:22:35.308: INFO: Got endpoints: latency-svc-j8d4j [1.03967154s]
    Jan 24 19:22:35.310: INFO: Got endpoints: latency-svc-fg2v7 [1.042052482s]
    Jan 24 19:22:35.311: INFO: Got endpoints: latency-svc-pbxqh [1.035435303s]
    Jan 24 19:22:35.322: INFO: Got endpoints: latency-svc-kv6sn [1.055868694s]
    Jan 24 19:22:35.353: INFO: Created: latency-svc-gjjcx
    Jan 24 19:22:35.363: INFO: Created: latency-svc-rl9mm
    Jan 24 19:22:35.393: INFO: Got endpoints: latency-svc-pfm5t [410.210311ms]
    Jan 24 19:22:35.424: INFO: Got endpoints: latency-svc-rl9mm [365.339172ms]
    Jan 24 19:22:35.454: INFO: Got endpoints: latency-svc-lf6js [390.220208ms]
    Jan 24 19:22:35.530: INFO: Created: latency-svc-88x4k
    Jan 24 19:22:35.590: INFO: Got endpoints: latency-svc-gjjcx [555.61959ms]
    Jan 24 19:22:35.599: INFO: Created: latency-svc-b9b4f
    Jan 24 19:22:35.743: INFO: Got endpoints: latency-svc-88x4k [694.321877ms]
    Jan 24 19:22:35.758: INFO: Got endpoints: latency-svc-b9b4f [722.966663ms]
    Jan 24 19:22:35.785: INFO: Created: latency-svc-l64c4
    Jan 24 19:22:35.859: INFO: Created: latency-svc-ztp96
    Jan 24 19:22:35.934: INFO: Created: latency-svc-smxp7
    Jan 24 19:22:35.953: INFO: Created: latency-svc-zwb6m
    Jan 24 19:22:36.034: INFO: Created: latency-svc-svkhl
    Jan 24 19:22:36.064: INFO: Created: latency-svc-lcl54
    Jan 24 19:22:36.225: INFO: Got endpoints: latency-svc-l64c4 [1.174483334s]
    Jan 24 19:22:36.481: INFO: Got endpoints: latency-svc-ztp96 [1.319723892s]
    Jan 24 19:22:36.483: INFO: Created: latency-svc-pxhwj
    Jan 24 19:22:36.508: INFO: Got endpoints: latency-svc-zwb6m [1.206242091s]
    Jan 24 19:22:36.509: INFO: Got endpoints: latency-svc-svkhl [1.186734254s]
    Jan 24 19:22:36.509: INFO: Got endpoints: latency-svc-lcl54 [1.201558012s]
    Jan 24 19:22:36.509: INFO: Got endpoints: latency-svc-smxp7 [1.261249138s]
    Jan 24 19:22:36.575: INFO: Created: latency-svc-prw9z
    Jan 24 19:22:36.576: INFO: Got endpoints: latency-svc-prw9z [1.26617059s]
    Jan 24 19:22:36.577: INFO: Got endpoints: latency-svc-pxhwj [1.265735769s]
    Jan 24 19:22:36.668: INFO: Created: latency-svc-v8rxt
    Jan 24 19:22:36.772: INFO: Created: latency-svc-54567
    Jan 24 19:22:36.772: INFO: Got endpoints: latency-svc-v8rxt [1.348359856s]
    Jan 24 19:22:36.802: INFO: Created: latency-svc-4fwg2
    Jan 24 19:22:36.848: INFO: Created: latency-svc-dnh5s
    Jan 24 19:22:36.848: INFO: Got endpoints: latency-svc-dnh5s [1.452614264s]
    Jan 24 19:22:36.996: INFO: Created: latency-svc-cs6bt
    Jan 24 19:22:37.036: INFO: Created: latency-svc-5k492
    Jan 24 19:22:37.129: INFO: Created: latency-svc-v6tkr
    Jan 24 19:22:37.131: INFO: Created: latency-svc-mll47
    Jan 24 19:22:37.132: INFO: Got endpoints: latency-svc-54567 [1.677555844s]
    Jan 24 19:22:37.132: INFO: Created: latency-svc-98vfv
    Jan 24 19:22:37.135: INFO: Got endpoints: latency-svc-5k492 [1.543522387s]
    Jan 24 19:22:37.135: INFO: Got endpoints: latency-svc-4fwg2 [2.076909277s]
    Jan 24 19:22:37.138: INFO: Got endpoints: latency-svc-v6tkr [656.171053ms]
    Jan 24 19:22:37.138: INFO: Got endpoints: latency-svc-cs6bt [1.379727352s]
    Jan 24 19:22:37.139: INFO: Got endpoints: latency-svc-98vfv [1.386514119s]
    Jan 24 19:22:37.159: INFO: Created: latency-svc-tqw55
    Jan 24 19:22:37.173: INFO: Got endpoints: latency-svc-mll47 [947.601127ms]
    Jan 24 19:22:37.190: INFO: Got endpoints: latency-svc-tqw55 [680.920126ms]
    Jan 24 19:22:37.210: INFO: Created: latency-svc-c8sml
    Jan 24 19:22:37.224: INFO: Created: latency-svc-nvthw
    Jan 24 19:22:37.246: INFO: Got endpoints: latency-svc-c8sml [731.663973ms]
    Jan 24 19:22:37.256: INFO: Got endpoints: latency-svc-nvthw [680.113878ms]
    Jan 24 19:22:37.452: INFO: Created: latency-svc-zw76p
    Jan 24 19:22:37.486: INFO: Created: latency-svc-rmhds
    Jan 24 19:22:37.491: INFO: Created: latency-svc-z558q
    Jan 24 19:22:37.493: INFO: Created: latency-svc-5s4dj
    Jan 24 19:22:37.515: INFO: Created: latency-svc-tgmh6
    Jan 24 19:22:37.515: INFO: Created: latency-svc-rr9vw
    Jan 24 19:22:37.533: INFO: Created: latency-svc-5bpvt
    Jan 24 19:22:37.554: INFO: Created: latency-svc-dfqtm
    Jan 24 19:22:37.556: INFO: Created: latency-svc-ztx5l
    Jan 24 19:22:37.556: INFO: Created: latency-svc-rbh6b
    Jan 24 19:22:37.557: INFO: Created: latency-svc-s6w97
    Jan 24 19:22:37.557: INFO: Got endpoints: latency-svc-s6w97 [310.733297ms]
    Jan 24 19:22:37.558: INFO: Created: latency-svc-8pzbm
    Jan 24 19:22:37.559: INFO: Created: latency-svc-24dmx
    Jan 24 19:22:37.559: INFO: Got endpoints: latency-svc-24dmx [302.049056ms]
    Jan 24 19:22:37.559: INFO: Created: latency-svc-mhz8v
    Jan 24 19:22:37.561: INFO: Created: latency-svc-45p2g
    Jan 24 19:22:37.566: INFO: Got endpoints: latency-svc-rbh6b [392.649161ms]
    Jan 24 19:22:37.655: INFO: Got endpoints: latency-svc-5bpvt [1.078220262s]
    Jan 24 19:22:37.656: INFO: Got endpoints: latency-svc-8pzbm [515.037242ms]
    Jan 24 19:22:37.657: INFO: Got endpoints: latency-svc-zw76p [519.117103ms]
    Jan 24 19:22:37.675: INFO: Got endpoints: latency-svc-ztx5l [539.789649ms]
    Jan 24 19:22:37.675: INFO: Got endpoints: latency-svc-tgmh6 [902.608059ms]
    Jan 24 19:22:37.728: INFO: Created: latency-svc-xpstq
    Jan 24 19:22:37.750: INFO: Created: latency-svc-8r65x
    Jan 24 19:22:37.797: INFO: Got endpoints: latency-svc-z558q [658.812057ms]
    Jan 24 19:22:37.812: INFO: Got endpoints: latency-svc-dfqtm [1.298645968s]
    Jan 24 19:22:37.812: INFO: Got endpoints: latency-svc-rmhds [676.842191ms]
    Jan 24 19:22:37.814: INFO: Created: latency-svc-2p6hn
    Jan 24 19:22:37.825: INFO: Got endpoints: latency-svc-mhz8v [693.00185ms]
    Jan 24 19:22:37.828: INFO: Got endpoints: latency-svc-rr9vw [1.317191542s]
    Jan 24 19:22:37.833: INFO: Got endpoints: latency-svc-5s4dj [985.214957ms]
    Jan 24 19:22:37.844: INFO: Got endpoints: latency-svc-8r65x [284.949901ms]
    Jan 24 19:22:37.857: INFO: Got endpoints: latency-svc-45p2g [666.06385ms]
    Jan 24 19:22:37.870: INFO: Got endpoints: latency-svc-xpstq [303.796579ms]
    Jan 24 19:22:37.988: INFO: Created: latency-svc-q7bkf
    Jan 24 19:22:38.029: INFO: Created: latency-svc-2lgj8
    Jan 24 19:22:38.035: INFO: Created: latency-svc-7tbhx
    Jan 24 19:22:38.036: INFO: Got endpoints: latency-svc-7tbhx [479.095337ms]
    Jan 24 19:22:38.037: INFO: Got endpoints: latency-svc-q7bkf [380.487705ms]
    Jan 24 19:22:38.038: INFO: Created: latency-svc-4mbhz
    Jan 24 19:22:38.038: INFO: Got endpoints: latency-svc-2lgj8 [382.72141ms]
    Jan 24 19:22:38.039: INFO: Got endpoints: latency-svc-2p6hn [381.718332ms]
    Jan 24 19:22:38.040: INFO: Created: latency-svc-mvdvl
    Jan 24 19:22:38.121: INFO: Created: latency-svc-vj56v
    Jan 24 19:22:38.133: INFO: Created: latency-svc-6jvm8
    Jan 24 19:22:38.134: INFO: Got endpoints: latency-svc-4mbhz [459.47899ms]
    Jan 24 19:22:38.171: INFO: Created: latency-svc-dssvc
    Jan 24 19:22:38.186: INFO: Created: latency-svc-9ck4p
    Jan 24 19:22:38.204: INFO: Created: latency-svc-7pvzr
    Jan 24 19:22:38.205: INFO: Got endpoints: latency-svc-mvdvl [530.54146ms]
    Jan 24 19:22:38.214: INFO: Got endpoints: latency-svc-vj56v [416.532ms]
    Jan 24 19:22:38.234: INFO: Got endpoints: latency-svc-6jvm8 [422.015386ms]
    Jan 24 19:22:38.240: INFO: Got endpoints: latency-svc-dssvc [428.667134ms]
    Jan 24 19:22:38.279: INFO: Created: latency-svc-zx8kn
    Jan 24 19:22:38.279: INFO: Got endpoints: latency-svc-7pvzr [409.5825ms]
    Jan 24 19:22:38.280: INFO: Got endpoints: latency-svc-9ck4p [455.187006ms]
    Jan 24 19:22:38.334: INFO: Created: latency-svc-swn96
    Jan 24 19:22:38.336: INFO: Got endpoints: latency-svc-zx8kn [499.411334ms]
    Jan 24 19:22:38.363: INFO: Got endpoints: latency-svc-swn96 [518.866647ms]
    Jan 24 19:22:38.365: INFO: Created: latency-svc-9rv9z
    Jan 24 19:22:38.381: INFO: Got endpoints: latency-svc-9rv9z [524.389183ms]
    Jan 24 19:22:38.384: INFO: Created: latency-svc-q4b88
    Jan 24 19:22:38.433: INFO: Created: latency-svc-shspz
    Jan 24 19:22:38.436: INFO: Got endpoints: latency-svc-q4b88 [608.605907ms]
    Jan 24 19:22:38.462: INFO: Got endpoints: latency-svc-shspz [425.962731ms]
    Jan 24 19:22:38.476: INFO: Created: latency-svc-49mxt
    Jan 24 19:22:38.598: INFO: Got endpoints: latency-svc-49mxt [560.750217ms]
    Jan 24 19:22:38.681: INFO: Created: latency-svc-7tgl5
    Jan 24 19:22:38.786: INFO: Got endpoints: latency-svc-7tgl5 [747.765726ms]
    Jan 24 19:22:38.894: INFO: Created: latency-svc-rhc66
    Jan 24 19:22:38.955: INFO: Got endpoints: latency-svc-rhc66 [813.361115ms]
    Jan 24 19:22:38.971: INFO: Created: latency-svc-qnxtc
    Jan 24 19:22:39.019: INFO: Created: latency-svc-xzntz
    Jan 24 19:22:39.047: INFO: Created: latency-svc-dhs9b
    Jan 24 19:22:39.053: INFO: Got endpoints: latency-svc-xzntz [838.842137ms]
    Jan 24 19:22:39.081: INFO: Created: latency-svc-xdr4m
    Jan 24 19:22:39.147: INFO: Created: latency-svc-wrgcz
    Jan 24 19:22:39.165: INFO: Created: latency-svc-t6j6d
    Jan 24 19:22:39.231: INFO: Got endpoints: latency-svc-xdr4m [951.349164ms]
    Jan 24 19:22:39.235: INFO: Got endpoints: latency-svc-dhs9b [1.000548802s]
    Jan 24 19:22:39.251: INFO: Created: latency-svc-q9x67
    Jan 24 19:22:39.269: INFO: Got endpoints: latency-svc-qnxtc [1.064049232s]
    Jan 24 19:22:39.304: INFO: Got endpoints: latency-svc-t6j6d [1.063352502s]
    Jan 24 19:22:39.391: INFO: Got endpoints: latency-svc-wrgcz [1.110336529s]
    Jan 24 19:22:39.413: INFO: Created: latency-svc-xcjdv
    Jan 24 19:22:39.414: INFO: Created: latency-svc-p2kgh
    Jan 24 19:22:39.427: INFO: Got endpoints: latency-svc-q9x67 [1.090622921s]
    Jan 24 19:22:39.428: INFO: Got endpoints: latency-svc-p2kgh [1.064947098s]
    Jan 24 19:22:39.460: INFO: Got endpoints: latency-svc-xcjdv [1.078152149s]
    Jan 24 19:22:39.461: INFO: Created: latency-svc-btlqh
    Jan 24 19:22:39.484: INFO: Got endpoints: latency-svc-btlqh [1.445541431s]
    Jan 24 19:22:39.666: INFO: Created: latency-svc-xl97c
    Jan 24 19:22:39.687: INFO: Created: latency-svc-hcpls
    Jan 24 19:22:39.692: INFO: Created: latency-svc-ms7kh
    Jan 24 19:22:39.692: INFO: Created: latency-svc-qdlnc
    Jan 24 19:22:39.761: INFO: Created: latency-svc-rckp8
    Jan 24 19:22:39.761: INFO: Created: latency-svc-tkv5w
    Jan 24 19:22:39.781: INFO: Created: latency-svc-klg65
    Jan 24 19:22:39.791: INFO: Created: latency-svc-dgcfk
    Jan 24 19:22:39.800: INFO: Created: latency-svc-26mmn
    Jan 24 19:22:39.828: INFO: Created: latency-svc-dwkz6
    Jan 24 19:22:39.824: INFO: Created: latency-svc-7pk9h
    Jan 24 19:22:39.837: INFO: Created: latency-svc-xz67v
    Jan 24 19:22:39.854: INFO: Created: latency-svc-4sqmq
    Jan 24 19:22:39.866: INFO: Got endpoints: latency-svc-xl97c [596.497385ms]
    Jan 24 19:22:39.868: INFO: Created: latency-svc-zwdjw
    Jan 24 19:22:39.886: INFO: Created: latency-svc-99l89
    Jan 24 19:22:40.037: INFO: Got endpoints: latency-svc-hcpls [984.328257ms]
    Jan 24 19:22:40.043: INFO: Got endpoints: latency-svc-qdlnc [652.003857ms]
    Jan 24 19:22:40.047: INFO: Got endpoints: latency-svc-ms7kh [1.610378032s]
    Jan 24 19:22:40.062: INFO: Got endpoints: latency-svc-xz67v [633.327752ms]
    Jan 24 19:22:40.121: INFO: Got endpoints: latency-svc-tkv5w [817.357299ms]
    Jan 24 19:22:40.144: INFO: Got endpoints: latency-svc-99l89 [1.545687458s]
    Jan 24 19:22:40.178: INFO: Got endpoints: latency-svc-4sqmq [750.649346ms]
    Jan 24 19:22:40.339: INFO: Created: latency-svc-kgx6v
    Jan 24 19:22:40.404: INFO: Got endpoints: latency-svc-dwkz6 [1.940916967s]
    Jan 24 19:22:40.406: INFO: Got endpoints: latency-svc-rckp8 [946.060571ms]
    Jan 24 19:22:40.407: INFO: Created: latency-svc-qthx5
    Jan 24 19:22:40.411: INFO: Got endpoints: latency-svc-klg65 [1.175638995s]
    Jan 24 19:22:40.413: INFO: Created: latency-svc-ph67d
    Jan 24 19:22:40.415: INFO: Created: latency-svc-272gc
    Jan 24 19:22:40.431: INFO: Got endpoints: latency-svc-dgcfk [1.199757895s]
    Jan 24 19:22:40.431: INFO: Got endpoints: latency-svc-26mmn [1.475256032s]
    Jan 24 19:22:40.437: INFO: Got endpoints: latency-svc-kgx6v [571.123902ms]
    Jan 24 19:22:40.437: INFO: Got endpoints: latency-svc-7pk9h [1.650892269s]
    Jan 24 19:22:40.437: INFO: Got endpoints: latency-svc-zwdjw [952.867704ms]
    Jan 24 19:22:40.497: INFO: Got endpoints: latency-svc-qthx5 [450.082928ms]
    Jan 24 19:22:40.665: INFO: Got endpoints: latency-svc-272gc [619.483662ms]
    Jan 24 19:22:40.707: INFO: Created: latency-svc-pw2q6
    Jan 24 19:22:40.805: INFO: Got endpoints: latency-svc-pw2q6 [683.89978ms]
    Jan 24 19:22:40.781: INFO: Got endpoints: latency-svc-ph67d [719.404769ms]
    Jan 24 19:22:40.797: INFO: Created: latency-svc-cndjs
    Jan 24 19:22:40.797: INFO: Created: latency-svc-fvkrq
    Jan 24 19:22:40.807: INFO: Got endpoints: latency-svc-fvkrq [662.996055ms]
    Jan 24 19:22:40.798: INFO: Created: latency-svc-v4w7b
    Jan 24 19:22:40.808: INFO: Got endpoints: latency-svc-v4w7b [760.034533ms]
    Jan 24 19:22:40.825: INFO: Created: latency-svc-vncg2
    Jan 24 19:22:40.839: INFO: Got endpoints: latency-svc-cndjs [434.305401ms]
    Jan 24 19:22:40.940: INFO: Got endpoints: latency-svc-vncg2 [494.254905ms]
    Jan 24 19:22:40.942: INFO: Created: latency-svc-qzwhw
    Jan 24 19:22:40.942: INFO: Created: latency-svc-s29sh
    Jan 24 19:22:41.000: INFO: Created: latency-svc-npzww
    Jan 24 19:22:41.035: INFO: Got endpoints: latency-svc-s29sh [619.098152ms]
    Jan 24 19:22:41.063: INFO: Got endpoints: latency-svc-qzwhw [601.03109ms]
    Jan 24 19:22:41.068: INFO: Created: latency-svc-qhp22
    Jan 24 19:22:41.398: INFO: Created: latency-svc-mz9vg
    Jan 24 19:22:41.608: INFO: Created: latency-svc-m7g2m
    Jan 24 19:22:41.613: INFO: Created: latency-svc-mtccn
    Jan 24 19:22:41.614: INFO: Created: latency-svc-t7s27
    Jan 24 19:22:41.615: INFO: Created: latency-svc-fzfjl
    Jan 24 19:22:41.614: INFO: Created: latency-svc-ncn2h
    Jan 24 19:22:41.623: INFO: Got endpoints: latency-svc-qhp22 [1.178547123s]
    Jan 24 19:22:41.688: INFO: Got endpoints: latency-svc-npzww [1.254126837s]
    Jan 24 19:22:41.727: INFO: Got endpoints: latency-svc-m7g2m [1.280055822s]
    Jan 24 19:22:41.730: INFO: Created: latency-svc-4vnrq
    Jan 24 19:22:41.730: INFO: Got endpoints: latency-svc-ncn2h [1.552468014s]
    Jan 24 19:22:41.731: INFO: Got endpoints: latency-svc-mz9vg [1.266225881s]
    Jan 24 19:22:41.865: INFO: Created: latency-svc-gjzc5
    Jan 24 19:22:41.865: INFO: Got endpoints: latency-svc-gjzc5 [1.056899714s]
    Jan 24 19:22:41.877: INFO: Created: latency-svc-pwxsb
    Jan 24 19:22:41.877: INFO: Got endpoints: latency-svc-fzfjl [1.070597229s]
    Jan 24 19:22:41.877: INFO: Got endpoints: latency-svc-mtccn [1.071237893s]
    Jan 24 19:22:41.882: INFO: Got endpoints: latency-svc-4vnrq [1.217779435s]
    Jan 24 19:22:41.883: INFO: Got endpoints: latency-svc-t7s27 [1.219190382s]
    Jan 24 19:22:41.884: INFO: Created: latency-svc-std4p
    Jan 24 19:22:41.884: INFO: Created: latency-svc-n6qbw
    Jan 24 19:22:41.884: INFO: Got endpoints: latency-svc-n6qbw [1.045031197s]
    Jan 24 19:22:41.891: INFO: Created: latency-svc-75htm
    Jan 24 19:22:41.894: INFO: Got endpoints: latency-svc-75htm [953.461554ms]
    Jan 24 19:22:41.975: INFO: Created: latency-svc-jh6d7
    Jan 24 19:22:41.987: INFO: Got endpoints: latency-svc-jh6d7 [1.179166032s]
    Jan 24 19:22:42.148: INFO: Got endpoints: latency-svc-pwxsb [1.112635755s]
    Jan 24 19:22:42.159: INFO: Got endpoints: latency-svc-std4p [1.096297424s]
    Jan 24 19:22:42.203: INFO: Created: latency-svc-p9xw7
    Jan 24 19:22:42.203: INFO: Got endpoints: latency-svc-p9xw7 [579.662216ms]
    Jan 24 19:22:42.274: INFO: Created: latency-svc-qqznx
    Jan 24 19:22:42.300: INFO: Created: latency-svc-srfqs
    Jan 24 19:22:42.305: INFO: Created: latency-svc-564xb
    Jan 24 19:22:42.307: INFO: Created: latency-svc-4mjnp
    Jan 24 19:22:43.063: INFO: Got endpoints: latency-svc-564xb [1.3339914s]
    Jan 24 19:22:43.066: INFO: Got endpoints: latency-svc-srfqs [1.264043868s]
    Jan 24 19:22:43.067: INFO: Got endpoints: latency-svc-qqznx [1.378438197s]
    Jan 24 19:22:43.200: INFO: Created: latency-svc-h6qlm
    Jan 24 19:22:43.201: INFO: Created: latency-svc-pmjh8
    Jan 24 19:22:43.201: INFO: Created: latency-svc-cgvlm
    Jan 24 19:22:43.202: INFO: Created: latency-svc-ksk22
    Jan 24 19:22:43.203: INFO: Created: latency-svc-kpslr
    Jan 24 19:22:43.203: INFO: Created: latency-svc-jwtn6
    Jan 24 19:22:43.204: INFO: Created: latency-svc-t6tjq
    Jan 24 19:22:43.204: INFO: Created: latency-svc-94nzg
    Jan 24 19:22:43.205: INFO: Created: latency-svc-jhd7l
    Jan 24 19:22:43.205: INFO: Got endpoints: latency-svc-4mjnp [1.33967927s]
    Jan 24 19:22:43.206: INFO: Created: latency-svc-tnszs
    Jan 24 19:22:43.247: INFO: Got endpoints: latency-svc-pmjh8 [1.36964907s]
    Jan 24 19:22:43.704: INFO: Created: latency-svc-qcnbf
    Jan 24 19:22:43.706: INFO: Created: latency-svc-b79zl
    Jan 24 19:22:43.728: INFO: Created: latency-svc-p466v
    Jan 24 19:22:43.736: INFO: Got endpoints: latency-svc-h6qlm [1.842023982s]
    Jan 24 19:22:44.446: INFO: Created: latency-svc-j7b9q
    Jan 24 19:22:44.468: INFO: Got endpoints: latency-svc-j7b9q [2.586775623s]
    Jan 24 19:22:43.737: INFO: Got endpoints: latency-svc-tnszs [1.853824375s]
    Jan 24 19:22:44.403: INFO: Got endpoints: latency-svc-kpslr [2.243959555s]
    Jan 24 19:22:44.403: INFO: Got endpoints: latency-svc-cgvlm [2.518895607s]
    Jan 24 19:22:44.403: INFO: Got endpoints: latency-svc-ksk22 [2.25548329s]
    Jan 24 19:22:44.403: INFO: Got endpoints: latency-svc-jwtn6 [2.602524438s]
    Jan 24 19:22:44.442: INFO: Got endpoints: latency-svc-94nzg [2.559278556s]
    Jan 24 19:22:44.539: INFO: Created: latency-svc-d545v
    Jan 24 19:22:44.801: INFO: Got endpoints: latency-svc-t6tjq [2.597708229s]
    Jan 24 19:22:44.810: INFO: Got endpoints: latency-svc-jhd7l [2.819613451s]
    Jan 24 19:22:45.079: INFO: Created: latency-svc-pc828
    Jan 24 19:22:45.128: INFO: Created: latency-svc-sqb9x
    Jan 24 19:22:45.129: INFO: Got endpoints: latency-svc-pc828 [571.095945ms]
    Jan 24 19:22:45.136: INFO: Got endpoints: latency-svc-b79zl [2.072824627s]
    Jan 24 19:22:45.139: INFO: Got endpoints: latency-svc-qcnbf [2.071537691s]
    Jan 24 19:22:45.176: INFO: Got endpoints: latency-svc-p466v [1.971615257s]
    Jan 24 19:22:45.203: INFO: Got endpoints: latency-svc-d545v [2.136728518s]
    Jan 24 19:22:45.230: INFO: Got endpoints: latency-svc-sqb9x [1.98253914s]
    Jan 24 19:22:45.239: INFO: Created: latency-svc-4fr9w
    Jan 24 19:22:45.885: INFO: Created: latency-svc-sxzsn
    Jan 24 19:22:45.885: INFO: Created: latency-svc-4c855
    Jan 24 19:22:45.885: INFO: Created: latency-svc-hkkp5
    Jan 24 19:22:45.886: INFO: Got endpoints: latency-svc-hkkp5 [1.231180548s]
    Jan 24 19:22:45.887: INFO: Got endpoints: latency-svc-4fr9w [1.414636208s]
    Jan 24 19:22:46.463: INFO: Created: latency-svc-p9q8r
    Jan 24 19:22:46.463: INFO: Got endpoints: latency-svc-sxzsn [1.805684692s]
    Jan 24 19:22:46.475: INFO: Got endpoints: latency-svc-4c855 [1.863072567s]
    Jan 24 19:22:46.487: INFO: Created: latency-svc-x5jj6
    Jan 24 19:22:46.489: INFO: Created: latency-svc-hdcth
    Jan 24 19:22:46.489: INFO: Got endpoints: latency-svc-p9q8r [2.047297746s]
    Jan 24 19:22:46.608: INFO: Created: latency-svc-s7kfx
    Jan 24 19:22:46.608: INFO: Created: latency-svc-84gk2
    Jan 24 19:22:46.609: INFO: Created: latency-svc-jtgf2
    Jan 24 19:22:46.609: INFO: Created: latency-svc-9jsqf
    Jan 24 19:22:46.610: INFO: Created: latency-svc-p4gzm
    Jan 24 19:22:46.610: INFO: Created: latency-svc-7z4k2
    Jan 24 19:22:46.611: INFO: Created: latency-svc-cvjgw
    Jan 24 19:22:46.611: INFO: Created: latency-svc-dqz4g
    Jan 24 19:22:46.624: INFO: Created: latency-svc-lxd5q
    Jan 24 19:22:46.640: INFO: Created: latency-svc-blkkz
    Jan 24 19:22:46.651: INFO: Got endpoints: latency-svc-84gk2 [1.84001041s]
    Jan 24 19:22:46.653: INFO: Got endpoints: latency-svc-x5jj6 [1.843124259s]
    Jan 24 19:22:46.676: INFO: Got endpoints: latency-svc-s7kfx [1.451105688s]
    Jan 24 19:22:46.681: INFO: Got endpoints: latency-svc-9jsqf [1.552007975s]
    Jan 24 19:22:46.683: INFO: Got endpoints: latency-svc-p4gzm [1.497926891s]
    Jan 24 19:22:46.819: INFO: Got endpoints: latency-svc-7z4k2 [1.682346138s]
    Jan 24 19:22:47.095: INFO: Created: latency-svc-cv8v6
    Jan 24 19:22:47.095: INFO: Created: latency-svc-hhrhm
    Jan 24 19:22:47.096: INFO: Created: latency-svc-6s6nz
    Jan 24 19:22:47.103: INFO: Got endpoints: latency-svc-blkkz [2.629664126s]
    Jan 24 19:22:47.103: INFO: Got endpoints: latency-svc-hdcth [1.873630801s]
    Jan 24 19:22:47.111: INFO: Created: latency-svc-khpln
    Jan 24 19:22:47.111: INFO: Created: latency-svc-4jpfh
    Jan 24 19:22:47.111: INFO: Got endpoints: latency-svc-4jpfh [647.877497ms]
    Jan 24 19:22:47.117: INFO: Created: latency-svc-lwssw
    Jan 24 19:22:47.117: INFO: Got endpoints: latency-svc-lwssw [520.74426ms]
    Jan 24 19:22:47.118: INFO: Got endpoints: latency-svc-dqz4g [1.945408914s]
    Jan 24 19:22:47.121: INFO: Got endpoints: latency-svc-jtgf2 [1.234037098s]
    Jan 24 19:22:47.121: INFO: Got endpoints: latency-svc-lxd5q [2.459410257s]
    Jan 24 19:22:47.121: INFO: Got endpoints: latency-svc-cvjgw [1.234593884s]
    Jan 24 19:22:47.122: INFO: Created: latency-svc-ghzzc
    Jan 24 19:22:47.122: INFO: Created: latency-svc-qghdg
    Jan 24 19:22:47.123: INFO: Created: latency-svc-q4sz6
    Jan 24 19:22:47.126: INFO: Got endpoints: latency-svc-qghdg [649.596409ms]
    Jan 24 19:22:47.129: INFO: Got endpoints: latency-svc-ghzzc [448.162956ms]
    Jan 24 19:22:47.129: INFO: Got endpoints: latency-svc-q4sz6 [477.127894ms]
    Jan 24 19:22:47.129: INFO: Got endpoints: latency-svc-khpln [465.594283ms]
    Jan 24 19:22:47.129: INFO: Got endpoints: latency-svc-cv8v6 [436.475339ms]
    Jan 24 19:22:47.129: INFO: Got endpoints: latency-svc-hhrhm [447.62118ms]
    Jan 24 19:22:47.132: INFO: Got endpoints: latency-svc-6s6nz [313.321867ms]
    Jan 24 19:22:47.162: INFO: Created: latency-svc-dd9qc
    Jan 24 19:22:47.188: INFO: Created: latency-svc-vvlsk
    Jan 24 19:22:47.200: INFO: Got endpoints: latency-svc-dd9qc [97.449798ms]
    Jan 24 19:22:47.218: INFO: Created: latency-svc-h8zcd
    Jan 24 19:22:47.231: INFO: Got endpoints: latency-svc-vvlsk [127.754176ms]
    Jan 24 19:22:47.332: INFO: Created: latency-svc-6dp5r
    Jan 24 19:22:47.338: INFO: Got endpoints: latency-svc-h8zcd [220.240529ms]
    Jan 24 19:22:47.339: INFO: Created: latency-svc-4jr9g
    Jan 24 19:22:47.341: INFO: Got endpoints: latency-svc-4jr9g [223.976109ms]
    Jan 24 19:22:47.369: INFO: Got endpoints: latency-svc-6dp5r [257.775937ms]
    Jan 24 19:22:47.369: INFO: Latencies: [97.449798ms 127.754176ms 128.327787ms 220.240529ms 223.976109ms 257.775937ms 284.949901ms 302.049056ms 303.796579ms 310.733297ms 313.321867ms 329.658019ms 365.339172ms 380.487705ms 381.718332ms 382.72141ms 390.220208ms 392.649161ms 409.5825ms 410.210311ms 416.532ms 422.015386ms 425.962731ms 428.667134ms 434.305401ms 436.475339ms 441.052201ms 447.62118ms 448.162956ms 450.082928ms 455.187006ms 459.47899ms 463.492992ms 465.594283ms 477.127894ms 479.095337ms 494.254905ms 499.411334ms 515.037242ms 518.866647ms 519.117103ms 520.74426ms 524.389183ms 530.54146ms 538.279246ms 539.789649ms 555.61959ms 560.750217ms 571.095945ms 571.123902ms 579.662216ms 596.497385ms 601.03109ms 608.605907ms 619.098152ms 619.483662ms 633.327752ms 647.877497ms 649.596409ms 652.003857ms 656.171053ms 658.812057ms 662.996055ms 666.06385ms 676.842191ms 680.113878ms 680.920126ms 683.89978ms 693.00185ms 694.321877ms 697.47303ms 719.404769ms 722.966663ms 731.663973ms 747.765726ms 750.649346ms 759.441059ms 760.034533ms 767.203567ms 767.844445ms 768.281611ms 773.64239ms 774.210868ms 777.470557ms 783.847244ms 813.361115ms 817.357299ms 838.842137ms 902.608059ms 946.060571ms 947.601127ms 951.349164ms 952.867704ms 953.461554ms 965.263427ms 984.328257ms 985.214957ms 1.000548802s 1.002246932s 1.026468782s 1.035435303s 1.03967154s 1.042052482s 1.045031197s 1.055868694s 1.056899714s 1.063352502s 1.064049232s 1.064947098s 1.070597229s 1.071237893s 1.078152149s 1.078220262s 1.090622921s 1.096297424s 1.110336529s 1.112635755s 1.174483334s 1.175638995s 1.178547123s 1.179166032s 1.186734254s 1.199757895s 1.201558012s 1.206242091s 1.217779435s 1.219190382s 1.231180548s 1.234037098s 1.234593884s 1.254126837s 1.261249138s 1.264043868s 1.265735769s 1.26617059s 1.266225881s 1.280055822s 1.298645968s 1.317191542s 1.319723892s 1.326405822s 1.326837415s 1.332719194s 1.3339914s 1.335384846s 1.335551371s 1.33967927s 1.340927465s 1.341048263s 1.341876098s 1.348359856s 1.36964907s 1.378438197s 1.379727352s 1.386514119s 1.414636208s 1.430235474s 1.431279607s 1.440350639s 1.442904815s 1.445541431s 1.448395596s 1.451105688s 1.452614264s 1.475256032s 1.497926891s 1.543522387s 1.545687458s 1.552007975s 1.552468014s 1.610378032s 1.650892269s 1.677555844s 1.682346138s 1.805684692s 1.84001041s 1.842023982s 1.843124259s 1.853824375s 1.863072567s 1.873630801s 1.940916967s 1.945408914s 1.971615257s 1.98253914s 2.047297746s 2.071537691s 2.072824627s 2.076909277s 2.136728518s 2.243959555s 2.25548329s 2.459410257s 2.518895607s 2.559278556s 2.586775623s 2.597708229s 2.602524438s 2.629664126s 2.819613451s]
    Jan 24 19:22:47.370: INFO: 50 %ile: 1.035435303s
    Jan 24 19:22:47.371: INFO: 90 %ile: 1.873630801s
    Jan 24 19:22:47.371: INFO: 99 %ile: 2.629664126s
    Jan 24 19:22:47.371: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Jan 24 19:22:47.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-1596" for this suite. 01/24/23 19:22:47.399
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:22:47.471
Jan 24 19:22:47.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 19:22:47.478
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:22:47.53
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:22:47.549
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-d23a2ab6-9d8d-40d4-9119-ca72f55953b8 01/24/23 19:22:47.563
STEP: Creating a pod to test consume secrets 01/24/23 19:22:47.586
Jan 24 19:22:47.627: INFO: Waiting up to 5m0s for pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3" in namespace "secrets-1050" to be "Succeeded or Failed"
Jan 24 19:22:47.668: INFO: Pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3": Phase="Pending", Reason="", readiness=false. Elapsed: 41.128744ms
Jan 24 19:22:49.688: INFO: Pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061362448s
Jan 24 19:22:51.685: INFO: Pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057928772s
Jan 24 19:22:53.888: INFO: Pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.260878529s
STEP: Saw pod success 01/24/23 19:22:53.888
Jan 24 19:22:53.889: INFO: Pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3" satisfied condition "Succeeded or Failed"
Jan 24 19:22:53.936: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3 container secret-volume-test: <nil>
STEP: delete the pod 01/24/23 19:22:54.085
Jan 24 19:22:54.341: INFO: Waiting for pod pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3 to disappear
Jan 24 19:22:54.581: INFO: Pod pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 24 19:22:54.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1050" for this suite. 01/24/23 19:22:54.662
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":135,"skipped":2653,"failed":0}
------------------------------
• [SLOW TEST] [7.437 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:22:47.471
    Jan 24 19:22:47.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 19:22:47.478
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:22:47.53
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:22:47.549
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-d23a2ab6-9d8d-40d4-9119-ca72f55953b8 01/24/23 19:22:47.563
    STEP: Creating a pod to test consume secrets 01/24/23 19:22:47.586
    Jan 24 19:22:47.627: INFO: Waiting up to 5m0s for pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3" in namespace "secrets-1050" to be "Succeeded or Failed"
    Jan 24 19:22:47.668: INFO: Pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3": Phase="Pending", Reason="", readiness=false. Elapsed: 41.128744ms
    Jan 24 19:22:49.688: INFO: Pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061362448s
    Jan 24 19:22:51.685: INFO: Pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057928772s
    Jan 24 19:22:53.888: INFO: Pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.260878529s
    STEP: Saw pod success 01/24/23 19:22:53.888
    Jan 24 19:22:53.889: INFO: Pod "pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3" satisfied condition "Succeeded or Failed"
    Jan 24 19:22:53.936: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3 container secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 19:22:54.085
    Jan 24 19:22:54.341: INFO: Waiting for pod pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3 to disappear
    Jan 24 19:22:54.581: INFO: Pod pod-secrets-8f44401b-6616-4e64-be9c-b4b9411b56c3 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 19:22:54.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1050" for this suite. 01/24/23 19:22:54.662
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:22:55.086
Jan 24 19:22:55.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 19:22:55.115
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:22:55.57
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:22:55.669
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-9ecaa93b-ff03-41c0-821b-b344aaf5bea2 01/24/23 19:22:55.79
STEP: Creating a pod to test consume configMaps 01/24/23 19:22:55.895
Jan 24 19:22:56.000: INFO: Waiting up to 5m0s for pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9" in namespace "configmap-2348" to be "Succeeded or Failed"
Jan 24 19:22:56.044: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 44.043331ms
Jan 24 19:22:58.074: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073529308s
Jan 24 19:23:00.306: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.30590044s
Jan 24 19:23:02.066: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.065485181s
Jan 24 19:23:04.063: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.062840947s
STEP: Saw pod success 01/24/23 19:23:04.063
Jan 24 19:23:04.064: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9" satisfied condition "Succeeded or Failed"
Jan 24 19:23:04.085: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 19:23:04.124
Jan 24 19:23:04.178: INFO: Waiting for pod pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9 to disappear
Jan 24 19:23:04.189: INFO: Pod pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 19:23:04.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2348" for this suite. 01/24/23 19:23:04.217
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":136,"skipped":2657,"failed":0}
------------------------------
• [SLOW TEST] [9.181 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:22:55.086
    Jan 24 19:22:55.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 19:22:55.115
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:22:55.57
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:22:55.669
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-9ecaa93b-ff03-41c0-821b-b344aaf5bea2 01/24/23 19:22:55.79
    STEP: Creating a pod to test consume configMaps 01/24/23 19:22:55.895
    Jan 24 19:22:56.000: INFO: Waiting up to 5m0s for pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9" in namespace "configmap-2348" to be "Succeeded or Failed"
    Jan 24 19:22:56.044: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 44.043331ms
    Jan 24 19:22:58.074: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073529308s
    Jan 24 19:23:00.306: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.30590044s
    Jan 24 19:23:02.066: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.065485181s
    Jan 24 19:23:04.063: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.062840947s
    STEP: Saw pod success 01/24/23 19:23:04.063
    Jan 24 19:23:04.064: INFO: Pod "pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9" satisfied condition "Succeeded or Failed"
    Jan 24 19:23:04.085: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 19:23:04.124
    Jan 24 19:23:04.178: INFO: Waiting for pod pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9 to disappear
    Jan 24 19:23:04.189: INFO: Pod pod-configmaps-890953cf-4317-4166-bcbc-a93723e50bd9 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 19:23:04.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2348" for this suite. 01/24/23 19:23:04.217
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:23:04.27
Jan 24 19:23:04.271: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sched-preemption 01/24/23 19:23:04.273
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:23:04.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:23:04.329
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jan 24 19:23:04.435: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 24 19:24:04.588: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:24:04.615
Jan 24 19:24:04.615: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sched-preemption-path 01/24/23 19:24:04.62
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:24:04.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:24:04.74
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Jan 24 19:24:04.832: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Jan 24 19:24:04.845: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Jan 24 19:24:04.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-3573" for this suite. 01/24/23 19:24:04.927
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jan 24 19:24:04.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8739" for this suite. 01/24/23 19:24:05.004
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":137,"skipped":2677,"failed":0}
------------------------------
• [SLOW TEST] [61.175 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:23:04.27
    Jan 24 19:23:04.271: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sched-preemption 01/24/23 19:23:04.273
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:23:04.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:23:04.329
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jan 24 19:23:04.435: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 24 19:24:04.588: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:24:04.615
    Jan 24 19:24:04.615: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sched-preemption-path 01/24/23 19:24:04.62
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:24:04.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:24:04.74
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Jan 24 19:24:04.832: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Jan 24 19:24:04.845: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Jan 24 19:24:04.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-3573" for this suite. 01/24/23 19:24:04.927
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 19:24:04.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8739" for this suite. 01/24/23 19:24:05.004
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:24:05.459
Jan 24 19:24:05.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pod-network-test 01/24/23 19:24:05.478
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:24:05.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:24:05.661
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-6214 01/24/23 19:24:05.694
STEP: creating a selector 01/24/23 19:24:05.699
STEP: Creating the service pods in kubernetes 01/24/23 19:24:05.699
Jan 24 19:24:05.700: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jan 24 19:24:06.015: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6214" to be "running and ready"
Jan 24 19:24:06.030: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.530484ms
Jan 24 19:24:06.030: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:24:08.039: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023668945s
Jan 24 19:24:08.039: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:24:10.079: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.063839244s
Jan 24 19:24:10.079: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:24:12.058: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.043045613s
Jan 24 19:24:12.058: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:24:14.104: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.088549322s
Jan 24 19:24:14.104: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:24:16.048: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.033022835s
Jan 24 19:24:16.048: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:24:18.043: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.027721868s
Jan 24 19:24:18.043: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:24:20.046: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.030614527s
Jan 24 19:24:20.046: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:24:22.039: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.023462237s
Jan 24 19:24:22.039: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:24:24.049: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.033959714s
Jan 24 19:24:24.049: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:24:26.050: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.035035208s
Jan 24 19:24:26.051: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:24:28.056: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.040737837s
Jan 24 19:24:28.056: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jan 24 19:24:28.056: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jan 24 19:24:28.089: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6214" to be "running and ready"
Jan 24 19:24:28.110: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 21.356858ms
Jan 24 19:24:28.110: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jan 24 19:24:28.110: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 01/24/23 19:24:28.198
Jan 24 19:24:28.409: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6214" to be "running"
Jan 24 19:24:28.532: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 123.299411ms
Jan 24 19:24:30.563: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.154362853s
Jan 24 19:24:32.542: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.133391343s
Jan 24 19:24:32.542: INFO: Pod "test-container-pod" satisfied condition "running"
Jan 24 19:24:32.551: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6214" to be "running"
Jan 24 19:24:32.560: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.385871ms
Jan 24 19:24:32.560: INFO: Pod "host-test-container-pod" satisfied condition "running"
Jan 24 19:24:32.565: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Jan 24 19:24:32.565: INFO: Going to poll 10.244.47.117 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Jan 24 19:24:32.571: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.47.117 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6214 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:24:32.571: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:24:32.573: INFO: ExecWithOptions: Clientset creation
Jan 24 19:24:32.574: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-6214/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.47.117+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 24 19:24:33.741: INFO: Found all 1 expected endpoints: [netserver-0]
Jan 24 19:24:33.743: INFO: Going to poll 10.244.71.215 on port 8081 at least 0 times, with a maximum of 34 tries before failing
Jan 24 19:24:33.753: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.71.215 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6214 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:24:33.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:24:33.756: INFO: ExecWithOptions: Clientset creation
Jan 24 19:24:33.756: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-6214/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.71.215+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 24 19:24:34.935: INFO: Found all 1 expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jan 24 19:24:34.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6214" for this suite. 01/24/23 19:24:34.945
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":138,"skipped":2731,"failed":0}
------------------------------
• [SLOW TEST] [29.507 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:24:05.459
    Jan 24 19:24:05.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pod-network-test 01/24/23 19:24:05.478
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:24:05.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:24:05.661
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-6214 01/24/23 19:24:05.694
    STEP: creating a selector 01/24/23 19:24:05.699
    STEP: Creating the service pods in kubernetes 01/24/23 19:24:05.699
    Jan 24 19:24:05.700: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jan 24 19:24:06.015: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6214" to be "running and ready"
    Jan 24 19:24:06.030: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.530484ms
    Jan 24 19:24:06.030: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:24:08.039: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023668945s
    Jan 24 19:24:08.039: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:24:10.079: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.063839244s
    Jan 24 19:24:10.079: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:24:12.058: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.043045613s
    Jan 24 19:24:12.058: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:24:14.104: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.088549322s
    Jan 24 19:24:14.104: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:24:16.048: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.033022835s
    Jan 24 19:24:16.048: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:24:18.043: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.027721868s
    Jan 24 19:24:18.043: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:24:20.046: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.030614527s
    Jan 24 19:24:20.046: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:24:22.039: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.023462237s
    Jan 24 19:24:22.039: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:24:24.049: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.033959714s
    Jan 24 19:24:24.049: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:24:26.050: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.035035208s
    Jan 24 19:24:26.051: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:24:28.056: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.040737837s
    Jan 24 19:24:28.056: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jan 24 19:24:28.056: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jan 24 19:24:28.089: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6214" to be "running and ready"
    Jan 24 19:24:28.110: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 21.356858ms
    Jan 24 19:24:28.110: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jan 24 19:24:28.110: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 01/24/23 19:24:28.198
    Jan 24 19:24:28.409: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6214" to be "running"
    Jan 24 19:24:28.532: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 123.299411ms
    Jan 24 19:24:30.563: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.154362853s
    Jan 24 19:24:32.542: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.133391343s
    Jan 24 19:24:32.542: INFO: Pod "test-container-pod" satisfied condition "running"
    Jan 24 19:24:32.551: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6214" to be "running"
    Jan 24 19:24:32.560: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.385871ms
    Jan 24 19:24:32.560: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Jan 24 19:24:32.565: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Jan 24 19:24:32.565: INFO: Going to poll 10.244.47.117 on port 8081 at least 0 times, with a maximum of 34 tries before failing
    Jan 24 19:24:32.571: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.47.117 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6214 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:24:32.571: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:24:32.573: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:24:32.574: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-6214/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.47.117+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 24 19:24:33.741: INFO: Found all 1 expected endpoints: [netserver-0]
    Jan 24 19:24:33.743: INFO: Going to poll 10.244.71.215 on port 8081 at least 0 times, with a maximum of 34 tries before failing
    Jan 24 19:24:33.753: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.71.215 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6214 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:24:33.753: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:24:33.756: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:24:33.756: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-6214/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.244.71.215+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 24 19:24:34.935: INFO: Found all 1 expected endpoints: [netserver-1]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jan 24 19:24:34.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6214" for this suite. 01/24/23 19:24:34.945
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:24:34.986
Jan 24 19:24:34.986: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 19:24:34.991
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:24:35.021
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:24:35.031
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 01/24/23 19:24:35.039
Jan 24 19:24:35.070: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022" in namespace "emptydir-3848" to be "running"
Jan 24 19:24:35.080: INFO: Pod "pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022": Phase="Pending", Reason="", readiness=false. Elapsed: 10.397083ms
Jan 24 19:24:37.097: INFO: Pod "pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026809286s
Jan 24 19:24:39.096: INFO: Pod "pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022": Phase="Running", Reason="", readiness=false. Elapsed: 4.026030009s
Jan 24 19:24:39.096: INFO: Pod "pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022" satisfied condition "running"
STEP: Reading file content from the nginx-container 01/24/23 19:24:39.096
Jan 24 19:24:39.097: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3848 PodName:pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:24:39.097: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:24:39.100: INFO: ExecWithOptions: Clientset creation
Jan 24 19:24:39.100: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/emptydir-3848/pods/pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Jan 24 19:24:39.404: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 19:24:39.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3848" for this suite. 01/24/23 19:24:39.413
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":139,"skipped":2746,"failed":0}
------------------------------
• [4.454 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:24:34.986
    Jan 24 19:24:34.986: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 19:24:34.991
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:24:35.021
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:24:35.031
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 01/24/23 19:24:35.039
    Jan 24 19:24:35.070: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022" in namespace "emptydir-3848" to be "running"
    Jan 24 19:24:35.080: INFO: Pod "pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022": Phase="Pending", Reason="", readiness=false. Elapsed: 10.397083ms
    Jan 24 19:24:37.097: INFO: Pod "pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026809286s
    Jan 24 19:24:39.096: INFO: Pod "pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022": Phase="Running", Reason="", readiness=false. Elapsed: 4.026030009s
    Jan 24 19:24:39.096: INFO: Pod "pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022" satisfied condition "running"
    STEP: Reading file content from the nginx-container 01/24/23 19:24:39.096
    Jan 24 19:24:39.097: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3848 PodName:pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:24:39.097: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:24:39.100: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:24:39.100: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/emptydir-3848/pods/pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Jan 24 19:24:39.404: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 19:24:39.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3848" for this suite. 01/24/23 19:24:39.413
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:24:39.453
Jan 24 19:24:39.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sched-pred 01/24/23 19:24:39.459
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:24:39.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:24:39.522
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jan 24 19:24:39.530: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 24 19:24:39.550: INFO: Waiting for terminating namespaces to be deleted...
Jan 24 19:24:39.573: INFO: 
Logging pods the apiserver thinks is on node vikash-v125latest-conf-59870 before test
Jan 24 19:24:39.606: INFO: haproxy-ingress-cb855dc7c-smnf7 from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container haproxy-ingress ready: true, restart count 0
Jan 24 19:24:39.606: INFO: ingress-default-backend-6f4477b7bc-qg2sz from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container ingress-default-backend ready: true, restart count 0
Jan 24 19:24:39.606: INFO: calico-kube-controllers-74677b4c5f-zd5w8 from kube-system started at 2023-01-24 18:20:11 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 24 19:24:39.606: INFO: calico-node-45c9d from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container calico-node ready: true, restart count 0
Jan 24 19:24:39.606: INFO: coredns-94487f57-9zlwt from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container coredns ready: true, restart count 0
Jan 24 19:24:39.606: INFO: coredns-94487f57-qldwh from kube-system started at 2023-01-24 18:34:25 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container coredns ready: true, restart count 0
Jan 24 19:24:39.606: INFO: kyverno-operator-5c87dbd458-txhlw from nirmata started at 2023-01-24 18:22:35 +0000 UTC (2 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jan 24 19:24:39.606: INFO: 	Container manager ready: true, restart count 0
Jan 24 19:24:39.606: INFO: nirmata-cni-installer-6skzt from nirmata started at 2023-01-24 08:32:34 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container install-cni ready: true, restart count 0
Jan 24 19:24:39.606: INFO: otel-agent-6dfc8d44b6-6kj5q from nirmata started at 2023-01-24 18:22:32 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container otel-agent ready: true, restart count 0
Jan 24 19:24:39.606: INFO: netserver-0 from pod-network-test-6214 started at 2023-01-24 19:24:05 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container webserver ready: true, restart count 0
Jan 24 19:24:39.606: INFO: sonobuoy from sonobuoy started at 2023-01-24 18:32:49 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 24 19:24:39.606: INFO: sonobuoy-e2e-job-d94c6e71d257417d from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container e2e ready: true, restart count 0
Jan 24 19:24:39.606: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 19:24:39.606: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 19:24:39.606: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 19:24:39.606: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 24 19:24:39.606: INFO: 
Logging pods the apiserver thinks is on node vikash-v125latest-conf-71087 before test
Jan 24 19:24:39.646: INFO: pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022 from emptydir-3848 started at 2023-01-24 19:24:35 +0000 UTC (2 container statuses recorded)
Jan 24 19:24:39.646: INFO: 	Container busybox-main-container ready: true, restart count 0
Jan 24 19:24:39.647: INFO: 	Container busybox-sub-container ready: false, restart count 0
Jan 24 19:24:39.647: INFO: calico-node-kfjch from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.647: INFO: 	Container calico-node ready: true, restart count 0
Jan 24 19:24:39.647: INFO: metrics-server-696f4844bb-xklrk from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.648: INFO: 	Container metrics-server ready: true, restart count 0
Jan 24 19:24:39.649: INFO: nirmata-cni-installer-swjzc from nirmata started at 2023-01-24 18:34:55 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.650: INFO: 	Container install-cni ready: true, restart count 0
Jan 24 19:24:39.651: INFO: nirmata-kube-controller-df864cd5c-bz5gj from nirmata started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.657: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
Jan 24 19:24:39.657: INFO: host-test-container-pod from pod-network-test-6214 started at 2023-01-24 19:24:28 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.657: INFO: 	Container agnhost-container ready: true, restart count 0
Jan 24 19:24:39.657: INFO: netserver-1 from pod-network-test-6214 started at 2023-01-24 19:24:05 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.658: INFO: 	Container webserver ready: true, restart count 0
Jan 24 19:24:39.658: INFO: test-container-pod from pod-network-test-6214 started at 2023-01-24 19:24:28 +0000 UTC (1 container statuses recorded)
Jan 24 19:24:39.658: INFO: 	Container webserver ready: true, restart count 0
Jan 24 19:24:39.659: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-x86sk from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 19:24:39.659: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 19:24:39.659: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 01/24/23 19:24:39.66
Jan 24 19:24:39.714: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8877" to be "running"
Jan 24 19:24:39.738: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 23.517168ms
Jan 24 19:24:41.749: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034029506s
Jan 24 19:24:43.816: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.101145694s
Jan 24 19:24:43.823: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 01/24/23 19:24:43.91
STEP: Trying to apply a random label on the found node. 01/24/23 19:24:44.258
STEP: verifying the node has the label kubernetes.io/e2e-bb89d218-0d50-4643-af99-777c6003ae39 42 01/24/23 19:24:45.248
STEP: Trying to relaunch the pod, now with labels. 01/24/23 19:24:45.485
Jan 24 19:24:45.721: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-8877" to be "not pending"
Jan 24 19:24:45.845: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 123.39498ms
Jan 24 19:24:47.868: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.146968289s
Jan 24 19:24:49.857: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 4.135918132s
Jan 24 19:24:49.857: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-bb89d218-0d50-4643-af99-777c6003ae39 off the node vikash-v125latest-conf-71087 01/24/23 19:24:49.866
STEP: verifying the node doesn't have the label kubernetes.io/e2e-bb89d218-0d50-4643-af99-777c6003ae39 01/24/23 19:24:49.91
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jan 24 19:24:49.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8877" for this suite. 01/24/23 19:24:49.974
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":140,"skipped":2775,"failed":0}
------------------------------
• [SLOW TEST] [10.553 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:24:39.453
    Jan 24 19:24:39.454: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sched-pred 01/24/23 19:24:39.459
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:24:39.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:24:39.522
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jan 24 19:24:39.530: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jan 24 19:24:39.550: INFO: Waiting for terminating namespaces to be deleted...
    Jan 24 19:24:39.573: INFO: 
    Logging pods the apiserver thinks is on node vikash-v125latest-conf-59870 before test
    Jan 24 19:24:39.606: INFO: haproxy-ingress-cb855dc7c-smnf7 from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container haproxy-ingress ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: ingress-default-backend-6f4477b7bc-qg2sz from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container ingress-default-backend ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: calico-kube-controllers-74677b4c5f-zd5w8 from kube-system started at 2023-01-24 18:20:11 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: calico-node-45c9d from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container calico-node ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: coredns-94487f57-9zlwt from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container coredns ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: coredns-94487f57-qldwh from kube-system started at 2023-01-24 18:34:25 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container coredns ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: kyverno-operator-5c87dbd458-txhlw from nirmata started at 2023-01-24 18:22:35 +0000 UTC (2 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: 	Container manager ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: nirmata-cni-installer-6skzt from nirmata started at 2023-01-24 08:32:34 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container install-cni ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: otel-agent-6dfc8d44b6-6kj5q from nirmata started at 2023-01-24 18:22:32 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container otel-agent ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: netserver-0 from pod-network-test-6214 started at 2023-01-24 19:24:05 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container webserver ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: sonobuoy from sonobuoy started at 2023-01-24 18:32:49 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: sonobuoy-e2e-job-d94c6e71d257417d from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container e2e ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 19:24:39.606: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 24 19:24:39.606: INFO: 
    Logging pods the apiserver thinks is on node vikash-v125latest-conf-71087 before test
    Jan 24 19:24:39.646: INFO: pod-sharedvolume-e729c24d-562c-4d4a-8339-d2d69be64022 from emptydir-3848 started at 2023-01-24 19:24:35 +0000 UTC (2 container statuses recorded)
    Jan 24 19:24:39.646: INFO: 	Container busybox-main-container ready: true, restart count 0
    Jan 24 19:24:39.647: INFO: 	Container busybox-sub-container ready: false, restart count 0
    Jan 24 19:24:39.647: INFO: calico-node-kfjch from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.647: INFO: 	Container calico-node ready: true, restart count 0
    Jan 24 19:24:39.647: INFO: metrics-server-696f4844bb-xklrk from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.648: INFO: 	Container metrics-server ready: true, restart count 0
    Jan 24 19:24:39.649: INFO: nirmata-cni-installer-swjzc from nirmata started at 2023-01-24 18:34:55 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.650: INFO: 	Container install-cni ready: true, restart count 0
    Jan 24 19:24:39.651: INFO: nirmata-kube-controller-df864cd5c-bz5gj from nirmata started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.657: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
    Jan 24 19:24:39.657: INFO: host-test-container-pod from pod-network-test-6214 started at 2023-01-24 19:24:28 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.657: INFO: 	Container agnhost-container ready: true, restart count 0
    Jan 24 19:24:39.657: INFO: netserver-1 from pod-network-test-6214 started at 2023-01-24 19:24:05 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.658: INFO: 	Container webserver ready: true, restart count 0
    Jan 24 19:24:39.658: INFO: test-container-pod from pod-network-test-6214 started at 2023-01-24 19:24:28 +0000 UTC (1 container statuses recorded)
    Jan 24 19:24:39.658: INFO: 	Container webserver ready: true, restart count 0
    Jan 24 19:24:39.659: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-x86sk from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 19:24:39.659: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 19:24:39.659: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 01/24/23 19:24:39.66
    Jan 24 19:24:39.714: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-8877" to be "running"
    Jan 24 19:24:39.738: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 23.517168ms
    Jan 24 19:24:41.749: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034029506s
    Jan 24 19:24:43.816: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.101145694s
    Jan 24 19:24:43.823: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 01/24/23 19:24:43.91
    STEP: Trying to apply a random label on the found node. 01/24/23 19:24:44.258
    STEP: verifying the node has the label kubernetes.io/e2e-bb89d218-0d50-4643-af99-777c6003ae39 42 01/24/23 19:24:45.248
    STEP: Trying to relaunch the pod, now with labels. 01/24/23 19:24:45.485
    Jan 24 19:24:45.721: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-8877" to be "not pending"
    Jan 24 19:24:45.845: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 123.39498ms
    Jan 24 19:24:47.868: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.146968289s
    Jan 24 19:24:49.857: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 4.135918132s
    Jan 24 19:24:49.857: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-bb89d218-0d50-4643-af99-777c6003ae39 off the node vikash-v125latest-conf-71087 01/24/23 19:24:49.866
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-bb89d218-0d50-4643-af99-777c6003ae39 01/24/23 19:24:49.91
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 19:24:49.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8877" for this suite. 01/24/23 19:24:49.974
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:24:50.011
Jan 24 19:24:50.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 19:24:50.014
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:24:50.136
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:24:50.153
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Jan 24 19:24:50.198: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/24/23 19:25:08.023
Jan 24 19:25:08.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-8743 --namespace=crd-publish-openapi-8743 create -f -'
Jan 24 19:25:09.633: INFO: stderr: ""
Jan 24 19:25:09.633: INFO: stdout: "e2e-test-crd-publish-openapi-7377-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jan 24 19:25:09.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-8743 --namespace=crd-publish-openapi-8743 delete e2e-test-crd-publish-openapi-7377-crds test-cr'
Jan 24 19:25:09.780: INFO: stderr: ""
Jan 24 19:25:09.780: INFO: stdout: "e2e-test-crd-publish-openapi-7377-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Jan 24 19:25:09.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-8743 --namespace=crd-publish-openapi-8743 apply -f -'
Jan 24 19:25:10.369: INFO: stderr: ""
Jan 24 19:25:10.369: INFO: stdout: "e2e-test-crd-publish-openapi-7377-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jan 24 19:25:10.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-8743 --namespace=crd-publish-openapi-8743 delete e2e-test-crd-publish-openapi-7377-crds test-cr'
Jan 24 19:25:10.516: INFO: stderr: ""
Jan 24 19:25:10.516: INFO: stdout: "e2e-test-crd-publish-openapi-7377-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 01/24/23 19:25:10.516
Jan 24 19:25:10.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-8743 explain e2e-test-crd-publish-openapi-7377-crds'
Jan 24 19:25:11.067: INFO: stderr: ""
Jan 24 19:25:11.067: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7377-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:25:22.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8743" for this suite. 01/24/23 19:25:22.267
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":141,"skipped":2806,"failed":0}
------------------------------
• [SLOW TEST] [32.273 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:24:50.011
    Jan 24 19:24:50.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 19:24:50.014
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:24:50.136
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:24:50.153
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Jan 24 19:24:50.198: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/24/23 19:25:08.023
    Jan 24 19:25:08.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-8743 --namespace=crd-publish-openapi-8743 create -f -'
    Jan 24 19:25:09.633: INFO: stderr: ""
    Jan 24 19:25:09.633: INFO: stdout: "e2e-test-crd-publish-openapi-7377-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Jan 24 19:25:09.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-8743 --namespace=crd-publish-openapi-8743 delete e2e-test-crd-publish-openapi-7377-crds test-cr'
    Jan 24 19:25:09.780: INFO: stderr: ""
    Jan 24 19:25:09.780: INFO: stdout: "e2e-test-crd-publish-openapi-7377-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Jan 24 19:25:09.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-8743 --namespace=crd-publish-openapi-8743 apply -f -'
    Jan 24 19:25:10.369: INFO: stderr: ""
    Jan 24 19:25:10.369: INFO: stdout: "e2e-test-crd-publish-openapi-7377-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Jan 24 19:25:10.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-8743 --namespace=crd-publish-openapi-8743 delete e2e-test-crd-publish-openapi-7377-crds test-cr'
    Jan 24 19:25:10.516: INFO: stderr: ""
    Jan 24 19:25:10.516: INFO: stdout: "e2e-test-crd-publish-openapi-7377-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 01/24/23 19:25:10.516
    Jan 24 19:25:10.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-8743 explain e2e-test-crd-publish-openapi-7377-crds'
    Jan 24 19:25:11.067: INFO: stderr: ""
    Jan 24 19:25:11.067: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7377-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:25:22.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8743" for this suite. 01/24/23 19:25:22.267
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:25:22.285
Jan 24 19:25:22.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 19:25:22.336
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:25:22.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:25:22.563
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-3370 01/24/23 19:25:22.577
Jan 24 19:25:22.613: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3370" to be "running and ready"
Jan 24 19:25:22.643: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 28.849226ms
Jan 24 19:25:22.645: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:25:24.660: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.045455663s
Jan 24 19:25:24.661: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Jan 24 19:25:24.662: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Jan 24 19:25:24.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Jan 24 19:25:25.444: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Jan 24 19:25:25.445: INFO: stdout: "iptables"
Jan 24 19:25:25.445: INFO: proxyMode: iptables
Jan 24 19:25:25.485: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Jan 24 19:25:25.495: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-3370 01/24/23 19:25:25.495
STEP: creating replication controller affinity-nodeport-timeout in namespace services-3370 01/24/23 19:25:25.563
I0124 19:25:25.636231      22 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-3370, replica count: 3
I0124 19:25:28.743956      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:25:31.745105      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 19:25:31.775: INFO: Creating new exec pod
Jan 24 19:25:31.789: INFO: Waiting up to 5m0s for pod "execpod-affinityn4tq2" in namespace "services-3370" to be "running"
Jan 24 19:25:31.796: INFO: Pod "execpod-affinityn4tq2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.240373ms
Jan 24 19:25:33.811: INFO: Pod "execpod-affinityn4tq2": Phase="Running", Reason="", readiness=true. Elapsed: 2.021578107s
Jan 24 19:25:33.811: INFO: Pod "execpod-affinityn4tq2" satisfied condition "running"
Jan 24 19:25:34.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Jan 24 19:25:35.467: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Jan 24 19:25:35.467: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:25:35.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.195.122 80'
Jan 24 19:25:36.154: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.195.122 80\nConnection to 10.10.195.122 80 port [tcp/http] succeeded!\n"
Jan 24 19:25:36.154: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:25:36.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 32195'
Jan 24 19:25:36.672: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 32195\nConnection to 10.10.1.213 32195 port [tcp/*] succeeded!\n"
Jan 24 19:25:36.672: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:25:36.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.127 32195'
Jan 24 19:25:37.322: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.127 32195\nConnection to 10.10.1.127 32195 port [tcp/*] succeeded!\n"
Jan 24 19:25:37.322: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:25:37.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.1.213:32195/ ; done'
Jan 24 19:25:38.319: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n"
Jan 24 19:25:38.320: INFO: stdout: "\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56"
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
Jan 24 19:25:38.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.10.1.213:32195/'
Jan 24 19:25:39.397: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n"
Jan 24 19:25:39.397: INFO: stdout: "affinity-nodeport-timeout-dws56"
Jan 24 19:25:59.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.10.1.213:32195/'
Jan 24 19:25:59.972: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n"
Jan 24 19:25:59.972: INFO: stdout: "affinity-nodeport-timeout-f8zrg"
Jan 24 19:25:59.972: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-3370, will wait for the garbage collector to delete the pods 01/24/23 19:26:00.041
Jan 24 19:26:00.124: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 18.974431ms
Jan 24 19:26:00.534: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 409.832193ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 19:26:06.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3370" for this suite. 01/24/23 19:26:06.794
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":142,"skipped":2810,"failed":0}
------------------------------
• [SLOW TEST] [44.522 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:25:22.285
    Jan 24 19:25:22.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 19:25:22.336
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:25:22.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:25:22.563
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-3370 01/24/23 19:25:22.577
    Jan 24 19:25:22.613: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-3370" to be "running and ready"
    Jan 24 19:25:22.643: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 28.849226ms
    Jan 24 19:25:22.645: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:25:24.660: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.045455663s
    Jan 24 19:25:24.661: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Jan 24 19:25:24.662: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Jan 24 19:25:24.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Jan 24 19:25:25.444: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Jan 24 19:25:25.445: INFO: stdout: "iptables"
    Jan 24 19:25:25.445: INFO: proxyMode: iptables
    Jan 24 19:25:25.485: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Jan 24 19:25:25.495: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-3370 01/24/23 19:25:25.495
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-3370 01/24/23 19:25:25.563
    I0124 19:25:25.636231      22 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-3370, replica count: 3
    I0124 19:25:28.743956      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:25:31.745105      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 19:25:31.775: INFO: Creating new exec pod
    Jan 24 19:25:31.789: INFO: Waiting up to 5m0s for pod "execpod-affinityn4tq2" in namespace "services-3370" to be "running"
    Jan 24 19:25:31.796: INFO: Pod "execpod-affinityn4tq2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.240373ms
    Jan 24 19:25:33.811: INFO: Pod "execpod-affinityn4tq2": Phase="Running", Reason="", readiness=true. Elapsed: 2.021578107s
    Jan 24 19:25:33.811: INFO: Pod "execpod-affinityn4tq2" satisfied condition "running"
    Jan 24 19:25:34.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Jan 24 19:25:35.467: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Jan 24 19:25:35.467: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:25:35.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.195.122 80'
    Jan 24 19:25:36.154: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.195.122 80\nConnection to 10.10.195.122 80 port [tcp/http] succeeded!\n"
    Jan 24 19:25:36.154: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:25:36.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 32195'
    Jan 24 19:25:36.672: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 32195\nConnection to 10.10.1.213 32195 port [tcp/*] succeeded!\n"
    Jan 24 19:25:36.672: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:25:36.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.127 32195'
    Jan 24 19:25:37.322: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.127 32195\nConnection to 10.10.1.127 32195 port [tcp/*] succeeded!\n"
    Jan 24 19:25:37.322: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:25:37.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.1.213:32195/ ; done'
    Jan 24 19:25:38.319: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n"
    Jan 24 19:25:38.320: INFO: stdout: "\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56\naffinity-nodeport-timeout-dws56"
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Received response from host: affinity-nodeport-timeout-dws56
    Jan 24 19:25:38.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.10.1.213:32195/'
    Jan 24 19:25:39.397: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n"
    Jan 24 19:25:39.397: INFO: stdout: "affinity-nodeport-timeout-dws56"
    Jan 24 19:25:59.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3370 exec execpod-affinityn4tq2 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.10.1.213:32195/'
    Jan 24 19:25:59.972: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.10.1.213:32195/\n"
    Jan 24 19:25:59.972: INFO: stdout: "affinity-nodeport-timeout-f8zrg"
    Jan 24 19:25:59.972: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-3370, will wait for the garbage collector to delete the pods 01/24/23 19:26:00.041
    Jan 24 19:26:00.124: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 18.974431ms
    Jan 24 19:26:00.534: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 409.832193ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 19:26:06.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3370" for this suite. 01/24/23 19:26:06.794
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:06.812
Jan 24 19:26:06.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 19:26:06.814
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:06.862
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:06.872
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 19:26:06.907
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:26:07.655
STEP: Deploying the webhook pod 01/24/23 19:26:07.671
STEP: Wait for the deployment to be ready 01/24/23 19:26:07.69
Jan 24 19:26:07.703: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Jan 24 19:26:09.726: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 19:26:11.736
STEP: Verifying the service has paired with the endpoint 01/24/23 19:26:11.769
Jan 24 19:26:12.772: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Jan 24 19:26:12.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2741-crds.webhook.example.com via the AdmissionRegistration API 01/24/23 19:26:13.357
STEP: Creating a custom resource while v1 is storage version 01/24/23 19:26:13.408
STEP: Patching Custom Resource Definition to set v2 as storage 01/24/23 19:26:15.622
STEP: Patching the custom resource while v2 is storage version 01/24/23 19:26:15.688
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:26:16.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5910" for this suite. 01/24/23 19:26:16.513
STEP: Destroying namespace "webhook-5910-markers" for this suite. 01/24/23 19:26:16.528
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":143,"skipped":2833,"failed":0}
------------------------------
• [SLOW TEST] [9.971 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:06.812
    Jan 24 19:26:06.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 19:26:06.814
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:06.862
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:06.872
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 19:26:06.907
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:26:07.655
    STEP: Deploying the webhook pod 01/24/23 19:26:07.671
    STEP: Wait for the deployment to be ready 01/24/23 19:26:07.69
    Jan 24 19:26:07.703: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Jan 24 19:26:09.726: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 7, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 7, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 19:26:11.736
    STEP: Verifying the service has paired with the endpoint 01/24/23 19:26:11.769
    Jan 24 19:26:12.772: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Jan 24 19:26:12.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2741-crds.webhook.example.com via the AdmissionRegistration API 01/24/23 19:26:13.357
    STEP: Creating a custom resource while v1 is storage version 01/24/23 19:26:13.408
    STEP: Patching Custom Resource Definition to set v2 as storage 01/24/23 19:26:15.622
    STEP: Patching the custom resource while v2 is storage version 01/24/23 19:26:15.688
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:26:16.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5910" for this suite. 01/24/23 19:26:16.513
    STEP: Destroying namespace "webhook-5910-markers" for this suite. 01/24/23 19:26:16.528
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:16.809
Jan 24 19:26:16.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename init-container 01/24/23 19:26:16.829
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:17.087
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:17.136
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 01/24/23 19:26:17.229
Jan 24 19:26:17.232: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 24 19:26:24.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3142" for this suite. 01/24/23 19:26:24.296
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":144,"skipped":2844,"failed":0}
------------------------------
• [SLOW TEST] [7.601 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:16.809
    Jan 24 19:26:16.809: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename init-container 01/24/23 19:26:16.829
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:17.087
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:17.136
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 01/24/23 19:26:17.229
    Jan 24 19:26:17.232: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 24 19:26:24.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-3142" for this suite. 01/24/23 19:26:24.296
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:24.504
Jan 24 19:26:24.505: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sysctl 01/24/23 19:26:24.508
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:24.735
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:24.755
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 01/24/23 19:26:24.778
STEP: Watching for error events or started pod 01/24/23 19:26:24.831
STEP: Waiting for pod completion 01/24/23 19:26:26.857
Jan 24 19:26:26.857: INFO: Waiting up to 3m0s for pod "sysctl-52db81d1-c740-438b-bea2-6ff9bc4cbd48" in namespace "sysctl-4581" to be "completed"
Jan 24 19:26:26.868: INFO: Pod "sysctl-52db81d1-c740-438b-bea2-6ff9bc4cbd48": Phase="Pending", Reason="", readiness=false. Elapsed: 10.606922ms
Jan 24 19:26:28.876: INFO: Pod "sysctl-52db81d1-c740-438b-bea2-6ff9bc4cbd48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018945686s
Jan 24 19:26:30.885: INFO: Pod "sysctl-52db81d1-c740-438b-bea2-6ff9bc4cbd48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027867721s
Jan 24 19:26:30.885: INFO: Pod "sysctl-52db81d1-c740-438b-bea2-6ff9bc4cbd48" satisfied condition "completed"
STEP: Checking that the pod succeeded 01/24/23 19:26:30.9
STEP: Getting logs from the pod 01/24/23 19:26:30.901
STEP: Checking that the sysctl is actually updated 01/24/23 19:26:30.985
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 24 19:26:30.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-4581" for this suite. 01/24/23 19:26:31.007
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":145,"skipped":2897,"failed":0}
------------------------------
• [SLOW TEST] [6.540 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:24.504
    Jan 24 19:26:24.505: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sysctl 01/24/23 19:26:24.508
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:24.735
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:24.755
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 01/24/23 19:26:24.778
    STEP: Watching for error events or started pod 01/24/23 19:26:24.831
    STEP: Waiting for pod completion 01/24/23 19:26:26.857
    Jan 24 19:26:26.857: INFO: Waiting up to 3m0s for pod "sysctl-52db81d1-c740-438b-bea2-6ff9bc4cbd48" in namespace "sysctl-4581" to be "completed"
    Jan 24 19:26:26.868: INFO: Pod "sysctl-52db81d1-c740-438b-bea2-6ff9bc4cbd48": Phase="Pending", Reason="", readiness=false. Elapsed: 10.606922ms
    Jan 24 19:26:28.876: INFO: Pod "sysctl-52db81d1-c740-438b-bea2-6ff9bc4cbd48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018945686s
    Jan 24 19:26:30.885: INFO: Pod "sysctl-52db81d1-c740-438b-bea2-6ff9bc4cbd48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027867721s
    Jan 24 19:26:30.885: INFO: Pod "sysctl-52db81d1-c740-438b-bea2-6ff9bc4cbd48" satisfied condition "completed"
    STEP: Checking that the pod succeeded 01/24/23 19:26:30.9
    STEP: Getting logs from the pod 01/24/23 19:26:30.901
    STEP: Checking that the sysctl is actually updated 01/24/23 19:26:30.985
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 24 19:26:30.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-4581" for this suite. 01/24/23 19:26:31.007
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:31.056
Jan 24 19:26:31.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 19:26:31.061
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:31.106
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:31.118
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 19:26:31.194
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:26:35.187
STEP: Deploying the webhook pod 01/24/23 19:26:35.23
STEP: Wait for the deployment to be ready 01/24/23 19:26:35.301
Jan 24 19:26:35.601: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 24 19:26:37.652: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 19:26:39.693
STEP: Verifying the service has paired with the endpoint 01/24/23 19:26:39.728
Jan 24 19:26:40.732: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 01/24/23 19:26:40.946
STEP: Creating a configMap that should be mutated 01/24/23 19:26:41.032
STEP: Deleting the collection of validation webhooks 01/24/23 19:26:41.247
STEP: Creating a configMap that should not be mutated 01/24/23 19:26:41.392
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:26:41.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5227" for this suite. 01/24/23 19:26:41.447
STEP: Destroying namespace "webhook-5227-markers" for this suite. 01/24/23 19:26:41.471
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":146,"skipped":2944,"failed":0}
------------------------------
• [SLOW TEST] [10.600 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:31.056
    Jan 24 19:26:31.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 19:26:31.061
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:31.106
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:31.118
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 19:26:31.194
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:26:35.187
    STEP: Deploying the webhook pod 01/24/23 19:26:35.23
    STEP: Wait for the deployment to be ready 01/24/23 19:26:35.301
    Jan 24 19:26:35.601: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 24 19:26:37.652: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 19:26:39.693
    STEP: Verifying the service has paired with the endpoint 01/24/23 19:26:39.728
    Jan 24 19:26:40.732: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 01/24/23 19:26:40.946
    STEP: Creating a configMap that should be mutated 01/24/23 19:26:41.032
    STEP: Deleting the collection of validation webhooks 01/24/23 19:26:41.247
    STEP: Creating a configMap that should not be mutated 01/24/23 19:26:41.392
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:26:41.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5227" for this suite. 01/24/23 19:26:41.447
    STEP: Destroying namespace "webhook-5227-markers" for this suite. 01/24/23 19:26:41.471
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:41.658
Jan 24 19:26:41.658: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename containers 01/24/23 19:26:41.678
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:41.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:41.872
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Jan 24 19:26:41.938: INFO: Waiting up to 5m0s for pod "client-containers-6204a4a3-6c24-4ded-92f5-c05ff24d9e85" in namespace "containers-2006" to be "running"
Jan 24 19:26:41.968: INFO: Pod "client-containers-6204a4a3-6c24-4ded-92f5-c05ff24d9e85": Phase="Pending", Reason="", readiness=false. Elapsed: 29.581147ms
Jan 24 19:26:44.041: INFO: Pod "client-containers-6204a4a3-6c24-4ded-92f5-c05ff24d9e85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102407232s
Jan 24 19:26:45.982: INFO: Pod "client-containers-6204a4a3-6c24-4ded-92f5-c05ff24d9e85": Phase="Running", Reason="", readiness=true. Elapsed: 4.044002763s
Jan 24 19:26:45.982: INFO: Pod "client-containers-6204a4a3-6c24-4ded-92f5-c05ff24d9e85" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jan 24 19:26:46.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2006" for this suite. 01/24/23 19:26:46.03
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":147,"skipped":2947,"failed":0}
------------------------------
• [4.421 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:41.658
    Jan 24 19:26:41.658: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename containers 01/24/23 19:26:41.678
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:41.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:41.872
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Jan 24 19:26:41.938: INFO: Waiting up to 5m0s for pod "client-containers-6204a4a3-6c24-4ded-92f5-c05ff24d9e85" in namespace "containers-2006" to be "running"
    Jan 24 19:26:41.968: INFO: Pod "client-containers-6204a4a3-6c24-4ded-92f5-c05ff24d9e85": Phase="Pending", Reason="", readiness=false. Elapsed: 29.581147ms
    Jan 24 19:26:44.041: INFO: Pod "client-containers-6204a4a3-6c24-4ded-92f5-c05ff24d9e85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102407232s
    Jan 24 19:26:45.982: INFO: Pod "client-containers-6204a4a3-6c24-4ded-92f5-c05ff24d9e85": Phase="Running", Reason="", readiness=true. Elapsed: 4.044002763s
    Jan 24 19:26:45.982: INFO: Pod "client-containers-6204a4a3-6c24-4ded-92f5-c05ff24d9e85" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jan 24 19:26:46.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-2006" for this suite. 01/24/23 19:26:46.03
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:46.093
Jan 24 19:26:46.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename podtemplate 01/24/23 19:26:46.098
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:46.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:46.3
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Jan 24 19:26:46.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-4272" for this suite. 01/24/23 19:26:46.539
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":148,"skipped":2983,"failed":0}
------------------------------
• [0.472 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:46.093
    Jan 24 19:26:46.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename podtemplate 01/24/23 19:26:46.098
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:46.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:46.3
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Jan 24 19:26:46.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-4272" for this suite. 01/24/23 19:26:46.539
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:46.566
Jan 24 19:26:46.567: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 19:26:46.573
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:46.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:46.619
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 19:26:46.659
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:26:47.909
STEP: Deploying the webhook pod 01/24/23 19:26:47.923
STEP: Wait for the deployment to be ready 01/24/23 19:26:47.952
Jan 24 19:26:47.989: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 24 19:26:50.015: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 19:26:52.041
STEP: Verifying the service has paired with the endpoint 01/24/23 19:26:52.076
Jan 24 19:26:53.077: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 01/24/23 19:26:53.083
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 01/24/23 19:26:53.086
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 01/24/23 19:26:53.086
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 01/24/23 19:26:53.086
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 01/24/23 19:26:53.089
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 01/24/23 19:26:53.089
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 01/24/23 19:26:53.095
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:26:53.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-146" for this suite. 01/24/23 19:26:53.109
STEP: Destroying namespace "webhook-146-markers" for this suite. 01/24/23 19:26:53.126
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":149,"skipped":2983,"failed":0}
------------------------------
• [SLOW TEST] [6.840 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:46.566
    Jan 24 19:26:46.567: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 19:26:46.573
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:46.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:46.619
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 19:26:46.659
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:26:47.909
    STEP: Deploying the webhook pod 01/24/23 19:26:47.923
    STEP: Wait for the deployment to be ready 01/24/23 19:26:47.952
    Jan 24 19:26:47.989: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 24 19:26:50.015: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 48, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 26, 48, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 26, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 19:26:52.041
    STEP: Verifying the service has paired with the endpoint 01/24/23 19:26:52.076
    Jan 24 19:26:53.077: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 01/24/23 19:26:53.083
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 01/24/23 19:26:53.086
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 01/24/23 19:26:53.086
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 01/24/23 19:26:53.086
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 01/24/23 19:26:53.089
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 01/24/23 19:26:53.089
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 01/24/23 19:26:53.095
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:26:53.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-146" for this suite. 01/24/23 19:26:53.109
    STEP: Destroying namespace "webhook-146-markers" for this suite. 01/24/23 19:26:53.126
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:53.407
Jan 24 19:26:53.408: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename svcaccounts 01/24/23 19:26:53.415
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:53.516
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:53.532
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  01/24/23 19:26:53.559
Jan 24 19:26:53.596: INFO: Waiting up to 5m0s for pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f" in namespace "svcaccounts-1757" to be "Succeeded or Failed"
Jan 24 19:26:53.605: INFO: Pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.430441ms
Jan 24 19:26:55.614: INFO: Pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018405075s
Jan 24 19:26:57.621: INFO: Pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025311355s
Jan 24 19:26:59.615: INFO: Pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019355421s
STEP: Saw pod success 01/24/23 19:26:59.615
Jan 24 19:26:59.616: INFO: Pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f" satisfied condition "Succeeded or Failed"
Jan 24 19:26:59.624: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f container agnhost-container: <nil>
STEP: delete the pod 01/24/23 19:26:59.637
Jan 24 19:26:59.659: INFO: Waiting for pod test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f to disappear
Jan 24 19:26:59.666: INFO: Pod test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 24 19:26:59.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1757" for this suite. 01/24/23 19:26:59.677
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":150,"skipped":2983,"failed":0}
------------------------------
• [SLOW TEST] [6.284 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:53.407
    Jan 24 19:26:53.408: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename svcaccounts 01/24/23 19:26:53.415
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:53.516
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:53.532
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  01/24/23 19:26:53.559
    Jan 24 19:26:53.596: INFO: Waiting up to 5m0s for pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f" in namespace "svcaccounts-1757" to be "Succeeded or Failed"
    Jan 24 19:26:53.605: INFO: Pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.430441ms
    Jan 24 19:26:55.614: INFO: Pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018405075s
    Jan 24 19:26:57.621: INFO: Pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025311355s
    Jan 24 19:26:59.615: INFO: Pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019355421s
    STEP: Saw pod success 01/24/23 19:26:59.615
    Jan 24 19:26:59.616: INFO: Pod "test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f" satisfied condition "Succeeded or Failed"
    Jan 24 19:26:59.624: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 19:26:59.637
    Jan 24 19:26:59.659: INFO: Waiting for pod test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f to disappear
    Jan 24 19:26:59.666: INFO: Pod test-pod-ccd8ea40-d620-462a-a17d-62f201d0f12f no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 24 19:26:59.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1757" for this suite. 01/24/23 19:26:59.677
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:59.693
Jan 24 19:26:59.693: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename lease-test 01/24/23 19:26:59.698
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:59.738
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:59.746
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Jan 24 19:26:59.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-4967" for this suite. 01/24/23 19:26:59.87
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":151,"skipped":2995,"failed":0}
------------------------------
• [0.188 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:59.693
    Jan 24 19:26:59.693: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename lease-test 01/24/23 19:26:59.698
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:59.738
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:59.746
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Jan 24 19:26:59.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-4967" for this suite. 01/24/23 19:26:59.87
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:59.888
Jan 24 19:26:59.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename server-version 01/24/23 19:26:59.891
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:59.92
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:59.927
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 01/24/23 19:26:59.935
STEP: Confirm major version 01/24/23 19:26:59.937
Jan 24 19:26:59.937: INFO: Major version: 1
STEP: Confirm minor version 01/24/23 19:26:59.938
Jan 24 19:26:59.938: INFO: cleanMinorVersion: 25
Jan 24 19:26:59.938: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Jan 24 19:26:59.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-9089" for this suite. 01/24/23 19:26:59.954
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":152,"skipped":2995,"failed":0}
------------------------------
• [0.081 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:59.888
    Jan 24 19:26:59.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename server-version 01/24/23 19:26:59.891
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:26:59.92
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:26:59.927
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 01/24/23 19:26:59.935
    STEP: Confirm major version 01/24/23 19:26:59.937
    Jan 24 19:26:59.937: INFO: Major version: 1
    STEP: Confirm minor version 01/24/23 19:26:59.938
    Jan 24 19:26:59.938: INFO: cleanMinorVersion: 25
    Jan 24 19:26:59.938: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Jan 24 19:26:59.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-9089" for this suite. 01/24/23 19:26:59.954
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:26:59.972
Jan 24 19:26:59.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 19:26:59.975
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:00.004
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:00.018
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 01/24/23 19:27:00.032
Jan 24 19:27:00.076: INFO: Waiting up to 5m0s for pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056" in namespace "emptydir-4602" to be "Succeeded or Failed"
Jan 24 19:27:00.083: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056": Phase="Pending", Reason="", readiness=false. Elapsed: 5.900222ms
Jan 24 19:27:02.099: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021813468s
Jan 24 19:27:04.106: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029355799s
Jan 24 19:27:06.101: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024594493s
Jan 24 19:27:08.103: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.026363826s
STEP: Saw pod success 01/24/23 19:27:08.103
Jan 24 19:27:08.104: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056" satisfied condition "Succeeded or Failed"
Jan 24 19:27:08.166: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-ff5fb182-8b50-4351-b476-de55e6ff9056 container test-container: <nil>
STEP: delete the pod 01/24/23 19:27:08.251
Jan 24 19:27:08.408: INFO: Waiting for pod pod-ff5fb182-8b50-4351-b476-de55e6ff9056 to disappear
Jan 24 19:27:08.434: INFO: Pod pod-ff5fb182-8b50-4351-b476-de55e6ff9056 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 19:27:08.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4602" for this suite. 01/24/23 19:27:08.465
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":153,"skipped":3017,"failed":0}
------------------------------
• [SLOW TEST] [8.561 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:26:59.972
    Jan 24 19:26:59.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 19:26:59.975
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:00.004
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:00.018
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 01/24/23 19:27:00.032
    Jan 24 19:27:00.076: INFO: Waiting up to 5m0s for pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056" in namespace "emptydir-4602" to be "Succeeded or Failed"
    Jan 24 19:27:00.083: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056": Phase="Pending", Reason="", readiness=false. Elapsed: 5.900222ms
    Jan 24 19:27:02.099: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021813468s
    Jan 24 19:27:04.106: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029355799s
    Jan 24 19:27:06.101: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024594493s
    Jan 24 19:27:08.103: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.026363826s
    STEP: Saw pod success 01/24/23 19:27:08.103
    Jan 24 19:27:08.104: INFO: Pod "pod-ff5fb182-8b50-4351-b476-de55e6ff9056" satisfied condition "Succeeded or Failed"
    Jan 24 19:27:08.166: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-ff5fb182-8b50-4351-b476-de55e6ff9056 container test-container: <nil>
    STEP: delete the pod 01/24/23 19:27:08.251
    Jan 24 19:27:08.408: INFO: Waiting for pod pod-ff5fb182-8b50-4351-b476-de55e6ff9056 to disappear
    Jan 24 19:27:08.434: INFO: Pod pod-ff5fb182-8b50-4351-b476-de55e6ff9056 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 19:27:08.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4602" for this suite. 01/24/23 19:27:08.465
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:27:08.543
Jan 24 19:27:08.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 19:27:08.547
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:08.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:08.696
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4945 01/24/23 19:27:08.709
STEP: changing the ExternalName service to type=ClusterIP 01/24/23 19:27:08.748
STEP: creating replication controller externalname-service in namespace services-4945 01/24/23 19:27:08.843
I0124 19:27:08.891063      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4945, replica count: 2
I0124 19:27:11.954777      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:27:14.955544      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 19:27:14.955: INFO: Creating new exec pod
Jan 24 19:27:14.979: INFO: Waiting up to 5m0s for pod "execpod6fdvj" in namespace "services-4945" to be "running"
Jan 24 19:27:14.997: INFO: Pod "execpod6fdvj": Phase="Pending", Reason="", readiness=false. Elapsed: 17.549467ms
Jan 24 19:27:17.007: INFO: Pod "execpod6fdvj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027637572s
Jan 24 19:27:19.027: INFO: Pod "execpod6fdvj": Phase="Running", Reason="", readiness=true. Elapsed: 4.047642424s
Jan 24 19:27:19.028: INFO: Pod "execpod6fdvj" satisfied condition "running"
Jan 24 19:27:20.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4945 exec execpod6fdvj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jan 24 19:27:20.721: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jan 24 19:27:20.721: INFO: stdout: ""
Jan 24 19:27:21.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4945 exec execpod6fdvj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jan 24 19:27:22.201: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jan 24 19:27:22.202: INFO: stdout: ""
Jan 24 19:27:22.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4945 exec execpod6fdvj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jan 24 19:27:23.314: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jan 24 19:27:23.314: INFO: stdout: "externalname-service-fwff4"
Jan 24 19:27:23.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4945 exec execpod6fdvj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.251.166 80'
Jan 24 19:27:23.733: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.251.166 80\nConnection to 10.10.251.166 80 port [tcp/http] succeeded!\n"
Jan 24 19:27:23.733: INFO: stdout: "externalname-service-9rkrc"
Jan 24 19:27:23.733: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 19:27:23.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4945" for this suite. 01/24/23 19:27:23.815
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":154,"skipped":3030,"failed":0}
------------------------------
• [SLOW TEST] [15.330 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:27:08.543
    Jan 24 19:27:08.543: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 19:27:08.547
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:08.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:08.696
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-4945 01/24/23 19:27:08.709
    STEP: changing the ExternalName service to type=ClusterIP 01/24/23 19:27:08.748
    STEP: creating replication controller externalname-service in namespace services-4945 01/24/23 19:27:08.843
    I0124 19:27:08.891063      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4945, replica count: 2
    I0124 19:27:11.954777      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:27:14.955544      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 19:27:14.955: INFO: Creating new exec pod
    Jan 24 19:27:14.979: INFO: Waiting up to 5m0s for pod "execpod6fdvj" in namespace "services-4945" to be "running"
    Jan 24 19:27:14.997: INFO: Pod "execpod6fdvj": Phase="Pending", Reason="", readiness=false. Elapsed: 17.549467ms
    Jan 24 19:27:17.007: INFO: Pod "execpod6fdvj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027637572s
    Jan 24 19:27:19.027: INFO: Pod "execpod6fdvj": Phase="Running", Reason="", readiness=true. Elapsed: 4.047642424s
    Jan 24 19:27:19.028: INFO: Pod "execpod6fdvj" satisfied condition "running"
    Jan 24 19:27:20.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4945 exec execpod6fdvj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Jan 24 19:27:20.721: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Jan 24 19:27:20.721: INFO: stdout: ""
    Jan 24 19:27:21.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4945 exec execpod6fdvj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Jan 24 19:27:22.201: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Jan 24 19:27:22.202: INFO: stdout: ""
    Jan 24 19:27:22.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4945 exec execpod6fdvj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Jan 24 19:27:23.314: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Jan 24 19:27:23.314: INFO: stdout: "externalname-service-fwff4"
    Jan 24 19:27:23.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4945 exec execpod6fdvj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.251.166 80'
    Jan 24 19:27:23.733: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.251.166 80\nConnection to 10.10.251.166 80 port [tcp/http] succeeded!\n"
    Jan 24 19:27:23.733: INFO: stdout: "externalname-service-9rkrc"
    Jan 24 19:27:23.733: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 19:27:23.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4945" for this suite. 01/24/23 19:27:23.815
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:27:23.935
Jan 24 19:27:23.936: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 19:27:23.944
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:24.036
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:24.048
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 01/24/23 19:27:24.067
Jan 24 19:27:24.148: INFO: Waiting up to 5m0s for pod "pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad" in namespace "pods-8060" to be "running and ready"
Jan 24 19:27:24.177: INFO: Pod "pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad": Phase="Pending", Reason="", readiness=false. Elapsed: 29.103954ms
Jan 24 19:27:24.178: INFO: The phase of Pod pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:27:26.193: INFO: Pod "pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044878385s
Jan 24 19:27:26.193: INFO: The phase of Pod pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:27:28.241: INFO: Pod "pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad": Phase="Running", Reason="", readiness=true. Elapsed: 4.092295509s
Jan 24 19:27:28.241: INFO: The phase of Pod pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad is Running (Ready = true)
Jan 24 19:27:28.241: INFO: Pod "pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad" satisfied condition "running and ready"
Jan 24 19:27:28.271: INFO: Pod pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad has hostIP: 10.10.1.127
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 24 19:27:28.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8060" for this suite. 01/24/23 19:27:28.283
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":155,"skipped":3050,"failed":0}
------------------------------
• [4.390 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:27:23.935
    Jan 24 19:27:23.936: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 19:27:23.944
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:24.036
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:24.048
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 01/24/23 19:27:24.067
    Jan 24 19:27:24.148: INFO: Waiting up to 5m0s for pod "pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad" in namespace "pods-8060" to be "running and ready"
    Jan 24 19:27:24.177: INFO: Pod "pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad": Phase="Pending", Reason="", readiness=false. Elapsed: 29.103954ms
    Jan 24 19:27:24.178: INFO: The phase of Pod pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:27:26.193: INFO: Pod "pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044878385s
    Jan 24 19:27:26.193: INFO: The phase of Pod pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:27:28.241: INFO: Pod "pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad": Phase="Running", Reason="", readiness=true. Elapsed: 4.092295509s
    Jan 24 19:27:28.241: INFO: The phase of Pod pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad is Running (Ready = true)
    Jan 24 19:27:28.241: INFO: Pod "pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad" satisfied condition "running and ready"
    Jan 24 19:27:28.271: INFO: Pod pod-hostip-ff3fda31-3f63-4d66-9dd2-ad11644ec7ad has hostIP: 10.10.1.127
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 24 19:27:28.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8060" for this suite. 01/24/23 19:27:28.283
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:27:28.333
Jan 24 19:27:28.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 19:27:28.336
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:28.394
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:28.422
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 19:27:28.566
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:27:34.869
STEP: Deploying the webhook pod 01/24/23 19:27:34.906
STEP: Wait for the deployment to be ready 01/24/23 19:27:34.954
Jan 24 19:27:35.004: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Jan 24 19:27:37.053: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 27, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 19:27:39.069: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 27, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 19:27:41.082
STEP: Verifying the service has paired with the endpoint 01/24/23 19:27:41.129
Jan 24 19:27:42.130: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 01/24/23 19:27:42.141
STEP: create a configmap that should be updated by the webhook 01/24/23 19:27:42.182
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:27:42.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3760" for this suite. 01/24/23 19:27:42.326
STEP: Destroying namespace "webhook-3760-markers" for this suite. 01/24/23 19:27:42.351
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":156,"skipped":3082,"failed":0}
------------------------------
• [SLOW TEST] [14.213 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:27:28.333
    Jan 24 19:27:28.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 19:27:28.336
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:28.394
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:28.422
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 19:27:28.566
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:27:34.869
    STEP: Deploying the webhook pod 01/24/23 19:27:34.906
    STEP: Wait for the deployment to be ready 01/24/23 19:27:34.954
    Jan 24 19:27:35.004: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Jan 24 19:27:37.053: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 27, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 19:27:39.069: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 27, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 27, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 19:27:41.082
    STEP: Verifying the service has paired with the endpoint 01/24/23 19:27:41.129
    Jan 24 19:27:42.130: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 01/24/23 19:27:42.141
    STEP: create a configmap that should be updated by the webhook 01/24/23 19:27:42.182
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:27:42.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3760" for this suite. 01/24/23 19:27:42.326
    STEP: Destroying namespace "webhook-3760-markers" for this suite. 01/24/23 19:27:42.351
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:27:42.619
Jan 24 19:27:42.619: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 19:27:42.714
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:42.908
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:43.021
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 01/24/23 19:27:43.129
STEP: listing secrets in all namespaces to ensure that there are more than zero 01/24/23 19:27:43.228
STEP: patching the secret 01/24/23 19:27:43.241
STEP: deleting the secret using a LabelSelector 01/24/23 19:27:43.316
STEP: listing secrets in all namespaces, searching for label name and value in patch 01/24/23 19:27:43.364
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jan 24 19:27:43.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8133" for this suite. 01/24/23 19:27:43.389
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":157,"skipped":3116,"failed":0}
------------------------------
• [0.789 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:27:42.619
    Jan 24 19:27:42.619: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 19:27:42.714
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:42.908
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:43.021
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 01/24/23 19:27:43.129
    STEP: listing secrets in all namespaces to ensure that there are more than zero 01/24/23 19:27:43.228
    STEP: patching the secret 01/24/23 19:27:43.241
    STEP: deleting the secret using a LabelSelector 01/24/23 19:27:43.316
    STEP: listing secrets in all namespaces, searching for label name and value in patch 01/24/23 19:27:43.364
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 19:27:43.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8133" for this suite. 01/24/23 19:27:43.389
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:27:43.412
Jan 24 19:27:43.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 19:27:43.42
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:43.477
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:43.501
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-6904 01/24/23 19:27:43.54
STEP: creating replication controller nodeport-test in namespace services-6904 01/24/23 19:27:43.607
I0124 19:27:43.666004      22 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-6904, replica count: 2
I0124 19:27:46.721423      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:27:49.723267      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 19:27:49.723: INFO: Creating new exec pod
Jan 24 19:27:49.755: INFO: Waiting up to 5m0s for pod "execpodt64t4" in namespace "services-6904" to be "running"
Jan 24 19:27:49.807: INFO: Pod "execpodt64t4": Phase="Pending", Reason="", readiness=false. Elapsed: 49.298069ms
Jan 24 19:27:51.824: INFO: Pod "execpodt64t4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067020549s
Jan 24 19:27:53.822: INFO: Pod "execpodt64t4": Phase="Running", Reason="", readiness=true. Elapsed: 4.064929967s
Jan 24 19:27:53.823: INFO: Pod "execpodt64t4" satisfied condition "running"
Jan 24 19:27:54.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jan 24 19:27:55.493: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jan 24 19:27:55.493: INFO: stdout: "nodeport-test-mjlp9"
Jan 24 19:27:55.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.166.202 80'
Jan 24 19:27:56.101: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.166.202 80\nConnection to 10.10.166.202 80 port [tcp/http] succeeded!\n"
Jan 24 19:27:56.101: INFO: stdout: "nodeport-test-mjlp9"
Jan 24 19:27:56.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 30292'
Jan 24 19:27:56.779: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 30292\nConnection to 10.10.1.213 30292 port [tcp/*] succeeded!\n"
Jan 24 19:27:56.779: INFO: stdout: ""
Jan 24 19:27:57.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 30292'
Jan 24 19:27:58.651: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 30292\nConnection to 10.10.1.213 30292 port [tcp/*] succeeded!\n"
Jan 24 19:27:58.651: INFO: stdout: ""
Jan 24 19:27:58.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 30292'
Jan 24 19:27:59.744: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 30292\nConnection to 10.10.1.213 30292 port [tcp/*] succeeded!\n"
Jan 24 19:27:59.744: INFO: stdout: "nodeport-test-mjlp9"
Jan 24 19:27:59.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.127 30292'
Jan 24 19:28:01.104: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.127 30292\nConnection to 10.10.1.127 30292 port [tcp/*] succeeded!\n"
Jan 24 19:28:01.105: INFO: stdout: "nodeport-test-5q6kg"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 19:28:01.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6904" for this suite. 01/24/23 19:28:01.119
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":158,"skipped":3116,"failed":0}
------------------------------
• [SLOW TEST] [17.741 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:27:43.412
    Jan 24 19:27:43.412: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 19:27:43.42
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:27:43.477
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:27:43.501
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-6904 01/24/23 19:27:43.54
    STEP: creating replication controller nodeport-test in namespace services-6904 01/24/23 19:27:43.607
    I0124 19:27:43.666004      22 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-6904, replica count: 2
    I0124 19:27:46.721423      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:27:49.723267      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 19:27:49.723: INFO: Creating new exec pod
    Jan 24 19:27:49.755: INFO: Waiting up to 5m0s for pod "execpodt64t4" in namespace "services-6904" to be "running"
    Jan 24 19:27:49.807: INFO: Pod "execpodt64t4": Phase="Pending", Reason="", readiness=false. Elapsed: 49.298069ms
    Jan 24 19:27:51.824: INFO: Pod "execpodt64t4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067020549s
    Jan 24 19:27:53.822: INFO: Pod "execpodt64t4": Phase="Running", Reason="", readiness=true. Elapsed: 4.064929967s
    Jan 24 19:27:53.823: INFO: Pod "execpodt64t4" satisfied condition "running"
    Jan 24 19:27:54.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Jan 24 19:27:55.493: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Jan 24 19:27:55.493: INFO: stdout: "nodeport-test-mjlp9"
    Jan 24 19:27:55.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.166.202 80'
    Jan 24 19:27:56.101: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.166.202 80\nConnection to 10.10.166.202 80 port [tcp/http] succeeded!\n"
    Jan 24 19:27:56.101: INFO: stdout: "nodeport-test-mjlp9"
    Jan 24 19:27:56.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 30292'
    Jan 24 19:27:56.779: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 30292\nConnection to 10.10.1.213 30292 port [tcp/*] succeeded!\n"
    Jan 24 19:27:56.779: INFO: stdout: ""
    Jan 24 19:27:57.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 30292'
    Jan 24 19:27:58.651: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 30292\nConnection to 10.10.1.213 30292 port [tcp/*] succeeded!\n"
    Jan 24 19:27:58.651: INFO: stdout: ""
    Jan 24 19:27:58.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 30292'
    Jan 24 19:27:59.744: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 30292\nConnection to 10.10.1.213 30292 port [tcp/*] succeeded!\n"
    Jan 24 19:27:59.744: INFO: stdout: "nodeport-test-mjlp9"
    Jan 24 19:27:59.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6904 exec execpodt64t4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.127 30292'
    Jan 24 19:28:01.104: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.127 30292\nConnection to 10.10.1.127 30292 port [tcp/*] succeeded!\n"
    Jan 24 19:28:01.105: INFO: stdout: "nodeport-test-5q6kg"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 19:28:01.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6904" for this suite. 01/24/23 19:28:01.119
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:28:01.166
Jan 24 19:28:01.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:28:01.191
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:28:01.273
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:28:01.311
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-dca59eab-c445-4ca0-9287-4ec31243f660 01/24/23 19:28:01.334
STEP: Creating a pod to test consume secrets 01/24/23 19:28:01.346
Jan 24 19:28:01.377: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310" in namespace "projected-6017" to be "Succeeded or Failed"
Jan 24 19:28:01.404: INFO: Pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310": Phase="Pending", Reason="", readiness=false. Elapsed: 27.28701ms
Jan 24 19:28:03.417: INFO: Pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040351256s
Jan 24 19:28:05.430: INFO: Pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05320891s
Jan 24 19:28:07.416: INFO: Pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039022727s
STEP: Saw pod success 01/24/23 19:28:07.416
Jan 24 19:28:07.417: INFO: Pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310" satisfied condition "Succeeded or Failed"
Jan 24 19:28:07.446: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310 container projected-secret-volume-test: <nil>
STEP: delete the pod 01/24/23 19:28:07.608
Jan 24 19:28:07.857: INFO: Waiting for pod pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310 to disappear
Jan 24 19:28:07.954: INFO: Pod pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 24 19:28:07.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6017" for this suite. 01/24/23 19:28:08.005
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":159,"skipped":3129,"failed":0}
------------------------------
• [SLOW TEST] [7.127 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:28:01.166
    Jan 24 19:28:01.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:28:01.191
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:28:01.273
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:28:01.311
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-dca59eab-c445-4ca0-9287-4ec31243f660 01/24/23 19:28:01.334
    STEP: Creating a pod to test consume secrets 01/24/23 19:28:01.346
    Jan 24 19:28:01.377: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310" in namespace "projected-6017" to be "Succeeded or Failed"
    Jan 24 19:28:01.404: INFO: Pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310": Phase="Pending", Reason="", readiness=false. Elapsed: 27.28701ms
    Jan 24 19:28:03.417: INFO: Pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040351256s
    Jan 24 19:28:05.430: INFO: Pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05320891s
    Jan 24 19:28:07.416: INFO: Pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.039022727s
    STEP: Saw pod success 01/24/23 19:28:07.416
    Jan 24 19:28:07.417: INFO: Pod "pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310" satisfied condition "Succeeded or Failed"
    Jan 24 19:28:07.446: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310 container projected-secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 19:28:07.608
    Jan 24 19:28:07.857: INFO: Waiting for pod pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310 to disappear
    Jan 24 19:28:07.954: INFO: Pod pod-projected-secrets-05504d2d-6efd-4b19-b0d3-367b89405310 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 24 19:28:07.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6017" for this suite. 01/24/23 19:28:08.005
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:28:08.413
Jan 24 19:28:08.432: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sched-preemption 01/24/23 19:28:08.444
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:28:08.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:28:08.78
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jan 24 19:28:09.193: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 24 19:29:09.417: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 01/24/23 19:29:09.431
Jan 24 19:29:09.556: INFO: Created pod: pod0-0-sched-preemption-low-priority
Jan 24 19:29:09.588: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Jan 24 19:29:09.728: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Jan 24 19:29:09.764: INFO: Created pod: pod1-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 01/24/23 19:29:09.773
Jan 24 19:29:09.774: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-5684" to be "running"
Jan 24 19:29:09.797: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 23.004761ms
Jan 24 19:29:11.810: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036089741s
Jan 24 19:29:13.848: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074213441s
Jan 24 19:29:15.903: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.129097341s
Jan 24 19:29:17.828: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05393124s
Jan 24 19:29:19.839: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.065319411s
Jan 24 19:29:21.859: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 12.084770805s
Jan 24 19:29:23.809: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 14.035054385s
Jan 24 19:29:25.826: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 16.05227561s
Jan 24 19:29:25.826: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Jan 24 19:29:25.827: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-5684" to be "running"
Jan 24 19:29:25.869: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 42.760011ms
Jan 24 19:29:27.879: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.052518394s
Jan 24 19:29:27.879: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Jan 24 19:29:27.879: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-5684" to be "running"
Jan 24 19:29:27.899: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 19.133271ms
Jan 24 19:29:27.899: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Jan 24 19:29:27.899: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-5684" to be "running"
Jan 24 19:29:27.922: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 23.460381ms
Jan 24 19:29:27.922: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 01/24/23 19:29:27.922
Jan 24 19:29:27.959: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-5684" to be "running"
Jan 24 19:29:27.992: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 31.970179ms
Jan 24 19:29:30.015: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055532396s
Jan 24 19:29:32.027: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.067264085s
Jan 24 19:29:34.029: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.069667867s
Jan 24 19:29:36.012: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.052289668s
Jan 24 19:29:38.017: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 10.057549382s
Jan 24 19:29:38.018: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jan 24 19:29:38.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-5684" for this suite. 01/24/23 19:29:38.119
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":160,"skipped":3132,"failed":0}
------------------------------
• [SLOW TEST] [90.477 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:28:08.413
    Jan 24 19:28:08.432: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sched-preemption 01/24/23 19:28:08.444
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:28:08.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:28:08.78
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jan 24 19:28:09.193: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 24 19:29:09.417: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 01/24/23 19:29:09.431
    Jan 24 19:29:09.556: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Jan 24 19:29:09.588: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Jan 24 19:29:09.728: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Jan 24 19:29:09.764: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 01/24/23 19:29:09.773
    Jan 24 19:29:09.774: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-5684" to be "running"
    Jan 24 19:29:09.797: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 23.004761ms
    Jan 24 19:29:11.810: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036089741s
    Jan 24 19:29:13.848: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074213441s
    Jan 24 19:29:15.903: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.129097341s
    Jan 24 19:29:17.828: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05393124s
    Jan 24 19:29:19.839: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.065319411s
    Jan 24 19:29:21.859: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 12.084770805s
    Jan 24 19:29:23.809: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 14.035054385s
    Jan 24 19:29:25.826: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 16.05227561s
    Jan 24 19:29:25.826: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Jan 24 19:29:25.827: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-5684" to be "running"
    Jan 24 19:29:25.869: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 42.760011ms
    Jan 24 19:29:27.879: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.052518394s
    Jan 24 19:29:27.879: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Jan 24 19:29:27.879: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-5684" to be "running"
    Jan 24 19:29:27.899: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 19.133271ms
    Jan 24 19:29:27.899: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Jan 24 19:29:27.899: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-5684" to be "running"
    Jan 24 19:29:27.922: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 23.460381ms
    Jan 24 19:29:27.922: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 01/24/23 19:29:27.922
    Jan 24 19:29:27.959: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-5684" to be "running"
    Jan 24 19:29:27.992: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 31.970179ms
    Jan 24 19:29:30.015: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055532396s
    Jan 24 19:29:32.027: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.067264085s
    Jan 24 19:29:34.029: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.069667867s
    Jan 24 19:29:36.012: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.052289668s
    Jan 24 19:29:38.017: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 10.057549382s
    Jan 24 19:29:38.018: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 19:29:38.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-5684" for this suite. 01/24/23 19:29:38.119
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:29:38.891
Jan 24 19:29:38.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename job 01/24/23 19:29:38.897
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:29:38.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:29:38.988
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 01/24/23 19:29:39.05
STEP: Patching the Job 01/24/23 19:29:39.076
STEP: Watching for Job to be patched 01/24/23 19:29:39.147
Jan 24 19:29:39.157: INFO: Event ADDED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking:]
Jan 24 19:29:39.158: INFO: Event MODIFIED found for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 01/24/23 19:29:39.16
STEP: Watching for Job to be updated 01/24/23 19:29:39.428
Jan 24 19:29:39.440: INFO: Event MODIFIED found for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 24 19:29:39.440: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 01/24/23 19:29:39.44
Jan 24 19:29:39.508: INFO: Job: e2e-77mv9 as labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9]
STEP: Waiting for job to complete 01/24/23 19:29:39.509
STEP: Delete a job collection with a labelselector 01/24/23 19:29:51.52
STEP: Watching for Job to be deleted 01/24/23 19:29:51.538
Jan 24 19:29:51.553: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 24 19:29:51.553: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 24 19:29:51.553: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 24 19:29:51.553: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 24 19:29:51.553: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 24 19:29:51.554: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 24 19:29:51.555: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 24 19:29:51.555: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 24 19:29:51.555: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Jan 24 19:29:51.555: INFO: Event DELETED found for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 01/24/23 19:29:51.555
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 24 19:29:51.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3654" for this suite. 01/24/23 19:29:51.586
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":161,"skipped":3132,"failed":0}
------------------------------
• [SLOW TEST] [12.719 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:29:38.891
    Jan 24 19:29:38.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename job 01/24/23 19:29:38.897
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:29:38.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:29:38.988
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 01/24/23 19:29:39.05
    STEP: Patching the Job 01/24/23 19:29:39.076
    STEP: Watching for Job to be patched 01/24/23 19:29:39.147
    Jan 24 19:29:39.157: INFO: Event ADDED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking:]
    Jan 24 19:29:39.158: INFO: Event MODIFIED found for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 01/24/23 19:29:39.16
    STEP: Watching for Job to be updated 01/24/23 19:29:39.428
    Jan 24 19:29:39.440: INFO: Event MODIFIED found for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 24 19:29:39.440: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 01/24/23 19:29:39.44
    Jan 24 19:29:39.508: INFO: Job: e2e-77mv9 as labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9]
    STEP: Waiting for job to complete 01/24/23 19:29:39.509
    STEP: Delete a job collection with a labelselector 01/24/23 19:29:51.52
    STEP: Watching for Job to be deleted 01/24/23 19:29:51.538
    Jan 24 19:29:51.553: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 24 19:29:51.553: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 24 19:29:51.553: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 24 19:29:51.553: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 24 19:29:51.553: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 24 19:29:51.554: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 24 19:29:51.555: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 24 19:29:51.555: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 24 19:29:51.555: INFO: Event MODIFIED observed for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Jan 24 19:29:51.555: INFO: Event DELETED found for Job e2e-77mv9 in namespace job-3654 with labels: map[e2e-77mv9:patched e2e-job-label:e2e-77mv9] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 01/24/23 19:29:51.555
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 24 19:29:51.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3654" for this suite. 01/24/23 19:29:51.586
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:29:51.611
Jan 24 19:29:51.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubelet-test 01/24/23 19:29:51.614
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:29:51.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:29:51.758
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jan 24 19:29:51.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8487" for this suite. 01/24/23 19:29:51.834
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":162,"skipped":3136,"failed":0}
------------------------------
• [0.245 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:29:51.611
    Jan 24 19:29:51.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubelet-test 01/24/23 19:29:51.614
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:29:51.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:29:51.758
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jan 24 19:29:51.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8487" for this suite. 01/24/23 19:29:51.834
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:29:51.858
Jan 24 19:29:51.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 01/24/23 19:29:51.863
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:29:51.905
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:29:51.925
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 01/24/23 19:29:51.944
STEP: Creating hostNetwork=false pod 01/24/23 19:29:51.945
Jan 24 19:29:51.971: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-4753" to be "running and ready"
Jan 24 19:29:51.980: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.541258ms
Jan 24 19:29:51.980: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:29:54.034: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062854558s
Jan 24 19:29:54.034: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:29:56.003: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.032000433s
Jan 24 19:29:56.003: INFO: The phase of Pod test-pod is Running (Ready = true)
Jan 24 19:29:56.003: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 01/24/23 19:29:56.017
Jan 24 19:29:56.039: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-4753" to be "running and ready"
Jan 24 19:29:56.053: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.026679ms
Jan 24 19:29:56.056: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:29:58.073: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034093598s
Jan 24 19:29:58.073: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:30:00.122: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.083514592s
Jan 24 19:30:00.122: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Jan 24 19:30:00.122: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 01/24/23 19:30:00.159
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 01/24/23 19:30:00.16
Jan 24 19:30:00.160: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:30:00.160: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:30:00.162: INFO: ExecWithOptions: Clientset creation
Jan 24 19:30:00.162: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jan 24 19:30:00.770: INFO: Exec stderr: ""
Jan 24 19:30:00.770: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:30:00.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:30:00.771: INFO: ExecWithOptions: Clientset creation
Jan 24 19:30:00.772: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jan 24 19:30:01.088: INFO: Exec stderr: ""
Jan 24 19:30:01.088: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:30:01.088: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:30:01.090: INFO: ExecWithOptions: Clientset creation
Jan 24 19:30:01.090: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jan 24 19:30:01.402: INFO: Exec stderr: ""
Jan 24 19:30:01.402: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:30:01.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:30:01.405: INFO: ExecWithOptions: Clientset creation
Jan 24 19:30:01.406: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jan 24 19:30:01.619: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 01/24/23 19:30:01.619
Jan 24 19:30:01.620: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:30:01.620: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:30:01.622: INFO: ExecWithOptions: Clientset creation
Jan 24 19:30:01.622: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Jan 24 19:30:01.836: INFO: Exec stderr: ""
Jan 24 19:30:01.837: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:30:01.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:30:01.839: INFO: ExecWithOptions: Clientset creation
Jan 24 19:30:01.840: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Jan 24 19:30:02.047: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 01/24/23 19:30:02.047
Jan 24 19:30:02.048: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:30:02.048: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:30:02.051: INFO: ExecWithOptions: Clientset creation
Jan 24 19:30:02.052: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jan 24 19:30:02.341: INFO: Exec stderr: ""
Jan 24 19:30:02.341: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:30:02.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:30:02.354: INFO: ExecWithOptions: Clientset creation
Jan 24 19:30:02.354: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jan 24 19:30:02.814: INFO: Exec stderr: ""
Jan 24 19:30:02.814: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:30:02.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:30:02.821: INFO: ExecWithOptions: Clientset creation
Jan 24 19:30:02.821: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jan 24 19:30:03.180: INFO: Exec stderr: ""
Jan 24 19:30:03.181: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:30:03.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:30:03.185: INFO: ExecWithOptions: Clientset creation
Jan 24 19:30:03.185: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jan 24 19:30:03.440: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Jan 24 19:30:03.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4753" for this suite. 01/24/23 19:30:03.466
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":163,"skipped":3140,"failed":0}
------------------------------
• [SLOW TEST] [11.653 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:29:51.858
    Jan 24 19:29:51.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 01/24/23 19:29:51.863
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:29:51.905
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:29:51.925
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 01/24/23 19:29:51.944
    STEP: Creating hostNetwork=false pod 01/24/23 19:29:51.945
    Jan 24 19:29:51.971: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-4753" to be "running and ready"
    Jan 24 19:29:51.980: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.541258ms
    Jan 24 19:29:51.980: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:29:54.034: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062854558s
    Jan 24 19:29:54.034: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:29:56.003: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.032000433s
    Jan 24 19:29:56.003: INFO: The phase of Pod test-pod is Running (Ready = true)
    Jan 24 19:29:56.003: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 01/24/23 19:29:56.017
    Jan 24 19:29:56.039: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-4753" to be "running and ready"
    Jan 24 19:29:56.053: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.026679ms
    Jan 24 19:29:56.056: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:29:58.073: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034093598s
    Jan 24 19:29:58.073: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:30:00.122: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.083514592s
    Jan 24 19:30:00.122: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Jan 24 19:30:00.122: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 01/24/23 19:30:00.159
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 01/24/23 19:30:00.16
    Jan 24 19:30:00.160: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:30:00.160: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:30:00.162: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:30:00.162: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jan 24 19:30:00.770: INFO: Exec stderr: ""
    Jan 24 19:30:00.770: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:30:00.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:30:00.771: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:30:00.772: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jan 24 19:30:01.088: INFO: Exec stderr: ""
    Jan 24 19:30:01.088: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:30:01.088: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:30:01.090: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:30:01.090: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jan 24 19:30:01.402: INFO: Exec stderr: ""
    Jan 24 19:30:01.402: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:30:01.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:30:01.405: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:30:01.406: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jan 24 19:30:01.619: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 01/24/23 19:30:01.619
    Jan 24 19:30:01.620: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:30:01.620: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:30:01.622: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:30:01.622: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Jan 24 19:30:01.836: INFO: Exec stderr: ""
    Jan 24 19:30:01.837: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:30:01.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:30:01.839: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:30:01.840: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Jan 24 19:30:02.047: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 01/24/23 19:30:02.047
    Jan 24 19:30:02.048: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:30:02.048: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:30:02.051: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:30:02.052: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jan 24 19:30:02.341: INFO: Exec stderr: ""
    Jan 24 19:30:02.341: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:30:02.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:30:02.354: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:30:02.354: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Jan 24 19:30:02.814: INFO: Exec stderr: ""
    Jan 24 19:30:02.814: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:30:02.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:30:02.821: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:30:02.821: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jan 24 19:30:03.180: INFO: Exec stderr: ""
    Jan 24 19:30:03.181: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4753 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:30:03.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:30:03.185: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:30:03.185: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4753/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Jan 24 19:30:03.440: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Jan 24 19:30:03.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-4753" for this suite. 01/24/23 19:30:03.466
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:30:03.536
Jan 24 19:30:03.536: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 19:30:03.539
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:30:03.597
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:30:03.612
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Jan 24 19:30:03.678: INFO: Waiting up to 5m0s for pod "server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268" in namespace "pods-4569" to be "running and ready"
Jan 24 19:30:03.696: INFO: Pod "server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268": Phase="Pending", Reason="", readiness=false. Elapsed: 18.424535ms
Jan 24 19:30:03.696: INFO: The phase of Pod server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:30:05.709: INFO: Pod "server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030891272s
Jan 24 19:30:05.709: INFO: The phase of Pod server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:30:07.709: INFO: Pod "server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268": Phase="Running", Reason="", readiness=true. Elapsed: 4.031335515s
Jan 24 19:30:07.710: INFO: The phase of Pod server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268 is Running (Ready = true)
Jan 24 19:30:07.710: INFO: Pod "server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268" satisfied condition "running and ready"
Jan 24 19:30:07.782: INFO: Waiting up to 5m0s for pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25" in namespace "pods-4569" to be "Succeeded or Failed"
Jan 24 19:30:07.817: INFO: Pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25": Phase="Pending", Reason="", readiness=false. Elapsed: 35.088753ms
Jan 24 19:30:09.857: INFO: Pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074835429s
Jan 24 19:30:11.832: INFO: Pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04974365s
Jan 24 19:30:13.841: INFO: Pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059092243s
STEP: Saw pod success 01/24/23 19:30:13.841
Jan 24 19:30:13.842: INFO: Pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25" satisfied condition "Succeeded or Failed"
Jan 24 19:30:13.857: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod client-envvars-804c2327-69d5-4679-b644-4d06165dea25 container env3cont: <nil>
STEP: delete the pod 01/24/23 19:30:13.915
Jan 24 19:30:14.011: INFO: Waiting for pod client-envvars-804c2327-69d5-4679-b644-4d06165dea25 to disappear
Jan 24 19:30:14.025: INFO: Pod client-envvars-804c2327-69d5-4679-b644-4d06165dea25 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 24 19:30:14.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4569" for this suite. 01/24/23 19:30:14.047
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":164,"skipped":3231,"failed":0}
------------------------------
• [SLOW TEST] [10.544 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:30:03.536
    Jan 24 19:30:03.536: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 19:30:03.539
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:30:03.597
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:30:03.612
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Jan 24 19:30:03.678: INFO: Waiting up to 5m0s for pod "server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268" in namespace "pods-4569" to be "running and ready"
    Jan 24 19:30:03.696: INFO: Pod "server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268": Phase="Pending", Reason="", readiness=false. Elapsed: 18.424535ms
    Jan 24 19:30:03.696: INFO: The phase of Pod server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:30:05.709: INFO: Pod "server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030891272s
    Jan 24 19:30:05.709: INFO: The phase of Pod server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:30:07.709: INFO: Pod "server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268": Phase="Running", Reason="", readiness=true. Elapsed: 4.031335515s
    Jan 24 19:30:07.710: INFO: The phase of Pod server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268 is Running (Ready = true)
    Jan 24 19:30:07.710: INFO: Pod "server-envvars-5344c560-601c-4e81-aaa8-1a19b7627268" satisfied condition "running and ready"
    Jan 24 19:30:07.782: INFO: Waiting up to 5m0s for pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25" in namespace "pods-4569" to be "Succeeded or Failed"
    Jan 24 19:30:07.817: INFO: Pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25": Phase="Pending", Reason="", readiness=false. Elapsed: 35.088753ms
    Jan 24 19:30:09.857: INFO: Pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074835429s
    Jan 24 19:30:11.832: INFO: Pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04974365s
    Jan 24 19:30:13.841: INFO: Pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059092243s
    STEP: Saw pod success 01/24/23 19:30:13.841
    Jan 24 19:30:13.842: INFO: Pod "client-envvars-804c2327-69d5-4679-b644-4d06165dea25" satisfied condition "Succeeded or Failed"
    Jan 24 19:30:13.857: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod client-envvars-804c2327-69d5-4679-b644-4d06165dea25 container env3cont: <nil>
    STEP: delete the pod 01/24/23 19:30:13.915
    Jan 24 19:30:14.011: INFO: Waiting for pod client-envvars-804c2327-69d5-4679-b644-4d06165dea25 to disappear
    Jan 24 19:30:14.025: INFO: Pod client-envvars-804c2327-69d5-4679-b644-4d06165dea25 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 24 19:30:14.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4569" for this suite. 01/24/23 19:30:14.047
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:30:14.086
Jan 24 19:30:14.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename var-expansion 01/24/23 19:30:14.112
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:30:14.286
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:30:14.347
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Jan 24 19:30:14.498: INFO: Waiting up to 2m0s for pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0" in namespace "var-expansion-1791" to be "container 0 failed with reason CreateContainerConfigError"
Jan 24 19:30:14.583: INFO: Pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0": Phase="Pending", Reason="", readiness=false. Elapsed: 77.394138ms
Jan 24 19:30:16.595: INFO: Pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089523338s
Jan 24 19:30:18.595: INFO: Pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.089889873s
Jan 24 19:30:18.595: INFO: Pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Jan 24 19:30:18.595: INFO: Deleting pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0" in namespace "var-expansion-1791"
Jan 24 19:30:18.640: INFO: Wait up to 5m0s for pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 24 19:30:24.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1791" for this suite. 01/24/23 19:30:24.709
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":165,"skipped":3237,"failed":0}
------------------------------
• [SLOW TEST] [10.641 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:30:14.086
    Jan 24 19:30:14.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename var-expansion 01/24/23 19:30:14.112
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:30:14.286
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:30:14.347
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Jan 24 19:30:14.498: INFO: Waiting up to 2m0s for pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0" in namespace "var-expansion-1791" to be "container 0 failed with reason CreateContainerConfigError"
    Jan 24 19:30:14.583: INFO: Pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0": Phase="Pending", Reason="", readiness=false. Elapsed: 77.394138ms
    Jan 24 19:30:16.595: INFO: Pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089523338s
    Jan 24 19:30:18.595: INFO: Pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.089889873s
    Jan 24 19:30:18.595: INFO: Pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Jan 24 19:30:18.595: INFO: Deleting pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0" in namespace "var-expansion-1791"
    Jan 24 19:30:18.640: INFO: Wait up to 5m0s for pod "var-expansion-994b3372-c84f-4bf6-90ce-5cb49ef70aa0" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 24 19:30:24.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1791" for this suite. 01/24/23 19:30:24.709
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:30:24.768
Jan 24 19:30:24.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename statefulset 01/24/23 19:30:24.772
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:30:24.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:30:25.023
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9568 01/24/23 19:30:25.053
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 01/24/23 19:30:25.155
STEP: Creating pod with conflicting port in namespace statefulset-9568 01/24/23 19:30:25.182
STEP: Waiting until pod test-pod will start running in namespace statefulset-9568 01/24/23 19:30:25.249
Jan 24 19:30:25.250: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-9568" to be "running"
Jan 24 19:30:25.388: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 137.749355ms
Jan 24 19:30:27.408: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.157961345s
Jan 24 19:30:29.425: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.17539252s
Jan 24 19:30:29.426: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-9568 01/24/23 19:30:29.426
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9568 01/24/23 19:30:29.46
Jan 24 19:30:29.532: INFO: Observed stateful pod in namespace: statefulset-9568, name: ss-0, uid: 09fd19d0-cc75-41bd-8292-ffd582dd5ebe, status phase: Pending. Waiting for statefulset controller to delete.
Jan 24 19:30:29.594: INFO: Observed stateful pod in namespace: statefulset-9568, name: ss-0, uid: 09fd19d0-cc75-41bd-8292-ffd582dd5ebe, status phase: Failed. Waiting for statefulset controller to delete.
Jan 24 19:30:29.733: INFO: Observed stateful pod in namespace: statefulset-9568, name: ss-0, uid: 09fd19d0-cc75-41bd-8292-ffd582dd5ebe, status phase: Failed. Waiting for statefulset controller to delete.
Jan 24 19:30:29.795: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9568
STEP: Removing pod with conflicting port in namespace statefulset-9568 01/24/23 19:30:29.795
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9568 and will be in running state 01/24/23 19:30:29.933
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 24 19:30:36.304: INFO: Deleting all statefulset in ns statefulset-9568
Jan 24 19:30:36.327: INFO: Scaling statefulset ss to 0
Jan 24 19:30:46.419: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 19:30:46.444: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 24 19:30:46.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9568" for this suite. 01/24/23 19:30:46.48
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":166,"skipped":3263,"failed":0}
------------------------------
• [SLOW TEST] [21.724 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:30:24.768
    Jan 24 19:30:24.769: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename statefulset 01/24/23 19:30:24.772
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:30:24.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:30:25.023
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9568 01/24/23 19:30:25.053
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 01/24/23 19:30:25.155
    STEP: Creating pod with conflicting port in namespace statefulset-9568 01/24/23 19:30:25.182
    STEP: Waiting until pod test-pod will start running in namespace statefulset-9568 01/24/23 19:30:25.249
    Jan 24 19:30:25.250: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-9568" to be "running"
    Jan 24 19:30:25.388: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 137.749355ms
    Jan 24 19:30:27.408: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.157961345s
    Jan 24 19:30:29.425: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.17539252s
    Jan 24 19:30:29.426: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-9568 01/24/23 19:30:29.426
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9568 01/24/23 19:30:29.46
    Jan 24 19:30:29.532: INFO: Observed stateful pod in namespace: statefulset-9568, name: ss-0, uid: 09fd19d0-cc75-41bd-8292-ffd582dd5ebe, status phase: Pending. Waiting for statefulset controller to delete.
    Jan 24 19:30:29.594: INFO: Observed stateful pod in namespace: statefulset-9568, name: ss-0, uid: 09fd19d0-cc75-41bd-8292-ffd582dd5ebe, status phase: Failed. Waiting for statefulset controller to delete.
    Jan 24 19:30:29.733: INFO: Observed stateful pod in namespace: statefulset-9568, name: ss-0, uid: 09fd19d0-cc75-41bd-8292-ffd582dd5ebe, status phase: Failed. Waiting for statefulset controller to delete.
    Jan 24 19:30:29.795: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9568
    STEP: Removing pod with conflicting port in namespace statefulset-9568 01/24/23 19:30:29.795
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9568 and will be in running state 01/24/23 19:30:29.933
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 24 19:30:36.304: INFO: Deleting all statefulset in ns statefulset-9568
    Jan 24 19:30:36.327: INFO: Scaling statefulset ss to 0
    Jan 24 19:30:46.419: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 19:30:46.444: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 24 19:30:46.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9568" for this suite. 01/24/23 19:30:46.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:30:46.51
Jan 24 19:30:46.510: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-probe 01/24/23 19:30:46.512
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:30:46.539
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:30:46.548
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-acbc7652-5b90-40c0-92b5-d436d747a697 in namespace container-probe-4071 01/24/23 19:30:46.556
Jan 24 19:30:46.578: INFO: Waiting up to 5m0s for pod "busybox-acbc7652-5b90-40c0-92b5-d436d747a697" in namespace "container-probe-4071" to be "not pending"
Jan 24 19:30:46.592: INFO: Pod "busybox-acbc7652-5b90-40c0-92b5-d436d747a697": Phase="Pending", Reason="", readiness=false. Elapsed: 14.630908ms
Jan 24 19:30:48.611: INFO: Pod "busybox-acbc7652-5b90-40c0-92b5-d436d747a697": Phase="Running", Reason="", readiness=true. Elapsed: 2.033447038s
Jan 24 19:30:48.612: INFO: Pod "busybox-acbc7652-5b90-40c0-92b5-d436d747a697" satisfied condition "not pending"
Jan 24 19:30:48.614: INFO: Started pod busybox-acbc7652-5b90-40c0-92b5-d436d747a697 in namespace container-probe-4071
STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:30:48.614
Jan 24 19:30:48.626: INFO: Initial restart count of pod busybox-acbc7652-5b90-40c0-92b5-d436d747a697 is 0
STEP: deleting the pod 01/24/23 19:34:49.641
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 24 19:34:49.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4071" for this suite. 01/24/23 19:34:49.709
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":167,"skipped":3283,"failed":0}
------------------------------
• [SLOW TEST] [243.264 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:30:46.51
    Jan 24 19:30:46.510: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-probe 01/24/23 19:30:46.512
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:30:46.539
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:30:46.548
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-acbc7652-5b90-40c0-92b5-d436d747a697 in namespace container-probe-4071 01/24/23 19:30:46.556
    Jan 24 19:30:46.578: INFO: Waiting up to 5m0s for pod "busybox-acbc7652-5b90-40c0-92b5-d436d747a697" in namespace "container-probe-4071" to be "not pending"
    Jan 24 19:30:46.592: INFO: Pod "busybox-acbc7652-5b90-40c0-92b5-d436d747a697": Phase="Pending", Reason="", readiness=false. Elapsed: 14.630908ms
    Jan 24 19:30:48.611: INFO: Pod "busybox-acbc7652-5b90-40c0-92b5-d436d747a697": Phase="Running", Reason="", readiness=true. Elapsed: 2.033447038s
    Jan 24 19:30:48.612: INFO: Pod "busybox-acbc7652-5b90-40c0-92b5-d436d747a697" satisfied condition "not pending"
    Jan 24 19:30:48.614: INFO: Started pod busybox-acbc7652-5b90-40c0-92b5-d436d747a697 in namespace container-probe-4071
    STEP: checking the pod's current state and verifying that restartCount is present 01/24/23 19:30:48.614
    Jan 24 19:30:48.626: INFO: Initial restart count of pod busybox-acbc7652-5b90-40c0-92b5-d436d747a697 is 0
    STEP: deleting the pod 01/24/23 19:34:49.641
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 24 19:34:49.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4071" for this suite. 01/24/23 19:34:49.709
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:34:49.777
Jan 24 19:34:49.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 19:34:49.821
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:34:49.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:34:49.904
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-2617 01/24/23 19:34:49.918
Jan 24 19:34:49.947: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-2617" to be "running and ready"
Jan 24 19:34:49.965: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 18.070767ms
Jan 24 19:34:49.965: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:34:51.975: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.028424357s
Jan 24 19:34:51.976: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Jan 24 19:34:51.977: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Jan 24 19:34:51.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Jan 24 19:34:52.552: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Jan 24 19:34:52.553: INFO: stdout: "iptables"
Jan 24 19:34:52.553: INFO: proxyMode: iptables
Jan 24 19:34:52.586: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Jan 24 19:34:52.594: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-2617 01/24/23 19:34:52.595
STEP: creating replication controller affinity-clusterip-timeout in namespace services-2617 01/24/23 19:34:52.628
I0124 19:34:52.676405      22 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-2617, replica count: 3
I0124 19:34:55.731241      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:34:58.733300      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:35:01.733786      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 19:35:01.756: INFO: Creating new exec pod
Jan 24 19:35:01.776: INFO: Waiting up to 5m0s for pod "execpod-affinity659v8" in namespace "services-2617" to be "running"
Jan 24 19:35:01.796: INFO: Pod "execpod-affinity659v8": Phase="Pending", Reason="", readiness=false. Elapsed: 19.485032ms
Jan 24 19:35:03.841: INFO: Pod "execpod-affinity659v8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064858092s
Jan 24 19:35:05.885: INFO: Pod "execpod-affinity659v8": Phase="Running", Reason="", readiness=true. Elapsed: 4.10900654s
Jan 24 19:35:05.885: INFO: Pod "execpod-affinity659v8" satisfied condition "running"
Jan 24 19:35:06.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec execpod-affinity659v8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Jan 24 19:35:07.433: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Jan 24 19:35:07.433: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:35:07.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec execpod-affinity659v8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.153.152 80'
Jan 24 19:35:08.104: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.153.152 80\nConnection to 10.10.153.152 80 port [tcp/http] succeeded!\n"
Jan 24 19:35:08.104: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:35:08.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec execpod-affinity659v8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.153.152:80/ ; done'
Jan 24 19:35:09.187: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n"
Jan 24 19:35:09.187: INFO: stdout: "\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt"
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
Jan 24 19:35:09.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec execpod-affinity659v8 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.10.153.152:80/'
Jan 24 19:35:09.767: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n"
Jan 24 19:35:09.767: INFO: stdout: "affinity-clusterip-timeout-phtbt"
Jan 24 19:35:29.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec execpod-affinity659v8 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.10.153.152:80/'
Jan 24 19:35:30.858: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n"
Jan 24 19:35:30.858: INFO: stdout: "affinity-clusterip-timeout-f7hdt"
Jan 24 19:35:30.858: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-2617, will wait for the garbage collector to delete the pods 01/24/23 19:35:31.025
Jan 24 19:35:31.236: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 50.887514ms
Jan 24 19:35:31.651: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 414.91002ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 19:35:36.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2617" for this suite. 01/24/23 19:35:36.097
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":168,"skipped":3289,"failed":0}
------------------------------
• [SLOW TEST] [46.339 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:34:49.777
    Jan 24 19:34:49.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 19:34:49.821
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:34:49.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:34:49.904
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-2617 01/24/23 19:34:49.918
    Jan 24 19:34:49.947: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-2617" to be "running and ready"
    Jan 24 19:34:49.965: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 18.070767ms
    Jan 24 19:34:49.965: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:34:51.975: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.028424357s
    Jan 24 19:34:51.976: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Jan 24 19:34:51.977: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Jan 24 19:34:51.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Jan 24 19:34:52.552: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Jan 24 19:34:52.553: INFO: stdout: "iptables"
    Jan 24 19:34:52.553: INFO: proxyMode: iptables
    Jan 24 19:34:52.586: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Jan 24 19:34:52.594: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-2617 01/24/23 19:34:52.595
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-2617 01/24/23 19:34:52.628
    I0124 19:34:52.676405      22 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-2617, replica count: 3
    I0124 19:34:55.731241      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:34:58.733300      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:35:01.733786      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 19:35:01.756: INFO: Creating new exec pod
    Jan 24 19:35:01.776: INFO: Waiting up to 5m0s for pod "execpod-affinity659v8" in namespace "services-2617" to be "running"
    Jan 24 19:35:01.796: INFO: Pod "execpod-affinity659v8": Phase="Pending", Reason="", readiness=false. Elapsed: 19.485032ms
    Jan 24 19:35:03.841: INFO: Pod "execpod-affinity659v8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064858092s
    Jan 24 19:35:05.885: INFO: Pod "execpod-affinity659v8": Phase="Running", Reason="", readiness=true. Elapsed: 4.10900654s
    Jan 24 19:35:05.885: INFO: Pod "execpod-affinity659v8" satisfied condition "running"
    Jan 24 19:35:06.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec execpod-affinity659v8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Jan 24 19:35:07.433: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Jan 24 19:35:07.433: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:35:07.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec execpod-affinity659v8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.153.152 80'
    Jan 24 19:35:08.104: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.153.152 80\nConnection to 10.10.153.152 80 port [tcp/http] succeeded!\n"
    Jan 24 19:35:08.104: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:35:08.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec execpod-affinity659v8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.153.152:80/ ; done'
    Jan 24 19:35:09.187: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n"
    Jan 24 19:35:09.187: INFO: stdout: "\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt\naffinity-clusterip-timeout-phtbt"
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Received response from host: affinity-clusterip-timeout-phtbt
    Jan 24 19:35:09.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec execpod-affinity659v8 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.10.153.152:80/'
    Jan 24 19:35:09.767: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n"
    Jan 24 19:35:09.767: INFO: stdout: "affinity-clusterip-timeout-phtbt"
    Jan 24 19:35:29.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-2617 exec execpod-affinity659v8 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.10.153.152:80/'
    Jan 24 19:35:30.858: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.10.153.152:80/\n"
    Jan 24 19:35:30.858: INFO: stdout: "affinity-clusterip-timeout-f7hdt"
    Jan 24 19:35:30.858: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-2617, will wait for the garbage collector to delete the pods 01/24/23 19:35:31.025
    Jan 24 19:35:31.236: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 50.887514ms
    Jan 24 19:35:31.651: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 414.91002ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 19:35:36.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2617" for this suite. 01/24/23 19:35:36.097
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:35:36.137
Jan 24 19:35:36.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename disruption 01/24/23 19:35:36.148
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:35:36.259
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:35:36.279
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 01/24/23 19:35:36.311
STEP: Waiting for all pods to be running 01/24/23 19:35:38.536
Jan 24 19:35:38.628: INFO: running pods: 0 < 3
Jan 24 19:35:40.662: INFO: running pods: 0 < 3
Jan 24 19:35:42.671: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jan 24 19:35:44.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1153" for this suite. 01/24/23 19:35:44.781
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":169,"skipped":3307,"failed":0}
------------------------------
• [SLOW TEST] [8.728 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:35:36.137
    Jan 24 19:35:36.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename disruption 01/24/23 19:35:36.148
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:35:36.259
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:35:36.279
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 01/24/23 19:35:36.311
    STEP: Waiting for all pods to be running 01/24/23 19:35:38.536
    Jan 24 19:35:38.628: INFO: running pods: 0 < 3
    Jan 24 19:35:40.662: INFO: running pods: 0 < 3
    Jan 24 19:35:42.671: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jan 24 19:35:44.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1153" for this suite. 01/24/23 19:35:44.781
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:35:44.877
Jan 24 19:35:44.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename gc 01/24/23 19:35:44.881
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:35:45.302
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:35:45.696
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 01/24/23 19:35:45.908
STEP: create the rc2 01/24/23 19:35:46.052
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 01/24/23 19:35:52.721
STEP: delete the rc simpletest-rc-to-be-deleted 01/24/23 19:36:24.915
STEP: wait for the rc to be deleted 01/24/23 19:36:24.968
Jan 24 19:36:32.949: INFO: 66 pods remaining
Jan 24 19:36:32.950: INFO: 66 pods has nil DeletionTimestamp
Jan 24 19:36:32.950: INFO: 
Jan 24 19:36:38.169: INFO: 58 pods remaining
Jan 24 19:36:38.169: INFO: 57 pods has nil DeletionTimestamp
Jan 24 19:36:38.169: INFO: 
STEP: Gathering metrics 01/24/23 19:36:40.219
W0124 19:36:40.257736      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 24 19:36:40.257: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Jan 24 19:36:40.257: INFO: Deleting pod "simpletest-rc-to-be-deleted-24nw8" in namespace "gc-2734"
Jan 24 19:36:40.328: INFO: Deleting pod "simpletest-rc-to-be-deleted-2cxcl" in namespace "gc-2734"
Jan 24 19:36:40.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-2dpbh" in namespace "gc-2734"
Jan 24 19:36:40.416: INFO: Deleting pod "simpletest-rc-to-be-deleted-424gt" in namespace "gc-2734"
Jan 24 19:36:40.784: INFO: Deleting pod "simpletest-rc-to-be-deleted-4b4mt" in namespace "gc-2734"
Jan 24 19:36:40.991: INFO: Deleting pod "simpletest-rc-to-be-deleted-4k97f" in namespace "gc-2734"
Jan 24 19:36:41.062: INFO: Deleting pod "simpletest-rc-to-be-deleted-4nxhr" in namespace "gc-2734"
Jan 24 19:36:41.097: INFO: Deleting pod "simpletest-rc-to-be-deleted-4pwjh" in namespace "gc-2734"
Jan 24 19:36:41.124: INFO: Deleting pod "simpletest-rc-to-be-deleted-4w7gd" in namespace "gc-2734"
Jan 24 19:36:41.154: INFO: Deleting pod "simpletest-rc-to-be-deleted-55k9f" in namespace "gc-2734"
Jan 24 19:36:41.226: INFO: Deleting pod "simpletest-rc-to-be-deleted-5n5jx" in namespace "gc-2734"
Jan 24 19:36:41.286: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zclk" in namespace "gc-2734"
Jan 24 19:36:41.326: INFO: Deleting pod "simpletest-rc-to-be-deleted-6dch4" in namespace "gc-2734"
Jan 24 19:36:41.374: INFO: Deleting pod "simpletest-rc-to-be-deleted-6g6sm" in namespace "gc-2734"
Jan 24 19:36:41.394: INFO: Deleting pod "simpletest-rc-to-be-deleted-6qbfm" in namespace "gc-2734"
Jan 24 19:36:41.444: INFO: Deleting pod "simpletest-rc-to-be-deleted-7dz4b" in namespace "gc-2734"
Jan 24 19:36:41.563: INFO: Deleting pod "simpletest-rc-to-be-deleted-7ff2w" in namespace "gc-2734"
Jan 24 19:36:41.598: INFO: Deleting pod "simpletest-rc-to-be-deleted-7fs6f" in namespace "gc-2734"
Jan 24 19:36:41.631: INFO: Deleting pod "simpletest-rc-to-be-deleted-7njkb" in namespace "gc-2734"
Jan 24 19:36:41.661: INFO: Deleting pod "simpletest-rc-to-be-deleted-85rvm" in namespace "gc-2734"
Jan 24 19:36:41.695: INFO: Deleting pod "simpletest-rc-to-be-deleted-8mmt8" in namespace "gc-2734"
Jan 24 19:36:41.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-8vhb9" in namespace "gc-2734"
Jan 24 19:36:41.812: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jwgq" in namespace "gc-2734"
Jan 24 19:36:41.886: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xlrt" in namespace "gc-2734"
Jan 24 19:36:41.922: INFO: Deleting pod "simpletest-rc-to-be-deleted-c6dct" in namespace "gc-2734"
Jan 24 19:36:42.078: INFO: Deleting pod "simpletest-rc-to-be-deleted-c7kq8" in namespace "gc-2734"
Jan 24 19:36:42.304: INFO: Deleting pod "simpletest-rc-to-be-deleted-ckmtz" in namespace "gc-2734"
Jan 24 19:36:42.342: INFO: Deleting pod "simpletest-rc-to-be-deleted-cpfqz" in namespace "gc-2734"
Jan 24 19:36:42.401: INFO: Deleting pod "simpletest-rc-to-be-deleted-cq4gz" in namespace "gc-2734"
Jan 24 19:36:42.428: INFO: Deleting pod "simpletest-rc-to-be-deleted-ffpgc" in namespace "gc-2734"
Jan 24 19:36:42.476: INFO: Deleting pod "simpletest-rc-to-be-deleted-fhzmf" in namespace "gc-2734"
Jan 24 19:36:42.569: INFO: Deleting pod "simpletest-rc-to-be-deleted-fpntq" in namespace "gc-2734"
Jan 24 19:36:42.684: INFO: Deleting pod "simpletest-rc-to-be-deleted-fqdrq" in namespace "gc-2734"
Jan 24 19:36:43.143: INFO: Deleting pod "simpletest-rc-to-be-deleted-fw6zk" in namespace "gc-2734"
Jan 24 19:36:43.892: INFO: Deleting pod "simpletest-rc-to-be-deleted-g49m9" in namespace "gc-2734"
Jan 24 19:36:44.567: INFO: Deleting pod "simpletest-rc-to-be-deleted-ggkhk" in namespace "gc-2734"
Jan 24 19:36:44.593: INFO: Deleting pod "simpletest-rc-to-be-deleted-gszr6" in namespace "gc-2734"
Jan 24 19:36:44.648: INFO: Deleting pod "simpletest-rc-to-be-deleted-gtvbd" in namespace "gc-2734"
Jan 24 19:36:44.811: INFO: Deleting pod "simpletest-rc-to-be-deleted-gvhrr" in namespace "gc-2734"
Jan 24 19:36:44.850: INFO: Deleting pod "simpletest-rc-to-be-deleted-gzmnl" in namespace "gc-2734"
Jan 24 19:36:44.898: INFO: Deleting pod "simpletest-rc-to-be-deleted-h4h98" in namespace "gc-2734"
Jan 24 19:36:45.000: INFO: Deleting pod "simpletest-rc-to-be-deleted-h6fnp" in namespace "gc-2734"
Jan 24 19:36:45.482: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjzc2" in namespace "gc-2734"
Jan 24 19:36:45.946: INFO: Deleting pod "simpletest-rc-to-be-deleted-hp754" in namespace "gc-2734"
Jan 24 19:36:45.979: INFO: Deleting pod "simpletest-rc-to-be-deleted-j2hqz" in namespace "gc-2734"
Jan 24 19:36:46.017: INFO: Deleting pod "simpletest-rc-to-be-deleted-jk8k6" in namespace "gc-2734"
Jan 24 19:36:46.101: INFO: Deleting pod "simpletest-rc-to-be-deleted-jw6cb" in namespace "gc-2734"
Jan 24 19:36:46.136: INFO: Deleting pod "simpletest-rc-to-be-deleted-k4czf" in namespace "gc-2734"
Jan 24 19:36:46.215: INFO: Deleting pod "simpletest-rc-to-be-deleted-klw6z" in namespace "gc-2734"
Jan 24 19:36:46.244: INFO: Deleting pod "simpletest-rc-to-be-deleted-l6hnd" in namespace "gc-2734"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 24 19:36:46.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2734" for this suite. 01/24/23 19:36:46.468
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":170,"skipped":3310,"failed":0}
------------------------------
• [SLOW TEST] [62.233 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:35:44.877
    Jan 24 19:35:44.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename gc 01/24/23 19:35:44.881
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:35:45.302
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:35:45.696
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 01/24/23 19:35:45.908
    STEP: create the rc2 01/24/23 19:35:46.052
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 01/24/23 19:35:52.721
    STEP: delete the rc simpletest-rc-to-be-deleted 01/24/23 19:36:24.915
    STEP: wait for the rc to be deleted 01/24/23 19:36:24.968
    Jan 24 19:36:32.949: INFO: 66 pods remaining
    Jan 24 19:36:32.950: INFO: 66 pods has nil DeletionTimestamp
    Jan 24 19:36:32.950: INFO: 
    Jan 24 19:36:38.169: INFO: 58 pods remaining
    Jan 24 19:36:38.169: INFO: 57 pods has nil DeletionTimestamp
    Jan 24 19:36:38.169: INFO: 
    STEP: Gathering metrics 01/24/23 19:36:40.219
    W0124 19:36:40.257736      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 24 19:36:40.257: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Jan 24 19:36:40.257: INFO: Deleting pod "simpletest-rc-to-be-deleted-24nw8" in namespace "gc-2734"
    Jan 24 19:36:40.328: INFO: Deleting pod "simpletest-rc-to-be-deleted-2cxcl" in namespace "gc-2734"
    Jan 24 19:36:40.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-2dpbh" in namespace "gc-2734"
    Jan 24 19:36:40.416: INFO: Deleting pod "simpletest-rc-to-be-deleted-424gt" in namespace "gc-2734"
    Jan 24 19:36:40.784: INFO: Deleting pod "simpletest-rc-to-be-deleted-4b4mt" in namespace "gc-2734"
    Jan 24 19:36:40.991: INFO: Deleting pod "simpletest-rc-to-be-deleted-4k97f" in namespace "gc-2734"
    Jan 24 19:36:41.062: INFO: Deleting pod "simpletest-rc-to-be-deleted-4nxhr" in namespace "gc-2734"
    Jan 24 19:36:41.097: INFO: Deleting pod "simpletest-rc-to-be-deleted-4pwjh" in namespace "gc-2734"
    Jan 24 19:36:41.124: INFO: Deleting pod "simpletest-rc-to-be-deleted-4w7gd" in namespace "gc-2734"
    Jan 24 19:36:41.154: INFO: Deleting pod "simpletest-rc-to-be-deleted-55k9f" in namespace "gc-2734"
    Jan 24 19:36:41.226: INFO: Deleting pod "simpletest-rc-to-be-deleted-5n5jx" in namespace "gc-2734"
    Jan 24 19:36:41.286: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zclk" in namespace "gc-2734"
    Jan 24 19:36:41.326: INFO: Deleting pod "simpletest-rc-to-be-deleted-6dch4" in namespace "gc-2734"
    Jan 24 19:36:41.374: INFO: Deleting pod "simpletest-rc-to-be-deleted-6g6sm" in namespace "gc-2734"
    Jan 24 19:36:41.394: INFO: Deleting pod "simpletest-rc-to-be-deleted-6qbfm" in namespace "gc-2734"
    Jan 24 19:36:41.444: INFO: Deleting pod "simpletest-rc-to-be-deleted-7dz4b" in namespace "gc-2734"
    Jan 24 19:36:41.563: INFO: Deleting pod "simpletest-rc-to-be-deleted-7ff2w" in namespace "gc-2734"
    Jan 24 19:36:41.598: INFO: Deleting pod "simpletest-rc-to-be-deleted-7fs6f" in namespace "gc-2734"
    Jan 24 19:36:41.631: INFO: Deleting pod "simpletest-rc-to-be-deleted-7njkb" in namespace "gc-2734"
    Jan 24 19:36:41.661: INFO: Deleting pod "simpletest-rc-to-be-deleted-85rvm" in namespace "gc-2734"
    Jan 24 19:36:41.695: INFO: Deleting pod "simpletest-rc-to-be-deleted-8mmt8" in namespace "gc-2734"
    Jan 24 19:36:41.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-8vhb9" in namespace "gc-2734"
    Jan 24 19:36:41.812: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jwgq" in namespace "gc-2734"
    Jan 24 19:36:41.886: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xlrt" in namespace "gc-2734"
    Jan 24 19:36:41.922: INFO: Deleting pod "simpletest-rc-to-be-deleted-c6dct" in namespace "gc-2734"
    Jan 24 19:36:42.078: INFO: Deleting pod "simpletest-rc-to-be-deleted-c7kq8" in namespace "gc-2734"
    Jan 24 19:36:42.304: INFO: Deleting pod "simpletest-rc-to-be-deleted-ckmtz" in namespace "gc-2734"
    Jan 24 19:36:42.342: INFO: Deleting pod "simpletest-rc-to-be-deleted-cpfqz" in namespace "gc-2734"
    Jan 24 19:36:42.401: INFO: Deleting pod "simpletest-rc-to-be-deleted-cq4gz" in namespace "gc-2734"
    Jan 24 19:36:42.428: INFO: Deleting pod "simpletest-rc-to-be-deleted-ffpgc" in namespace "gc-2734"
    Jan 24 19:36:42.476: INFO: Deleting pod "simpletest-rc-to-be-deleted-fhzmf" in namespace "gc-2734"
    Jan 24 19:36:42.569: INFO: Deleting pod "simpletest-rc-to-be-deleted-fpntq" in namespace "gc-2734"
    Jan 24 19:36:42.684: INFO: Deleting pod "simpletest-rc-to-be-deleted-fqdrq" in namespace "gc-2734"
    Jan 24 19:36:43.143: INFO: Deleting pod "simpletest-rc-to-be-deleted-fw6zk" in namespace "gc-2734"
    Jan 24 19:36:43.892: INFO: Deleting pod "simpletest-rc-to-be-deleted-g49m9" in namespace "gc-2734"
    Jan 24 19:36:44.567: INFO: Deleting pod "simpletest-rc-to-be-deleted-ggkhk" in namespace "gc-2734"
    Jan 24 19:36:44.593: INFO: Deleting pod "simpletest-rc-to-be-deleted-gszr6" in namespace "gc-2734"
    Jan 24 19:36:44.648: INFO: Deleting pod "simpletest-rc-to-be-deleted-gtvbd" in namespace "gc-2734"
    Jan 24 19:36:44.811: INFO: Deleting pod "simpletest-rc-to-be-deleted-gvhrr" in namespace "gc-2734"
    Jan 24 19:36:44.850: INFO: Deleting pod "simpletest-rc-to-be-deleted-gzmnl" in namespace "gc-2734"
    Jan 24 19:36:44.898: INFO: Deleting pod "simpletest-rc-to-be-deleted-h4h98" in namespace "gc-2734"
    Jan 24 19:36:45.000: INFO: Deleting pod "simpletest-rc-to-be-deleted-h6fnp" in namespace "gc-2734"
    Jan 24 19:36:45.482: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjzc2" in namespace "gc-2734"
    Jan 24 19:36:45.946: INFO: Deleting pod "simpletest-rc-to-be-deleted-hp754" in namespace "gc-2734"
    Jan 24 19:36:45.979: INFO: Deleting pod "simpletest-rc-to-be-deleted-j2hqz" in namespace "gc-2734"
    Jan 24 19:36:46.017: INFO: Deleting pod "simpletest-rc-to-be-deleted-jk8k6" in namespace "gc-2734"
    Jan 24 19:36:46.101: INFO: Deleting pod "simpletest-rc-to-be-deleted-jw6cb" in namespace "gc-2734"
    Jan 24 19:36:46.136: INFO: Deleting pod "simpletest-rc-to-be-deleted-k4czf" in namespace "gc-2734"
    Jan 24 19:36:46.215: INFO: Deleting pod "simpletest-rc-to-be-deleted-klw6z" in namespace "gc-2734"
    Jan 24 19:36:46.244: INFO: Deleting pod "simpletest-rc-to-be-deleted-l6hnd" in namespace "gc-2734"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 24 19:36:46.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2734" for this suite. 01/24/23 19:36:46.468
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:36:47.339
Jan 24 19:36:47.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 19:36:47.352
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:36:47.721
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:36:49.435
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-3269 01/24/23 19:36:49.62
STEP: creating service affinity-clusterip in namespace services-3269 01/24/23 19:36:49.62
STEP: creating replication controller affinity-clusterip in namespace services-3269 01/24/23 19:36:49.692
I0124 19:36:50.003682      22 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-3269, replica count: 3
I0124 19:36:53.071992      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:36:56.077221      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:36:59.102940      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 19:36:59.197: INFO: Creating new exec pod
Jan 24 19:36:59.350: INFO: Waiting up to 5m0s for pod "execpod-affinityt26ln" in namespace "services-3269" to be "running"
Jan 24 19:36:59.429: INFO: Pod "execpod-affinityt26ln": Phase="Pending", Reason="", readiness=false. Elapsed: 14.326448ms
Jan 24 19:37:01.502: INFO: Pod "execpod-affinityt26ln": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08776883s
Jan 24 19:37:03.436: INFO: Pod "execpod-affinityt26ln": Phase="Running", Reason="", readiness=true. Elapsed: 4.021241112s
Jan 24 19:37:03.436: INFO: Pod "execpod-affinityt26ln" satisfied condition "running"
Jan 24 19:37:04.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3269 exec execpod-affinityt26ln -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Jan 24 19:37:05.411: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Jan 24 19:37:05.411: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:37:05.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3269 exec execpod-affinityt26ln -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.137.72 80'
Jan 24 19:37:07.116: INFO: stderr: "+ + nc -v -t -w 2 10.10.137.72 80\nConnection to 10.10.137.72 80 port [tcp/http] succeeded!\necho hostName\n"
Jan 24 19:37:07.116: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:37:07.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3269 exec execpod-affinityt26ln -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.137.72:80/ ; done'
Jan 24 19:37:12.951: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n"
Jan 24 19:37:12.951: INFO: stdout: "\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb"
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
Jan 24 19:37:12.951: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-3269, will wait for the garbage collector to delete the pods 01/24/23 19:37:13.067
Jan 24 19:37:13.545: INFO: Deleting ReplicationController affinity-clusterip took: 25.999833ms
Jan 24 19:37:14.066: INFO: Terminating ReplicationController affinity-clusterip pods took: 521.121715ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 19:37:24.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3269" for this suite. 01/24/23 19:37:25.028
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":171,"skipped":3318,"failed":0}
------------------------------
• [SLOW TEST] [37.754 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:36:47.339
    Jan 24 19:36:47.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 19:36:47.352
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:36:47.721
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:36:49.435
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-3269 01/24/23 19:36:49.62
    STEP: creating service affinity-clusterip in namespace services-3269 01/24/23 19:36:49.62
    STEP: creating replication controller affinity-clusterip in namespace services-3269 01/24/23 19:36:49.692
    I0124 19:36:50.003682      22 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-3269, replica count: 3
    I0124 19:36:53.071992      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:36:56.077221      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 1 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:36:59.102940      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 19:36:59.197: INFO: Creating new exec pod
    Jan 24 19:36:59.350: INFO: Waiting up to 5m0s for pod "execpod-affinityt26ln" in namespace "services-3269" to be "running"
    Jan 24 19:36:59.429: INFO: Pod "execpod-affinityt26ln": Phase="Pending", Reason="", readiness=false. Elapsed: 14.326448ms
    Jan 24 19:37:01.502: INFO: Pod "execpod-affinityt26ln": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08776883s
    Jan 24 19:37:03.436: INFO: Pod "execpod-affinityt26ln": Phase="Running", Reason="", readiness=true. Elapsed: 4.021241112s
    Jan 24 19:37:03.436: INFO: Pod "execpod-affinityt26ln" satisfied condition "running"
    Jan 24 19:37:04.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3269 exec execpod-affinityt26ln -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Jan 24 19:37:05.411: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Jan 24 19:37:05.411: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:37:05.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3269 exec execpod-affinityt26ln -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.137.72 80'
    Jan 24 19:37:07.116: INFO: stderr: "+ + nc -v -t -w 2 10.10.137.72 80\nConnection to 10.10.137.72 80 port [tcp/http] succeeded!\necho hostName\n"
    Jan 24 19:37:07.116: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:37:07.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-3269 exec execpod-affinityt26ln -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.137.72:80/ ; done'
    Jan 24 19:37:12.951: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.137.72:80/\n"
    Jan 24 19:37:12.951: INFO: stdout: "\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb\naffinity-clusterip-zbbhb"
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Received response from host: affinity-clusterip-zbbhb
    Jan 24 19:37:12.951: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-3269, will wait for the garbage collector to delete the pods 01/24/23 19:37:13.067
    Jan 24 19:37:13.545: INFO: Deleting ReplicationController affinity-clusterip took: 25.999833ms
    Jan 24 19:37:14.066: INFO: Terminating ReplicationController affinity-clusterip pods took: 521.121715ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 19:37:24.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3269" for this suite. 01/24/23 19:37:25.028
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:37:25.111
Jan 24 19:37:25.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename init-container 01/24/23 19:37:25.12
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:37:25.19
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:37:25.214
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 01/24/23 19:37:25.242
Jan 24 19:37:25.242: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 24 19:37:29.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1495" for this suite. 01/24/23 19:37:29.049
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":172,"skipped":3392,"failed":0}
------------------------------
• [3.963 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:37:25.111
    Jan 24 19:37:25.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename init-container 01/24/23 19:37:25.12
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:37:25.19
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:37:25.214
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 01/24/23 19:37:25.242
    Jan 24 19:37:25.242: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 24 19:37:29.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-1495" for this suite. 01/24/23 19:37:29.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:37:29.103
Jan 24 19:37:29.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename runtimeclass 01/24/23 19:37:29.11
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:37:29.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:37:29.159
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jan 24 19:37:29.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8825" for this suite. 01/24/23 19:37:29.195
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":173,"skipped":3424,"failed":0}
------------------------------
• [0.114 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:37:29.103
    Jan 24 19:37:29.104: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename runtimeclass 01/24/23 19:37:29.11
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:37:29.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:37:29.159
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jan 24 19:37:29.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-8825" for this suite. 01/24/23 19:37:29.195
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:37:29.225
Jan 24 19:37:29.226: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename statefulset 01/24/23 19:37:29.229
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:37:29.273
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:37:29.281
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4754 01/24/23 19:37:29.289
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 01/24/23 19:37:29.311
Jan 24 19:37:29.344: INFO: Found 0 stateful pods, waiting for 3
Jan 24 19:37:39.362: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 19:37:39.363: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 19:37:39.363: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 19:37:39.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-4754 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 24 19:37:40.183: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 24 19:37:40.183: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 24 19:37:40.183: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 01/24/23 19:37:50.318
Jan 24 19:37:50.363: INFO: Updating stateful set ss2
STEP: Creating a new revision 01/24/23 19:37:50.363
STEP: Updating Pods in reverse ordinal order 01/24/23 19:38:00.441
Jan 24 19:38:00.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-4754 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 24 19:38:01.764: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 24 19:38:01.764: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 24 19:38:01.764: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jan 24 19:38:11.989: INFO: Waiting for StatefulSet statefulset-4754/ss2 to complete update
Jan 24 19:38:11.989: INFO: Waiting for Pod statefulset-4754/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Jan 24 19:38:11.996: INFO: Waiting for Pod statefulset-4754/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Jan 24 19:38:22.017: INFO: Waiting for StatefulSet statefulset-4754/ss2 to complete update
Jan 24 19:38:22.017: INFO: Waiting for Pod statefulset-4754/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Jan 24 19:38:22.017: INFO: Waiting for Pod statefulset-4754/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Jan 24 19:38:32.030: INFO: Waiting for StatefulSet statefulset-4754/ss2 to complete update
Jan 24 19:38:32.030: INFO: Waiting for Pod statefulset-4754/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Jan 24 19:38:42.026: INFO: Waiting for StatefulSet statefulset-4754/ss2 to complete update
Jan 24 19:38:42.026: INFO: Waiting for Pod statefulset-4754/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Jan 24 19:38:52.023: INFO: Waiting for StatefulSet statefulset-4754/ss2 to complete update
STEP: Rolling back to a previous revision 01/24/23 19:39:02.021
Jan 24 19:39:02.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-4754 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jan 24 19:39:02.957: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jan 24 19:39:02.961: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jan 24 19:39:02.961: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jan 24 19:39:13.341: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 01/24/23 19:39:23.461
Jan 24 19:39:23.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-4754 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jan 24 19:39:24.130: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jan 24 19:39:24.130: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jan 24 19:39:24.130: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 24 19:39:44.204: INFO: Deleting all statefulset in ns statefulset-4754
Jan 24 19:39:44.216: INFO: Scaling statefulset ss2 to 0
Jan 24 19:39:54.399: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 19:39:54.443: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 24 19:39:54.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4754" for this suite. 01/24/23 19:39:54.766
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":174,"skipped":3443,"failed":0}
------------------------------
• [SLOW TEST] [145.578 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:37:29.225
    Jan 24 19:37:29.226: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename statefulset 01/24/23 19:37:29.229
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:37:29.273
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:37:29.281
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4754 01/24/23 19:37:29.289
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 01/24/23 19:37:29.311
    Jan 24 19:37:29.344: INFO: Found 0 stateful pods, waiting for 3
    Jan 24 19:37:39.362: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 19:37:39.363: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 19:37:39.363: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 19:37:39.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-4754 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 24 19:37:40.183: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 24 19:37:40.183: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 24 19:37:40.183: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 01/24/23 19:37:50.318
    Jan 24 19:37:50.363: INFO: Updating stateful set ss2
    STEP: Creating a new revision 01/24/23 19:37:50.363
    STEP: Updating Pods in reverse ordinal order 01/24/23 19:38:00.441
    Jan 24 19:38:00.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-4754 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 24 19:38:01.764: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 24 19:38:01.764: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 24 19:38:01.764: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Jan 24 19:38:11.989: INFO: Waiting for StatefulSet statefulset-4754/ss2 to complete update
    Jan 24 19:38:11.989: INFO: Waiting for Pod statefulset-4754/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Jan 24 19:38:11.996: INFO: Waiting for Pod statefulset-4754/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Jan 24 19:38:22.017: INFO: Waiting for StatefulSet statefulset-4754/ss2 to complete update
    Jan 24 19:38:22.017: INFO: Waiting for Pod statefulset-4754/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Jan 24 19:38:22.017: INFO: Waiting for Pod statefulset-4754/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Jan 24 19:38:32.030: INFO: Waiting for StatefulSet statefulset-4754/ss2 to complete update
    Jan 24 19:38:32.030: INFO: Waiting for Pod statefulset-4754/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Jan 24 19:38:42.026: INFO: Waiting for StatefulSet statefulset-4754/ss2 to complete update
    Jan 24 19:38:42.026: INFO: Waiting for Pod statefulset-4754/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Jan 24 19:38:52.023: INFO: Waiting for StatefulSet statefulset-4754/ss2 to complete update
    STEP: Rolling back to a previous revision 01/24/23 19:39:02.021
    Jan 24 19:39:02.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-4754 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Jan 24 19:39:02.957: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Jan 24 19:39:02.961: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Jan 24 19:39:02.961: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Jan 24 19:39:13.341: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 01/24/23 19:39:23.461
    Jan 24 19:39:23.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=statefulset-4754 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Jan 24 19:39:24.130: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Jan 24 19:39:24.130: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Jan 24 19:39:24.130: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 24 19:39:44.204: INFO: Deleting all statefulset in ns statefulset-4754
    Jan 24 19:39:44.216: INFO: Scaling statefulset ss2 to 0
    Jan 24 19:39:54.399: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 19:39:54.443: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 24 19:39:54.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4754" for this suite. 01/24/23 19:39:54.766
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:39:54.831
Jan 24 19:39:54.832: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename job 01/24/23 19:39:54.849
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:39:54.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:39:55.017
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 01/24/23 19:39:55.087
STEP: Ensuring active pods == parallelism 01/24/23 19:39:55.115
STEP: Orphaning one of the Job's Pods 01/24/23 19:39:59.242
Jan 24 19:40:00.003: INFO: Successfully updated pod "adopt-release-vgxbm"
STEP: Checking that the Job readopts the Pod 01/24/23 19:40:00.003
Jan 24 19:40:00.004: INFO: Waiting up to 15m0s for pod "adopt-release-vgxbm" in namespace "job-3039" to be "adopted"
Jan 24 19:40:00.301: INFO: Pod "adopt-release-vgxbm": Phase="Running", Reason="", readiness=true. Elapsed: 297.268443ms
Jan 24 19:40:02.322: INFO: Pod "adopt-release-vgxbm": Phase="Running", Reason="", readiness=true. Elapsed: 2.318016563s
Jan 24 19:40:02.322: INFO: Pod "adopt-release-vgxbm" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 01/24/23 19:40:02.322
Jan 24 19:40:02.852: INFO: Successfully updated pod "adopt-release-vgxbm"
STEP: Checking that the Job releases the Pod 01/24/23 19:40:02.852
Jan 24 19:40:02.852: INFO: Waiting up to 15m0s for pod "adopt-release-vgxbm" in namespace "job-3039" to be "released"
Jan 24 19:40:02.862: INFO: Pod "adopt-release-vgxbm": Phase="Running", Reason="", readiness=true. Elapsed: 9.948099ms
Jan 24 19:40:04.871: INFO: Pod "adopt-release-vgxbm": Phase="Running", Reason="", readiness=true. Elapsed: 2.018584866s
Jan 24 19:40:04.871: INFO: Pod "adopt-release-vgxbm" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 24 19:40:04.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3039" for this suite. 01/24/23 19:40:04.878
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":175,"skipped":3444,"failed":0}
------------------------------
• [SLOW TEST] [10.073 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:39:54.831
    Jan 24 19:39:54.832: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename job 01/24/23 19:39:54.849
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:39:54.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:39:55.017
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 01/24/23 19:39:55.087
    STEP: Ensuring active pods == parallelism 01/24/23 19:39:55.115
    STEP: Orphaning one of the Job's Pods 01/24/23 19:39:59.242
    Jan 24 19:40:00.003: INFO: Successfully updated pod "adopt-release-vgxbm"
    STEP: Checking that the Job readopts the Pod 01/24/23 19:40:00.003
    Jan 24 19:40:00.004: INFO: Waiting up to 15m0s for pod "adopt-release-vgxbm" in namespace "job-3039" to be "adopted"
    Jan 24 19:40:00.301: INFO: Pod "adopt-release-vgxbm": Phase="Running", Reason="", readiness=true. Elapsed: 297.268443ms
    Jan 24 19:40:02.322: INFO: Pod "adopt-release-vgxbm": Phase="Running", Reason="", readiness=true. Elapsed: 2.318016563s
    Jan 24 19:40:02.322: INFO: Pod "adopt-release-vgxbm" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 01/24/23 19:40:02.322
    Jan 24 19:40:02.852: INFO: Successfully updated pod "adopt-release-vgxbm"
    STEP: Checking that the Job releases the Pod 01/24/23 19:40:02.852
    Jan 24 19:40:02.852: INFO: Waiting up to 15m0s for pod "adopt-release-vgxbm" in namespace "job-3039" to be "released"
    Jan 24 19:40:02.862: INFO: Pod "adopt-release-vgxbm": Phase="Running", Reason="", readiness=true. Elapsed: 9.948099ms
    Jan 24 19:40:04.871: INFO: Pod "adopt-release-vgxbm": Phase="Running", Reason="", readiness=true. Elapsed: 2.018584866s
    Jan 24 19:40:04.871: INFO: Pod "adopt-release-vgxbm" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 24 19:40:04.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3039" for this suite. 01/24/23 19:40:04.878
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:40:04.899
Jan 24 19:40:04.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 19:40:04.902
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:04.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:04.943
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 01/24/23 19:40:04.948
Jan 24 19:40:04.972: INFO: Waiting up to 5m0s for pod "pod-8b45e34d-3186-45cb-84b5-301e22d33d4c" in namespace "emptydir-9892" to be "Succeeded or Failed"
Jan 24 19:40:04.992: INFO: Pod "pod-8b45e34d-3186-45cb-84b5-301e22d33d4c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.359606ms
Jan 24 19:40:07.007: INFO: Pod "pod-8b45e34d-3186-45cb-84b5-301e22d33d4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034799606s
Jan 24 19:40:09.002: INFO: Pod "pod-8b45e34d-3186-45cb-84b5-301e22d33d4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030011615s
STEP: Saw pod success 01/24/23 19:40:09.002
Jan 24 19:40:09.003: INFO: Pod "pod-8b45e34d-3186-45cb-84b5-301e22d33d4c" satisfied condition "Succeeded or Failed"
Jan 24 19:40:09.016: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-8b45e34d-3186-45cb-84b5-301e22d33d4c container test-container: <nil>
STEP: delete the pod 01/24/23 19:40:09.075
Jan 24 19:40:09.108: INFO: Waiting for pod pod-8b45e34d-3186-45cb-84b5-301e22d33d4c to disappear
Jan 24 19:40:09.119: INFO: Pod pod-8b45e34d-3186-45cb-84b5-301e22d33d4c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 19:40:09.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9892" for this suite. 01/24/23 19:40:09.128
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":176,"skipped":3448,"failed":0}
------------------------------
• [4.270 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:40:04.899
    Jan 24 19:40:04.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 19:40:04.902
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:04.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:04.943
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 01/24/23 19:40:04.948
    Jan 24 19:40:04.972: INFO: Waiting up to 5m0s for pod "pod-8b45e34d-3186-45cb-84b5-301e22d33d4c" in namespace "emptydir-9892" to be "Succeeded or Failed"
    Jan 24 19:40:04.992: INFO: Pod "pod-8b45e34d-3186-45cb-84b5-301e22d33d4c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.359606ms
    Jan 24 19:40:07.007: INFO: Pod "pod-8b45e34d-3186-45cb-84b5-301e22d33d4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034799606s
    Jan 24 19:40:09.002: INFO: Pod "pod-8b45e34d-3186-45cb-84b5-301e22d33d4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030011615s
    STEP: Saw pod success 01/24/23 19:40:09.002
    Jan 24 19:40:09.003: INFO: Pod "pod-8b45e34d-3186-45cb-84b5-301e22d33d4c" satisfied condition "Succeeded or Failed"
    Jan 24 19:40:09.016: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-8b45e34d-3186-45cb-84b5-301e22d33d4c container test-container: <nil>
    STEP: delete the pod 01/24/23 19:40:09.075
    Jan 24 19:40:09.108: INFO: Waiting for pod pod-8b45e34d-3186-45cb-84b5-301e22d33d4c to disappear
    Jan 24 19:40:09.119: INFO: Pod pod-8b45e34d-3186-45cb-84b5-301e22d33d4c no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 19:40:09.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9892" for this suite. 01/24/23 19:40:09.128
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:40:09.179
Jan 24 19:40:09.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir-wrapper 01/24/23 19:40:09.186
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:09.263
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:09.293
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Jan 24 19:40:09.377: INFO: Waiting up to 5m0s for pod "pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f" in namespace "emptydir-wrapper-2037" to be "running and ready"
Jan 24 19:40:09.390: INFO: Pod "pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.281779ms
Jan 24 19:40:09.391: INFO: The phase of Pod pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:40:11.429: INFO: Pod "pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051470096s
Jan 24 19:40:11.429: INFO: The phase of Pod pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:40:13.398: INFO: Pod "pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f": Phase="Running", Reason="", readiness=true. Elapsed: 4.020438799s
Jan 24 19:40:13.398: INFO: The phase of Pod pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f is Running (Ready = true)
Jan 24 19:40:13.398: INFO: Pod "pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f" satisfied condition "running and ready"
STEP: Cleaning up the secret 01/24/23 19:40:13.404
STEP: Cleaning up the configmap 01/24/23 19:40:13.416
STEP: Cleaning up the pod 01/24/23 19:40:13.427
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Jan 24 19:40:13.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2037" for this suite. 01/24/23 19:40:13.48
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":177,"skipped":3478,"failed":0}
------------------------------
• [4.328 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:40:09.179
    Jan 24 19:40:09.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir-wrapper 01/24/23 19:40:09.186
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:09.263
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:09.293
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Jan 24 19:40:09.377: INFO: Waiting up to 5m0s for pod "pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f" in namespace "emptydir-wrapper-2037" to be "running and ready"
    Jan 24 19:40:09.390: INFO: Pod "pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.281779ms
    Jan 24 19:40:09.391: INFO: The phase of Pod pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:40:11.429: INFO: Pod "pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051470096s
    Jan 24 19:40:11.429: INFO: The phase of Pod pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:40:13.398: INFO: Pod "pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f": Phase="Running", Reason="", readiness=true. Elapsed: 4.020438799s
    Jan 24 19:40:13.398: INFO: The phase of Pod pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f is Running (Ready = true)
    Jan 24 19:40:13.398: INFO: Pod "pod-secrets-81cf5585-4539-4d1b-b4bc-7e9935112c3f" satisfied condition "running and ready"
    STEP: Cleaning up the secret 01/24/23 19:40:13.404
    STEP: Cleaning up the configmap 01/24/23 19:40:13.416
    STEP: Cleaning up the pod 01/24/23 19:40:13.427
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Jan 24 19:40:13.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-2037" for this suite. 01/24/23 19:40:13.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:40:13.532
Jan 24 19:40:13.532: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:40:13.537
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:13.596
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:13.607
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 01/24/23 19:40:13.617
Jan 24 19:40:13.663: INFO: Waiting up to 5m0s for pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e" in namespace "projected-3189" to be "Succeeded or Failed"
Jan 24 19:40:13.679: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.024226ms
Jan 24 19:40:15.737: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073302224s
Jan 24 19:40:17.694: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031012569s
Jan 24 19:40:19.693: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.030021982s
Jan 24 19:40:21.690: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.027007376s
STEP: Saw pod success 01/24/23 19:40:21.69
Jan 24 19:40:21.692: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e" satisfied condition "Succeeded or Failed"
Jan 24 19:40:21.706: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e container client-container: <nil>
STEP: delete the pod 01/24/23 19:40:21.724
Jan 24 19:40:21.765: INFO: Waiting for pod downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e to disappear
Jan 24 19:40:21.783: INFO: Pod downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 19:40:21.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3189" for this suite. 01/24/23 19:40:21.818
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":178,"skipped":3531,"failed":0}
------------------------------
• [SLOW TEST] [8.313 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:40:13.532
    Jan 24 19:40:13.532: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:40:13.537
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:13.596
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:13.607
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 01/24/23 19:40:13.617
    Jan 24 19:40:13.663: INFO: Waiting up to 5m0s for pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e" in namespace "projected-3189" to be "Succeeded or Failed"
    Jan 24 19:40:13.679: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.024226ms
    Jan 24 19:40:15.737: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073302224s
    Jan 24 19:40:17.694: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031012569s
    Jan 24 19:40:19.693: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.030021982s
    Jan 24 19:40:21.690: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.027007376s
    STEP: Saw pod success 01/24/23 19:40:21.69
    Jan 24 19:40:21.692: INFO: Pod "downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e" satisfied condition "Succeeded or Failed"
    Jan 24 19:40:21.706: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e container client-container: <nil>
    STEP: delete the pod 01/24/23 19:40:21.724
    Jan 24 19:40:21.765: INFO: Waiting for pod downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e to disappear
    Jan 24 19:40:21.783: INFO: Pod downwardapi-volume-010659df-f079-453d-86df-5df1d829de6e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 19:40:21.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3189" for this suite. 01/24/23 19:40:21.818
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:40:21.849
Jan 24 19:40:21.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename events 01/24/23 19:40:21.857
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:21.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:21.997
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 01/24/23 19:40:22.035
STEP: listing all events in all namespaces 01/24/23 19:40:22.059
STEP: patching the test event 01/24/23 19:40:22.072
STEP: fetching the test event 01/24/23 19:40:22.092
STEP: updating the test event 01/24/23 19:40:22.116
STEP: getting the test event 01/24/23 19:40:22.155
STEP: deleting the test event 01/24/23 19:40:22.181
STEP: listing all events in all namespaces 01/24/23 19:40:22.253
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Jan 24 19:40:22.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8082" for this suite. 01/24/23 19:40:22.319
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":179,"skipped":3540,"failed":0}
------------------------------
• [0.539 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:40:21.849
    Jan 24 19:40:21.852: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename events 01/24/23 19:40:21.857
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:21.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:21.997
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 01/24/23 19:40:22.035
    STEP: listing all events in all namespaces 01/24/23 19:40:22.059
    STEP: patching the test event 01/24/23 19:40:22.072
    STEP: fetching the test event 01/24/23 19:40:22.092
    STEP: updating the test event 01/24/23 19:40:22.116
    STEP: getting the test event 01/24/23 19:40:22.155
    STEP: deleting the test event 01/24/23 19:40:22.181
    STEP: listing all events in all namespaces 01/24/23 19:40:22.253
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Jan 24 19:40:22.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-8082" for this suite. 01/24/23 19:40:22.319
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:40:22.415
Jan 24 19:40:22.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename proxy 01/24/23 19:40:22.421
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:22.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:22.569
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 01/24/23 19:40:22.786
STEP: creating replication controller proxy-service-nlkhw in namespace proxy-8991 01/24/23 19:40:22.802
I0124 19:40:22.871623      22 runners.go:193] Created replication controller with name: proxy-service-nlkhw, namespace: proxy-8991, replica count: 1
I0124 19:40:23.992487      22 runners.go:193] proxy-service-nlkhw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:40:24.995474      22 runners.go:193] proxy-service-nlkhw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:40:25.999633      22 runners.go:193] proxy-service-nlkhw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:40:27.000807      22 runners.go:193] proxy-service-nlkhw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0124 19:40:28.001282      22 runners.go:193] proxy-service-nlkhw Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 19:40:28.006: INFO: setup took 5.427665338s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 01/24/23 19:40:28.006
Jan 24 19:40:28.033: INFO: (0) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 25.860089ms)
Jan 24 19:40:28.033: INFO: (0) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 25.654072ms)
Jan 24 19:40:28.036: INFO: (0) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 28.552223ms)
Jan 24 19:40:28.045: INFO: (0) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 37.865248ms)
Jan 24 19:40:28.065: INFO: (0) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 57.396732ms)
Jan 24 19:40:28.066: INFO: (0) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 57.59376ms)
Jan 24 19:40:28.065: INFO: (0) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 59.243143ms)
Jan 24 19:40:28.068: INFO: (0) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 60.675599ms)
Jan 24 19:40:28.068: INFO: (0) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 61.366139ms)
Jan 24 19:40:28.068: INFO: (0) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 60.019613ms)
Jan 24 19:40:28.069: INFO: (0) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 60.433753ms)
Jan 24 19:40:28.069: INFO: (0) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 61.698745ms)
Jan 24 19:40:28.069: INFO: (0) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 62.646413ms)
Jan 24 19:40:28.069: INFO: (0) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 63.141793ms)
Jan 24 19:40:28.072: INFO: (0) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 63.831378ms)
Jan 24 19:40:28.073: INFO: (0) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 64.580494ms)
Jan 24 19:40:28.099: INFO: (1) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 25.35103ms)
Jan 24 19:40:28.099: INFO: (1) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 25.387653ms)
Jan 24 19:40:28.099: INFO: (1) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 25.867685ms)
Jan 24 19:40:28.102: INFO: (1) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 28.62123ms)
Jan 24 19:40:28.102: INFO: (1) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 28.938958ms)
Jan 24 19:40:28.102: INFO: (1) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 28.612844ms)
Jan 24 19:40:28.102: INFO: (1) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 28.786053ms)
Jan 24 19:40:28.105: INFO: (1) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 31.910465ms)
Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 32.027733ms)
Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 32.268334ms)
Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 32.062678ms)
Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 32.365435ms)
Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 33.184599ms)
Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 32.89968ms)
Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 33.119995ms)
Jan 24 19:40:28.107: INFO: (1) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 33.859153ms)
Jan 24 19:40:28.127: INFO: (2) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 19.709058ms)
Jan 24 19:40:28.131: INFO: (2) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 23.557886ms)
Jan 24 19:40:28.132: INFO: (2) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 24.155632ms)
Jan 24 19:40:28.139: INFO: (2) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 30.904004ms)
Jan 24 19:40:28.139: INFO: (2) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 32.69352ms)
Jan 24 19:40:28.140: INFO: (2) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 31.700369ms)
Jan 24 19:40:28.141: INFO: (2) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 32.917145ms)
Jan 24 19:40:28.141: INFO: (2) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 33.104419ms)
Jan 24 19:40:28.141: INFO: (2) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 33.216491ms)
Jan 24 19:40:28.142: INFO: (2) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 34.096217ms)
Jan 24 19:40:28.145: INFO: (2) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 36.822651ms)
Jan 24 19:40:28.145: INFO: (2) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 36.829717ms)
Jan 24 19:40:28.146: INFO: (2) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 37.168243ms)
Jan 24 19:40:28.149: INFO: (2) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 42.380729ms)
Jan 24 19:40:28.150: INFO: (2) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 42.254785ms)
Jan 24 19:40:28.151: INFO: (2) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 42.891294ms)
Jan 24 19:40:28.186: INFO: (3) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 34.275163ms)
Jan 24 19:40:28.186: INFO: (3) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 32.809739ms)
Jan 24 19:40:28.187: INFO: (3) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 32.768811ms)
Jan 24 19:40:28.187: INFO: (3) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 32.929088ms)
Jan 24 19:40:28.187: INFO: (3) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 35.57385ms)
Jan 24 19:40:28.188: INFO: (3) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 35.565282ms)
Jan 24 19:40:28.188: INFO: (3) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 35.777334ms)
Jan 24 19:40:28.188: INFO: (3) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 36.117169ms)
Jan 24 19:40:28.189: INFO: (3) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 35.826544ms)
Jan 24 19:40:28.191: INFO: (3) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 39.068521ms)
Jan 24 19:40:28.191: INFO: (3) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 37.516091ms)
Jan 24 19:40:28.191: INFO: (3) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 39.716982ms)
Jan 24 19:40:28.193: INFO: (3) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 40.358923ms)
Jan 24 19:40:28.193: INFO: (3) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 40.442496ms)
Jan 24 19:40:28.193: INFO: (3) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 41.101653ms)
Jan 24 19:40:28.193: INFO: (3) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 40.96953ms)
Jan 24 19:40:28.227: INFO: (4) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 31.998717ms)
Jan 24 19:40:28.230: INFO: (4) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 35.550006ms)
Jan 24 19:40:28.231: INFO: (4) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 35.473763ms)
Jan 24 19:40:28.231: INFO: (4) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 35.313135ms)
Jan 24 19:40:28.232: INFO: (4) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 36.781503ms)
Jan 24 19:40:28.234: INFO: (4) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 39.185017ms)
Jan 24 19:40:28.235: INFO: (4) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 39.423667ms)
Jan 24 19:40:28.235: INFO: (4) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 39.553557ms)
Jan 24 19:40:28.235: INFO: (4) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 40.75805ms)
Jan 24 19:40:28.235: INFO: (4) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 40.676215ms)
Jan 24 19:40:28.237: INFO: (4) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 41.485978ms)
Jan 24 19:40:28.237: INFO: (4) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 41.864248ms)
Jan 24 19:40:28.238: INFO: (4) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 42.196755ms)
Jan 24 19:40:28.239: INFO: (4) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 43.72666ms)
Jan 24 19:40:28.240: INFO: (4) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 45.118288ms)
Jan 24 19:40:28.241: INFO: (4) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 45.937244ms)
Jan 24 19:40:28.290: INFO: (5) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 49.035115ms)
Jan 24 19:40:28.290: INFO: (5) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 49.443337ms)
Jan 24 19:40:28.292: INFO: (5) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 50.225991ms)
Jan 24 19:40:28.292: INFO: (5) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 50.787094ms)
Jan 24 19:40:28.295: INFO: (5) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 53.6791ms)
Jan 24 19:40:28.295: INFO: (5) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 54.297698ms)
Jan 24 19:40:28.296: INFO: (5) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 53.865404ms)
Jan 24 19:40:28.296: INFO: (5) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 54.157996ms)
Jan 24 19:40:28.297: INFO: (5) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 56.249289ms)
Jan 24 19:40:28.297: INFO: (5) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 56.209703ms)
Jan 24 19:40:28.297: INFO: (5) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 56.185476ms)
Jan 24 19:40:28.297: INFO: (5) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 55.990763ms)
Jan 24 19:40:28.297: INFO: (5) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 55.852322ms)
Jan 24 19:40:28.301: INFO: (5) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 59.109746ms)
Jan 24 19:40:28.305: INFO: (5) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 63.479845ms)
Jan 24 19:40:28.306: INFO: (5) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 64.464153ms)
Jan 24 19:40:28.320: INFO: (6) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 12.108711ms)
Jan 24 19:40:28.320: INFO: (6) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 13.172467ms)
Jan 24 19:40:28.321: INFO: (6) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 13.920007ms)
Jan 24 19:40:28.322: INFO: (6) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 15.560252ms)
Jan 24 19:40:28.322: INFO: (6) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 15.227656ms)
Jan 24 19:40:28.324: INFO: (6) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 15.42602ms)
Jan 24 19:40:28.332: INFO: (6) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 25.414174ms)
Jan 24 19:40:28.333: INFO: (6) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 24.230457ms)
Jan 24 19:40:28.333: INFO: (6) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 24.78834ms)
Jan 24 19:40:28.333: INFO: (6) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 25.506729ms)
Jan 24 19:40:28.333: INFO: (6) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 25.707678ms)
Jan 24 19:40:28.333: INFO: (6) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 26.995561ms)
Jan 24 19:40:28.334: INFO: (6) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 27.537548ms)
Jan 24 19:40:28.335: INFO: (6) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 26.199353ms)
Jan 24 19:40:28.338: INFO: (6) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 31.444321ms)
Jan 24 19:40:28.338: INFO: (6) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 31.262309ms)
Jan 24 19:40:28.360: INFO: (7) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 20.136461ms)
Jan 24 19:40:28.360: INFO: (7) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 21.403116ms)
Jan 24 19:40:28.361: INFO: (7) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 21.076915ms)
Jan 24 19:40:28.366: INFO: (7) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 26.578511ms)
Jan 24 19:40:28.368: INFO: (7) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 27.82277ms)
Jan 24 19:40:28.368: INFO: (7) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 28.013806ms)
Jan 24 19:40:28.368: INFO: (7) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 29.13488ms)
Jan 24 19:40:28.368: INFO: (7) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 29.427361ms)
Jan 24 19:40:28.368: INFO: (7) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 28.049761ms)
Jan 24 19:40:28.369: INFO: (7) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 31.558233ms)
Jan 24 19:40:28.369: INFO: (7) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 31.395149ms)
Jan 24 19:40:28.370: INFO: (7) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 31.284951ms)
Jan 24 19:40:28.372: INFO: (7) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 32.586411ms)
Jan 24 19:40:28.372: INFO: (7) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 32.47775ms)
Jan 24 19:40:28.374: INFO: (7) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 35.492829ms)
Jan 24 19:40:28.374: INFO: (7) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 35.802922ms)
Jan 24 19:40:28.385: INFO: (8) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 10.438582ms)
Jan 24 19:40:28.392: INFO: (8) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 16.223065ms)
Jan 24 19:40:28.392: INFO: (8) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 17.738963ms)
Jan 24 19:40:28.395: INFO: (8) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 19.790493ms)
Jan 24 19:40:28.395: INFO: (8) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 19.947858ms)
Jan 24 19:40:28.396: INFO: (8) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 19.474469ms)
Jan 24 19:40:28.396: INFO: (8) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 19.035249ms)
Jan 24 19:40:28.396: INFO: (8) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 20.835444ms)
Jan 24 19:40:28.397: INFO: (8) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 20.531862ms)
Jan 24 19:40:28.397: INFO: (8) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 22.028873ms)
Jan 24 19:40:28.399: INFO: (8) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 22.537735ms)
Jan 24 19:40:28.401: INFO: (8) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 26.111084ms)
Jan 24 19:40:28.401: INFO: (8) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 25.604622ms)
Jan 24 19:40:28.402: INFO: (8) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 25.957806ms)
Jan 24 19:40:28.404: INFO: (8) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 27.857391ms)
Jan 24 19:40:28.409: INFO: (8) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 32.39942ms)
Jan 24 19:40:28.434: INFO: (9) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 22.968033ms)
Jan 24 19:40:28.437: INFO: (9) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 25.425815ms)
Jan 24 19:40:28.437: INFO: (9) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 27.088773ms)
Jan 24 19:40:28.437: INFO: (9) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 28.040884ms)
Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 27.123523ms)
Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 27.514151ms)
Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 28.151969ms)
Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 28.705046ms)
Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 27.761509ms)
Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 27.652012ms)
Jan 24 19:40:28.439: INFO: (9) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 29.143306ms)
Jan 24 19:40:28.440: INFO: (9) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 29.762621ms)
Jan 24 19:40:28.441: INFO: (9) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 30.649459ms)
Jan 24 19:40:28.442: INFO: (9) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 31.620394ms)
Jan 24 19:40:28.442: INFO: (9) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 32.204122ms)
Jan 24 19:40:28.443: INFO: (9) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 33.156398ms)
Jan 24 19:40:28.460: INFO: (10) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 15.758536ms)
Jan 24 19:40:28.460: INFO: (10) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 15.923662ms)
Jan 24 19:40:28.461: INFO: (10) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 18.425087ms)
Jan 24 19:40:28.462: INFO: (10) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 18.410352ms)
Jan 24 19:40:28.462: INFO: (10) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 19.081608ms)
Jan 24 19:40:28.465: INFO: (10) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 21.527599ms)
Jan 24 19:40:28.465: INFO: (10) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 22.271171ms)
Jan 24 19:40:28.469: INFO: (10) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 25.648852ms)
Jan 24 19:40:28.470: INFO: (10) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 26.895613ms)
Jan 24 19:40:28.473: INFO: (10) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 30.034482ms)
Jan 24 19:40:28.475: INFO: (10) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 31.361097ms)
Jan 24 19:40:28.475: INFO: (10) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 31.565965ms)
Jan 24 19:40:28.475: INFO: (10) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 31.51689ms)
Jan 24 19:40:28.475: INFO: (10) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 31.371511ms)
Jan 24 19:40:28.475: INFO: (10) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 32.374645ms)
Jan 24 19:40:28.476: INFO: (10) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 32.485772ms)
Jan 24 19:40:28.509: INFO: (11) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 32.75094ms)
Jan 24 19:40:28.509: INFO: (11) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 32.362806ms)
Jan 24 19:40:28.512: INFO: (11) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 35.482556ms)
Jan 24 19:40:28.512: INFO: (11) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 35.649204ms)
Jan 24 19:40:28.512: INFO: (11) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 35.652056ms)
Jan 24 19:40:28.512: INFO: (11) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 35.659327ms)
Jan 24 19:40:28.513: INFO: (11) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 36.469587ms)
Jan 24 19:40:28.520: INFO: (11) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 43.786437ms)
Jan 24 19:40:28.521: INFO: (11) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 44.649499ms)
Jan 24 19:40:28.521: INFO: (11) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 45.21935ms)
Jan 24 19:40:28.521: INFO: (11) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 45.106475ms)
Jan 24 19:40:28.521: INFO: (11) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 45.094758ms)
Jan 24 19:40:28.522: INFO: (11) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 45.321195ms)
Jan 24 19:40:28.522: INFO: (11) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 45.449663ms)
Jan 24 19:40:28.522: INFO: (11) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 45.59735ms)
Jan 24 19:40:28.522: INFO: (11) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 45.775738ms)
Jan 24 19:40:28.544: INFO: (12) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 21.725323ms)
Jan 24 19:40:28.544: INFO: (12) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 22.077489ms)
Jan 24 19:40:28.547: INFO: (12) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 23.012519ms)
Jan 24 19:40:28.547: INFO: (12) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 24.181008ms)
Jan 24 19:40:28.547: INFO: (12) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 24.004987ms)
Jan 24 19:40:28.547: INFO: (12) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 23.995006ms)
Jan 24 19:40:28.547: INFO: (12) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 24.280693ms)
Jan 24 19:40:28.549: INFO: (12) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 25.338689ms)
Jan 24 19:40:28.549: INFO: (12) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 26.28715ms)
Jan 24 19:40:28.551: INFO: (12) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 28.78076ms)
Jan 24 19:40:28.551: INFO: (12) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 27.880726ms)
Jan 24 19:40:28.552: INFO: (12) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 28.465738ms)
Jan 24 19:40:28.555: INFO: (12) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 31.802724ms)
Jan 24 19:40:28.557: INFO: (12) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 33.894032ms)
Jan 24 19:40:28.559: INFO: (12) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 35.865815ms)
Jan 24 19:40:28.560: INFO: (12) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 37.153114ms)
Jan 24 19:40:28.587: INFO: (13) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 26.479761ms)
Jan 24 19:40:28.587: INFO: (13) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 26.464236ms)
Jan 24 19:40:28.588: INFO: (13) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 27.321204ms)
Jan 24 19:40:28.588: INFO: (13) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 26.866883ms)
Jan 24 19:40:28.588: INFO: (13) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 27.682948ms)
Jan 24 19:40:28.590: INFO: (13) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 29.082328ms)
Jan 24 19:40:28.591: INFO: (13) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 30.044495ms)
Jan 24 19:40:28.592: INFO: (13) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 30.751983ms)
Jan 24 19:40:28.595: INFO: (13) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 34.995692ms)
Jan 24 19:40:28.596: INFO: (13) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 35.135892ms)
Jan 24 19:40:28.596: INFO: (13) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 35.480642ms)
Jan 24 19:40:28.597: INFO: (13) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 35.276403ms)
Jan 24 19:40:28.597: INFO: (13) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 35.822303ms)
Jan 24 19:40:28.603: INFO: (13) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 41.913517ms)
Jan 24 19:40:28.603: INFO: (13) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 42.249559ms)
Jan 24 19:40:28.604: INFO: (13) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 42.383793ms)
Jan 24 19:40:28.612: INFO: (14) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 7.973231ms)
Jan 24 19:40:28.617: INFO: (14) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 11.528194ms)
Jan 24 19:40:28.617: INFO: (14) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 12.23071ms)
Jan 24 19:40:28.620: INFO: (14) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 14.711347ms)
Jan 24 19:40:28.621: INFO: (14) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 15.41668ms)
Jan 24 19:40:28.628: INFO: (14) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 21.53477ms)
Jan 24 19:40:28.628: INFO: (14) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 23.944007ms)
Jan 24 19:40:28.627: INFO: (14) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 21.399799ms)
Jan 24 19:40:28.632: INFO: (14) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 25.659566ms)
Jan 24 19:40:28.633: INFO: (14) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 26.934004ms)
Jan 24 19:40:28.637: INFO: (14) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 30.689417ms)
Jan 24 19:40:28.640: INFO: (14) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 34.056002ms)
Jan 24 19:40:28.643: INFO: (14) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 36.263336ms)
Jan 24 19:40:28.643: INFO: (14) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 35.97056ms)
Jan 24 19:40:28.644: INFO: (14) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 37.245766ms)
Jan 24 19:40:28.644: INFO: (14) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 35.289859ms)
Jan 24 19:40:28.664: INFO: (15) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 17.888031ms)
Jan 24 19:40:28.664: INFO: (15) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 19.896157ms)
Jan 24 19:40:28.665: INFO: (15) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 20.026717ms)
Jan 24 19:40:28.665: INFO: (15) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 19.783979ms)
Jan 24 19:40:28.665: INFO: (15) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 20.176833ms)
Jan 24 19:40:28.667: INFO: (15) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 21.437284ms)
Jan 24 19:40:28.668: INFO: (15) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 22.068655ms)
Jan 24 19:40:28.668: INFO: (15) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 23.213734ms)
Jan 24 19:40:28.672: INFO: (15) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 25.23121ms)
Jan 24 19:40:28.673: INFO: (15) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 26.643526ms)
Jan 24 19:40:28.673: INFO: (15) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 26.877958ms)
Jan 24 19:40:28.674: INFO: (15) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 27.574784ms)
Jan 24 19:40:28.675: INFO: (15) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 29.337194ms)
Jan 24 19:40:28.675: INFO: (15) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 28.348543ms)
Jan 24 19:40:28.676: INFO: (15) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 28.682234ms)
Jan 24 19:40:28.682: INFO: (15) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 35.02065ms)
Jan 24 19:40:28.722: INFO: (16) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 38.761853ms)
Jan 24 19:40:28.722: INFO: (16) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 37.672096ms)
Jan 24 19:40:28.727: INFO: (16) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 44.275001ms)
Jan 24 19:40:28.742: INFO: (16) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 57.69833ms)
Jan 24 19:40:28.745: INFO: (16) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 59.67499ms)
Jan 24 19:40:28.745: INFO: (16) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 60.219502ms)
Jan 24 19:40:28.750: INFO: (16) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 64.40268ms)
Jan 24 19:40:28.750: INFO: (16) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 66.598637ms)
Jan 24 19:40:28.756: INFO: (16) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 70.859265ms)
Jan 24 19:40:28.764: INFO: (16) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 79.98784ms)
Jan 24 19:40:28.764: INFO: (16) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 80.466087ms)
Jan 24 19:40:28.764: INFO: (16) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 80.289932ms)
Jan 24 19:40:28.765: INFO: (16) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 80.807866ms)
Jan 24 19:40:28.768: INFO: (16) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 85.293663ms)
Jan 24 19:40:28.773: INFO: (16) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 88.92958ms)
Jan 24 19:40:28.773: INFO: (16) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 88.565168ms)
Jan 24 19:40:28.789: INFO: (17) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 15.148588ms)
Jan 24 19:40:28.799: INFO: (17) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 24.575597ms)
Jan 24 19:40:28.799: INFO: (17) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 24.771621ms)
Jan 24 19:40:28.802: INFO: (17) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 27.048411ms)
Jan 24 19:40:28.802: INFO: (17) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 27.232134ms)
Jan 24 19:40:28.802: INFO: (17) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 28.465715ms)
Jan 24 19:40:28.803: INFO: (17) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 28.716416ms)
Jan 24 19:40:28.803: INFO: (17) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 28.627785ms)
Jan 24 19:40:28.803: INFO: (17) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 28.956944ms)
Jan 24 19:40:28.803: INFO: (17) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 28.863108ms)
Jan 24 19:40:28.803: INFO: (17) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 28.727516ms)
Jan 24 19:40:28.805: INFO: (17) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 30.747352ms)
Jan 24 19:40:28.805: INFO: (17) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 30.870391ms)
Jan 24 19:40:28.805: INFO: (17) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 31.329116ms)
Jan 24 19:40:28.805: INFO: (17) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 30.687102ms)
Jan 24 19:40:28.806: INFO: (17) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 31.754712ms)
Jan 24 19:40:28.827: INFO: (18) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 20.371425ms)
Jan 24 19:40:28.832: INFO: (18) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 24.909057ms)
Jan 24 19:40:28.832: INFO: (18) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 25.685667ms)
Jan 24 19:40:28.832: INFO: (18) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 26.035237ms)
Jan 24 19:40:28.838: INFO: (18) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 29.562595ms)
Jan 24 19:40:28.838: INFO: (18) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 30.704432ms)
Jan 24 19:40:28.839: INFO: (18) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 31.598325ms)
Jan 24 19:40:28.839: INFO: (18) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 32.262088ms)
Jan 24 19:40:28.840: INFO: (18) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 31.914443ms)
Jan 24 19:40:28.840: INFO: (18) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 32.000861ms)
Jan 24 19:40:28.841: INFO: (18) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 33.040124ms)
Jan 24 19:40:28.841: INFO: (18) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 33.194067ms)
Jan 24 19:40:28.841: INFO: (18) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 32.984383ms)
Jan 24 19:40:28.841: INFO: (18) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 33.973587ms)
Jan 24 19:40:28.844: INFO: (18) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 36.541876ms)
Jan 24 19:40:28.844: INFO: (18) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 36.4104ms)
Jan 24 19:40:28.870: INFO: (19) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 25.042713ms)
Jan 24 19:40:28.872: INFO: (19) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 27.031961ms)
Jan 24 19:40:28.872: INFO: (19) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 26.132695ms)
Jan 24 19:40:28.872: INFO: (19) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 26.33422ms)
Jan 24 19:40:28.872: INFO: (19) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 26.638548ms)
Jan 24 19:40:28.876: INFO: (19) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 30.263539ms)
Jan 24 19:40:28.876: INFO: (19) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 30.658299ms)
Jan 24 19:40:28.876: INFO: (19) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 30.783169ms)
Jan 24 19:40:28.876: INFO: (19) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 31.465699ms)
Jan 24 19:40:28.876: INFO: (19) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 31.327418ms)
Jan 24 19:40:28.877: INFO: (19) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 31.578513ms)
Jan 24 19:40:28.878: INFO: (19) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 33.066933ms)
Jan 24 19:40:28.881: INFO: (19) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 36.150406ms)
Jan 24 19:40:28.882: INFO: (19) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 36.577546ms)
Jan 24 19:40:28.882: INFO: (19) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 36.759764ms)
Jan 24 19:40:28.882: INFO: (19) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 36.778773ms)
STEP: deleting ReplicationController proxy-service-nlkhw in namespace proxy-8991, will wait for the garbage collector to delete the pods 01/24/23 19:40:28.882
Jan 24 19:40:28.958: INFO: Deleting ReplicationController proxy-service-nlkhw took: 16.191315ms
Jan 24 19:40:29.059: INFO: Terminating ReplicationController proxy-service-nlkhw pods took: 101.783437ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Jan 24 19:40:31.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8991" for this suite. 01/24/23 19:40:31.089
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":180,"skipped":3574,"failed":0}
------------------------------
• [SLOW TEST] [8.699 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:40:22.415
    Jan 24 19:40:22.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename proxy 01/24/23 19:40:22.421
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:22.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:22.569
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 01/24/23 19:40:22.786
    STEP: creating replication controller proxy-service-nlkhw in namespace proxy-8991 01/24/23 19:40:22.802
    I0124 19:40:22.871623      22 runners.go:193] Created replication controller with name: proxy-service-nlkhw, namespace: proxy-8991, replica count: 1
    I0124 19:40:23.992487      22 runners.go:193] proxy-service-nlkhw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:40:24.995474      22 runners.go:193] proxy-service-nlkhw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:40:25.999633      22 runners.go:193] proxy-service-nlkhw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:40:27.000807      22 runners.go:193] proxy-service-nlkhw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I0124 19:40:28.001282      22 runners.go:193] proxy-service-nlkhw Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 19:40:28.006: INFO: setup took 5.427665338s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 01/24/23 19:40:28.006
    Jan 24 19:40:28.033: INFO: (0) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 25.860089ms)
    Jan 24 19:40:28.033: INFO: (0) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 25.654072ms)
    Jan 24 19:40:28.036: INFO: (0) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 28.552223ms)
    Jan 24 19:40:28.045: INFO: (0) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 37.865248ms)
    Jan 24 19:40:28.065: INFO: (0) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 57.396732ms)
    Jan 24 19:40:28.066: INFO: (0) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 57.59376ms)
    Jan 24 19:40:28.065: INFO: (0) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 59.243143ms)
    Jan 24 19:40:28.068: INFO: (0) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 60.675599ms)
    Jan 24 19:40:28.068: INFO: (0) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 61.366139ms)
    Jan 24 19:40:28.068: INFO: (0) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 60.019613ms)
    Jan 24 19:40:28.069: INFO: (0) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 60.433753ms)
    Jan 24 19:40:28.069: INFO: (0) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 61.698745ms)
    Jan 24 19:40:28.069: INFO: (0) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 62.646413ms)
    Jan 24 19:40:28.069: INFO: (0) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 63.141793ms)
    Jan 24 19:40:28.072: INFO: (0) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 63.831378ms)
    Jan 24 19:40:28.073: INFO: (0) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 64.580494ms)
    Jan 24 19:40:28.099: INFO: (1) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 25.35103ms)
    Jan 24 19:40:28.099: INFO: (1) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 25.387653ms)
    Jan 24 19:40:28.099: INFO: (1) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 25.867685ms)
    Jan 24 19:40:28.102: INFO: (1) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 28.62123ms)
    Jan 24 19:40:28.102: INFO: (1) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 28.938958ms)
    Jan 24 19:40:28.102: INFO: (1) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 28.612844ms)
    Jan 24 19:40:28.102: INFO: (1) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 28.786053ms)
    Jan 24 19:40:28.105: INFO: (1) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 31.910465ms)
    Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 32.027733ms)
    Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 32.268334ms)
    Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 32.062678ms)
    Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 32.365435ms)
    Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 33.184599ms)
    Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 32.89968ms)
    Jan 24 19:40:28.106: INFO: (1) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 33.119995ms)
    Jan 24 19:40:28.107: INFO: (1) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 33.859153ms)
    Jan 24 19:40:28.127: INFO: (2) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 19.709058ms)
    Jan 24 19:40:28.131: INFO: (2) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 23.557886ms)
    Jan 24 19:40:28.132: INFO: (2) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 24.155632ms)
    Jan 24 19:40:28.139: INFO: (2) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 30.904004ms)
    Jan 24 19:40:28.139: INFO: (2) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 32.69352ms)
    Jan 24 19:40:28.140: INFO: (2) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 31.700369ms)
    Jan 24 19:40:28.141: INFO: (2) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 32.917145ms)
    Jan 24 19:40:28.141: INFO: (2) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 33.104419ms)
    Jan 24 19:40:28.141: INFO: (2) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 33.216491ms)
    Jan 24 19:40:28.142: INFO: (2) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 34.096217ms)
    Jan 24 19:40:28.145: INFO: (2) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 36.822651ms)
    Jan 24 19:40:28.145: INFO: (2) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 36.829717ms)
    Jan 24 19:40:28.146: INFO: (2) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 37.168243ms)
    Jan 24 19:40:28.149: INFO: (2) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 42.380729ms)
    Jan 24 19:40:28.150: INFO: (2) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 42.254785ms)
    Jan 24 19:40:28.151: INFO: (2) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 42.891294ms)
    Jan 24 19:40:28.186: INFO: (3) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 34.275163ms)
    Jan 24 19:40:28.186: INFO: (3) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 32.809739ms)
    Jan 24 19:40:28.187: INFO: (3) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 32.768811ms)
    Jan 24 19:40:28.187: INFO: (3) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 32.929088ms)
    Jan 24 19:40:28.187: INFO: (3) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 35.57385ms)
    Jan 24 19:40:28.188: INFO: (3) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 35.565282ms)
    Jan 24 19:40:28.188: INFO: (3) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 35.777334ms)
    Jan 24 19:40:28.188: INFO: (3) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 36.117169ms)
    Jan 24 19:40:28.189: INFO: (3) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 35.826544ms)
    Jan 24 19:40:28.191: INFO: (3) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 39.068521ms)
    Jan 24 19:40:28.191: INFO: (3) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 37.516091ms)
    Jan 24 19:40:28.191: INFO: (3) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 39.716982ms)
    Jan 24 19:40:28.193: INFO: (3) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 40.358923ms)
    Jan 24 19:40:28.193: INFO: (3) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 40.442496ms)
    Jan 24 19:40:28.193: INFO: (3) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 41.101653ms)
    Jan 24 19:40:28.193: INFO: (3) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 40.96953ms)
    Jan 24 19:40:28.227: INFO: (4) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 31.998717ms)
    Jan 24 19:40:28.230: INFO: (4) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 35.550006ms)
    Jan 24 19:40:28.231: INFO: (4) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 35.473763ms)
    Jan 24 19:40:28.231: INFO: (4) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 35.313135ms)
    Jan 24 19:40:28.232: INFO: (4) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 36.781503ms)
    Jan 24 19:40:28.234: INFO: (4) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 39.185017ms)
    Jan 24 19:40:28.235: INFO: (4) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 39.423667ms)
    Jan 24 19:40:28.235: INFO: (4) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 39.553557ms)
    Jan 24 19:40:28.235: INFO: (4) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 40.75805ms)
    Jan 24 19:40:28.235: INFO: (4) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 40.676215ms)
    Jan 24 19:40:28.237: INFO: (4) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 41.485978ms)
    Jan 24 19:40:28.237: INFO: (4) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 41.864248ms)
    Jan 24 19:40:28.238: INFO: (4) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 42.196755ms)
    Jan 24 19:40:28.239: INFO: (4) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 43.72666ms)
    Jan 24 19:40:28.240: INFO: (4) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 45.118288ms)
    Jan 24 19:40:28.241: INFO: (4) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 45.937244ms)
    Jan 24 19:40:28.290: INFO: (5) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 49.035115ms)
    Jan 24 19:40:28.290: INFO: (5) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 49.443337ms)
    Jan 24 19:40:28.292: INFO: (5) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 50.225991ms)
    Jan 24 19:40:28.292: INFO: (5) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 50.787094ms)
    Jan 24 19:40:28.295: INFO: (5) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 53.6791ms)
    Jan 24 19:40:28.295: INFO: (5) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 54.297698ms)
    Jan 24 19:40:28.296: INFO: (5) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 53.865404ms)
    Jan 24 19:40:28.296: INFO: (5) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 54.157996ms)
    Jan 24 19:40:28.297: INFO: (5) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 56.249289ms)
    Jan 24 19:40:28.297: INFO: (5) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 56.209703ms)
    Jan 24 19:40:28.297: INFO: (5) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 56.185476ms)
    Jan 24 19:40:28.297: INFO: (5) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 55.990763ms)
    Jan 24 19:40:28.297: INFO: (5) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 55.852322ms)
    Jan 24 19:40:28.301: INFO: (5) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 59.109746ms)
    Jan 24 19:40:28.305: INFO: (5) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 63.479845ms)
    Jan 24 19:40:28.306: INFO: (5) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 64.464153ms)
    Jan 24 19:40:28.320: INFO: (6) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 12.108711ms)
    Jan 24 19:40:28.320: INFO: (6) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 13.172467ms)
    Jan 24 19:40:28.321: INFO: (6) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 13.920007ms)
    Jan 24 19:40:28.322: INFO: (6) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 15.560252ms)
    Jan 24 19:40:28.322: INFO: (6) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 15.227656ms)
    Jan 24 19:40:28.324: INFO: (6) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 15.42602ms)
    Jan 24 19:40:28.332: INFO: (6) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 25.414174ms)
    Jan 24 19:40:28.333: INFO: (6) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 24.230457ms)
    Jan 24 19:40:28.333: INFO: (6) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 24.78834ms)
    Jan 24 19:40:28.333: INFO: (6) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 25.506729ms)
    Jan 24 19:40:28.333: INFO: (6) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 25.707678ms)
    Jan 24 19:40:28.333: INFO: (6) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 26.995561ms)
    Jan 24 19:40:28.334: INFO: (6) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 27.537548ms)
    Jan 24 19:40:28.335: INFO: (6) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 26.199353ms)
    Jan 24 19:40:28.338: INFO: (6) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 31.444321ms)
    Jan 24 19:40:28.338: INFO: (6) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 31.262309ms)
    Jan 24 19:40:28.360: INFO: (7) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 20.136461ms)
    Jan 24 19:40:28.360: INFO: (7) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 21.403116ms)
    Jan 24 19:40:28.361: INFO: (7) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 21.076915ms)
    Jan 24 19:40:28.366: INFO: (7) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 26.578511ms)
    Jan 24 19:40:28.368: INFO: (7) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 27.82277ms)
    Jan 24 19:40:28.368: INFO: (7) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 28.013806ms)
    Jan 24 19:40:28.368: INFO: (7) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 29.13488ms)
    Jan 24 19:40:28.368: INFO: (7) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 29.427361ms)
    Jan 24 19:40:28.368: INFO: (7) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 28.049761ms)
    Jan 24 19:40:28.369: INFO: (7) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 31.558233ms)
    Jan 24 19:40:28.369: INFO: (7) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 31.395149ms)
    Jan 24 19:40:28.370: INFO: (7) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 31.284951ms)
    Jan 24 19:40:28.372: INFO: (7) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 32.586411ms)
    Jan 24 19:40:28.372: INFO: (7) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 32.47775ms)
    Jan 24 19:40:28.374: INFO: (7) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 35.492829ms)
    Jan 24 19:40:28.374: INFO: (7) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 35.802922ms)
    Jan 24 19:40:28.385: INFO: (8) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 10.438582ms)
    Jan 24 19:40:28.392: INFO: (8) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 16.223065ms)
    Jan 24 19:40:28.392: INFO: (8) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 17.738963ms)
    Jan 24 19:40:28.395: INFO: (8) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 19.790493ms)
    Jan 24 19:40:28.395: INFO: (8) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 19.947858ms)
    Jan 24 19:40:28.396: INFO: (8) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 19.474469ms)
    Jan 24 19:40:28.396: INFO: (8) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 19.035249ms)
    Jan 24 19:40:28.396: INFO: (8) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 20.835444ms)
    Jan 24 19:40:28.397: INFO: (8) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 20.531862ms)
    Jan 24 19:40:28.397: INFO: (8) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 22.028873ms)
    Jan 24 19:40:28.399: INFO: (8) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 22.537735ms)
    Jan 24 19:40:28.401: INFO: (8) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 26.111084ms)
    Jan 24 19:40:28.401: INFO: (8) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 25.604622ms)
    Jan 24 19:40:28.402: INFO: (8) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 25.957806ms)
    Jan 24 19:40:28.404: INFO: (8) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 27.857391ms)
    Jan 24 19:40:28.409: INFO: (8) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 32.39942ms)
    Jan 24 19:40:28.434: INFO: (9) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 22.968033ms)
    Jan 24 19:40:28.437: INFO: (9) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 25.425815ms)
    Jan 24 19:40:28.437: INFO: (9) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 27.088773ms)
    Jan 24 19:40:28.437: INFO: (9) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 28.040884ms)
    Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 27.123523ms)
    Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 27.514151ms)
    Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 28.151969ms)
    Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 28.705046ms)
    Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 27.761509ms)
    Jan 24 19:40:28.438: INFO: (9) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 27.652012ms)
    Jan 24 19:40:28.439: INFO: (9) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 29.143306ms)
    Jan 24 19:40:28.440: INFO: (9) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 29.762621ms)
    Jan 24 19:40:28.441: INFO: (9) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 30.649459ms)
    Jan 24 19:40:28.442: INFO: (9) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 31.620394ms)
    Jan 24 19:40:28.442: INFO: (9) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 32.204122ms)
    Jan 24 19:40:28.443: INFO: (9) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 33.156398ms)
    Jan 24 19:40:28.460: INFO: (10) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 15.758536ms)
    Jan 24 19:40:28.460: INFO: (10) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 15.923662ms)
    Jan 24 19:40:28.461: INFO: (10) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 18.425087ms)
    Jan 24 19:40:28.462: INFO: (10) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 18.410352ms)
    Jan 24 19:40:28.462: INFO: (10) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 19.081608ms)
    Jan 24 19:40:28.465: INFO: (10) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 21.527599ms)
    Jan 24 19:40:28.465: INFO: (10) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 22.271171ms)
    Jan 24 19:40:28.469: INFO: (10) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 25.648852ms)
    Jan 24 19:40:28.470: INFO: (10) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 26.895613ms)
    Jan 24 19:40:28.473: INFO: (10) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 30.034482ms)
    Jan 24 19:40:28.475: INFO: (10) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 31.361097ms)
    Jan 24 19:40:28.475: INFO: (10) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 31.565965ms)
    Jan 24 19:40:28.475: INFO: (10) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 31.51689ms)
    Jan 24 19:40:28.475: INFO: (10) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 31.371511ms)
    Jan 24 19:40:28.475: INFO: (10) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 32.374645ms)
    Jan 24 19:40:28.476: INFO: (10) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 32.485772ms)
    Jan 24 19:40:28.509: INFO: (11) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 32.75094ms)
    Jan 24 19:40:28.509: INFO: (11) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 32.362806ms)
    Jan 24 19:40:28.512: INFO: (11) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 35.482556ms)
    Jan 24 19:40:28.512: INFO: (11) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 35.649204ms)
    Jan 24 19:40:28.512: INFO: (11) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 35.652056ms)
    Jan 24 19:40:28.512: INFO: (11) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 35.659327ms)
    Jan 24 19:40:28.513: INFO: (11) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 36.469587ms)
    Jan 24 19:40:28.520: INFO: (11) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 43.786437ms)
    Jan 24 19:40:28.521: INFO: (11) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 44.649499ms)
    Jan 24 19:40:28.521: INFO: (11) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 45.21935ms)
    Jan 24 19:40:28.521: INFO: (11) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 45.106475ms)
    Jan 24 19:40:28.521: INFO: (11) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 45.094758ms)
    Jan 24 19:40:28.522: INFO: (11) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 45.321195ms)
    Jan 24 19:40:28.522: INFO: (11) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 45.449663ms)
    Jan 24 19:40:28.522: INFO: (11) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 45.59735ms)
    Jan 24 19:40:28.522: INFO: (11) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 45.775738ms)
    Jan 24 19:40:28.544: INFO: (12) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 21.725323ms)
    Jan 24 19:40:28.544: INFO: (12) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 22.077489ms)
    Jan 24 19:40:28.547: INFO: (12) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 23.012519ms)
    Jan 24 19:40:28.547: INFO: (12) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 24.181008ms)
    Jan 24 19:40:28.547: INFO: (12) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 24.004987ms)
    Jan 24 19:40:28.547: INFO: (12) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 23.995006ms)
    Jan 24 19:40:28.547: INFO: (12) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 24.280693ms)
    Jan 24 19:40:28.549: INFO: (12) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 25.338689ms)
    Jan 24 19:40:28.549: INFO: (12) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 26.28715ms)
    Jan 24 19:40:28.551: INFO: (12) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 28.78076ms)
    Jan 24 19:40:28.551: INFO: (12) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 27.880726ms)
    Jan 24 19:40:28.552: INFO: (12) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 28.465738ms)
    Jan 24 19:40:28.555: INFO: (12) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 31.802724ms)
    Jan 24 19:40:28.557: INFO: (12) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 33.894032ms)
    Jan 24 19:40:28.559: INFO: (12) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 35.865815ms)
    Jan 24 19:40:28.560: INFO: (12) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 37.153114ms)
    Jan 24 19:40:28.587: INFO: (13) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 26.479761ms)
    Jan 24 19:40:28.587: INFO: (13) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 26.464236ms)
    Jan 24 19:40:28.588: INFO: (13) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 27.321204ms)
    Jan 24 19:40:28.588: INFO: (13) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 26.866883ms)
    Jan 24 19:40:28.588: INFO: (13) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 27.682948ms)
    Jan 24 19:40:28.590: INFO: (13) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 29.082328ms)
    Jan 24 19:40:28.591: INFO: (13) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 30.044495ms)
    Jan 24 19:40:28.592: INFO: (13) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 30.751983ms)
    Jan 24 19:40:28.595: INFO: (13) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 34.995692ms)
    Jan 24 19:40:28.596: INFO: (13) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 35.135892ms)
    Jan 24 19:40:28.596: INFO: (13) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 35.480642ms)
    Jan 24 19:40:28.597: INFO: (13) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 35.276403ms)
    Jan 24 19:40:28.597: INFO: (13) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 35.822303ms)
    Jan 24 19:40:28.603: INFO: (13) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 41.913517ms)
    Jan 24 19:40:28.603: INFO: (13) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 42.249559ms)
    Jan 24 19:40:28.604: INFO: (13) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 42.383793ms)
    Jan 24 19:40:28.612: INFO: (14) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 7.973231ms)
    Jan 24 19:40:28.617: INFO: (14) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 11.528194ms)
    Jan 24 19:40:28.617: INFO: (14) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 12.23071ms)
    Jan 24 19:40:28.620: INFO: (14) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 14.711347ms)
    Jan 24 19:40:28.621: INFO: (14) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 15.41668ms)
    Jan 24 19:40:28.628: INFO: (14) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 21.53477ms)
    Jan 24 19:40:28.628: INFO: (14) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 23.944007ms)
    Jan 24 19:40:28.627: INFO: (14) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 21.399799ms)
    Jan 24 19:40:28.632: INFO: (14) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 25.659566ms)
    Jan 24 19:40:28.633: INFO: (14) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 26.934004ms)
    Jan 24 19:40:28.637: INFO: (14) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 30.689417ms)
    Jan 24 19:40:28.640: INFO: (14) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 34.056002ms)
    Jan 24 19:40:28.643: INFO: (14) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 36.263336ms)
    Jan 24 19:40:28.643: INFO: (14) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 35.97056ms)
    Jan 24 19:40:28.644: INFO: (14) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 37.245766ms)
    Jan 24 19:40:28.644: INFO: (14) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 35.289859ms)
    Jan 24 19:40:28.664: INFO: (15) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 17.888031ms)
    Jan 24 19:40:28.664: INFO: (15) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 19.896157ms)
    Jan 24 19:40:28.665: INFO: (15) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 20.026717ms)
    Jan 24 19:40:28.665: INFO: (15) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 19.783979ms)
    Jan 24 19:40:28.665: INFO: (15) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 20.176833ms)
    Jan 24 19:40:28.667: INFO: (15) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 21.437284ms)
    Jan 24 19:40:28.668: INFO: (15) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 22.068655ms)
    Jan 24 19:40:28.668: INFO: (15) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 23.213734ms)
    Jan 24 19:40:28.672: INFO: (15) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 25.23121ms)
    Jan 24 19:40:28.673: INFO: (15) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 26.643526ms)
    Jan 24 19:40:28.673: INFO: (15) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 26.877958ms)
    Jan 24 19:40:28.674: INFO: (15) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 27.574784ms)
    Jan 24 19:40:28.675: INFO: (15) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 29.337194ms)
    Jan 24 19:40:28.675: INFO: (15) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 28.348543ms)
    Jan 24 19:40:28.676: INFO: (15) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 28.682234ms)
    Jan 24 19:40:28.682: INFO: (15) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 35.02065ms)
    Jan 24 19:40:28.722: INFO: (16) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 38.761853ms)
    Jan 24 19:40:28.722: INFO: (16) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 37.672096ms)
    Jan 24 19:40:28.727: INFO: (16) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 44.275001ms)
    Jan 24 19:40:28.742: INFO: (16) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 57.69833ms)
    Jan 24 19:40:28.745: INFO: (16) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 59.67499ms)
    Jan 24 19:40:28.745: INFO: (16) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 60.219502ms)
    Jan 24 19:40:28.750: INFO: (16) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 64.40268ms)
    Jan 24 19:40:28.750: INFO: (16) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 66.598637ms)
    Jan 24 19:40:28.756: INFO: (16) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 70.859265ms)
    Jan 24 19:40:28.764: INFO: (16) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 79.98784ms)
    Jan 24 19:40:28.764: INFO: (16) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 80.466087ms)
    Jan 24 19:40:28.764: INFO: (16) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 80.289932ms)
    Jan 24 19:40:28.765: INFO: (16) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 80.807866ms)
    Jan 24 19:40:28.768: INFO: (16) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 85.293663ms)
    Jan 24 19:40:28.773: INFO: (16) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 88.92958ms)
    Jan 24 19:40:28.773: INFO: (16) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 88.565168ms)
    Jan 24 19:40:28.789: INFO: (17) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 15.148588ms)
    Jan 24 19:40:28.799: INFO: (17) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 24.575597ms)
    Jan 24 19:40:28.799: INFO: (17) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 24.771621ms)
    Jan 24 19:40:28.802: INFO: (17) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 27.048411ms)
    Jan 24 19:40:28.802: INFO: (17) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 27.232134ms)
    Jan 24 19:40:28.802: INFO: (17) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 28.465715ms)
    Jan 24 19:40:28.803: INFO: (17) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 28.716416ms)
    Jan 24 19:40:28.803: INFO: (17) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 28.627785ms)
    Jan 24 19:40:28.803: INFO: (17) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 28.956944ms)
    Jan 24 19:40:28.803: INFO: (17) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 28.863108ms)
    Jan 24 19:40:28.803: INFO: (17) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 28.727516ms)
    Jan 24 19:40:28.805: INFO: (17) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 30.747352ms)
    Jan 24 19:40:28.805: INFO: (17) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 30.870391ms)
    Jan 24 19:40:28.805: INFO: (17) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 31.329116ms)
    Jan 24 19:40:28.805: INFO: (17) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 30.687102ms)
    Jan 24 19:40:28.806: INFO: (17) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 31.754712ms)
    Jan 24 19:40:28.827: INFO: (18) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 20.371425ms)
    Jan 24 19:40:28.832: INFO: (18) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 24.909057ms)
    Jan 24 19:40:28.832: INFO: (18) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 25.685667ms)
    Jan 24 19:40:28.832: INFO: (18) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 26.035237ms)
    Jan 24 19:40:28.838: INFO: (18) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 29.562595ms)
    Jan 24 19:40:28.838: INFO: (18) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 30.704432ms)
    Jan 24 19:40:28.839: INFO: (18) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 31.598325ms)
    Jan 24 19:40:28.839: INFO: (18) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 32.262088ms)
    Jan 24 19:40:28.840: INFO: (18) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 31.914443ms)
    Jan 24 19:40:28.840: INFO: (18) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 32.000861ms)
    Jan 24 19:40:28.841: INFO: (18) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 33.040124ms)
    Jan 24 19:40:28.841: INFO: (18) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 33.194067ms)
    Jan 24 19:40:28.841: INFO: (18) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 32.984383ms)
    Jan 24 19:40:28.841: INFO: (18) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 33.973587ms)
    Jan 24 19:40:28.844: INFO: (18) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 36.541876ms)
    Jan 24 19:40:28.844: INFO: (18) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 36.4104ms)
    Jan 24 19:40:28.870: INFO: (19) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 25.042713ms)
    Jan 24 19:40:28.872: INFO: (19) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 27.031961ms)
    Jan 24 19:40:28.872: INFO: (19) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">... (200; 26.132695ms)
    Jan 24 19:40:28.872: INFO: (19) /api/v1/namespaces/proxy-8991/pods/http:proxy-service-nlkhw-p85g2:160/proxy/: foo (200; 26.33422ms)
    Jan 24 19:40:28.872: INFO: (19) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:1080/proxy/rewriteme">test<... (200; 26.638548ms)
    Jan 24 19:40:28.876: INFO: (19) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2/proxy/rewriteme">test</a> (200; 30.263539ms)
    Jan 24 19:40:28.876: INFO: (19) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/: <a href="/api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:443/proxy/tlsrewritem... (200; 30.658299ms)
    Jan 24 19:40:28.876: INFO: (19) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:460/proxy/: tls baz (200; 30.783169ms)
    Jan 24 19:40:28.876: INFO: (19) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname2/proxy/: tls qux (200; 31.465699ms)
    Jan 24 19:40:28.876: INFO: (19) /api/v1/namespaces/proxy-8991/pods/https:proxy-service-nlkhw-p85g2:462/proxy/: tls qux (200; 31.327418ms)
    Jan 24 19:40:28.877: INFO: (19) /api/v1/namespaces/proxy-8991/pods/proxy-service-nlkhw-p85g2:162/proxy/: bar (200; 31.578513ms)
    Jan 24 19:40:28.878: INFO: (19) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname2/proxy/: bar (200; 33.066933ms)
    Jan 24 19:40:28.881: INFO: (19) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname1/proxy/: foo (200; 36.150406ms)
    Jan 24 19:40:28.882: INFO: (19) /api/v1/namespaces/proxy-8991/services/http:proxy-service-nlkhw:portname1/proxy/: foo (200; 36.577546ms)
    Jan 24 19:40:28.882: INFO: (19) /api/v1/namespaces/proxy-8991/services/proxy-service-nlkhw:portname2/proxy/: bar (200; 36.759764ms)
    Jan 24 19:40:28.882: INFO: (19) /api/v1/namespaces/proxy-8991/services/https:proxy-service-nlkhw:tlsportname1/proxy/: tls baz (200; 36.778773ms)
    STEP: deleting ReplicationController proxy-service-nlkhw in namespace proxy-8991, will wait for the garbage collector to delete the pods 01/24/23 19:40:28.882
    Jan 24 19:40:28.958: INFO: Deleting ReplicationController proxy-service-nlkhw took: 16.191315ms
    Jan 24 19:40:29.059: INFO: Terminating ReplicationController proxy-service-nlkhw pods took: 101.783437ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Jan 24 19:40:31.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-8991" for this suite. 01/24/23 19:40:31.089
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:40:31.117
Jan 24 19:40:31.117: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:40:31.119
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:31.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:31.225
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-78afa86c-b993-45bf-a172-a09f434fef84 01/24/23 19:40:31.234
STEP: Creating a pod to test consume configMaps 01/24/23 19:40:31.242
Jan 24 19:40:31.265: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0" in namespace "projected-5921" to be "Succeeded or Failed"
Jan 24 19:40:31.308: INFO: Pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0": Phase="Pending", Reason="", readiness=false. Elapsed: 42.814449ms
Jan 24 19:40:33.317: INFO: Pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051060032s
Jan 24 19:40:35.320: INFO: Pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055007497s
Jan 24 19:40:37.325: INFO: Pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059090359s
STEP: Saw pod success 01/24/23 19:40:37.325
Jan 24 19:40:37.325: INFO: Pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0" satisfied condition "Succeeded or Failed"
Jan 24 19:40:37.339: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 19:40:37.362
Jan 24 19:40:37.399: INFO: Waiting for pod pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0 to disappear
Jan 24 19:40:37.411: INFO: Pod pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 24 19:40:37.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5921" for this suite. 01/24/23 19:40:37.428
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":181,"skipped":3589,"failed":0}
------------------------------
• [SLOW TEST] [6.333 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:40:31.117
    Jan 24 19:40:31.117: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:40:31.119
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:31.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:31.225
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-78afa86c-b993-45bf-a172-a09f434fef84 01/24/23 19:40:31.234
    STEP: Creating a pod to test consume configMaps 01/24/23 19:40:31.242
    Jan 24 19:40:31.265: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0" in namespace "projected-5921" to be "Succeeded or Failed"
    Jan 24 19:40:31.308: INFO: Pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0": Phase="Pending", Reason="", readiness=false. Elapsed: 42.814449ms
    Jan 24 19:40:33.317: INFO: Pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051060032s
    Jan 24 19:40:35.320: INFO: Pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055007497s
    Jan 24 19:40:37.325: INFO: Pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059090359s
    STEP: Saw pod success 01/24/23 19:40:37.325
    Jan 24 19:40:37.325: INFO: Pod "pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0" satisfied condition "Succeeded or Failed"
    Jan 24 19:40:37.339: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 19:40:37.362
    Jan 24 19:40:37.399: INFO: Waiting for pod pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0 to disappear
    Jan 24 19:40:37.411: INFO: Pod pod-projected-configmaps-1e6985ee-da39-4de4-a027-e475e352ded0 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 24 19:40:37.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5921" for this suite. 01/24/23 19:40:37.428
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:40:37.463
Jan 24 19:40:37.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename daemonsets 01/24/23 19:40:37.475
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:37.531
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:37.542
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 01/24/23 19:40:37.623
STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 19:40:37.642
Jan 24 19:40:37.672: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:40:37.672: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:38.739: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:40:38.739: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:39.732: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:40:39.732: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:40.719: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:40:40.720: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:41.784: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 24 19:40:41.784: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 01/24/23 19:40:41.814
Jan 24 19:40:42.027: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:40:42.027: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:43.310: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:40:43.310: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:44.241: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:40:44.241: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:45.100: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:40:45.100: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:46.083: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:40:46.083: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:47.054: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:40:47.054: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:48.045: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:40:48.046: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:49.050: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:40:49.050: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:40:50.057: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 24 19:40:50.057: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/24/23 19:40:50.081
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7062, will wait for the garbage collector to delete the pods 01/24/23 19:40:50.082
Jan 24 19:40:50.176: INFO: Deleting DaemonSet.extensions daemon-set took: 31.455912ms
Jan 24 19:40:50.334: INFO: Terminating DaemonSet.extensions daemon-set pods took: 158.41192ms
Jan 24 19:40:53.870: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:40:53.870: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 24 19:40:53.885: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30440"},"items":null}

Jan 24 19:40:53.944: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30440"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 24 19:40:54.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7062" for this suite. 01/24/23 19:40:54.068
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":182,"skipped":3591,"failed":0}
------------------------------
• [SLOW TEST] [16.634 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:40:37.463
    Jan 24 19:40:37.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename daemonsets 01/24/23 19:40:37.475
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:37.531
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:37.542
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 01/24/23 19:40:37.623
    STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 19:40:37.642
    Jan 24 19:40:37.672: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:40:37.672: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:38.739: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:40:38.739: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:39.732: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:40:39.732: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:40.719: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:40:40.720: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:41.784: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 24 19:40:41.784: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 01/24/23 19:40:41.814
    Jan 24 19:40:42.027: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:40:42.027: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:43.310: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:40:43.310: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:44.241: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:40:44.241: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:45.100: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:40:45.100: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:46.083: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:40:46.083: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:47.054: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:40:47.054: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:48.045: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:40:48.046: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:49.050: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:40:49.050: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:40:50.057: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 24 19:40:50.057: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/24/23 19:40:50.081
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7062, will wait for the garbage collector to delete the pods 01/24/23 19:40:50.082
    Jan 24 19:40:50.176: INFO: Deleting DaemonSet.extensions daemon-set took: 31.455912ms
    Jan 24 19:40:50.334: INFO: Terminating DaemonSet.extensions daemon-set pods took: 158.41192ms
    Jan 24 19:40:53.870: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:40:53.870: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 24 19:40:53.885: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30440"},"items":null}

    Jan 24 19:40:53.944: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30440"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 19:40:54.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7062" for this suite. 01/24/23 19:40:54.068
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:40:54.125
Jan 24 19:40:54.125: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 19:40:54.13
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:54.233
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:54.296
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 01/24/23 19:40:54.386
Jan 24 19:40:54.440: INFO: Waiting up to 5m0s for pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe" in namespace "downward-api-4465" to be "running and ready"
Jan 24 19:40:54.454: INFO: Pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe": Phase="Pending", Reason="", readiness=false. Elapsed: 14.205004ms
Jan 24 19:40:54.456: INFO: The phase of Pod labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:40:56.479: INFO: Pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039081449s
Jan 24 19:40:56.480: INFO: The phase of Pod labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:40:58.488: INFO: Pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe": Phase="Running", Reason="", readiness=true. Elapsed: 4.047624413s
Jan 24 19:40:58.488: INFO: The phase of Pod labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe is Running (Ready = true)
Jan 24 19:40:58.489: INFO: Pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe" satisfied condition "running and ready"
Jan 24 19:40:59.323: INFO: Successfully updated pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 19:41:01.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4465" for this suite. 01/24/23 19:41:01.658
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":183,"skipped":3598,"failed":0}
------------------------------
• [SLOW TEST] [7.768 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:40:54.125
    Jan 24 19:40:54.125: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 19:40:54.13
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:40:54.233
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:40:54.296
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 01/24/23 19:40:54.386
    Jan 24 19:40:54.440: INFO: Waiting up to 5m0s for pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe" in namespace "downward-api-4465" to be "running and ready"
    Jan 24 19:40:54.454: INFO: Pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe": Phase="Pending", Reason="", readiness=false. Elapsed: 14.205004ms
    Jan 24 19:40:54.456: INFO: The phase of Pod labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:40:56.479: INFO: Pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039081449s
    Jan 24 19:40:56.480: INFO: The phase of Pod labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:40:58.488: INFO: Pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe": Phase="Running", Reason="", readiness=true. Elapsed: 4.047624413s
    Jan 24 19:40:58.488: INFO: The phase of Pod labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe is Running (Ready = true)
    Jan 24 19:40:58.489: INFO: Pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe" satisfied condition "running and ready"
    Jan 24 19:40:59.323: INFO: Successfully updated pod "labelsupdate3b1849a0-b6c1-4b15-be53-908bb3f1bebe"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 19:41:01.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4465" for this suite. 01/24/23 19:41:01.658
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:41:01.918
Jan 24 19:41:01.918: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 19:41:01.923
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:02.192
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:02.294
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 01/24/23 19:41:02.736
Jan 24 19:41:02.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-7559 create -f -'
Jan 24 19:41:12.365: INFO: stderr: ""
Jan 24 19:41:12.366: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 01/24/23 19:41:12.366
Jan 24 19:41:12.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-7559 diff -f -'
Jan 24 19:41:16.627: INFO: rc: 1
Jan 24 19:41:16.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-7559 delete -f -'
Jan 24 19:41:16.789: INFO: stderr: ""
Jan 24 19:41:16.789: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 19:41:16.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7559" for this suite. 01/24/23 19:41:16.8
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":184,"skipped":3607,"failed":0}
------------------------------
• [SLOW TEST] [14.896 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:41:01.918
    Jan 24 19:41:01.918: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 19:41:01.923
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:02.192
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:02.294
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 01/24/23 19:41:02.736
    Jan 24 19:41:02.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-7559 create -f -'
    Jan 24 19:41:12.365: INFO: stderr: ""
    Jan 24 19:41:12.366: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 01/24/23 19:41:12.366
    Jan 24 19:41:12.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-7559 diff -f -'
    Jan 24 19:41:16.627: INFO: rc: 1
    Jan 24 19:41:16.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-7559 delete -f -'
    Jan 24 19:41:16.789: INFO: stderr: ""
    Jan 24 19:41:16.789: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 19:41:16.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7559" for this suite. 01/24/23 19:41:16.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:41:16.817
Jan 24 19:41:16.817: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 19:41:16.822
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:16.853
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:16.859
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 01/24/23 19:41:16.863
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 19:41:16.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6031" for this suite. 01/24/23 19:41:16.876
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":185,"skipped":3635,"failed":0}
------------------------------
• [0.076 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:41:16.817
    Jan 24 19:41:16.817: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 19:41:16.822
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:16.853
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:16.859
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 01/24/23 19:41:16.863
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 19:41:16.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6031" for this suite. 01/24/23 19:41:16.876
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:41:16.902
Jan 24 19:41:16.902: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubelet-test 01/24/23 19:41:16.906
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:16.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:16.936
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Jan 24 19:41:16.952: INFO: Waiting up to 5m0s for pod "busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254" in namespace "kubelet-test-225" to be "running and ready"
Jan 24 19:41:16.980: INFO: Pod "busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254": Phase="Pending", Reason="", readiness=false. Elapsed: 27.891477ms
Jan 24 19:41:16.980: INFO: The phase of Pod busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:41:18.988: INFO: Pod "busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254": Phase="Running", Reason="", readiness=true. Elapsed: 2.035156821s
Jan 24 19:41:18.988: INFO: The phase of Pod busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254 is Running (Ready = true)
Jan 24 19:41:18.989: INFO: Pod "busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jan 24 19:41:19.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-225" for this suite. 01/24/23 19:41:19.025
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":186,"skipped":3685,"failed":0}
------------------------------
• [2.138 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:41:16.902
    Jan 24 19:41:16.902: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubelet-test 01/24/23 19:41:16.906
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:16.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:16.936
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Jan 24 19:41:16.952: INFO: Waiting up to 5m0s for pod "busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254" in namespace "kubelet-test-225" to be "running and ready"
    Jan 24 19:41:16.980: INFO: Pod "busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254": Phase="Pending", Reason="", readiness=false. Elapsed: 27.891477ms
    Jan 24 19:41:16.980: INFO: The phase of Pod busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:41:18.988: INFO: Pod "busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254": Phase="Running", Reason="", readiness=true. Elapsed: 2.035156821s
    Jan 24 19:41:18.988: INFO: The phase of Pod busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254 is Running (Ready = true)
    Jan 24 19:41:18.989: INFO: Pod "busybox-scheduling-a8d0fb4a-305e-413d-86c6-550f0ab09254" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jan 24 19:41:19.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-225" for this suite. 01/24/23 19:41:19.025
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:41:19.041
Jan 24 19:41:19.041: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 19:41:19.043
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:19.083
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:19.098
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 01/24/23 19:41:19.107
STEP: Creating a ResourceQuota 01/24/23 19:41:24.113
STEP: Ensuring resource quota status is calculated 01/24/23 19:41:24.154
STEP: Creating a Service 01/24/23 19:41:26.165
STEP: Creating a NodePort Service 01/24/23 19:41:26.223
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 01/24/23 19:41:26.315
STEP: Ensuring resource quota status captures service creation 01/24/23 19:41:26.364
STEP: Deleting Services 01/24/23 19:41:28.387
STEP: Ensuring resource quota status released usage 01/24/23 19:41:28.762
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 19:41:30.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5448" for this suite. 01/24/23 19:41:30.83
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":187,"skipped":3685,"failed":0}
------------------------------
• [SLOW TEST] [11.807 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:41:19.041
    Jan 24 19:41:19.041: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 19:41:19.043
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:19.083
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:19.098
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 01/24/23 19:41:19.107
    STEP: Creating a ResourceQuota 01/24/23 19:41:24.113
    STEP: Ensuring resource quota status is calculated 01/24/23 19:41:24.154
    STEP: Creating a Service 01/24/23 19:41:26.165
    STEP: Creating a NodePort Service 01/24/23 19:41:26.223
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 01/24/23 19:41:26.315
    STEP: Ensuring resource quota status captures service creation 01/24/23 19:41:26.364
    STEP: Deleting Services 01/24/23 19:41:28.387
    STEP: Ensuring resource quota status released usage 01/24/23 19:41:28.762
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 19:41:30.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5448" for this suite. 01/24/23 19:41:30.83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:41:30.861
Jan 24 19:41:30.861: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename job 01/24/23 19:41:30.864
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:30.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:31.001
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 01/24/23 19:41:31.031
STEP: Ensure pods equal to paralellism count is attached to the job 01/24/23 19:41:31.05
STEP: patching /status 01/24/23 19:41:37.067
STEP: updating /status 01/24/23 19:41:37.093
STEP: get /status 01/24/23 19:41:37.12
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 24 19:41:37.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7315" for this suite. 01/24/23 19:41:37.149
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":188,"skipped":3692,"failed":0}
------------------------------
• [SLOW TEST] [6.311 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:41:30.861
    Jan 24 19:41:30.861: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename job 01/24/23 19:41:30.864
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:30.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:31.001
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 01/24/23 19:41:31.031
    STEP: Ensure pods equal to paralellism count is attached to the job 01/24/23 19:41:31.05
    STEP: patching /status 01/24/23 19:41:37.067
    STEP: updating /status 01/24/23 19:41:37.093
    STEP: get /status 01/24/23 19:41:37.12
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 24 19:41:37.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7315" for this suite. 01/24/23 19:41:37.149
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:41:37.173
Jan 24 19:41:37.174: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubelet-test 01/24/23 19:41:37.177
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:37.213
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:37.248
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 01/24/23 19:41:37.299
Jan 24 19:41:37.299: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061" in namespace "kubelet-test-2420" to be "completed"
Jan 24 19:41:37.324: INFO: Pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061": Phase="Pending", Reason="", readiness=false. Elapsed: 24.702617ms
Jan 24 19:41:39.351: INFO: Pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052077041s
Jan 24 19:41:41.338: INFO: Pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038753136s
Jan 24 19:41:43.348: INFO: Pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0486074s
Jan 24 19:41:43.348: INFO: Pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jan 24 19:41:43.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2420" for this suite. 01/24/23 19:41:43.386
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":189,"skipped":3695,"failed":0}
------------------------------
• [SLOW TEST] [6.225 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:41:37.173
    Jan 24 19:41:37.174: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubelet-test 01/24/23 19:41:37.177
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:37.213
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:37.248
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 01/24/23 19:41:37.299
    Jan 24 19:41:37.299: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061" in namespace "kubelet-test-2420" to be "completed"
    Jan 24 19:41:37.324: INFO: Pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061": Phase="Pending", Reason="", readiness=false. Elapsed: 24.702617ms
    Jan 24 19:41:39.351: INFO: Pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052077041s
    Jan 24 19:41:41.338: INFO: Pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038753136s
    Jan 24 19:41:43.348: INFO: Pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0486074s
    Jan 24 19:41:43.348: INFO: Pod "agnhost-host-aliases1a77cfde-d1ad-4ef3-8d5f-7be8297a6061" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jan 24 19:41:43.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2420" for this suite. 01/24/23 19:41:43.386
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:41:43.404
Jan 24 19:41:43.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename deployment 01/24/23 19:41:43.414
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:43.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:43.489
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 01/24/23 19:41:43.535
Jan 24 19:41:43.536: INFO: Creating simple deployment test-deployment-2vbg4
Jan 24 19:41:43.674: INFO: deployment "test-deployment-2vbg4" doesn't have the required revision set
Jan 24 19:41:45.738: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 41, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 41, 43, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 41, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 41, 43, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-2vbg4-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Getting /status 01/24/23 19:41:47.834
Jan 24 19:41:47.907: INFO: Deployment test-deployment-2vbg4 has Conditions: [{Available True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2vbg4-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 01/24/23 19:41:47.907
Jan 24 19:41:47.955: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 41, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 41, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 41, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 41, 43, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-2vbg4-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 01/24/23 19:41:47.955
Jan 24 19:41:47.981: INFO: Observed &Deployment event: ADDED
Jan 24 19:41:47.981: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2vbg4-777898ffcc"}
Jan 24 19:41:47.981: INFO: Observed &Deployment event: MODIFIED
Jan 24 19:41:47.981: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2vbg4-777898ffcc"}
Jan 24 19:41:47.981: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jan 24 19:41:47.982: INFO: Observed &Deployment event: MODIFIED
Jan 24 19:41:47.982: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jan 24 19:41:47.983: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-2vbg4-777898ffcc" is progressing.}
Jan 24 19:41:47.987: INFO: Observed &Deployment event: MODIFIED
Jan 24 19:41:47.988: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jan 24 19:41:47.989: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2vbg4-777898ffcc" has successfully progressed.}
Jan 24 19:41:47.991: INFO: Observed &Deployment event: MODIFIED
Jan 24 19:41:47.991: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jan 24 19:41:47.991: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2vbg4-777898ffcc" has successfully progressed.}
Jan 24 19:41:47.991: INFO: Found Deployment test-deployment-2vbg4 in namespace deployment-3624 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jan 24 19:41:47.991: INFO: Deployment test-deployment-2vbg4 has an updated status
STEP: patching the Statefulset Status 01/24/23 19:41:47.991
Jan 24 19:41:47.992: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jan 24 19:41:48.039: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 01/24/23 19:41:48.043
Jan 24 19:41:48.063: INFO: Observed &Deployment event: ADDED
Jan 24 19:41:48.077: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2vbg4-777898ffcc"}
Jan 24 19:41:48.077: INFO: Observed &Deployment event: MODIFIED
Jan 24 19:41:48.077: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2vbg4-777898ffcc"}
Jan 24 19:41:48.077: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jan 24 19:41:48.078: INFO: Observed &Deployment event: MODIFIED
Jan 24 19:41:48.078: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jan 24 19:41:48.078: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-2vbg4-777898ffcc" is progressing.}
Jan 24 19:41:48.079: INFO: Observed &Deployment event: MODIFIED
Jan 24 19:41:48.079: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jan 24 19:41:48.080: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2vbg4-777898ffcc" has successfully progressed.}
Jan 24 19:41:48.082: INFO: Observed &Deployment event: MODIFIED
Jan 24 19:41:48.084: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jan 24 19:41:48.084: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2vbg4-777898ffcc" has successfully progressed.}
Jan 24 19:41:48.085: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jan 24 19:41:48.086: INFO: Observed &Deployment event: MODIFIED
Jan 24 19:41:48.088: INFO: Found deployment test-deployment-2vbg4 in namespace deployment-3624 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Jan 24 19:41:48.088: INFO: Deployment test-deployment-2vbg4 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 24 19:41:48.102: INFO: Deployment "test-deployment-2vbg4":
&Deployment{ObjectMeta:{test-deployment-2vbg4  deployment-3624  f72e8817-2984-4d22-bf1c-7e46689caa9f 30735 1 2023-01-24 19:41:43 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-01-24 19:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-01-24 19:41:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-01-24 19:41:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002eb9508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-2vbg4-777898ffcc",LastUpdateTime:2023-01-24 19:41:48 +0000 UTC,LastTransitionTime:2023-01-24 19:41:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jan 24 19:41:48.118: INFO: New ReplicaSet "test-deployment-2vbg4-777898ffcc" of Deployment "test-deployment-2vbg4":
&ReplicaSet{ObjectMeta:{test-deployment-2vbg4-777898ffcc  deployment-3624  80e01a78-a4dd-40de-81a9-bb84fc4574b1 30729 1 2023-01-24 19:41:43 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-2vbg4 f72e8817-2984-4d22-bf1c-7e46689caa9f 0xc002eb9900 0xc002eb9901}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f72e8817-2984-4d22-bf1c-7e46689caa9f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:41:46 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002eb99a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jan 24 19:41:48.148: INFO: Pod "test-deployment-2vbg4-777898ffcc-vzk8q" is available:
&Pod{ObjectMeta:{test-deployment-2vbg4-777898ffcc-vzk8q test-deployment-2vbg4-777898ffcc- deployment-3624  ad43a6f5-5a80-42cc-a671-f297d1657537 30727 0 2023-01-24 19:41:43 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:c361e68f6ca5aa3ed3b953198155bbc769457bcd652ce353c5ba71fb76d9a0a9 cni.projectcalico.org/podIP:10.244.71.247/32 cni.projectcalico.org/podIPs:10.244.71.247/32] [{apps/v1 ReplicaSet test-deployment-2vbg4-777898ffcc 80e01a78-a4dd-40de-81a9-bb84fc4574b1 0xc0035c1410 0xc0035c1411}] [] [{kube-controller-manager Update v1 2023-01-24 19:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"80e01a78-a4dd-40de-81a9-bb84fc4574b1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 19:41:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 19:41:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.247\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tj9d8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tj9d8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:41:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:41:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.247,StartTime:2023-01-24 19:41:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 19:41:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6c7c1281a3ab337617a6b9c240106e91516df060922e65c83ada418a5ec5dd05,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.247,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 24 19:41:48.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3624" for this suite. 01/24/23 19:41:48.202
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":190,"skipped":3696,"failed":0}
------------------------------
• [4.886 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:41:43.404
    Jan 24 19:41:43.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename deployment 01/24/23 19:41:43.414
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:43.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:43.489
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 01/24/23 19:41:43.535
    Jan 24 19:41:43.536: INFO: Creating simple deployment test-deployment-2vbg4
    Jan 24 19:41:43.674: INFO: deployment "test-deployment-2vbg4" doesn't have the required revision set
    Jan 24 19:41:45.738: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 41, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 41, 43, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 41, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 41, 43, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-2vbg4-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Getting /status 01/24/23 19:41:47.834
    Jan 24 19:41:47.907: INFO: Deployment test-deployment-2vbg4 has Conditions: [{Available True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2vbg4-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 01/24/23 19:41:47.907
    Jan 24 19:41:47.955: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 41, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 41, 46, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 41, 46, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 41, 43, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-2vbg4-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 01/24/23 19:41:47.955
    Jan 24 19:41:47.981: INFO: Observed &Deployment event: ADDED
    Jan 24 19:41:47.981: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2vbg4-777898ffcc"}
    Jan 24 19:41:47.981: INFO: Observed &Deployment event: MODIFIED
    Jan 24 19:41:47.981: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2vbg4-777898ffcc"}
    Jan 24 19:41:47.981: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jan 24 19:41:47.982: INFO: Observed &Deployment event: MODIFIED
    Jan 24 19:41:47.982: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jan 24 19:41:47.983: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-2vbg4-777898ffcc" is progressing.}
    Jan 24 19:41:47.987: INFO: Observed &Deployment event: MODIFIED
    Jan 24 19:41:47.988: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jan 24 19:41:47.989: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2vbg4-777898ffcc" has successfully progressed.}
    Jan 24 19:41:47.991: INFO: Observed &Deployment event: MODIFIED
    Jan 24 19:41:47.991: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jan 24 19:41:47.991: INFO: Observed Deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2vbg4-777898ffcc" has successfully progressed.}
    Jan 24 19:41:47.991: INFO: Found Deployment test-deployment-2vbg4 in namespace deployment-3624 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jan 24 19:41:47.991: INFO: Deployment test-deployment-2vbg4 has an updated status
    STEP: patching the Statefulset Status 01/24/23 19:41:47.991
    Jan 24 19:41:47.992: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Jan 24 19:41:48.039: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 01/24/23 19:41:48.043
    Jan 24 19:41:48.063: INFO: Observed &Deployment event: ADDED
    Jan 24 19:41:48.077: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2vbg4-777898ffcc"}
    Jan 24 19:41:48.077: INFO: Observed &Deployment event: MODIFIED
    Jan 24 19:41:48.077: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-2vbg4-777898ffcc"}
    Jan 24 19:41:48.077: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jan 24 19:41:48.078: INFO: Observed &Deployment event: MODIFIED
    Jan 24 19:41:48.078: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Jan 24 19:41:48.078: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:43 +0000 UTC 2023-01-24 19:41:43 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-2vbg4-777898ffcc" is progressing.}
    Jan 24 19:41:48.079: INFO: Observed &Deployment event: MODIFIED
    Jan 24 19:41:48.079: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jan 24 19:41:48.080: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2vbg4-777898ffcc" has successfully progressed.}
    Jan 24 19:41:48.082: INFO: Observed &Deployment event: MODIFIED
    Jan 24 19:41:48.084: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:46 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Jan 24 19:41:48.084: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-01-24 19:41:46 +0000 UTC 2023-01-24 19:41:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-2vbg4-777898ffcc" has successfully progressed.}
    Jan 24 19:41:48.085: INFO: Observed deployment test-deployment-2vbg4 in namespace deployment-3624 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jan 24 19:41:48.086: INFO: Observed &Deployment event: MODIFIED
    Jan 24 19:41:48.088: INFO: Found deployment test-deployment-2vbg4 in namespace deployment-3624 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Jan 24 19:41:48.088: INFO: Deployment test-deployment-2vbg4 has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 24 19:41:48.102: INFO: Deployment "test-deployment-2vbg4":
    &Deployment{ObjectMeta:{test-deployment-2vbg4  deployment-3624  f72e8817-2984-4d22-bf1c-7e46689caa9f 30735 1 2023-01-24 19:41:43 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-01-24 19:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-01-24 19:41:48 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-01-24 19:41:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002eb9508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-2vbg4-777898ffcc",LastUpdateTime:2023-01-24 19:41:48 +0000 UTC,LastTransitionTime:2023-01-24 19:41:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jan 24 19:41:48.118: INFO: New ReplicaSet "test-deployment-2vbg4-777898ffcc" of Deployment "test-deployment-2vbg4":
    &ReplicaSet{ObjectMeta:{test-deployment-2vbg4-777898ffcc  deployment-3624  80e01a78-a4dd-40de-81a9-bb84fc4574b1 30729 1 2023-01-24 19:41:43 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-2vbg4 f72e8817-2984-4d22-bf1c-7e46689caa9f 0xc002eb9900 0xc002eb9901}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f72e8817-2984-4d22-bf1c-7e46689caa9f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:41:46 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002eb99a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 19:41:48.148: INFO: Pod "test-deployment-2vbg4-777898ffcc-vzk8q" is available:
    &Pod{ObjectMeta:{test-deployment-2vbg4-777898ffcc-vzk8q test-deployment-2vbg4-777898ffcc- deployment-3624  ad43a6f5-5a80-42cc-a671-f297d1657537 30727 0 2023-01-24 19:41:43 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:c361e68f6ca5aa3ed3b953198155bbc769457bcd652ce353c5ba71fb76d9a0a9 cni.projectcalico.org/podIP:10.244.71.247/32 cni.projectcalico.org/podIPs:10.244.71.247/32] [{apps/v1 ReplicaSet test-deployment-2vbg4-777898ffcc 80e01a78-a4dd-40de-81a9-bb84fc4574b1 0xc0035c1410 0xc0035c1411}] [] [{kube-controller-manager Update v1 2023-01-24 19:41:43 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"80e01a78-a4dd-40de-81a9-bb84fc4574b1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 19:41:44 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 19:41:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.247\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tj9d8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tj9d8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:41:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:41:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.247,StartTime:2023-01-24 19:41:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 19:41:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6c7c1281a3ab337617a6b9c240106e91516df060922e65c83ada418a5ec5dd05,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.247,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 24 19:41:48.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3624" for this suite. 01/24/23 19:41:48.202
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:41:48.319
Jan 24 19:41:48.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-probe 01/24/23 19:41:48.323
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:48.618
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:48.673
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Jan 24 19:42:48.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6365" for this suite. 01/24/23 19:42:48.896
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":191,"skipped":3702,"failed":0}
------------------------------
• [SLOW TEST] [60.625 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:41:48.319
    Jan 24 19:41:48.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-probe 01/24/23 19:41:48.323
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:41:48.618
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:41:48.673
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Jan 24 19:42:48.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6365" for this suite. 01/24/23 19:42:48.896
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:42:48.947
Jan 24 19:42:48.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename cronjob 01/24/23 19:42:48.951
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:42:49.011
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:42:49.085
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 01/24/23 19:42:49.105
STEP: Ensuring no jobs are scheduled 01/24/23 19:42:49.124
STEP: Ensuring no job exists by listing jobs explicitly 01/24/23 19:47:49.146
STEP: Removing cronjob 01/24/23 19:47:49.152
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jan 24 19:47:49.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-8169" for this suite. 01/24/23 19:47:49.172
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":192,"skipped":3705,"failed":0}
------------------------------
• [SLOW TEST] [300.243 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:42:48.947
    Jan 24 19:42:48.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename cronjob 01/24/23 19:42:48.951
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:42:49.011
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:42:49.085
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 01/24/23 19:42:49.105
    STEP: Ensuring no jobs are scheduled 01/24/23 19:42:49.124
    STEP: Ensuring no job exists by listing jobs explicitly 01/24/23 19:47:49.146
    STEP: Removing cronjob 01/24/23 19:47:49.152
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jan 24 19:47:49.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-8169" for this suite. 01/24/23 19:47:49.172
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:47:49.192
Jan 24 19:47:49.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-lifecycle-hook 01/24/23 19:47:49.195
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:47:49.26
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:47:49.272
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 01/24/23 19:47:49.312
Jan 24 19:47:49.338: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5662" to be "running and ready"
Jan 24 19:47:49.352: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 13.53721ms
Jan 24 19:47:49.352: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:47:51.388: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050008049s
Jan 24 19:47:51.388: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:47:53.383: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.045205033s
Jan 24 19:47:53.384: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jan 24 19:47:53.385: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 01/24/23 19:47:53.396
Jan 24 19:47:53.429: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-5662" to be "running and ready"
Jan 24 19:47:53.441: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 9.303407ms
Jan 24 19:47:53.442: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:47:55.466: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034648903s
Jan 24 19:47:55.466: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:47:57.460: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.028781322s
Jan 24 19:47:57.460: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Jan 24 19:47:57.460: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 01/24/23 19:47:57.477
Jan 24 19:47:57.497: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 24 19:47:57.516: INFO: Pod pod-with-prestop-http-hook still exists
Jan 24 19:47:59.516: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 24 19:47:59.533: INFO: Pod pod-with-prestop-http-hook still exists
Jan 24 19:48:01.517: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 24 19:48:01.554: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 01/24/23 19:48:01.554
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jan 24 19:48:01.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5662" for this suite. 01/24/23 19:48:01.663
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":193,"skipped":3718,"failed":0}
------------------------------
• [SLOW TEST] [12.497 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:47:49.192
    Jan 24 19:47:49.193: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-lifecycle-hook 01/24/23 19:47:49.195
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:47:49.26
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:47:49.272
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 01/24/23 19:47:49.312
    Jan 24 19:47:49.338: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5662" to be "running and ready"
    Jan 24 19:47:49.352: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 13.53721ms
    Jan 24 19:47:49.352: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:47:51.388: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050008049s
    Jan 24 19:47:51.388: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:47:53.383: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.045205033s
    Jan 24 19:47:53.384: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jan 24 19:47:53.385: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 01/24/23 19:47:53.396
    Jan 24 19:47:53.429: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-5662" to be "running and ready"
    Jan 24 19:47:53.441: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 9.303407ms
    Jan 24 19:47:53.442: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:47:55.466: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034648903s
    Jan 24 19:47:55.466: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:47:57.460: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.028781322s
    Jan 24 19:47:57.460: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Jan 24 19:47:57.460: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 01/24/23 19:47:57.477
    Jan 24 19:47:57.497: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Jan 24 19:47:57.516: INFO: Pod pod-with-prestop-http-hook still exists
    Jan 24 19:47:59.516: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Jan 24 19:47:59.533: INFO: Pod pod-with-prestop-http-hook still exists
    Jan 24 19:48:01.517: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Jan 24 19:48:01.554: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 01/24/23 19:48:01.554
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jan 24 19:48:01.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-5662" for this suite. 01/24/23 19:48:01.663
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:48:01.695
Jan 24 19:48:01.696: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename security-context-test 01/24/23 19:48:01.706
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:48:01.859
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:48:01.882
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Jan 24 19:48:01.942: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f" in namespace "security-context-test-2445" to be "Succeeded or Failed"
Jan 24 19:48:01.966: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.512904ms
Jan 24 19:48:04.005: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063500813s
Jan 24 19:48:06.000: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058531252s
Jan 24 19:48:07.988: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04596225s
Jan 24 19:48:09.993: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.050818098s
Jan 24 19:48:09.993: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 24 19:48:10.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2445" for this suite. 01/24/23 19:48:10.049
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":194,"skipped":3719,"failed":0}
------------------------------
• [SLOW TEST] [8.396 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:48:01.695
    Jan 24 19:48:01.696: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename security-context-test 01/24/23 19:48:01.706
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:48:01.859
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:48:01.882
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Jan 24 19:48:01.942: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f" in namespace "security-context-test-2445" to be "Succeeded or Failed"
    Jan 24 19:48:01.966: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.512904ms
    Jan 24 19:48:04.005: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063500813s
    Jan 24 19:48:06.000: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058531252s
    Jan 24 19:48:07.988: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04596225s
    Jan 24 19:48:09.993: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.050818098s
    Jan 24 19:48:09.993: INFO: Pod "alpine-nnp-false-20ca0507-d801-4f6f-8da7-7caff38d314f" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 24 19:48:10.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-2445" for this suite. 01/24/23 19:48:10.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:48:10.093
Jan 24 19:48:10.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 19:48:10.104
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:48:10.199
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:48:10.221
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-39483203-f1e5-4c0a-b0d6-54d308e391aa 01/24/23 19:48:10.274
STEP: Creating the pod 01/24/23 19:48:10.295
Jan 24 19:48:10.343: INFO: Waiting up to 5m0s for pod "pod-configmaps-c658f343-8256-42ff-9c8e-b0048374159e" in namespace "configmap-441" to be "running"
Jan 24 19:48:10.433: INFO: Pod "pod-configmaps-c658f343-8256-42ff-9c8e-b0048374159e": Phase="Pending", Reason="", readiness=false. Elapsed: 89.938184ms
Jan 24 19:48:12.469: INFO: Pod "pod-configmaps-c658f343-8256-42ff-9c8e-b0048374159e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.125954932s
Jan 24 19:48:14.620: INFO: Pod "pod-configmaps-c658f343-8256-42ff-9c8e-b0048374159e": Phase="Running", Reason="", readiness=false. Elapsed: 4.277076562s
Jan 24 19:48:14.620: INFO: Pod "pod-configmaps-c658f343-8256-42ff-9c8e-b0048374159e" satisfied condition "running"
STEP: Waiting for pod with text data 01/24/23 19:48:14.62
STEP: Waiting for pod with binary data 01/24/23 19:48:14.705
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 19:48:14.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-441" for this suite. 01/24/23 19:48:14.836
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":195,"skipped":3728,"failed":0}
------------------------------
• [4.793 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:48:10.093
    Jan 24 19:48:10.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 19:48:10.104
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:48:10.199
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:48:10.221
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-39483203-f1e5-4c0a-b0d6-54d308e391aa 01/24/23 19:48:10.274
    STEP: Creating the pod 01/24/23 19:48:10.295
    Jan 24 19:48:10.343: INFO: Waiting up to 5m0s for pod "pod-configmaps-c658f343-8256-42ff-9c8e-b0048374159e" in namespace "configmap-441" to be "running"
    Jan 24 19:48:10.433: INFO: Pod "pod-configmaps-c658f343-8256-42ff-9c8e-b0048374159e": Phase="Pending", Reason="", readiness=false. Elapsed: 89.938184ms
    Jan 24 19:48:12.469: INFO: Pod "pod-configmaps-c658f343-8256-42ff-9c8e-b0048374159e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.125954932s
    Jan 24 19:48:14.620: INFO: Pod "pod-configmaps-c658f343-8256-42ff-9c8e-b0048374159e": Phase="Running", Reason="", readiness=false. Elapsed: 4.277076562s
    Jan 24 19:48:14.620: INFO: Pod "pod-configmaps-c658f343-8256-42ff-9c8e-b0048374159e" satisfied condition "running"
    STEP: Waiting for pod with text data 01/24/23 19:48:14.62
    STEP: Waiting for pod with binary data 01/24/23 19:48:14.705
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 19:48:14.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-441" for this suite. 01/24/23 19:48:14.836
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:48:14.96
Jan 24 19:48:14.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename disruption 01/24/23 19:48:14.981
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:48:15.531
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:48:15.602
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 01/24/23 19:48:15.802
STEP: Waiting for the pdb to be processed 01/24/23 19:48:15.88
STEP: First trying to evict a pod which shouldn't be evictable 01/24/23 19:48:18.009
STEP: Waiting for all pods to be running 01/24/23 19:48:18.009
Jan 24 19:48:18.017: INFO: pods: 0 < 3
Jan 24 19:48:20.039: INFO: running pods: 2 < 3
STEP: locating a running pod 01/24/23 19:48:22.034
STEP: Updating the pdb to allow a pod to be evicted 01/24/23 19:48:22.065
STEP: Waiting for the pdb to be processed 01/24/23 19:48:22.097
STEP: Trying to evict the same pod we tried earlier which should now be evictable 01/24/23 19:48:24.137
STEP: Waiting for all pods to be running 01/24/23 19:48:24.137
STEP: Waiting for the pdb to observed all healthy pods 01/24/23 19:48:24.156
STEP: Patching the pdb to disallow a pod to be evicted 01/24/23 19:48:24.243
STEP: Waiting for the pdb to be processed 01/24/23 19:48:24.31
STEP: Waiting for all pods to be running 01/24/23 19:48:26.365
Jan 24 19:48:26.377: INFO: running pods: 2 < 3
STEP: locating a running pod 01/24/23 19:48:28.404
STEP: Deleting the pdb to allow a pod to be evicted 01/24/23 19:48:28.586
STEP: Waiting for the pdb to be deleted 01/24/23 19:48:28.689
STEP: Trying to evict the same pod we tried earlier which should now be evictable 01/24/23 19:48:28.865
STEP: Waiting for all pods to be running 01/24/23 19:48:28.866
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jan 24 19:48:28.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1712" for this suite. 01/24/23 19:48:28.979
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":196,"skipped":3749,"failed":0}
------------------------------
• [SLOW TEST] [14.181 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:48:14.96
    Jan 24 19:48:14.974: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename disruption 01/24/23 19:48:14.981
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:48:15.531
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:48:15.602
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 01/24/23 19:48:15.802
    STEP: Waiting for the pdb to be processed 01/24/23 19:48:15.88
    STEP: First trying to evict a pod which shouldn't be evictable 01/24/23 19:48:18.009
    STEP: Waiting for all pods to be running 01/24/23 19:48:18.009
    Jan 24 19:48:18.017: INFO: pods: 0 < 3
    Jan 24 19:48:20.039: INFO: running pods: 2 < 3
    STEP: locating a running pod 01/24/23 19:48:22.034
    STEP: Updating the pdb to allow a pod to be evicted 01/24/23 19:48:22.065
    STEP: Waiting for the pdb to be processed 01/24/23 19:48:22.097
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 01/24/23 19:48:24.137
    STEP: Waiting for all pods to be running 01/24/23 19:48:24.137
    STEP: Waiting for the pdb to observed all healthy pods 01/24/23 19:48:24.156
    STEP: Patching the pdb to disallow a pod to be evicted 01/24/23 19:48:24.243
    STEP: Waiting for the pdb to be processed 01/24/23 19:48:24.31
    STEP: Waiting for all pods to be running 01/24/23 19:48:26.365
    Jan 24 19:48:26.377: INFO: running pods: 2 < 3
    STEP: locating a running pod 01/24/23 19:48:28.404
    STEP: Deleting the pdb to allow a pod to be evicted 01/24/23 19:48:28.586
    STEP: Waiting for the pdb to be deleted 01/24/23 19:48:28.689
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 01/24/23 19:48:28.865
    STEP: Waiting for all pods to be running 01/24/23 19:48:28.866
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jan 24 19:48:28.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1712" for this suite. 01/24/23 19:48:28.979
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:48:29.268
Jan 24 19:48:29.269: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 19:48:29.457
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:48:29.544
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:48:29.552
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-3f08ff85-773f-4de7-8987-ae175edba2f2 01/24/23 19:48:29.582
STEP: Creating a pod to test consume secrets 01/24/23 19:48:29.598
Jan 24 19:48:29.654: INFO: Waiting up to 5m0s for pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd" in namespace "secrets-9261" to be "Succeeded or Failed"
Jan 24 19:48:29.666: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.987109ms
Jan 24 19:48:31.840: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.184750964s
Jan 24 19:48:33.688: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032754752s
Jan 24 19:48:35.696: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041377837s
Jan 24 19:48:37.687: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.031809305s
STEP: Saw pod success 01/24/23 19:48:37.687
Jan 24 19:48:37.688: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd" satisfied condition "Succeeded or Failed"
Jan 24 19:48:37.702: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd container secret-volume-test: <nil>
STEP: delete the pod 01/24/23 19:48:37.737
Jan 24 19:48:37.802: INFO: Waiting for pod pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd to disappear
Jan 24 19:48:37.826: INFO: Pod pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 24 19:48:37.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9261" for this suite. 01/24/23 19:48:37.842
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":197,"skipped":3761,"failed":0}
------------------------------
• [SLOW TEST] [8.612 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:48:29.268
    Jan 24 19:48:29.269: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 19:48:29.457
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:48:29.544
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:48:29.552
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-3f08ff85-773f-4de7-8987-ae175edba2f2 01/24/23 19:48:29.582
    STEP: Creating a pod to test consume secrets 01/24/23 19:48:29.598
    Jan 24 19:48:29.654: INFO: Waiting up to 5m0s for pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd" in namespace "secrets-9261" to be "Succeeded or Failed"
    Jan 24 19:48:29.666: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.987109ms
    Jan 24 19:48:31.840: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.184750964s
    Jan 24 19:48:33.688: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032754752s
    Jan 24 19:48:35.696: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041377837s
    Jan 24 19:48:37.687: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.031809305s
    STEP: Saw pod success 01/24/23 19:48:37.687
    Jan 24 19:48:37.688: INFO: Pod "pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd" satisfied condition "Succeeded or Failed"
    Jan 24 19:48:37.702: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd container secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 19:48:37.737
    Jan 24 19:48:37.802: INFO: Waiting for pod pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd to disappear
    Jan 24 19:48:37.826: INFO: Pod pod-secrets-dfa5ae83-1b73-4846-add9-347935e6aecd no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 19:48:37.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9261" for this suite. 01/24/23 19:48:37.842
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:48:37.93
Jan 24 19:48:37.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pod-network-test 01/24/23 19:48:37.933
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:48:37.999
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:48:38.031
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-1745 01/24/23 19:48:38.051
STEP: creating a selector 01/24/23 19:48:38.052
STEP: Creating the service pods in kubernetes 01/24/23 19:48:38.052
Jan 24 19:48:38.054: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jan 24 19:48:38.126: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1745" to be "running and ready"
Jan 24 19:48:38.197: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 71.05973ms
Jan 24 19:48:38.198: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:48:40.214: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087455451s
Jan 24 19:48:40.214: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:48:42.235: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.108838322s
Jan 24 19:48:42.235: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:48:44.254: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.12750842s
Jan 24 19:48:44.254: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:48:46.212: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.085592299s
Jan 24 19:48:46.212: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:48:48.268: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.141453321s
Jan 24 19:48:48.268: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:48:50.226: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.099436969s
Jan 24 19:48:50.226: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:48:52.218: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.092019788s
Jan 24 19:48:52.219: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:48:54.246: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.119796307s
Jan 24 19:48:54.246: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:48:56.215: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.088452813s
Jan 24 19:48:56.215: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:48:58.244: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.11725525s
Jan 24 19:48:58.245: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:49:00.215: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.089161404s
Jan 24 19:49:00.217: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jan 24 19:49:00.218: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jan 24 19:49:00.243: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1745" to be "running and ready"
Jan 24 19:49:00.253: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.203045ms
Jan 24 19:49:00.253: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jan 24 19:49:00.253: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 01/24/23 19:49:00.269
Jan 24 19:49:00.317: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1745" to be "running"
Jan 24 19:49:00.332: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.18255ms
Jan 24 19:49:02.373: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055146671s
Jan 24 19:49:04.351: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.033832059s
Jan 24 19:49:04.351: INFO: Pod "test-container-pod" satisfied condition "running"
Jan 24 19:49:04.363: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Jan 24 19:49:04.363: INFO: Breadth first check of 10.244.47.69 on host 10.10.1.213...
Jan 24 19:49:04.376: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.71.230:9080/dial?request=hostname&protocol=udp&host=10.244.47.69&port=8081&tries=1'] Namespace:pod-network-test-1745 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:49:04.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:49:04.404: INFO: ExecWithOptions: Clientset creation
Jan 24 19:49:04.404: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-1745/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.71.230%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.47.69%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jan 24 19:49:04.842: INFO: Waiting for responses: map[]
Jan 24 19:49:04.842: INFO: reached 10.244.47.69 after 0/1 tries
Jan 24 19:49:04.842: INFO: Breadth first check of 10.244.71.252 on host 10.10.1.127...
Jan 24 19:49:04.857: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.71.230:9080/dial?request=hostname&protocol=udp&host=10.244.71.252&port=8081&tries=1'] Namespace:pod-network-test-1745 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:49:04.857: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:49:04.861: INFO: ExecWithOptions: Clientset creation
Jan 24 19:49:04.862: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-1745/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.71.230%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.71.252%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jan 24 19:49:05.221: INFO: Waiting for responses: map[]
Jan 24 19:49:05.222: INFO: reached 10.244.71.252 after 0/1 tries
Jan 24 19:49:05.222: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jan 24 19:49:05.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1745" for this suite. 01/24/23 19:49:05.24
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":198,"skipped":3799,"failed":0}
------------------------------
• [SLOW TEST] [27.345 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:48:37.93
    Jan 24 19:48:37.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pod-network-test 01/24/23 19:48:37.933
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:48:37.999
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:48:38.031
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-1745 01/24/23 19:48:38.051
    STEP: creating a selector 01/24/23 19:48:38.052
    STEP: Creating the service pods in kubernetes 01/24/23 19:48:38.052
    Jan 24 19:48:38.054: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jan 24 19:48:38.126: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1745" to be "running and ready"
    Jan 24 19:48:38.197: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 71.05973ms
    Jan 24 19:48:38.198: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:48:40.214: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087455451s
    Jan 24 19:48:40.214: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:48:42.235: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.108838322s
    Jan 24 19:48:42.235: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:48:44.254: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.12750842s
    Jan 24 19:48:44.254: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:48:46.212: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.085592299s
    Jan 24 19:48:46.212: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:48:48.268: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.141453321s
    Jan 24 19:48:48.268: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:48:50.226: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.099436969s
    Jan 24 19:48:50.226: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:48:52.218: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.092019788s
    Jan 24 19:48:52.219: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:48:54.246: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.119796307s
    Jan 24 19:48:54.246: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:48:56.215: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.088452813s
    Jan 24 19:48:56.215: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:48:58.244: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.11725525s
    Jan 24 19:48:58.245: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:49:00.215: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.089161404s
    Jan 24 19:49:00.217: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jan 24 19:49:00.218: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jan 24 19:49:00.243: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1745" to be "running and ready"
    Jan 24 19:49:00.253: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.203045ms
    Jan 24 19:49:00.253: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jan 24 19:49:00.253: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 01/24/23 19:49:00.269
    Jan 24 19:49:00.317: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1745" to be "running"
    Jan 24 19:49:00.332: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.18255ms
    Jan 24 19:49:02.373: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055146671s
    Jan 24 19:49:04.351: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.033832059s
    Jan 24 19:49:04.351: INFO: Pod "test-container-pod" satisfied condition "running"
    Jan 24 19:49:04.363: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Jan 24 19:49:04.363: INFO: Breadth first check of 10.244.47.69 on host 10.10.1.213...
    Jan 24 19:49:04.376: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.71.230:9080/dial?request=hostname&protocol=udp&host=10.244.47.69&port=8081&tries=1'] Namespace:pod-network-test-1745 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:49:04.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:49:04.404: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:49:04.404: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-1745/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.71.230%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.47.69%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jan 24 19:49:04.842: INFO: Waiting for responses: map[]
    Jan 24 19:49:04.842: INFO: reached 10.244.47.69 after 0/1 tries
    Jan 24 19:49:04.842: INFO: Breadth first check of 10.244.71.252 on host 10.10.1.127...
    Jan 24 19:49:04.857: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.71.230:9080/dial?request=hostname&protocol=udp&host=10.244.71.252&port=8081&tries=1'] Namespace:pod-network-test-1745 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:49:04.857: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:49:04.861: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:49:04.862: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-1745/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.71.230%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.244.71.252%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jan 24 19:49:05.221: INFO: Waiting for responses: map[]
    Jan 24 19:49:05.222: INFO: reached 10.244.71.252 after 0/1 tries
    Jan 24 19:49:05.222: INFO: Going to retry 0 out of 2 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jan 24 19:49:05.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-1745" for this suite. 01/24/23 19:49:05.24
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:49:05.362
Jan 24 19:49:05.363: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 19:49:05.369
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:49:05.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:49:05.754
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 01/24/23 19:49:05.821
Jan 24 19:49:05.878: INFO: Waiting up to 5m0s for pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2" in namespace "emptydir-8345" to be "Succeeded or Failed"
Jan 24 19:49:05.925: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2": Phase="Pending", Reason="", readiness=false. Elapsed: 46.748538ms
Jan 24 19:49:07.966: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087426052s
Jan 24 19:49:09.949: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.071114164s
Jan 24 19:49:12.184: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.306029168s
Jan 24 19:49:13.943: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.064955985s
STEP: Saw pod success 01/24/23 19:49:13.943
Jan 24 19:49:13.944: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2" satisfied condition "Succeeded or Failed"
Jan 24 19:49:13.956: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2 container test-container: <nil>
STEP: delete the pod 01/24/23 19:49:13.981
Jan 24 19:49:14.009: INFO: Waiting for pod pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2 to disappear
Jan 24 19:49:14.016: INFO: Pod pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 19:49:14.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8345" for this suite. 01/24/23 19:49:14.035
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":199,"skipped":3825,"failed":0}
------------------------------
• [SLOW TEST] [8.710 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:49:05.362
    Jan 24 19:49:05.363: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 19:49:05.369
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:49:05.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:49:05.754
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 01/24/23 19:49:05.821
    Jan 24 19:49:05.878: INFO: Waiting up to 5m0s for pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2" in namespace "emptydir-8345" to be "Succeeded or Failed"
    Jan 24 19:49:05.925: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2": Phase="Pending", Reason="", readiness=false. Elapsed: 46.748538ms
    Jan 24 19:49:07.966: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087426052s
    Jan 24 19:49:09.949: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.071114164s
    Jan 24 19:49:12.184: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.306029168s
    Jan 24 19:49:13.943: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.064955985s
    STEP: Saw pod success 01/24/23 19:49:13.943
    Jan 24 19:49:13.944: INFO: Pod "pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2" satisfied condition "Succeeded or Failed"
    Jan 24 19:49:13.956: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2 container test-container: <nil>
    STEP: delete the pod 01/24/23 19:49:13.981
    Jan 24 19:49:14.009: INFO: Waiting for pod pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2 to disappear
    Jan 24 19:49:14.016: INFO: Pod pod-7b0b47f4-e3bf-4acf-a709-1083cfeaaba2 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 19:49:14.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8345" for this suite. 01/24/23 19:49:14.035
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:49:14.142
Jan 24 19:49:14.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename svcaccounts 01/24/23 19:49:14.187
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:49:14.261
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:49:14.29
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Jan 24 19:49:14.524: INFO: Waiting up to 5m0s for pod "pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c" in namespace "svcaccounts-2315" to be "running"
Jan 24 19:49:14.548: INFO: Pod "pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c": Phase="Pending", Reason="", readiness=false. Elapsed: 24.159019ms
Jan 24 19:49:16.568: INFO: Pod "pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044166083s
Jan 24 19:49:18.565: INFO: Pod "pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c": Phase="Running", Reason="", readiness=true. Elapsed: 4.040686651s
Jan 24 19:49:18.565: INFO: Pod "pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c" satisfied condition "running"
STEP: reading a file in the container 01/24/23 19:49:18.565
Jan 24 19:49:18.568: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2315 pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 01/24/23 19:49:19.118
Jan 24 19:49:19.124: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2315 pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 01/24/23 19:49:20.038
Jan 24 19:49:20.039: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2315 pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Jan 24 19:49:20.746: INFO: Got root ca configmap in namespace "svcaccounts-2315"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 24 19:49:20.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2315" for this suite. 01/24/23 19:49:20.761
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":200,"skipped":3852,"failed":0}
------------------------------
• [SLOW TEST] [6.633 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:49:14.142
    Jan 24 19:49:14.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename svcaccounts 01/24/23 19:49:14.187
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:49:14.261
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:49:14.29
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Jan 24 19:49:14.524: INFO: Waiting up to 5m0s for pod "pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c" in namespace "svcaccounts-2315" to be "running"
    Jan 24 19:49:14.548: INFO: Pod "pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c": Phase="Pending", Reason="", readiness=false. Elapsed: 24.159019ms
    Jan 24 19:49:16.568: INFO: Pod "pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044166083s
    Jan 24 19:49:18.565: INFO: Pod "pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c": Phase="Running", Reason="", readiness=true. Elapsed: 4.040686651s
    Jan 24 19:49:18.565: INFO: Pod "pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c" satisfied condition "running"
    STEP: reading a file in the container 01/24/23 19:49:18.565
    Jan 24 19:49:18.568: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2315 pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 01/24/23 19:49:19.118
    Jan 24 19:49:19.124: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2315 pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 01/24/23 19:49:20.038
    Jan 24 19:49:20.039: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2315 pod-service-account-a5bf10c9-9bf3-490b-ac02-3d2d4a5a327c -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Jan 24 19:49:20.746: INFO: Got root ca configmap in namespace "svcaccounts-2315"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 24 19:49:20.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2315" for this suite. 01/24/23 19:49:20.761
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:49:20.781
Jan 24 19:49:20.781: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename deployment 01/24/23 19:49:20.784
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:49:20.836
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:49:20.863
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Jan 24 19:49:20.874: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 24 19:49:20.906: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 24 19:49:25.932: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/24/23 19:49:25.932
Jan 24 19:49:25.932: INFO: Creating deployment "test-rolling-update-deployment"
Jan 24 19:49:25.967: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 24 19:49:25.995: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 24 19:49:28.012: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 24 19:49:28.018: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 49, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 26, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 49, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 19:49:30.028: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 24 19:49:30.105: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9073  91a84296-180c-469a-9d17-6f41e99ab11f 31552 1 2023-01-24 19:49:25 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-01-24 19:49:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038b1788 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-24 19:49:26 +0000 UTC,LastTransitionTime:2023-01-24 19:49:26 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-01-24 19:49:28 +0000 UTC,LastTransitionTime:2023-01-24 19:49:26 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jan 24 19:49:30.134: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-9073  8f499eff-9408-4245-8ec5-3fbc2ef25f7a 31541 1 2023-01-24 19:49:26 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 91a84296-180c-469a-9d17-6f41e99ab11f 0xc0053016c7 0xc0053016c8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:49:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"91a84296-180c-469a-9d17-6f41e99ab11f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:49:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005301778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jan 24 19:49:30.135: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 24 19:49:30.136: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9073  f14506fe-aab1-404e-a94d-32f9f10ca0d6 31551 2 2023-01-24 19:49:20 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 91a84296-180c-469a-9d17-6f41e99ab11f 0xc005301597 0xc005301598}] [] [{e2e.test Update apps/v1 2023-01-24 19:49:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"91a84296-180c-469a-9d17-6f41e99ab11f\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:49:28 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005301658 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 24 19:49:30.147: INFO: Pod "test-rolling-update-deployment-78f575d8ff-pdnrx" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-pdnrx test-rolling-update-deployment-78f575d8ff- deployment-9073  a4a6edff-bdfb-4c34-8d7d-c1bc46be076e 31539 0 2023-01-24 19:49:26 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:5bcd371cfe5b0d13d0d61b9b9b537071544fde79b1afe5ddd582ebb6a1a4c2b8 cni.projectcalico.org/podIP:10.244.71.225/32 cni.projectcalico.org/podIPs:10.244.71.225/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 8f499eff-9408-4245-8ec5-3fbc2ef25f7a 0xc0038b1b87 0xc0038b1b88}] [] [{kube-controller-manager Update v1 2023-01-24 19:49:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8f499eff-9408-4245-8ec5-3fbc2ef25f7a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 19:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 19:49:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.225\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g5p7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g5p7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:49:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:49:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:49:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:49:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.225,StartTime:2023-01-24 19:49:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 19:49:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://87d890a7f4bd1c484406889589b111593699468722eb3e07c90094d198e17294,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 24 19:49:30.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9073" for this suite. 01/24/23 19:49:30.164
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":201,"skipped":3876,"failed":0}
------------------------------
• [SLOW TEST] [9.426 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:49:20.781
    Jan 24 19:49:20.781: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename deployment 01/24/23 19:49:20.784
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:49:20.836
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:49:20.863
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Jan 24 19:49:20.874: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Jan 24 19:49:20.906: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jan 24 19:49:25.932: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/24/23 19:49:25.932
    Jan 24 19:49:25.932: INFO: Creating deployment "test-rolling-update-deployment"
    Jan 24 19:49:25.967: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Jan 24 19:49:25.995: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Jan 24 19:49:28.012: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Jan 24 19:49:28.018: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 49, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 26, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 49, 26, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 19:49:30.028: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 24 19:49:30.105: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9073  91a84296-180c-469a-9d17-6f41e99ab11f 31552 1 2023-01-24 19:49:25 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-01-24 19:49:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038b1788 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-24 19:49:26 +0000 UTC,LastTransitionTime:2023-01-24 19:49:26 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-01-24 19:49:28 +0000 UTC,LastTransitionTime:2023-01-24 19:49:26 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jan 24 19:49:30.134: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-9073  8f499eff-9408-4245-8ec5-3fbc2ef25f7a 31541 1 2023-01-24 19:49:26 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 91a84296-180c-469a-9d17-6f41e99ab11f 0xc0053016c7 0xc0053016c8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:49:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"91a84296-180c-469a-9d17-6f41e99ab11f\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:49:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005301778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 19:49:30.135: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Jan 24 19:49:30.136: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9073  f14506fe-aab1-404e-a94d-32f9f10ca0d6 31551 2 2023-01-24 19:49:20 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 91a84296-180c-469a-9d17-6f41e99ab11f 0xc005301597 0xc005301598}] [] [{e2e.test Update apps/v1 2023-01-24 19:49:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:49:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"91a84296-180c-469a-9d17-6f41e99ab11f\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:49:28 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005301658 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 19:49:30.147: INFO: Pod "test-rolling-update-deployment-78f575d8ff-pdnrx" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-pdnrx test-rolling-update-deployment-78f575d8ff- deployment-9073  a4a6edff-bdfb-4c34-8d7d-c1bc46be076e 31539 0 2023-01-24 19:49:26 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:5bcd371cfe5b0d13d0d61b9b9b537071544fde79b1afe5ddd582ebb6a1a4c2b8 cni.projectcalico.org/podIP:10.244.71.225/32 cni.projectcalico.org/podIPs:10.244.71.225/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 8f499eff-9408-4245-8ec5-3fbc2ef25f7a 0xc0038b1b87 0xc0038b1b88}] [] [{kube-controller-manager Update v1 2023-01-24 19:49:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8f499eff-9408-4245-8ec5-3fbc2ef25f7a\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 19:49:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 19:49:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.225\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g5p7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g5p7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:49:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:49:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:49:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:49:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.225,StartTime:2023-01-24 19:49:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 19:49:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://87d890a7f4bd1c484406889589b111593699468722eb3e07c90094d198e17294,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 24 19:49:30.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9073" for this suite. 01/24/23 19:49:30.164
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:49:30.221
Jan 24 19:49:30.222: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename init-container 01/24/23 19:49:30.225
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:49:30.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:49:30.355
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 01/24/23 19:49:30.397
Jan 24 19:49:30.398: INFO: PodSpec: initContainers in spec.initContainers
Jan 24 19:50:19.873: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ebba4b52-007a-480a-b2ba-c47218696a8c", GenerateName:"", Namespace:"init-container-7765", SelfLink:"", UID:"56a874dd-2307-4845-8798-1d9b4a60c02e", ResourceVersion:"31640", Generation:0, CreationTimestamp:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"398105934"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"ab9dddd9eef4ac2f810e3055dc5d5f9befe9518b09787691af11180d810dccbd", "cni.projectcalico.org/podIP":"10.244.71.241/32", "cni.projectcalico.org/podIPs":"10.244.71.241/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003828018), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 24, 19, 49, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003828048), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 24, 19, 50, 19, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003828090), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-zx7f7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00300ee60), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-zx7f7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-zx7f7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-zx7f7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc005ea4e90), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"vikash-v125latest-conf-71087", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0041c6c40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005ea4f20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005ea4f40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc005ea4f48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc005ea4f4c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000dca160), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.1.127", PodIP:"10.244.71.241", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.71.241"}}, StartTime:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0041c6d20)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0041c6d90)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://cbc60d0841ec9d953bc30bb4bdc468fee65992d16372bf879c52176a2e5b22b8", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00300eee0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00300eec0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc005ea4fcf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 24 19:50:19.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7765" for this suite. 01/24/23 19:50:19.882
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":202,"skipped":3883,"failed":0}
------------------------------
• [SLOW TEST] [49.667 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:49:30.221
    Jan 24 19:49:30.222: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename init-container 01/24/23 19:49:30.225
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:49:30.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:49:30.355
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 01/24/23 19:49:30.397
    Jan 24 19:49:30.398: INFO: PodSpec: initContainers in spec.initContainers
    Jan 24 19:50:19.873: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ebba4b52-007a-480a-b2ba-c47218696a8c", GenerateName:"", Namespace:"init-container-7765", SelfLink:"", UID:"56a874dd-2307-4845-8798-1d9b4a60c02e", ResourceVersion:"31640", Generation:0, CreationTimestamp:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"398105934"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"ab9dddd9eef4ac2f810e3055dc5d5f9befe9518b09787691af11180d810dccbd", "cni.projectcalico.org/podIP":"10.244.71.241/32", "cni.projectcalico.org/podIPs":"10.244.71.241/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003828018), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 24, 19, 49, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003828048), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.January, 24, 19, 50, 19, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003828090), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-zx7f7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00300ee60), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-zx7f7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-zx7f7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-zx7f7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc005ea4e90), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"vikash-v125latest-conf-71087", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0041c6c40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005ea4f20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005ea4f40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc005ea4f48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc005ea4f4c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000dca160), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.1.127", PodIP:"10.244.71.241", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.71.241"}}, StartTime:time.Date(2023, time.January, 24, 19, 49, 30, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0041c6d20)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0041c6d90)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://cbc60d0841ec9d953bc30bb4bdc468fee65992d16372bf879c52176a2e5b22b8", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00300eee0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00300eec0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc005ea4fcf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 24 19:50:19.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-7765" for this suite. 01/24/23 19:50:19.882
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:50:19.894
Jan 24 19:50:19.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 19:50:19.897
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:19.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:19.936
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 19:50:19.956
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:50:20.76
STEP: Deploying the webhook pod 01/24/23 19:50:20.774
STEP: Wait for the deployment to be ready 01/24/23 19:50:20.795
Jan 24 19:50:20.806: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 24 19:50:22.837: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 50, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 50, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 50, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 50, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 19:50:24.844
STEP: Verifying the service has paired with the endpoint 01/24/23 19:50:24.873
Jan 24 19:50:25.886: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 01/24/23 19:50:25.896
STEP: Creating a configMap that does not comply to the validation webhook rules 01/24/23 19:50:25.955
STEP: Updating a validating webhook configuration's rules to not include the create operation 01/24/23 19:50:25.991
STEP: Creating a configMap that does not comply to the validation webhook rules 01/24/23 19:50:26.015
STEP: Patching a validating webhook configuration's rules to include the create operation 01/24/23 19:50:26.042
STEP: Creating a configMap that does not comply to the validation webhook rules 01/24/23 19:50:26.064
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:50:26.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8872" for this suite. 01/24/23 19:50:26.101
STEP: Destroying namespace "webhook-8872-markers" for this suite. 01/24/23 19:50:26.119
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":203,"skipped":3931,"failed":0}
------------------------------
• [SLOW TEST] [6.381 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:50:19.894
    Jan 24 19:50:19.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 19:50:19.897
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:19.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:19.936
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 19:50:19.956
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 19:50:20.76
    STEP: Deploying the webhook pod 01/24/23 19:50:20.774
    STEP: Wait for the deployment to be ready 01/24/23 19:50:20.795
    Jan 24 19:50:20.806: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 24 19:50:22.837: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 50, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 50, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 50, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 50, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 19:50:24.844
    STEP: Verifying the service has paired with the endpoint 01/24/23 19:50:24.873
    Jan 24 19:50:25.886: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 01/24/23 19:50:25.896
    STEP: Creating a configMap that does not comply to the validation webhook rules 01/24/23 19:50:25.955
    STEP: Updating a validating webhook configuration's rules to not include the create operation 01/24/23 19:50:25.991
    STEP: Creating a configMap that does not comply to the validation webhook rules 01/24/23 19:50:26.015
    STEP: Patching a validating webhook configuration's rules to include the create operation 01/24/23 19:50:26.042
    STEP: Creating a configMap that does not comply to the validation webhook rules 01/24/23 19:50:26.064
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:50:26.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8872" for this suite. 01/24/23 19:50:26.101
    STEP: Destroying namespace "webhook-8872-markers" for this suite. 01/24/23 19:50:26.119
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:50:26.293
Jan 24 19:50:26.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 19:50:26.296
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:26.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:26.37
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 01/24/23 19:50:26.379
Jan 24 19:50:26.408: INFO: Waiting up to 5m0s for pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c" in namespace "downward-api-4230" to be "Succeeded or Failed"
Jan 24 19:50:26.420: INFO: Pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.053356ms
Jan 24 19:50:28.461: INFO: Pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052213921s
Jan 24 19:50:30.436: INFO: Pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027808002s
Jan 24 19:50:32.433: INFO: Pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02508751s
STEP: Saw pod success 01/24/23 19:50:32.434
Jan 24 19:50:32.434: INFO: Pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c" satisfied condition "Succeeded or Failed"
Jan 24 19:50:32.454: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c container dapi-container: <nil>
STEP: delete the pod 01/24/23 19:50:32.688
Jan 24 19:50:32.906: INFO: Waiting for pod downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c to disappear
Jan 24 19:50:32.951: INFO: Pod downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jan 24 19:50:32.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4230" for this suite. 01/24/23 19:50:32.992
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":204,"skipped":3956,"failed":0}
------------------------------
• [SLOW TEST] [6.739 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:50:26.293
    Jan 24 19:50:26.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 19:50:26.296
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:26.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:26.37
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 01/24/23 19:50:26.379
    Jan 24 19:50:26.408: INFO: Waiting up to 5m0s for pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c" in namespace "downward-api-4230" to be "Succeeded or Failed"
    Jan 24 19:50:26.420: INFO: Pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.053356ms
    Jan 24 19:50:28.461: INFO: Pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052213921s
    Jan 24 19:50:30.436: INFO: Pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027808002s
    Jan 24 19:50:32.433: INFO: Pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02508751s
    STEP: Saw pod success 01/24/23 19:50:32.434
    Jan 24 19:50:32.434: INFO: Pod "downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c" satisfied condition "Succeeded or Failed"
    Jan 24 19:50:32.454: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c container dapi-container: <nil>
    STEP: delete the pod 01/24/23 19:50:32.688
    Jan 24 19:50:32.906: INFO: Waiting for pod downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c to disappear
    Jan 24 19:50:32.951: INFO: Pod downward-api-d187d2c4-5ebd-45e2-b404-18a3f9fdb79c no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jan 24 19:50:32.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4230" for this suite. 01/24/23 19:50:32.992
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:50:33.036
Jan 24 19:50:33.036: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename custom-resource-definition 01/24/23 19:50:33.04
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:33.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:33.225
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Jan 24 19:50:33.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:50:36.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6757" for this suite. 01/24/23 19:50:36.921
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":205,"skipped":3960,"failed":0}
------------------------------
• [3.903 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:50:33.036
    Jan 24 19:50:33.036: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename custom-resource-definition 01/24/23 19:50:33.04
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:33.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:33.225
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Jan 24 19:50:33.274: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:50:36.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-6757" for this suite. 01/24/23 19:50:36.921
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:50:36.939
Jan 24 19:50:36.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sched-pred 01/24/23 19:50:36.948
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:36.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:36.994
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jan 24 19:50:37.016: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 24 19:50:37.046: INFO: Waiting for terminating namespaces to be deleted...
Jan 24 19:50:37.053: INFO: 
Logging pods the apiserver thinks is on node vikash-v125latest-conf-59870 before test
Jan 24 19:50:37.079: INFO: haproxy-ingress-cb855dc7c-smnf7 from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.079: INFO: 	Container haproxy-ingress ready: true, restart count 0
Jan 24 19:50:37.079: INFO: ingress-default-backend-6f4477b7bc-qg2sz from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.079: INFO: 	Container ingress-default-backend ready: true, restart count 0
Jan 24 19:50:37.080: INFO: calico-kube-controllers-74677b4c5f-zd5w8 from kube-system started at 2023-01-24 18:20:11 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.080: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 24 19:50:37.080: INFO: calico-node-45c9d from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.080: INFO: 	Container calico-node ready: true, restart count 0
Jan 24 19:50:37.080: INFO: coredns-94487f57-9zlwt from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.080: INFO: 	Container coredns ready: true, restart count 0
Jan 24 19:50:37.080: INFO: coredns-94487f57-qldwh from kube-system started at 2023-01-24 18:34:25 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.080: INFO: 	Container coredns ready: true, restart count 0
Jan 24 19:50:37.080: INFO: kyverno-operator-5c87dbd458-txhlw from nirmata started at 2023-01-24 18:22:35 +0000 UTC (2 container statuses recorded)
Jan 24 19:50:37.080: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jan 24 19:50:37.080: INFO: 	Container manager ready: true, restart count 0
Jan 24 19:50:37.080: INFO: nirmata-cni-installer-6skzt from nirmata started at 2023-01-24 08:32:34 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.080: INFO: 	Container install-cni ready: true, restart count 0
Jan 24 19:50:37.081: INFO: otel-agent-6dfc8d44b6-6kj5q from nirmata started at 2023-01-24 18:22:32 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.081: INFO: 	Container otel-agent ready: true, restart count 0
Jan 24 19:50:37.081: INFO: sonobuoy from sonobuoy started at 2023-01-24 18:32:49 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.081: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 24 19:50:37.081: INFO: sonobuoy-e2e-job-d94c6e71d257417d from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 19:50:37.081: INFO: 	Container e2e ready: true, restart count 0
Jan 24 19:50:37.081: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 19:50:37.081: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 19:50:37.081: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 19:50:37.081: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 24 19:50:37.081: INFO: 
Logging pods the apiserver thinks is on node vikash-v125latest-conf-71087 before test
Jan 24 19:50:37.104: INFO: calico-node-kfjch from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.104: INFO: 	Container calico-node ready: true, restart count 0
Jan 24 19:50:37.104: INFO: metrics-server-696f4844bb-xklrk from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.104: INFO: 	Container metrics-server ready: true, restart count 0
Jan 24 19:50:37.104: INFO: nirmata-cni-installer-swjzc from nirmata started at 2023-01-24 18:34:55 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.104: INFO: 	Container install-cni ready: true, restart count 0
Jan 24 19:50:37.104: INFO: nirmata-kube-controller-df864cd5c-bz5gj from nirmata started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 19:50:37.104: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
Jan 24 19:50:37.104: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-x86sk from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 19:50:37.104: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 19:50:37.104: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 01/24/23 19:50:37.104
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.173d5695a6311d53], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] 01/24/23 19:50:37.21
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jan 24 19:50:38.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3222" for this suite. 01/24/23 19:50:38.249
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":206,"skipped":3961,"failed":0}
------------------------------
• [1.331 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:50:36.939
    Jan 24 19:50:36.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sched-pred 01/24/23 19:50:36.948
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:36.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:36.994
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jan 24 19:50:37.016: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jan 24 19:50:37.046: INFO: Waiting for terminating namespaces to be deleted...
    Jan 24 19:50:37.053: INFO: 
    Logging pods the apiserver thinks is on node vikash-v125latest-conf-59870 before test
    Jan 24 19:50:37.079: INFO: haproxy-ingress-cb855dc7c-smnf7 from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.079: INFO: 	Container haproxy-ingress ready: true, restart count 0
    Jan 24 19:50:37.079: INFO: ingress-default-backend-6f4477b7bc-qg2sz from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.079: INFO: 	Container ingress-default-backend ready: true, restart count 0
    Jan 24 19:50:37.080: INFO: calico-kube-controllers-74677b4c5f-zd5w8 from kube-system started at 2023-01-24 18:20:11 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.080: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Jan 24 19:50:37.080: INFO: calico-node-45c9d from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.080: INFO: 	Container calico-node ready: true, restart count 0
    Jan 24 19:50:37.080: INFO: coredns-94487f57-9zlwt from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.080: INFO: 	Container coredns ready: true, restart count 0
    Jan 24 19:50:37.080: INFO: coredns-94487f57-qldwh from kube-system started at 2023-01-24 18:34:25 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.080: INFO: 	Container coredns ready: true, restart count 0
    Jan 24 19:50:37.080: INFO: kyverno-operator-5c87dbd458-txhlw from nirmata started at 2023-01-24 18:22:35 +0000 UTC (2 container statuses recorded)
    Jan 24 19:50:37.080: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
    Jan 24 19:50:37.080: INFO: 	Container manager ready: true, restart count 0
    Jan 24 19:50:37.080: INFO: nirmata-cni-installer-6skzt from nirmata started at 2023-01-24 08:32:34 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.080: INFO: 	Container install-cni ready: true, restart count 0
    Jan 24 19:50:37.081: INFO: otel-agent-6dfc8d44b6-6kj5q from nirmata started at 2023-01-24 18:22:32 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.081: INFO: 	Container otel-agent ready: true, restart count 0
    Jan 24 19:50:37.081: INFO: sonobuoy from sonobuoy started at 2023-01-24 18:32:49 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.081: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jan 24 19:50:37.081: INFO: sonobuoy-e2e-job-d94c6e71d257417d from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 19:50:37.081: INFO: 	Container e2e ready: true, restart count 0
    Jan 24 19:50:37.081: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 19:50:37.081: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 19:50:37.081: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 19:50:37.081: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 24 19:50:37.081: INFO: 
    Logging pods the apiserver thinks is on node vikash-v125latest-conf-71087 before test
    Jan 24 19:50:37.104: INFO: calico-node-kfjch from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.104: INFO: 	Container calico-node ready: true, restart count 0
    Jan 24 19:50:37.104: INFO: metrics-server-696f4844bb-xklrk from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.104: INFO: 	Container metrics-server ready: true, restart count 0
    Jan 24 19:50:37.104: INFO: nirmata-cni-installer-swjzc from nirmata started at 2023-01-24 18:34:55 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.104: INFO: 	Container install-cni ready: true, restart count 0
    Jan 24 19:50:37.104: INFO: nirmata-kube-controller-df864cd5c-bz5gj from nirmata started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 19:50:37.104: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
    Jan 24 19:50:37.104: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-x86sk from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 19:50:37.104: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 19:50:37.104: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 01/24/23 19:50:37.104
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.173d5695a6311d53], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] 01/24/23 19:50:37.21
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 19:50:38.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-3222" for this suite. 01/24/23 19:50:38.249
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:50:38.293
Jan 24 19:50:38.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename var-expansion 01/24/23 19:50:38.316
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:38.371
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:38.381
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 01/24/23 19:50:38.393
Jan 24 19:50:38.426: INFO: Waiting up to 5m0s for pod "var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a" in namespace "var-expansion-7444" to be "Succeeded or Failed"
Jan 24 19:50:38.449: INFO: Pod "var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.661196ms
Jan 24 19:50:40.460: INFO: Pod "var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0320758s
Jan 24 19:50:42.467: INFO: Pod "var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038584357s
STEP: Saw pod success 01/24/23 19:50:42.467
Jan 24 19:50:42.473: INFO: Pod "var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a" satisfied condition "Succeeded or Failed"
Jan 24 19:50:42.488: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a container dapi-container: <nil>
STEP: delete the pod 01/24/23 19:50:42.528
Jan 24 19:50:42.594: INFO: Waiting for pod var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a to disappear
Jan 24 19:50:42.631: INFO: Pod var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 24 19:50:42.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7444" for this suite. 01/24/23 19:50:42.678
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":207,"skipped":3962,"failed":0}
------------------------------
• [4.474 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:50:38.293
    Jan 24 19:50:38.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename var-expansion 01/24/23 19:50:38.316
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:38.371
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:38.381
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 01/24/23 19:50:38.393
    Jan 24 19:50:38.426: INFO: Waiting up to 5m0s for pod "var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a" in namespace "var-expansion-7444" to be "Succeeded or Failed"
    Jan 24 19:50:38.449: INFO: Pod "var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.661196ms
    Jan 24 19:50:40.460: INFO: Pod "var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0320758s
    Jan 24 19:50:42.467: INFO: Pod "var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038584357s
    STEP: Saw pod success 01/24/23 19:50:42.467
    Jan 24 19:50:42.473: INFO: Pod "var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a" satisfied condition "Succeeded or Failed"
    Jan 24 19:50:42.488: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a container dapi-container: <nil>
    STEP: delete the pod 01/24/23 19:50:42.528
    Jan 24 19:50:42.594: INFO: Waiting for pod var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a to disappear
    Jan 24 19:50:42.631: INFO: Pod var-expansion-1656cad0-6ebb-4ee2-8454-e9b7716bf85a no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 24 19:50:42.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7444" for this suite. 01/24/23 19:50:42.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:50:42.777
Jan 24 19:50:42.781: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 19:50:42.797
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:42.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:42.89
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-5396/secret-test-c4b5b7e4-4d68-4ec2-88e2-97fd10e07b2d 01/24/23 19:50:42.906
STEP: Creating a pod to test consume secrets 01/24/23 19:50:42.922
Jan 24 19:50:42.974: INFO: Waiting up to 5m0s for pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280" in namespace "secrets-5396" to be "Succeeded or Failed"
Jan 24 19:50:43.008: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280": Phase="Pending", Reason="", readiness=false. Elapsed: 33.642767ms
Jan 24 19:50:45.026: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051321028s
Jan 24 19:50:47.025: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050608081s
Jan 24 19:50:49.031: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056992955s
Jan 24 19:50:51.040: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.066109897s
STEP: Saw pod success 01/24/23 19:50:51.041
Jan 24 19:50:51.041: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280" satisfied condition "Succeeded or Failed"
Jan 24 19:50:51.061: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280 container env-test: <nil>
STEP: delete the pod 01/24/23 19:50:51.107
Jan 24 19:50:51.327: INFO: Waiting for pod pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280 to disappear
Jan 24 19:50:51.370: INFO: Pod pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jan 24 19:50:51.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5396" for this suite. 01/24/23 19:50:51.444
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":208,"skipped":4003,"failed":0}
------------------------------
• [SLOW TEST] [8.698 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:50:42.777
    Jan 24 19:50:42.781: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 19:50:42.797
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:42.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:42.89
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-5396/secret-test-c4b5b7e4-4d68-4ec2-88e2-97fd10e07b2d 01/24/23 19:50:42.906
    STEP: Creating a pod to test consume secrets 01/24/23 19:50:42.922
    Jan 24 19:50:42.974: INFO: Waiting up to 5m0s for pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280" in namespace "secrets-5396" to be "Succeeded or Failed"
    Jan 24 19:50:43.008: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280": Phase="Pending", Reason="", readiness=false. Elapsed: 33.642767ms
    Jan 24 19:50:45.026: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051321028s
    Jan 24 19:50:47.025: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050608081s
    Jan 24 19:50:49.031: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056992955s
    Jan 24 19:50:51.040: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.066109897s
    STEP: Saw pod success 01/24/23 19:50:51.041
    Jan 24 19:50:51.041: INFO: Pod "pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280" satisfied condition "Succeeded or Failed"
    Jan 24 19:50:51.061: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280 container env-test: <nil>
    STEP: delete the pod 01/24/23 19:50:51.107
    Jan 24 19:50:51.327: INFO: Waiting for pod pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280 to disappear
    Jan 24 19:50:51.370: INFO: Pod pod-configmaps-30294997-66fe-4653-8728-89cc2f06d280 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 19:50:51.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5396" for this suite. 01/24/23 19:50:51.444
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:50:51.502
Jan 24 19:50:51.503: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 19:50:51.507
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:51.583
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:51.609
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-a12f4922-a49b-4ac9-a174-ba8f276de28e 01/24/23 19:50:51.665
STEP: Creating a pod to test consume secrets 01/24/23 19:50:51.692
Jan 24 19:50:51.722: INFO: Waiting up to 5m0s for pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846" in namespace "secrets-6880" to be "Succeeded or Failed"
Jan 24 19:50:51.746: INFO: Pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846": Phase="Pending", Reason="", readiness=false. Elapsed: 23.779256ms
Jan 24 19:50:53.770: INFO: Pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047371586s
Jan 24 19:50:55.763: INFO: Pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846": Phase="Running", Reason="", readiness=false. Elapsed: 4.040968021s
Jan 24 19:50:57.767: INFO: Pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045086371s
STEP: Saw pod success 01/24/23 19:50:57.767
Jan 24 19:50:57.768: INFO: Pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846" satisfied condition "Succeeded or Failed"
Jan 24 19:50:57.794: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846 container secret-volume-test: <nil>
STEP: delete the pod 01/24/23 19:50:57.821
Jan 24 19:50:57.870: INFO: Waiting for pod pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846 to disappear
Jan 24 19:50:57.884: INFO: Pod pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 24 19:50:57.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6880" for this suite. 01/24/23 19:50:57.904
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":209,"skipped":4005,"failed":0}
------------------------------
• [SLOW TEST] [6.435 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:50:51.502
    Jan 24 19:50:51.503: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 19:50:51.507
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:51.583
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:51.609
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-a12f4922-a49b-4ac9-a174-ba8f276de28e 01/24/23 19:50:51.665
    STEP: Creating a pod to test consume secrets 01/24/23 19:50:51.692
    Jan 24 19:50:51.722: INFO: Waiting up to 5m0s for pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846" in namespace "secrets-6880" to be "Succeeded or Failed"
    Jan 24 19:50:51.746: INFO: Pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846": Phase="Pending", Reason="", readiness=false. Elapsed: 23.779256ms
    Jan 24 19:50:53.770: INFO: Pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047371586s
    Jan 24 19:50:55.763: INFO: Pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846": Phase="Running", Reason="", readiness=false. Elapsed: 4.040968021s
    Jan 24 19:50:57.767: INFO: Pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.045086371s
    STEP: Saw pod success 01/24/23 19:50:57.767
    Jan 24 19:50:57.768: INFO: Pod "pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846" satisfied condition "Succeeded or Failed"
    Jan 24 19:50:57.794: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846 container secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 19:50:57.821
    Jan 24 19:50:57.870: INFO: Waiting for pod pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846 to disappear
    Jan 24 19:50:57.884: INFO: Pod pod-secrets-26f1ced6-ab96-470c-834d-2b2a07c3c846 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 19:50:57.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6880" for this suite. 01/24/23 19:50:57.904
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:50:57.964
Jan 24 19:50:57.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir-wrapper 01/24/23 19:50:57.968
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:58.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:58.042
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 01/24/23 19:50:58.048
STEP: Creating RC which spawns configmap-volume pods 01/24/23 19:50:59.014
Jan 24 19:50:59.056: INFO: Pod name wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c: Found 0 pods out of 5
Jan 24 19:51:04.122: INFO: Pod name wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c: Found 5 pods out of 5
STEP: Ensuring each pod is running 01/24/23 19:51:04.122
Jan 24 19:51:04.123: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:51:04.185: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 62.332031ms
Jan 24 19:51:06.204: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081202746s
Jan 24 19:51:08.227: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.104016952s
Jan 24 19:51:10.789: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 6.666189005s
Jan 24 19:51:12.494: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 8.370818226s
Jan 24 19:51:14.279: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 10.156551484s
Jan 24 19:51:16.571: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 12.447850612s
Jan 24 19:51:18.211: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 14.08859375s
Jan 24 19:51:20.483: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 16.359866767s
Jan 24 19:51:22.218: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 18.095071692s
Jan 24 19:51:24.360: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Running", Reason="", readiness=true. Elapsed: 20.237538495s
Jan 24 19:51:24.360: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr" satisfied condition "running"
Jan 24 19:51:24.361: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5trzg" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:51:24.477: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5trzg": Phase="Running", Reason="", readiness=true. Elapsed: 116.298901ms
Jan 24 19:51:24.477: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5trzg" satisfied condition "running"
Jan 24 19:51:24.477: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-65fhk" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:51:24.569: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-65fhk": Phase="Running", Reason="", readiness=true. Elapsed: 91.573403ms
Jan 24 19:51:24.569: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-65fhk" satisfied condition "running"
Jan 24 19:51:24.569: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-msthq" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:51:24.685: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-msthq": Phase="Running", Reason="", readiness=true. Elapsed: 116.159086ms
Jan 24 19:51:24.685: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-msthq" satisfied condition "running"
Jan 24 19:51:24.685: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-nskt8" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:51:24.710: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-nskt8": Phase="Running", Reason="", readiness=true. Elapsed: 24.426867ms
Jan 24 19:51:24.710: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-nskt8" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c in namespace emptydir-wrapper-3762, will wait for the garbage collector to delete the pods 01/24/23 19:51:24.71
Jan 24 19:51:24.846: INFO: Deleting ReplicationController wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c took: 46.08646ms
Jan 24 19:51:25.747: INFO: Terminating ReplicationController wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c pods took: 900.768388ms
STEP: Creating RC which spawns configmap-volume pods 01/24/23 19:51:29.589
Jan 24 19:51:29.633: INFO: Pod name wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270: Found 0 pods out of 5
Jan 24 19:51:34.666: INFO: Pod name wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270: Found 5 pods out of 5
STEP: Ensuring each pod is running 01/24/23 19:51:34.666
Jan 24 19:51:34.667: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:51:34.684: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 17.67684ms
Jan 24 19:51:36.732: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065653511s
Jan 24 19:51:38.706: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039730499s
Jan 24 19:51:40.720: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.05382908s
Jan 24 19:51:42.829: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.162605044s
Jan 24 19:51:45.882: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.215876511s
Jan 24 19:51:46.709: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.042748052s
Jan 24 19:51:48.696: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Running", Reason="", readiness=true. Elapsed: 14.029707017s
Jan 24 19:51:48.696: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6" satisfied condition "running"
Jan 24 19:51:48.696: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-8z6j7" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:51:48.704: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-8z6j7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.305273ms
Jan 24 19:51:50.719: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-8z6j7": Phase="Running", Reason="", readiness=true. Elapsed: 2.022984751s
Jan 24 19:51:50.720: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-8z6j7" satisfied condition "running"
Jan 24 19:51:50.720: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-9j6r5" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:51:50.730: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-9j6r5": Phase="Running", Reason="", readiness=true. Elapsed: 9.596559ms
Jan 24 19:51:50.730: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-9j6r5" satisfied condition "running"
Jan 24 19:51:50.730: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-n4zzs" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:51:50.741: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-n4zzs": Phase="Running", Reason="", readiness=true. Elapsed: 11.255321ms
Jan 24 19:51:50.741: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-n4zzs" satisfied condition "running"
Jan 24 19:51:50.742: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-nn7h6" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:51:50.750: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-nn7h6": Phase="Running", Reason="", readiness=true. Elapsed: 8.047693ms
Jan 24 19:51:50.750: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-nn7h6" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270 in namespace emptydir-wrapper-3762, will wait for the garbage collector to delete the pods 01/24/23 19:51:50.751
Jan 24 19:51:50.828: INFO: Deleting ReplicationController wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270 took: 18.012894ms
Jan 24 19:51:51.030: INFO: Terminating ReplicationController wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270 pods took: 202.321034ms
STEP: Creating RC which spawns configmap-volume pods 01/24/23 19:51:55.647
Jan 24 19:51:55.679: INFO: Pod name wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef: Found 0 pods out of 5
Jan 24 19:52:00.860: INFO: Pod name wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef: Found 5 pods out of 5
STEP: Ensuring each pod is running 01/24/23 19:52:00.86
Jan 24 19:52:00.860: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:52:00.879: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 18.485599ms
Jan 24 19:52:02.926: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066059289s
Jan 24 19:52:04.906: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045484125s
Jan 24 19:52:07.057: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.197176577s
Jan 24 19:52:08.925: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.065193518s
Jan 24 19:52:10.926: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 10.065758675s
Jan 24 19:52:12.942: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Running", Reason="", readiness=true. Elapsed: 12.081437021s
Jan 24 19:52:12.942: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl" satisfied condition "running"
Jan 24 19:52:12.942: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-9v6fv" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:52:13.043: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-9v6fv": Phase="Running", Reason="", readiness=true. Elapsed: 97.877093ms
Jan 24 19:52:13.067: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-9v6fv" satisfied condition "running"
Jan 24 19:52:13.067: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-bdcn5" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:52:13.139: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-bdcn5": Phase="Running", Reason="", readiness=true. Elapsed: 71.59404ms
Jan 24 19:52:13.139: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-bdcn5" satisfied condition "running"
Jan 24 19:52:13.139: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-pdwhh" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:52:13.169: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-pdwhh": Phase="Running", Reason="", readiness=true. Elapsed: 29.758129ms
Jan 24 19:52:13.169: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-pdwhh" satisfied condition "running"
Jan 24 19:52:13.169: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-t42nd" in namespace "emptydir-wrapper-3762" to be "running"
Jan 24 19:52:13.187: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-t42nd": Phase="Running", Reason="", readiness=true. Elapsed: 18.606933ms
Jan 24 19:52:13.187: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-t42nd" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef in namespace emptydir-wrapper-3762, will wait for the garbage collector to delete the pods 01/24/23 19:52:13.187
Jan 24 19:52:13.272: INFO: Deleting ReplicationController wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef took: 22.278883ms
Jan 24 19:52:13.472: INFO: Terminating ReplicationController wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef pods took: 200.365089ms
STEP: Cleaning up the configMaps 01/24/23 19:52:22.59
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Jan 24 19:52:23.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3762" for this suite. 01/24/23 19:52:23.47
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":210,"skipped":4040,"failed":0}
------------------------------
• [SLOW TEST] [85.518 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:50:57.964
    Jan 24 19:50:57.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir-wrapper 01/24/23 19:50:57.968
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:50:58.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:50:58.042
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 01/24/23 19:50:58.048
    STEP: Creating RC which spawns configmap-volume pods 01/24/23 19:50:59.014
    Jan 24 19:50:59.056: INFO: Pod name wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c: Found 0 pods out of 5
    Jan 24 19:51:04.122: INFO: Pod name wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c: Found 5 pods out of 5
    STEP: Ensuring each pod is running 01/24/23 19:51:04.122
    Jan 24 19:51:04.123: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:51:04.185: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 62.332031ms
    Jan 24 19:51:06.204: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081202746s
    Jan 24 19:51:08.227: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.104016952s
    Jan 24 19:51:10.789: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 6.666189005s
    Jan 24 19:51:12.494: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 8.370818226s
    Jan 24 19:51:14.279: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 10.156551484s
    Jan 24 19:51:16.571: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 12.447850612s
    Jan 24 19:51:18.211: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 14.08859375s
    Jan 24 19:51:20.483: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 16.359866767s
    Jan 24 19:51:22.218: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Pending", Reason="", readiness=false. Elapsed: 18.095071692s
    Jan 24 19:51:24.360: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr": Phase="Running", Reason="", readiness=true. Elapsed: 20.237538495s
    Jan 24 19:51:24.360: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5hnlr" satisfied condition "running"
    Jan 24 19:51:24.361: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5trzg" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:51:24.477: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5trzg": Phase="Running", Reason="", readiness=true. Elapsed: 116.298901ms
    Jan 24 19:51:24.477: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-5trzg" satisfied condition "running"
    Jan 24 19:51:24.477: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-65fhk" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:51:24.569: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-65fhk": Phase="Running", Reason="", readiness=true. Elapsed: 91.573403ms
    Jan 24 19:51:24.569: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-65fhk" satisfied condition "running"
    Jan 24 19:51:24.569: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-msthq" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:51:24.685: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-msthq": Phase="Running", Reason="", readiness=true. Elapsed: 116.159086ms
    Jan 24 19:51:24.685: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-msthq" satisfied condition "running"
    Jan 24 19:51:24.685: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-nskt8" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:51:24.710: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-nskt8": Phase="Running", Reason="", readiness=true. Elapsed: 24.426867ms
    Jan 24 19:51:24.710: INFO: Pod "wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c-nskt8" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c in namespace emptydir-wrapper-3762, will wait for the garbage collector to delete the pods 01/24/23 19:51:24.71
    Jan 24 19:51:24.846: INFO: Deleting ReplicationController wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c took: 46.08646ms
    Jan 24 19:51:25.747: INFO: Terminating ReplicationController wrapped-volume-race-835becf8-eba4-42c1-9cbc-bd9857103e3c pods took: 900.768388ms
    STEP: Creating RC which spawns configmap-volume pods 01/24/23 19:51:29.589
    Jan 24 19:51:29.633: INFO: Pod name wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270: Found 0 pods out of 5
    Jan 24 19:51:34.666: INFO: Pod name wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270: Found 5 pods out of 5
    STEP: Ensuring each pod is running 01/24/23 19:51:34.666
    Jan 24 19:51:34.667: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:51:34.684: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 17.67684ms
    Jan 24 19:51:36.732: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065653511s
    Jan 24 19:51:38.706: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039730499s
    Jan 24 19:51:40.720: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.05382908s
    Jan 24 19:51:42.829: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.162605044s
    Jan 24 19:51:45.882: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.215876511s
    Jan 24 19:51:46.709: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.042748052s
    Jan 24 19:51:48.696: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6": Phase="Running", Reason="", readiness=true. Elapsed: 14.029707017s
    Jan 24 19:51:48.696: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-2l7m6" satisfied condition "running"
    Jan 24 19:51:48.696: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-8z6j7" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:51:48.704: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-8z6j7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.305273ms
    Jan 24 19:51:50.719: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-8z6j7": Phase="Running", Reason="", readiness=true. Elapsed: 2.022984751s
    Jan 24 19:51:50.720: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-8z6j7" satisfied condition "running"
    Jan 24 19:51:50.720: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-9j6r5" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:51:50.730: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-9j6r5": Phase="Running", Reason="", readiness=true. Elapsed: 9.596559ms
    Jan 24 19:51:50.730: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-9j6r5" satisfied condition "running"
    Jan 24 19:51:50.730: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-n4zzs" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:51:50.741: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-n4zzs": Phase="Running", Reason="", readiness=true. Elapsed: 11.255321ms
    Jan 24 19:51:50.741: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-n4zzs" satisfied condition "running"
    Jan 24 19:51:50.742: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-nn7h6" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:51:50.750: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-nn7h6": Phase="Running", Reason="", readiness=true. Elapsed: 8.047693ms
    Jan 24 19:51:50.750: INFO: Pod "wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270-nn7h6" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270 in namespace emptydir-wrapper-3762, will wait for the garbage collector to delete the pods 01/24/23 19:51:50.751
    Jan 24 19:51:50.828: INFO: Deleting ReplicationController wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270 took: 18.012894ms
    Jan 24 19:51:51.030: INFO: Terminating ReplicationController wrapped-volume-race-b269eea2-444f-4209-b7bd-2be2225cc270 pods took: 202.321034ms
    STEP: Creating RC which spawns configmap-volume pods 01/24/23 19:51:55.647
    Jan 24 19:51:55.679: INFO: Pod name wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef: Found 0 pods out of 5
    Jan 24 19:52:00.860: INFO: Pod name wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef: Found 5 pods out of 5
    STEP: Ensuring each pod is running 01/24/23 19:52:00.86
    Jan 24 19:52:00.860: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:52:00.879: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 18.485599ms
    Jan 24 19:52:02.926: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066059289s
    Jan 24 19:52:04.906: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045484125s
    Jan 24 19:52:07.057: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.197176577s
    Jan 24 19:52:08.925: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.065193518s
    Jan 24 19:52:10.926: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Pending", Reason="", readiness=false. Elapsed: 10.065758675s
    Jan 24 19:52:12.942: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl": Phase="Running", Reason="", readiness=true. Elapsed: 12.081437021s
    Jan 24 19:52:12.942: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-55bcl" satisfied condition "running"
    Jan 24 19:52:12.942: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-9v6fv" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:52:13.043: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-9v6fv": Phase="Running", Reason="", readiness=true. Elapsed: 97.877093ms
    Jan 24 19:52:13.067: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-9v6fv" satisfied condition "running"
    Jan 24 19:52:13.067: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-bdcn5" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:52:13.139: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-bdcn5": Phase="Running", Reason="", readiness=true. Elapsed: 71.59404ms
    Jan 24 19:52:13.139: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-bdcn5" satisfied condition "running"
    Jan 24 19:52:13.139: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-pdwhh" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:52:13.169: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-pdwhh": Phase="Running", Reason="", readiness=true. Elapsed: 29.758129ms
    Jan 24 19:52:13.169: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-pdwhh" satisfied condition "running"
    Jan 24 19:52:13.169: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-t42nd" in namespace "emptydir-wrapper-3762" to be "running"
    Jan 24 19:52:13.187: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-t42nd": Phase="Running", Reason="", readiness=true. Elapsed: 18.606933ms
    Jan 24 19:52:13.187: INFO: Pod "wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef-t42nd" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef in namespace emptydir-wrapper-3762, will wait for the garbage collector to delete the pods 01/24/23 19:52:13.187
    Jan 24 19:52:13.272: INFO: Deleting ReplicationController wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef took: 22.278883ms
    Jan 24 19:52:13.472: INFO: Terminating ReplicationController wrapped-volume-race-3a1af2f9-611e-4866-99e0-ea36ba5219ef pods took: 200.365089ms
    STEP: Cleaning up the configMaps 01/24/23 19:52:22.59
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Jan 24 19:52:23.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-3762" for this suite. 01/24/23 19:52:23.47
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:52:23.503
Jan 24 19:52:23.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:52:23.506
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:52:23.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:52:23.547
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-5cb11094-f88e-4d68-b1c8-a8d553c0534f 01/24/23 19:52:23.552
STEP: Creating a pod to test consume secrets 01/24/23 19:52:23.564
Jan 24 19:52:23.584: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841" in namespace "projected-2714" to be "Succeeded or Failed"
Jan 24 19:52:23.591: INFO: Pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841": Phase="Pending", Reason="", readiness=false. Elapsed: 7.484164ms
Jan 24 19:52:25.624: INFO: Pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03986423s
Jan 24 19:52:27.609: INFO: Pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025047644s
Jan 24 19:52:29.621: INFO: Pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037664377s
STEP: Saw pod success 01/24/23 19:52:29.63
Jan 24 19:52:29.631: INFO: Pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841" satisfied condition "Succeeded or Failed"
Jan 24 19:52:29.643: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841 container secret-volume-test: <nil>
STEP: delete the pod 01/24/23 19:52:29.721
Jan 24 19:52:29.808: INFO: Waiting for pod pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841 to disappear
Jan 24 19:52:29.861: INFO: Pod pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 24 19:52:29.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2714" for this suite. 01/24/23 19:52:29.889
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":211,"skipped":4069,"failed":0}
------------------------------
• [SLOW TEST] [6.447 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:52:23.503
    Jan 24 19:52:23.504: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:52:23.506
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:52:23.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:52:23.547
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-5cb11094-f88e-4d68-b1c8-a8d553c0534f 01/24/23 19:52:23.552
    STEP: Creating a pod to test consume secrets 01/24/23 19:52:23.564
    Jan 24 19:52:23.584: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841" in namespace "projected-2714" to be "Succeeded or Failed"
    Jan 24 19:52:23.591: INFO: Pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841": Phase="Pending", Reason="", readiness=false. Elapsed: 7.484164ms
    Jan 24 19:52:25.624: INFO: Pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03986423s
    Jan 24 19:52:27.609: INFO: Pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025047644s
    Jan 24 19:52:29.621: INFO: Pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037664377s
    STEP: Saw pod success 01/24/23 19:52:29.63
    Jan 24 19:52:29.631: INFO: Pod "pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841" satisfied condition "Succeeded or Failed"
    Jan 24 19:52:29.643: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841 container secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 19:52:29.721
    Jan 24 19:52:29.808: INFO: Waiting for pod pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841 to disappear
    Jan 24 19:52:29.861: INFO: Pod pod-projected-secrets-2141801d-ce7f-40e9-bc0b-2694b5e53841 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 24 19:52:29.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2714" for this suite. 01/24/23 19:52:29.889
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:52:29.952
Jan 24 19:52:29.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename cronjob 01/24/23 19:52:30.021
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:52:30.281
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:52:30.329
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 01/24/23 19:52:30.434
STEP: Ensuring a job is scheduled 01/24/23 19:52:30.487
STEP: Ensuring exactly one is scheduled 01/24/23 19:53:00.51
STEP: Ensuring exactly one running job exists by listing jobs explicitly 01/24/23 19:53:00.526
STEP: Ensuring the job is replaced with a new one 01/24/23 19:53:00.571
STEP: Removing cronjob 01/24/23 19:54:00.821
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jan 24 19:54:00.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7837" for this suite. 01/24/23 19:54:01.133
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":212,"skipped":4072,"failed":0}
------------------------------
• [SLOW TEST] [91.228 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:52:29.952
    Jan 24 19:52:29.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename cronjob 01/24/23 19:52:30.021
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:52:30.281
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:52:30.329
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 01/24/23 19:52:30.434
    STEP: Ensuring a job is scheduled 01/24/23 19:52:30.487
    STEP: Ensuring exactly one is scheduled 01/24/23 19:53:00.51
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 01/24/23 19:53:00.526
    STEP: Ensuring the job is replaced with a new one 01/24/23 19:53:00.571
    STEP: Removing cronjob 01/24/23 19:54:00.821
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jan 24 19:54:00.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-7837" for this suite. 01/24/23 19:54:01.133
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:54:01.181
Jan 24 19:54:01.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-webhook 01/24/23 19:54:01.299
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:54:01.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:54:02.071
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 01/24/23 19:54:02.522
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 01/24/23 19:54:07.31
STEP: Deploying the custom resource conversion webhook pod 01/24/23 19:54:07.319
STEP: Wait for the deployment to be ready 01/24/23 19:54:07.332
Jan 24 19:54:07.344: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/24/23 19:54:09.36
STEP: Verifying the service has paired with the endpoint 01/24/23 19:54:09.384
Jan 24 19:54:10.384: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Jan 24 19:54:10.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Creating a v1 custom resource 01/24/23 19:54:13.094
STEP: v2 custom resource should be converted 01/24/23 19:54:13.109
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:54:13.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-85" for this suite. 01/24/23 19:54:13.665
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":213,"skipped":4075,"failed":0}
------------------------------
• [SLOW TEST] [12.628 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:54:01.181
    Jan 24 19:54:01.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-webhook 01/24/23 19:54:01.299
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:54:01.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:54:02.071
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 01/24/23 19:54:02.522
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 01/24/23 19:54:07.31
    STEP: Deploying the custom resource conversion webhook pod 01/24/23 19:54:07.319
    STEP: Wait for the deployment to be ready 01/24/23 19:54:07.332
    Jan 24 19:54:07.344: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/24/23 19:54:09.36
    STEP: Verifying the service has paired with the endpoint 01/24/23 19:54:09.384
    Jan 24 19:54:10.384: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Jan 24 19:54:10.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Creating a v1 custom resource 01/24/23 19:54:13.094
    STEP: v2 custom resource should be converted 01/24/23 19:54:13.109
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:54:13.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-85" for this suite. 01/24/23 19:54:13.665
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:54:13.819
Jan 24 19:54:13.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename watch 01/24/23 19:54:13.831
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:54:13.927
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:54:13.948
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 01/24/23 19:54:13.987
STEP: creating a new configmap 01/24/23 19:54:13.993
STEP: modifying the configmap once 01/24/23 19:54:14.044
STEP: changing the label value of the configmap 01/24/23 19:54:14.119
STEP: Expecting to observe a delete notification for the watched object 01/24/23 19:54:14.219
Jan 24 19:54:14.224: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33103 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 19:54:14.246: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33104 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 19:54:14.248: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33105 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 01/24/23 19:54:14.248
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 01/24/23 19:54:14.279
STEP: changing the label value of the configmap back 01/24/23 19:54:24.282
STEP: modifying the configmap a third time 01/24/23 19:54:24.455
STEP: deleting the configmap 01/24/23 19:54:24.571
STEP: Expecting to observe an add notification for the watched object when the label value was restored 01/24/23 19:54:24.737
Jan 24 19:54:24.737: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33126 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 19:54:24.738: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33128 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 19:54:24.739: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33129 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jan 24 19:54:24.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2389" for this suite. 01/24/23 19:54:24.777
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":214,"skipped":4078,"failed":0}
------------------------------
• [SLOW TEST] [10.986 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:54:13.819
    Jan 24 19:54:13.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename watch 01/24/23 19:54:13.831
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:54:13.927
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:54:13.948
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 01/24/23 19:54:13.987
    STEP: creating a new configmap 01/24/23 19:54:13.993
    STEP: modifying the configmap once 01/24/23 19:54:14.044
    STEP: changing the label value of the configmap 01/24/23 19:54:14.119
    STEP: Expecting to observe a delete notification for the watched object 01/24/23 19:54:14.219
    Jan 24 19:54:14.224: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33103 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 19:54:14.246: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33104 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 19:54:14.248: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33105 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 01/24/23 19:54:14.248
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 01/24/23 19:54:14.279
    STEP: changing the label value of the configmap back 01/24/23 19:54:24.282
    STEP: modifying the configmap a third time 01/24/23 19:54:24.455
    STEP: deleting the configmap 01/24/23 19:54:24.571
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 01/24/23 19:54:24.737
    Jan 24 19:54:24.737: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33126 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 19:54:24.738: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33128 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 19:54:24.739: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2389  a8ccc966-8d47-411d-a3e3-6a1f69c2ff4d 33129 0 2023-01-24 19:54:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-01-24 19:54:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jan 24 19:54:24.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2389" for this suite. 01/24/23 19:54:24.777
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:54:24.895
Jan 24 19:54:24.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 19:54:24.898
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:54:25.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:54:25.254
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/24/23 19:54:25.272
Jan 24 19:54:25.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9460 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Jan 24 19:54:26.544: INFO: stderr: ""
Jan 24 19:54:26.544: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 01/24/23 19:54:26.544
Jan 24 19:54:26.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9460 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Jan 24 19:54:32.563: INFO: stderr: ""
Jan 24 19:54:32.563: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/24/23 19:54:32.563
Jan 24 19:54:32.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9460 delete pods e2e-test-httpd-pod'
Jan 24 19:54:34.895: INFO: stderr: ""
Jan 24 19:54:34.895: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 19:54:34.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9460" for this suite. 01/24/23 19:54:34.909
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":215,"skipped":4086,"failed":0}
------------------------------
• [SLOW TEST] [10.043 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:54:24.895
    Jan 24 19:54:24.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 19:54:24.898
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:54:25.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:54:25.254
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/24/23 19:54:25.272
    Jan 24 19:54:25.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9460 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Jan 24 19:54:26.544: INFO: stderr: ""
    Jan 24 19:54:26.544: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 01/24/23 19:54:26.544
    Jan 24 19:54:26.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9460 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Jan 24 19:54:32.563: INFO: stderr: ""
    Jan 24 19:54:32.563: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 01/24/23 19:54:32.563
    Jan 24 19:54:32.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9460 delete pods e2e-test-httpd-pod'
    Jan 24 19:54:34.895: INFO: stderr: ""
    Jan 24 19:54:34.895: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 19:54:34.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9460" for this suite. 01/24/23 19:54:34.909
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:54:34.942
Jan 24 19:54:34.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename subpath 01/24/23 19:54:34.948
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:54:34.993
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:54:35.013
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 01/24/23 19:54:35.021
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-x4k8 01/24/23 19:54:35.049
STEP: Creating a pod to test atomic-volume-subpath 01/24/23 19:54:35.049
Jan 24 19:54:35.084: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-x4k8" in namespace "subpath-4192" to be "Succeeded or Failed"
Jan 24 19:54:35.098: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.039973ms
Jan 24 19:54:37.135: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050076547s
Jan 24 19:54:39.114: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 4.028945321s
Jan 24 19:54:41.112: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 6.027383903s
Jan 24 19:54:43.148: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 8.063525175s
Jan 24 19:54:45.164: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 10.079517554s
Jan 24 19:54:47.112: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 12.027122491s
Jan 24 19:54:49.113: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 14.028047806s
Jan 24 19:54:51.122: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 16.037294317s
Jan 24 19:54:53.159: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 18.074206543s
Jan 24 19:54:55.140: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 20.055629157s
Jan 24 19:54:57.114: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 22.028960741s
Jan 24 19:54:59.111: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=false. Elapsed: 24.026350704s
Jan 24 19:55:01.107: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.022329919s
STEP: Saw pod success 01/24/23 19:55:01.107
Jan 24 19:55:01.107: INFO: Pod "pod-subpath-test-downwardapi-x4k8" satisfied condition "Succeeded or Failed"
Jan 24 19:55:01.109: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-subpath-test-downwardapi-x4k8 container test-container-subpath-downwardapi-x4k8: <nil>
STEP: delete the pod 01/24/23 19:55:01.131
Jan 24 19:55:01.145: INFO: Waiting for pod pod-subpath-test-downwardapi-x4k8 to disappear
Jan 24 19:55:01.158: INFO: Pod pod-subpath-test-downwardapi-x4k8 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-x4k8 01/24/23 19:55:01.158
Jan 24 19:55:01.158: INFO: Deleting pod "pod-subpath-test-downwardapi-x4k8" in namespace "subpath-4192"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jan 24 19:55:01.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4192" for this suite. 01/24/23 19:55:01.169
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":216,"skipped":4092,"failed":0}
------------------------------
• [SLOW TEST] [26.237 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:54:34.942
    Jan 24 19:54:34.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename subpath 01/24/23 19:54:34.948
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:54:34.993
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:54:35.013
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 01/24/23 19:54:35.021
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-x4k8 01/24/23 19:54:35.049
    STEP: Creating a pod to test atomic-volume-subpath 01/24/23 19:54:35.049
    Jan 24 19:54:35.084: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-x4k8" in namespace "subpath-4192" to be "Succeeded or Failed"
    Jan 24 19:54:35.098: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.039973ms
    Jan 24 19:54:37.135: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050076547s
    Jan 24 19:54:39.114: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 4.028945321s
    Jan 24 19:54:41.112: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 6.027383903s
    Jan 24 19:54:43.148: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 8.063525175s
    Jan 24 19:54:45.164: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 10.079517554s
    Jan 24 19:54:47.112: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 12.027122491s
    Jan 24 19:54:49.113: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 14.028047806s
    Jan 24 19:54:51.122: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 16.037294317s
    Jan 24 19:54:53.159: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 18.074206543s
    Jan 24 19:54:55.140: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 20.055629157s
    Jan 24 19:54:57.114: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=true. Elapsed: 22.028960741s
    Jan 24 19:54:59.111: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Running", Reason="", readiness=false. Elapsed: 24.026350704s
    Jan 24 19:55:01.107: INFO: Pod "pod-subpath-test-downwardapi-x4k8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.022329919s
    STEP: Saw pod success 01/24/23 19:55:01.107
    Jan 24 19:55:01.107: INFO: Pod "pod-subpath-test-downwardapi-x4k8" satisfied condition "Succeeded or Failed"
    Jan 24 19:55:01.109: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-subpath-test-downwardapi-x4k8 container test-container-subpath-downwardapi-x4k8: <nil>
    STEP: delete the pod 01/24/23 19:55:01.131
    Jan 24 19:55:01.145: INFO: Waiting for pod pod-subpath-test-downwardapi-x4k8 to disappear
    Jan 24 19:55:01.158: INFO: Pod pod-subpath-test-downwardapi-x4k8 no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-x4k8 01/24/23 19:55:01.158
    Jan 24 19:55:01.158: INFO: Deleting pod "pod-subpath-test-downwardapi-x4k8" in namespace "subpath-4192"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jan 24 19:55:01.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-4192" for this suite. 01/24/23 19:55:01.169
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:55:01.197
Jan 24 19:55:01.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 19:55:01.199
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:01.225
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:01.229
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 01/24/23 19:55:01.233
Jan 24 19:55:01.248: INFO: Waiting up to 5m0s for pod "downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c" in namespace "downward-api-6970" to be "Succeeded or Failed"
Jan 24 19:55:01.261: INFO: Pod "downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.364199ms
Jan 24 19:55:03.270: INFO: Pod "downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021064179s
Jan 24 19:55:05.272: INFO: Pod "downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022921079s
STEP: Saw pod success 01/24/23 19:55:05.272
Jan 24 19:55:05.272: INFO: Pod "downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c" satisfied condition "Succeeded or Failed"
Jan 24 19:55:05.281: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c container client-container: <nil>
STEP: delete the pod 01/24/23 19:55:05.294
Jan 24 19:55:05.323: INFO: Waiting for pod downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c to disappear
Jan 24 19:55:05.332: INFO: Pod downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 19:55:05.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6970" for this suite. 01/24/23 19:55:05.343
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":217,"skipped":4116,"failed":0}
------------------------------
• [4.165 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:55:01.197
    Jan 24 19:55:01.197: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 19:55:01.199
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:01.225
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:01.229
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 01/24/23 19:55:01.233
    Jan 24 19:55:01.248: INFO: Waiting up to 5m0s for pod "downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c" in namespace "downward-api-6970" to be "Succeeded or Failed"
    Jan 24 19:55:01.261: INFO: Pod "downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.364199ms
    Jan 24 19:55:03.270: INFO: Pod "downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021064179s
    Jan 24 19:55:05.272: INFO: Pod "downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022921079s
    STEP: Saw pod success 01/24/23 19:55:05.272
    Jan 24 19:55:05.272: INFO: Pod "downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c" satisfied condition "Succeeded or Failed"
    Jan 24 19:55:05.281: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c container client-container: <nil>
    STEP: delete the pod 01/24/23 19:55:05.294
    Jan 24 19:55:05.323: INFO: Waiting for pod downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c to disappear
    Jan 24 19:55:05.332: INFO: Pod downwardapi-volume-796a05a0-8ff9-4a0e-9f44-f99ccc7e591c no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 19:55:05.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6970" for this suite. 01/24/23 19:55:05.343
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:55:05.366
Jan 24 19:55:05.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename controllerrevisions 01/24/23 19:55:05.373
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:05.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:05.432
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-pk8g4-daemon-set" 01/24/23 19:55:05.49
STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 19:55:05.509
Jan 24 19:55:05.539: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 0
Jan 24 19:55:05.540: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:55:06.697: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 0
Jan 24 19:55:06.698: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:55:07.573: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 0
Jan 24 19:55:07.573: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:55:08.578: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 1
Jan 24 19:55:08.579: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:55:09.590: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 2
Jan 24 19:55:09.590: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-pk8g4-daemon-set
STEP: Confirm DaemonSet "e2e-pk8g4-daemon-set" successfully created with "daemonset-name=e2e-pk8g4-daemon-set" label 01/24/23 19:55:09.608
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-pk8g4-daemon-set" 01/24/23 19:55:09.658
Jan 24 19:55:09.673: INFO: Located ControllerRevision: "e2e-pk8g4-daemon-set-5bcd785555"
STEP: Patching ControllerRevision "e2e-pk8g4-daemon-set-5bcd785555" 01/24/23 19:55:09.686
Jan 24 19:55:09.718: INFO: e2e-pk8g4-daemon-set-5bcd785555 has been patched
STEP: Create a new ControllerRevision 01/24/23 19:55:09.719
Jan 24 19:55:09.736: INFO: Created ControllerRevision: e2e-pk8g4-daemon-set-75fd6f89c9
STEP: Confirm that there are two ControllerRevisions 01/24/23 19:55:09.737
Jan 24 19:55:09.739: INFO: Requesting list of ControllerRevisions to confirm quantity
Jan 24 19:55:09.762: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-pk8g4-daemon-set-5bcd785555" 01/24/23 19:55:09.762
STEP: Confirm that there is only one ControllerRevision 01/24/23 19:55:09.791
Jan 24 19:55:09.793: INFO: Requesting list of ControllerRevisions to confirm quantity
Jan 24 19:55:09.811: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-pk8g4-daemon-set-75fd6f89c9" 01/24/23 19:55:09.82
Jan 24 19:55:09.873: INFO: e2e-pk8g4-daemon-set-75fd6f89c9 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 01/24/23 19:55:09.873
W0124 19:55:09.893986      22 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 01/24/23 19:55:09.894
Jan 24 19:55:09.894: INFO: Requesting list of ControllerRevisions to confirm quantity
Jan 24 19:55:10.908: INFO: Requesting list of ControllerRevisions to confirm quantity
Jan 24 19:55:10.940: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-pk8g4-daemon-set-75fd6f89c9=updated" 01/24/23 19:55:10.94
STEP: Confirm that there is only one ControllerRevision 01/24/23 19:55:11.09
Jan 24 19:55:11.091: INFO: Requesting list of ControllerRevisions to confirm quantity
Jan 24 19:55:11.118: INFO: Found 1 ControllerRevisions
Jan 24 19:55:11.173: INFO: ControllerRevision "e2e-pk8g4-daemon-set-59885dd7fd" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-pk8g4-daemon-set" 01/24/23 19:55:11.202
STEP: deleting DaemonSet.extensions e2e-pk8g4-daemon-set in namespace controllerrevisions-4674, will wait for the garbage collector to delete the pods 01/24/23 19:55:11.203
Jan 24 19:55:11.435: INFO: Deleting DaemonSet.extensions e2e-pk8g4-daemon-set took: 94.593658ms
Jan 24 19:55:11.748: INFO: Terminating DaemonSet.extensions e2e-pk8g4-daemon-set pods took: 313.158891ms
Jan 24 19:55:15.717: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 0
Jan 24 19:55:15.717: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-pk8g4-daemon-set
Jan 24 19:55:15.739: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33338"},"items":null}

Jan 24 19:55:15.856: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33338"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Jan 24 19:55:15.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-4674" for this suite. 01/24/23 19:55:15.937
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":218,"skipped":4134,"failed":0}
------------------------------
• [SLOW TEST] [10.603 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:55:05.366
    Jan 24 19:55:05.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename controllerrevisions 01/24/23 19:55:05.373
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:05.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:05.432
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-pk8g4-daemon-set" 01/24/23 19:55:05.49
    STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 19:55:05.509
    Jan 24 19:55:05.539: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 0
    Jan 24 19:55:05.540: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:55:06.697: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 0
    Jan 24 19:55:06.698: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:55:07.573: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 0
    Jan 24 19:55:07.573: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:55:08.578: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 1
    Jan 24 19:55:08.579: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:55:09.590: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 2
    Jan 24 19:55:09.590: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset e2e-pk8g4-daemon-set
    STEP: Confirm DaemonSet "e2e-pk8g4-daemon-set" successfully created with "daemonset-name=e2e-pk8g4-daemon-set" label 01/24/23 19:55:09.608
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-pk8g4-daemon-set" 01/24/23 19:55:09.658
    Jan 24 19:55:09.673: INFO: Located ControllerRevision: "e2e-pk8g4-daemon-set-5bcd785555"
    STEP: Patching ControllerRevision "e2e-pk8g4-daemon-set-5bcd785555" 01/24/23 19:55:09.686
    Jan 24 19:55:09.718: INFO: e2e-pk8g4-daemon-set-5bcd785555 has been patched
    STEP: Create a new ControllerRevision 01/24/23 19:55:09.719
    Jan 24 19:55:09.736: INFO: Created ControllerRevision: e2e-pk8g4-daemon-set-75fd6f89c9
    STEP: Confirm that there are two ControllerRevisions 01/24/23 19:55:09.737
    Jan 24 19:55:09.739: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jan 24 19:55:09.762: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-pk8g4-daemon-set-5bcd785555" 01/24/23 19:55:09.762
    STEP: Confirm that there is only one ControllerRevision 01/24/23 19:55:09.791
    Jan 24 19:55:09.793: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jan 24 19:55:09.811: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-pk8g4-daemon-set-75fd6f89c9" 01/24/23 19:55:09.82
    Jan 24 19:55:09.873: INFO: e2e-pk8g4-daemon-set-75fd6f89c9 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 01/24/23 19:55:09.873
    W0124 19:55:09.893986      22 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 01/24/23 19:55:09.894
    Jan 24 19:55:09.894: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jan 24 19:55:10.908: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jan 24 19:55:10.940: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-pk8g4-daemon-set-75fd6f89c9=updated" 01/24/23 19:55:10.94
    STEP: Confirm that there is only one ControllerRevision 01/24/23 19:55:11.09
    Jan 24 19:55:11.091: INFO: Requesting list of ControllerRevisions to confirm quantity
    Jan 24 19:55:11.118: INFO: Found 1 ControllerRevisions
    Jan 24 19:55:11.173: INFO: ControllerRevision "e2e-pk8g4-daemon-set-59885dd7fd" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-pk8g4-daemon-set" 01/24/23 19:55:11.202
    STEP: deleting DaemonSet.extensions e2e-pk8g4-daemon-set in namespace controllerrevisions-4674, will wait for the garbage collector to delete the pods 01/24/23 19:55:11.203
    Jan 24 19:55:11.435: INFO: Deleting DaemonSet.extensions e2e-pk8g4-daemon-set took: 94.593658ms
    Jan 24 19:55:11.748: INFO: Terminating DaemonSet.extensions e2e-pk8g4-daemon-set pods took: 313.158891ms
    Jan 24 19:55:15.717: INFO: Number of nodes with available pods controlled by daemonset e2e-pk8g4-daemon-set: 0
    Jan 24 19:55:15.717: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-pk8g4-daemon-set
    Jan 24 19:55:15.739: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33338"},"items":null}

    Jan 24 19:55:15.856: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33338"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 19:55:15.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-4674" for this suite. 01/24/23 19:55:15.937
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:55:16.023
Jan 24 19:55:16.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:55:16.029
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:16.085
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:16.116
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 01/24/23 19:55:16.148
Jan 24 19:55:16.191: INFO: Waiting up to 5m0s for pod "annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19" in namespace "projected-2586" to be "running and ready"
Jan 24 19:55:16.219: INFO: Pod "annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19": Phase="Pending", Reason="", readiness=false. Elapsed: 13.727213ms
Jan 24 19:55:16.219: INFO: The phase of Pod annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:55:18.238: INFO: Pod "annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19": Phase="Running", Reason="", readiness=true. Elapsed: 2.032316119s
Jan 24 19:55:18.238: INFO: The phase of Pod annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19 is Running (Ready = true)
Jan 24 19:55:18.238: INFO: Pod "annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19" satisfied condition "running and ready"
Jan 24 19:55:18.850: INFO: Successfully updated pod "annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 19:55:20.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2586" for this suite. 01/24/23 19:55:20.954
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":219,"skipped":4196,"failed":0}
------------------------------
• [4.963 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:55:16.023
    Jan 24 19:55:16.023: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:55:16.029
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:16.085
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:16.116
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 01/24/23 19:55:16.148
    Jan 24 19:55:16.191: INFO: Waiting up to 5m0s for pod "annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19" in namespace "projected-2586" to be "running and ready"
    Jan 24 19:55:16.219: INFO: Pod "annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19": Phase="Pending", Reason="", readiness=false. Elapsed: 13.727213ms
    Jan 24 19:55:16.219: INFO: The phase of Pod annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:55:18.238: INFO: Pod "annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19": Phase="Running", Reason="", readiness=true. Elapsed: 2.032316119s
    Jan 24 19:55:18.238: INFO: The phase of Pod annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19 is Running (Ready = true)
    Jan 24 19:55:18.238: INFO: Pod "annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19" satisfied condition "running and ready"
    Jan 24 19:55:18.850: INFO: Successfully updated pod "annotationupdate3be1fbeb-3007-4fe9-a9d2-98c992c0ea19"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 19:55:20.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2586" for this suite. 01/24/23 19:55:20.954
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:55:20.996
Jan 24 19:55:20.997: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename deployment 01/24/23 19:55:21.001
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:21.112
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:21.144
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Jan 24 19:55:21.160: INFO: Creating deployment "test-recreate-deployment"
Jan 24 19:55:21.208: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 24 19:55:21.298: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jan 24 19:55:23.332: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 24 19:55:23.339: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 55, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 55, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 55, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 55, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 19:55:25.351: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 24 19:55:25.401: INFO: Updating deployment test-recreate-deployment
Jan 24 19:55:25.401: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 24 19:55:25.703: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4950  a02021fe-8d57-4bfd-8310-6b5486d29cf7 33421 2 2023-01-24 19:55:21 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005301778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-01-24 19:55:25 +0000 UTC,LastTransitionTime:2023-01-24 19:55:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-01-24 19:55:25 +0000 UTC,LastTransitionTime:2023-01-24 19:55:21 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Jan 24 19:55:25.721: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-4950  3502c300-5ed8-4723-bfe7-7348888328b4 33420 1 2023-01-24 19:55:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment a02021fe-8d57-4bfd-8310-6b5486d29cf7 0xc005301c60 0xc005301c61}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a02021fe-8d57-4bfd-8310-6b5486d29cf7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005301cf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 24 19:55:25.721: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 24 19:55:25.722: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-4950  ceb26287-53e8-44cd-9082-2852e6981e63 33410 2 2023-01-24 19:55:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment a02021fe-8d57-4bfd-8310-6b5486d29cf7 0xc005301b37 0xc005301b38}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a02021fe-8d57-4bfd-8310-6b5486d29cf7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005301bf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 24 19:55:25.735: INFO: Pod "test-recreate-deployment-9d58999df-rkz67" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-rkz67 test-recreate-deployment-9d58999df- deployment-4950  06cb6d42-f315-42a2-b6ff-b62a4a27cc19 33422 0 2023-01-24 19:55:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 3502c300-5ed8-4723-bfe7-7348888328b4 0xc0038b05c0 0xc0038b05c1}] [] [{kube-controller-manager Update v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3502c300-5ed8-4723-bfe7-7348888328b4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mpn48,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mpn48,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:55:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:55:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:55:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:55:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 19:55:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 24 19:55:25.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4950" for this suite. 01/24/23 19:55:25.772
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":220,"skipped":4202,"failed":0}
------------------------------
• [4.806 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:55:20.996
    Jan 24 19:55:20.997: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename deployment 01/24/23 19:55:21.001
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:21.112
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:21.144
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Jan 24 19:55:21.160: INFO: Creating deployment "test-recreate-deployment"
    Jan 24 19:55:21.208: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Jan 24 19:55:21.298: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Jan 24 19:55:23.332: INFO: Waiting deployment "test-recreate-deployment" to complete
    Jan 24 19:55:23.339: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 19, 55, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 55, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 19, 55, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 19, 55, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 19:55:25.351: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Jan 24 19:55:25.401: INFO: Updating deployment test-recreate-deployment
    Jan 24 19:55:25.401: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 24 19:55:25.703: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-4950  a02021fe-8d57-4bfd-8310-6b5486d29cf7 33421 2 2023-01-24 19:55:21 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005301778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-01-24 19:55:25 +0000 UTC,LastTransitionTime:2023-01-24 19:55:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-01-24 19:55:25 +0000 UTC,LastTransitionTime:2023-01-24 19:55:21 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Jan 24 19:55:25.721: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-4950  3502c300-5ed8-4723-bfe7-7348888328b4 33420 1 2023-01-24 19:55:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment a02021fe-8d57-4bfd-8310-6b5486d29cf7 0xc005301c60 0xc005301c61}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a02021fe-8d57-4bfd-8310-6b5486d29cf7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005301cf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 19:55:25.721: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Jan 24 19:55:25.722: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-4950  ceb26287-53e8-44cd-9082-2852e6981e63 33410 2 2023-01-24 19:55:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment a02021fe-8d57-4bfd-8310-6b5486d29cf7 0xc005301b37 0xc005301b38}] [] [{kube-controller-manager Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a02021fe-8d57-4bfd-8310-6b5486d29cf7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005301bf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 19:55:25.735: INFO: Pod "test-recreate-deployment-9d58999df-rkz67" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-rkz67 test-recreate-deployment-9d58999df- deployment-4950  06cb6d42-f315-42a2-b6ff-b62a4a27cc19 33422 0 2023-01-24 19:55:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 3502c300-5ed8-4723-bfe7-7348888328b4 0xc0038b05c0 0xc0038b05c1}] [] [{kube-controller-manager Update v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3502c300-5ed8-4723-bfe7-7348888328b4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-01-24 19:55:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mpn48,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mpn48,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:55:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:55:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:55:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 19:55:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:,StartTime:2023-01-24 19:55:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 24 19:55:25.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4950" for this suite. 01/24/23 19:55:25.772
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:55:25.796
Jan 24 19:55:25.796: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename prestop 01/24/23 19:55:25.802
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:25.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:25.886
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-9990 01/24/23 19:55:25.909
STEP: Waiting for pods to come up. 01/24/23 19:55:25.953
Jan 24 19:55:25.954: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-9990" to be "running"
Jan 24 19:55:26.005: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 51.699879ms
Jan 24 19:55:28.068: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.113940117s
Jan 24 19:55:30.026: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 4.072120107s
Jan 24 19:55:30.026: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-9990 01/24/23 19:55:30.036
Jan 24 19:55:30.083: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-9990" to be "running"
Jan 24 19:55:30.146: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 62.580208ms
Jan 24 19:55:32.173: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089429726s
Jan 24 19:55:34.167: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.083500129s
Jan 24 19:55:34.167: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 01/24/23 19:55:34.167
Jan 24 19:55:39.248: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 01/24/23 19:55:39.249
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Jan 24 19:55:39.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9990" for this suite. 01/24/23 19:55:39.333
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":221,"skipped":4206,"failed":0}
------------------------------
• [SLOW TEST] [13.559 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:55:25.796
    Jan 24 19:55:25.796: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename prestop 01/24/23 19:55:25.802
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:25.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:25.886
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-9990 01/24/23 19:55:25.909
    STEP: Waiting for pods to come up. 01/24/23 19:55:25.953
    Jan 24 19:55:25.954: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-9990" to be "running"
    Jan 24 19:55:26.005: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 51.699879ms
    Jan 24 19:55:28.068: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.113940117s
    Jan 24 19:55:30.026: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 4.072120107s
    Jan 24 19:55:30.026: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-9990 01/24/23 19:55:30.036
    Jan 24 19:55:30.083: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-9990" to be "running"
    Jan 24 19:55:30.146: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 62.580208ms
    Jan 24 19:55:32.173: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089429726s
    Jan 24 19:55:34.167: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.083500129s
    Jan 24 19:55:34.167: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 01/24/23 19:55:34.167
    Jan 24 19:55:39.248: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 01/24/23 19:55:39.249
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Jan 24 19:55:39.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-9990" for this suite. 01/24/23 19:55:39.333
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:55:39.374
Jan 24 19:55:39.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename ingressclass 01/24/23 19:55:39.385
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:39.446
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:39.458
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 01/24/23 19:55:39.474
STEP: getting /apis/networking.k8s.io 01/24/23 19:55:39.491
STEP: getting /apis/networking.k8s.iov1 01/24/23 19:55:39.495
STEP: creating 01/24/23 19:55:39.501
STEP: getting 01/24/23 19:55:39.562
STEP: listing 01/24/23 19:55:39.582
STEP: watching 01/24/23 19:55:39.605
Jan 24 19:55:39.607: INFO: starting watch
STEP: patching 01/24/23 19:55:39.613
STEP: updating 01/24/23 19:55:39.632
Jan 24 19:55:39.662: INFO: waiting for watch events with expected annotations
Jan 24 19:55:39.662: INFO: saw patched and updated annotations
STEP: deleting 01/24/23 19:55:39.666
STEP: deleting a collection 01/24/23 19:55:39.716
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Jan 24 19:55:39.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-8808" for this suite. 01/24/23 19:55:39.845
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":222,"skipped":4210,"failed":0}
------------------------------
• [0.525 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:55:39.374
    Jan 24 19:55:39.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename ingressclass 01/24/23 19:55:39.385
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:39.446
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:39.458
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 01/24/23 19:55:39.474
    STEP: getting /apis/networking.k8s.io 01/24/23 19:55:39.491
    STEP: getting /apis/networking.k8s.iov1 01/24/23 19:55:39.495
    STEP: creating 01/24/23 19:55:39.501
    STEP: getting 01/24/23 19:55:39.562
    STEP: listing 01/24/23 19:55:39.582
    STEP: watching 01/24/23 19:55:39.605
    Jan 24 19:55:39.607: INFO: starting watch
    STEP: patching 01/24/23 19:55:39.613
    STEP: updating 01/24/23 19:55:39.632
    Jan 24 19:55:39.662: INFO: waiting for watch events with expected annotations
    Jan 24 19:55:39.662: INFO: saw patched and updated annotations
    STEP: deleting 01/24/23 19:55:39.666
    STEP: deleting a collection 01/24/23 19:55:39.716
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Jan 24 19:55:39.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-8808" for this suite. 01/24/23 19:55:39.845
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:55:39.899
Jan 24 19:55:39.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename gc 01/24/23 19:55:39.91
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:40.037
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:40.076
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 01/24/23 19:55:40.098
STEP: delete the rc 01/24/23 19:55:45.213
STEP: wait for all pods to be garbage collected 01/24/23 19:55:45.464
STEP: Gathering metrics 01/24/23 19:55:50.487
W0124 19:55:50.510732      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 24 19:55:50.511: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 24 19:55:50.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5430" for this suite. 01/24/23 19:55:50.531
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":223,"skipped":4211,"failed":0}
------------------------------
• [SLOW TEST] [10.677 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:55:39.899
    Jan 24 19:55:39.899: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename gc 01/24/23 19:55:39.91
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:40.037
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:40.076
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 01/24/23 19:55:40.098
    STEP: delete the rc 01/24/23 19:55:45.213
    STEP: wait for all pods to be garbage collected 01/24/23 19:55:45.464
    STEP: Gathering metrics 01/24/23 19:55:50.487
    W0124 19:55:50.510732      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 24 19:55:50.511: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 24 19:55:50.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5430" for this suite. 01/24/23 19:55:50.531
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:55:50.599
Jan 24 19:55:50.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename security-context 01/24/23 19:55:50.603
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:50.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:50.75
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 01/24/23 19:55:50.765
Jan 24 19:55:50.885: INFO: Waiting up to 5m0s for pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee" in namespace "security-context-1719" to be "Succeeded or Failed"
Jan 24 19:55:50.921: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 36.524766ms
Jan 24 19:55:52.973: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088474792s
Jan 24 19:55:55.019: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee": Phase="Running", Reason="", readiness=false. Elapsed: 4.118674749s
Jan 24 19:55:56.937: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee": Phase="Running", Reason="", readiness=false. Elapsed: 6.052321622s
Jan 24 19:55:58.931: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.046279386s
STEP: Saw pod success 01/24/23 19:55:58.931
Jan 24 19:55:58.932: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee" satisfied condition "Succeeded or Failed"
Jan 24 19:55:58.935: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee container test-container: <nil>
STEP: delete the pod 01/24/23 19:55:58.941
Jan 24 19:55:58.954: INFO: Waiting for pod security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee to disappear
Jan 24 19:55:58.961: INFO: Pod security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 24 19:55:58.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-1719" for this suite. 01/24/23 19:55:58.965
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":224,"skipped":4211,"failed":0}
------------------------------
• [SLOW TEST] [8.371 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:55:50.599
    Jan 24 19:55:50.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename security-context 01/24/23 19:55:50.603
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:50.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:50.75
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 01/24/23 19:55:50.765
    Jan 24 19:55:50.885: INFO: Waiting up to 5m0s for pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee" in namespace "security-context-1719" to be "Succeeded or Failed"
    Jan 24 19:55:50.921: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 36.524766ms
    Jan 24 19:55:52.973: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088474792s
    Jan 24 19:55:55.019: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee": Phase="Running", Reason="", readiness=false. Elapsed: 4.118674749s
    Jan 24 19:55:56.937: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee": Phase="Running", Reason="", readiness=false. Elapsed: 6.052321622s
    Jan 24 19:55:58.931: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.046279386s
    STEP: Saw pod success 01/24/23 19:55:58.931
    Jan 24 19:55:58.932: INFO: Pod "security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee" satisfied condition "Succeeded or Failed"
    Jan 24 19:55:58.935: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee container test-container: <nil>
    STEP: delete the pod 01/24/23 19:55:58.941
    Jan 24 19:55:58.954: INFO: Waiting for pod security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee to disappear
    Jan 24 19:55:58.961: INFO: Pod security-context-2a37fcf3-2d44-4e9d-863d-42b73486f9ee no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 24 19:55:58.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-1719" for this suite. 01/24/23 19:55:58.965
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:55:58.971
Jan 24 19:55:58.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename daemonsets 01/24/23 19:55:58.974
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:58.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:59.002
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 01/24/23 19:55:59.029
STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 19:55:59.036
Jan 24 19:55:59.046: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:55:59.046: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:56:00.057: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:56:00.057: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 19:56:01.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:56:01.082: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 19:56:02.063: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 19:56:02.064: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
Jan 24 19:56:03.067: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 24 19:56:03.068: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 01/24/23 19:56:03.075
Jan 24 19:56:03.151: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 24 19:56:03.153: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 01/24/23 19:56:03.153
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/24/23 19:56:04.298
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8778, will wait for the garbage collector to delete the pods 01/24/23 19:56:04.298
Jan 24 19:56:04.451: INFO: Deleting DaemonSet.extensions daemon-set took: 67.117805ms
Jan 24 19:56:04.652: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.705549ms
Jan 24 19:56:07.762: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 19:56:07.762: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 24 19:56:07.770: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33735"},"items":null}

Jan 24 19:56:07.781: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33735"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 24 19:56:07.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8778" for this suite. 01/24/23 19:56:07.818
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":225,"skipped":4213,"failed":0}
------------------------------
• [SLOW TEST] [8.862 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:55:58.971
    Jan 24 19:55:58.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename daemonsets 01/24/23 19:55:58.974
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:55:58.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:55:59.002
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 01/24/23 19:55:59.029
    STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 19:55:59.036
    Jan 24 19:55:59.046: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:55:59.046: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:56:00.057: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:56:00.057: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 19:56:01.082: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:56:01.082: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 19:56:02.063: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 19:56:02.064: INFO: Node vikash-v125latest-conf-71087 is running 0 daemon pod, expected 1
    Jan 24 19:56:03.067: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 24 19:56:03.068: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 01/24/23 19:56:03.075
    Jan 24 19:56:03.151: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 24 19:56:03.153: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 01/24/23 19:56:03.153
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/24/23 19:56:04.298
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8778, will wait for the garbage collector to delete the pods 01/24/23 19:56:04.298
    Jan 24 19:56:04.451: INFO: Deleting DaemonSet.extensions daemon-set took: 67.117805ms
    Jan 24 19:56:04.652: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.705549ms
    Jan 24 19:56:07.762: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 19:56:07.762: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 24 19:56:07.770: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33735"},"items":null}

    Jan 24 19:56:07.781: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33735"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 19:56:07.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8778" for this suite. 01/24/23 19:56:07.818
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:56:07.841
Jan 24 19:56:07.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 19:56:07.844
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:56:07.873
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:56:07.881
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 01/24/23 19:56:07.886
Jan 24 19:56:07.905: INFO: Waiting up to 5m0s for pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5" in namespace "emptydir-4106" to be "Succeeded or Failed"
Jan 24 19:56:07.913: INFO: Pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.376161ms
Jan 24 19:56:09.943: INFO: Pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037164419s
Jan 24 19:56:11.934: INFO: Pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028374713s
Jan 24 19:56:14.028: INFO: Pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.122709647s
STEP: Saw pod success 01/24/23 19:56:14.028
Jan 24 19:56:14.035: INFO: Pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5" satisfied condition "Succeeded or Failed"
Jan 24 19:56:14.062: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-7cc47d75-e438-45a0-9bb8-98671a185bd5 container test-container: <nil>
STEP: delete the pod 01/24/23 19:56:14.108
Jan 24 19:56:14.204: INFO: Waiting for pod pod-7cc47d75-e438-45a0-9bb8-98671a185bd5 to disappear
Jan 24 19:56:14.227: INFO: Pod pod-7cc47d75-e438-45a0-9bb8-98671a185bd5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 19:56:14.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4106" for this suite. 01/24/23 19:56:14.295
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":226,"skipped":4239,"failed":0}
------------------------------
• [SLOW TEST] [6.537 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:56:07.841
    Jan 24 19:56:07.842: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 19:56:07.844
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:56:07.873
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:56:07.881
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 01/24/23 19:56:07.886
    Jan 24 19:56:07.905: INFO: Waiting up to 5m0s for pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5" in namespace "emptydir-4106" to be "Succeeded or Failed"
    Jan 24 19:56:07.913: INFO: Pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.376161ms
    Jan 24 19:56:09.943: INFO: Pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037164419s
    Jan 24 19:56:11.934: INFO: Pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028374713s
    Jan 24 19:56:14.028: INFO: Pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.122709647s
    STEP: Saw pod success 01/24/23 19:56:14.028
    Jan 24 19:56:14.035: INFO: Pod "pod-7cc47d75-e438-45a0-9bb8-98671a185bd5" satisfied condition "Succeeded or Failed"
    Jan 24 19:56:14.062: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-7cc47d75-e438-45a0-9bb8-98671a185bd5 container test-container: <nil>
    STEP: delete the pod 01/24/23 19:56:14.108
    Jan 24 19:56:14.204: INFO: Waiting for pod pod-7cc47d75-e438-45a0-9bb8-98671a185bd5 to disappear
    Jan 24 19:56:14.227: INFO: Pod pod-7cc47d75-e438-45a0-9bb8-98671a185bd5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 19:56:14.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4106" for this suite. 01/24/23 19:56:14.295
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:56:14.559
Jan 24 19:56:14.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pod-network-test 01/24/23 19:56:14.615
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:56:14.964
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:56:15.068
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-6516 01/24/23 19:56:15.108
STEP: creating a selector 01/24/23 19:56:15.109
STEP: Creating the service pods in kubernetes 01/24/23 19:56:15.11
Jan 24 19:56:15.110: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jan 24 19:56:15.843: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6516" to be "running and ready"
Jan 24 19:56:16.005: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 161.990215ms
Jan 24 19:56:16.005: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:56:18.012: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.169084436s
Jan 24 19:56:18.012: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:56:20.013: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.169529208s
Jan 24 19:56:20.013: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:56:22.016: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.172588912s
Jan 24 19:56:22.016: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:56:24.021: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.178081621s
Jan 24 19:56:24.021: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:56:26.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.181211393s
Jan 24 19:56:26.027: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:56:28.016: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.172775611s
Jan 24 19:56:28.016: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:56:30.023: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.179891264s
Jan 24 19:56:30.023: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:56:32.034: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.191150117s
Jan 24 19:56:32.035: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:56:34.039: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.196016332s
Jan 24 19:56:34.040: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:56:36.019: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.175721499s
Jan 24 19:56:36.019: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Jan 24 19:56:38.047: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.203635815s
Jan 24 19:56:38.047: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Jan 24 19:56:38.047: INFO: Pod "netserver-0" satisfied condition "running and ready"
Jan 24 19:56:38.066: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6516" to be "running and ready"
Jan 24 19:56:38.124: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 57.632132ms
Jan 24 19:56:38.124: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Jan 24 19:56:38.124: INFO: Pod "netserver-1" satisfied condition "running and ready"
STEP: Creating test pods 01/24/23 19:56:38.213
Jan 24 19:56:38.383: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6516" to be "running"
Jan 24 19:56:38.486: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 102.770496ms
Jan 24 19:56:40.506: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123076249s
Jan 24 19:56:42.499: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.115476746s
Jan 24 19:56:42.499: INFO: Pod "test-container-pod" satisfied condition "running"
Jan 24 19:56:42.517: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
Jan 24 19:56:42.517: INFO: Breadth first check of 10.244.47.79 on host 10.10.1.213...
Jan 24 19:56:42.535: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.71.211:9080/dial?request=hostname&protocol=http&host=10.244.47.79&port=8083&tries=1'] Namespace:pod-network-test-6516 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:56:42.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:56:42.537: INFO: ExecWithOptions: Clientset creation
Jan 24 19:56:42.537: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-6516/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.71.211%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.47.79%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jan 24 19:56:43.006: INFO: Waiting for responses: map[]
Jan 24 19:56:43.006: INFO: reached 10.244.47.79 after 0/1 tries
Jan 24 19:56:43.006: INFO: Breadth first check of 10.244.71.204 on host 10.10.1.127...
Jan 24 19:56:43.024: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.71.211:9080/dial?request=hostname&protocol=http&host=10.244.71.204&port=8083&tries=1'] Namespace:pod-network-test-6516 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 19:56:43.024: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 19:56:43.028: INFO: ExecWithOptions: Clientset creation
Jan 24 19:56:43.030: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-6516/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.71.211%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.71.204%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jan 24 19:56:43.302: INFO: Waiting for responses: map[]
Jan 24 19:56:43.302: INFO: reached 10.244.71.204 after 0/1 tries
Jan 24 19:56:43.302: INFO: Going to retry 0 out of 2 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Jan 24 19:56:43.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6516" for this suite. 01/24/23 19:56:43.317
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":227,"skipped":4287,"failed":0}
------------------------------
• [SLOW TEST] [28.788 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:56:14.559
    Jan 24 19:56:14.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pod-network-test 01/24/23 19:56:14.615
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:56:14.964
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:56:15.068
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-6516 01/24/23 19:56:15.108
    STEP: creating a selector 01/24/23 19:56:15.109
    STEP: Creating the service pods in kubernetes 01/24/23 19:56:15.11
    Jan 24 19:56:15.110: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Jan 24 19:56:15.843: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6516" to be "running and ready"
    Jan 24 19:56:16.005: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 161.990215ms
    Jan 24 19:56:16.005: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:56:18.012: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.169084436s
    Jan 24 19:56:18.012: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:56:20.013: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.169529208s
    Jan 24 19:56:20.013: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:56:22.016: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.172588912s
    Jan 24 19:56:22.016: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:56:24.021: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.178081621s
    Jan 24 19:56:24.021: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:56:26.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.181211393s
    Jan 24 19:56:26.027: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:56:28.016: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.172775611s
    Jan 24 19:56:28.016: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:56:30.023: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.179891264s
    Jan 24 19:56:30.023: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:56:32.034: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.191150117s
    Jan 24 19:56:32.035: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:56:34.039: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.196016332s
    Jan 24 19:56:34.040: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:56:36.019: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.175721499s
    Jan 24 19:56:36.019: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Jan 24 19:56:38.047: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.203635815s
    Jan 24 19:56:38.047: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Jan 24 19:56:38.047: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Jan 24 19:56:38.066: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6516" to be "running and ready"
    Jan 24 19:56:38.124: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 57.632132ms
    Jan 24 19:56:38.124: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Jan 24 19:56:38.124: INFO: Pod "netserver-1" satisfied condition "running and ready"
    STEP: Creating test pods 01/24/23 19:56:38.213
    Jan 24 19:56:38.383: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6516" to be "running"
    Jan 24 19:56:38.486: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 102.770496ms
    Jan 24 19:56:40.506: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123076249s
    Jan 24 19:56:42.499: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.115476746s
    Jan 24 19:56:42.499: INFO: Pod "test-container-pod" satisfied condition "running"
    Jan 24 19:56:42.517: INFO: Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
    Jan 24 19:56:42.517: INFO: Breadth first check of 10.244.47.79 on host 10.10.1.213...
    Jan 24 19:56:42.535: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.71.211:9080/dial?request=hostname&protocol=http&host=10.244.47.79&port=8083&tries=1'] Namespace:pod-network-test-6516 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:56:42.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:56:42.537: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:56:42.537: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-6516/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.71.211%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.47.79%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jan 24 19:56:43.006: INFO: Waiting for responses: map[]
    Jan 24 19:56:43.006: INFO: reached 10.244.47.79 after 0/1 tries
    Jan 24 19:56:43.006: INFO: Breadth first check of 10.244.71.204 on host 10.10.1.127...
    Jan 24 19:56:43.024: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.71.211:9080/dial?request=hostname&protocol=http&host=10.244.71.204&port=8083&tries=1'] Namespace:pod-network-test-6516 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 19:56:43.024: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 19:56:43.028: INFO: ExecWithOptions: Clientset creation
    Jan 24 19:56:43.030: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/pod-network-test-6516/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.244.71.211%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.244.71.204%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Jan 24 19:56:43.302: INFO: Waiting for responses: map[]
    Jan 24 19:56:43.302: INFO: reached 10.244.71.204 after 0/1 tries
    Jan 24 19:56:43.302: INFO: Going to retry 0 out of 2 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Jan 24 19:56:43.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6516" for this suite. 01/24/23 19:56:43.317
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:56:43.378
Jan 24 19:56:43.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 19:56:43.384
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:56:43.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:56:43.477
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-4847 01/24/23 19:56:43.491
STEP: creating service affinity-nodeport in namespace services-4847 01/24/23 19:56:43.494
STEP: creating replication controller affinity-nodeport in namespace services-4847 01/24/23 19:56:43.597
I0124 19:56:43.646305      22 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4847, replica count: 3
I0124 19:56:46.822110      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 19:56:49.891839      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 19:56:50.213: INFO: Creating new exec pod
Jan 24 19:56:50.227: INFO: Waiting up to 5m0s for pod "execpod-affinity2rcsp" in namespace "services-4847" to be "running"
Jan 24 19:56:50.261: INFO: Pod "execpod-affinity2rcsp": Phase="Pending", Reason="", readiness=false. Elapsed: 27.033976ms
Jan 24 19:56:52.274: INFO: Pod "execpod-affinity2rcsp": Phase="Running", Reason="", readiness=true. Elapsed: 2.040357568s
Jan 24 19:56:52.274: INFO: Pod "execpod-affinity2rcsp" satisfied condition "running"
Jan 24 19:56:53.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4847 exec execpod-affinity2rcsp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Jan 24 19:56:53.841: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Jan 24 19:56:53.841: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:56:53.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4847 exec execpod-affinity2rcsp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.173.128 80'
Jan 24 19:56:54.426: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.173.128 80\nConnection to 10.10.173.128 80 port [tcp/http] succeeded!\n"
Jan 24 19:56:54.426: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:56:54.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4847 exec execpod-affinity2rcsp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 30533'
Jan 24 19:56:54.935: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 30533\nConnection to 10.10.1.213 30533 port [tcp/*] succeeded!\n"
Jan 24 19:56:54.935: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:56:54.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4847 exec execpod-affinity2rcsp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.127 30533'
Jan 24 19:56:55.568: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.127 30533\nConnection to 10.10.1.127 30533 port [tcp/*] succeeded!\n"
Jan 24 19:56:55.568: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 19:56:55.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4847 exec execpod-affinity2rcsp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.1.213:30533/ ; done'
Jan 24 19:56:57.101: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n"
Jan 24 19:56:57.101: INFO: stdout: "\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b"
Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
Jan 24 19:56:57.104: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-4847, will wait for the garbage collector to delete the pods 01/24/23 19:56:57.158
Jan 24 19:56:57.313: INFO: Deleting ReplicationController affinity-nodeport took: 41.942325ms
Jan 24 19:56:57.914: INFO: Terminating ReplicationController affinity-nodeport pods took: 601.581176ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 19:57:03.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4847" for this suite. 01/24/23 19:57:03.079
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":228,"skipped":4307,"failed":0}
------------------------------
• [SLOW TEST] [19.728 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:56:43.378
    Jan 24 19:56:43.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 19:56:43.384
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:56:43.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:56:43.477
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-4847 01/24/23 19:56:43.491
    STEP: creating service affinity-nodeport in namespace services-4847 01/24/23 19:56:43.494
    STEP: creating replication controller affinity-nodeport in namespace services-4847 01/24/23 19:56:43.597
    I0124 19:56:43.646305      22 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-4847, replica count: 3
    I0124 19:56:46.822110      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 19:56:49.891839      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 19:56:50.213: INFO: Creating new exec pod
    Jan 24 19:56:50.227: INFO: Waiting up to 5m0s for pod "execpod-affinity2rcsp" in namespace "services-4847" to be "running"
    Jan 24 19:56:50.261: INFO: Pod "execpod-affinity2rcsp": Phase="Pending", Reason="", readiness=false. Elapsed: 27.033976ms
    Jan 24 19:56:52.274: INFO: Pod "execpod-affinity2rcsp": Phase="Running", Reason="", readiness=true. Elapsed: 2.040357568s
    Jan 24 19:56:52.274: INFO: Pod "execpod-affinity2rcsp" satisfied condition "running"
    Jan 24 19:56:53.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4847 exec execpod-affinity2rcsp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Jan 24 19:56:53.841: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Jan 24 19:56:53.841: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:56:53.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4847 exec execpod-affinity2rcsp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.173.128 80'
    Jan 24 19:56:54.426: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.173.128 80\nConnection to 10.10.173.128 80 port [tcp/http] succeeded!\n"
    Jan 24 19:56:54.426: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:56:54.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4847 exec execpod-affinity2rcsp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 30533'
    Jan 24 19:56:54.935: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 30533\nConnection to 10.10.1.213 30533 port [tcp/*] succeeded!\n"
    Jan 24 19:56:54.935: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:56:54.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4847 exec execpod-affinity2rcsp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.127 30533'
    Jan 24 19:56:55.568: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.127 30533\nConnection to 10.10.1.127 30533 port [tcp/*] succeeded!\n"
    Jan 24 19:56:55.568: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 19:56:55.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4847 exec execpod-affinity2rcsp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.1.213:30533/ ; done'
    Jan 24 19:56:57.101: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:30533/\n"
    Jan 24 19:56:57.101: INFO: stdout: "\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b\naffinity-nodeport-lwr5b"
    Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.102: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.104: INFO: Received response from host: affinity-nodeport-lwr5b
    Jan 24 19:56:57.104: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-4847, will wait for the garbage collector to delete the pods 01/24/23 19:56:57.158
    Jan 24 19:56:57.313: INFO: Deleting ReplicationController affinity-nodeport took: 41.942325ms
    Jan 24 19:56:57.914: INFO: Terminating ReplicationController affinity-nodeport pods took: 601.581176ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 19:57:03.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4847" for this suite. 01/24/23 19:57:03.079
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:57:03.109
Jan 24 19:57:03.114: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename discovery 01/24/23 19:57:03.118
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:03.242
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:03.264
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 01/24/23 19:57:03.376
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Jan 24 19:57:05.842: INFO: Checking APIGroup: apiregistration.k8s.io
Jan 24 19:57:05.845: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Jan 24 19:57:05.845: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Jan 24 19:57:05.845: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Jan 24 19:57:05.845: INFO: Checking APIGroup: apps
Jan 24 19:57:05.847: INFO: PreferredVersion.GroupVersion: apps/v1
Jan 24 19:57:05.847: INFO: Versions found [{apps/v1 v1}]
Jan 24 19:57:05.847: INFO: apps/v1 matches apps/v1
Jan 24 19:57:05.847: INFO: Checking APIGroup: events.k8s.io
Jan 24 19:57:05.849: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Jan 24 19:57:05.849: INFO: Versions found [{events.k8s.io/v1 v1}]
Jan 24 19:57:05.849: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Jan 24 19:57:05.849: INFO: Checking APIGroup: authentication.k8s.io
Jan 24 19:57:05.850: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Jan 24 19:57:05.850: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Jan 24 19:57:05.850: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Jan 24 19:57:05.850: INFO: Checking APIGroup: authorization.k8s.io
Jan 24 19:57:05.853: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Jan 24 19:57:05.853: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Jan 24 19:57:05.853: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Jan 24 19:57:05.853: INFO: Checking APIGroup: autoscaling
Jan 24 19:57:05.856: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Jan 24 19:57:05.856: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Jan 24 19:57:05.856: INFO: autoscaling/v2 matches autoscaling/v2
Jan 24 19:57:05.856: INFO: Checking APIGroup: batch
Jan 24 19:57:05.858: INFO: PreferredVersion.GroupVersion: batch/v1
Jan 24 19:57:05.858: INFO: Versions found [{batch/v1 v1}]
Jan 24 19:57:05.858: INFO: batch/v1 matches batch/v1
Jan 24 19:57:05.858: INFO: Checking APIGroup: certificates.k8s.io
Jan 24 19:57:05.862: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Jan 24 19:57:05.862: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Jan 24 19:57:05.862: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Jan 24 19:57:05.862: INFO: Checking APIGroup: networking.k8s.io
Jan 24 19:57:05.864: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Jan 24 19:57:05.864: INFO: Versions found [{networking.k8s.io/v1 v1}]
Jan 24 19:57:05.864: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Jan 24 19:57:05.864: INFO: Checking APIGroup: policy
Jan 24 19:57:05.866: INFO: PreferredVersion.GroupVersion: policy/v1
Jan 24 19:57:05.866: INFO: Versions found [{policy/v1 v1}]
Jan 24 19:57:05.866: INFO: policy/v1 matches policy/v1
Jan 24 19:57:05.866: INFO: Checking APIGroup: rbac.authorization.k8s.io
Jan 24 19:57:05.869: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Jan 24 19:57:05.869: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Jan 24 19:57:05.869: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Jan 24 19:57:05.869: INFO: Checking APIGroup: storage.k8s.io
Jan 24 19:57:05.871: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Jan 24 19:57:05.871: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Jan 24 19:57:05.871: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Jan 24 19:57:05.871: INFO: Checking APIGroup: admissionregistration.k8s.io
Jan 24 19:57:05.873: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Jan 24 19:57:05.874: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Jan 24 19:57:05.874: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Jan 24 19:57:05.874: INFO: Checking APIGroup: apiextensions.k8s.io
Jan 24 19:57:05.877: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Jan 24 19:57:05.877: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Jan 24 19:57:05.877: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Jan 24 19:57:05.877: INFO: Checking APIGroup: scheduling.k8s.io
Jan 24 19:57:05.879: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Jan 24 19:57:05.879: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Jan 24 19:57:05.879: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Jan 24 19:57:05.879: INFO: Checking APIGroup: coordination.k8s.io
Jan 24 19:57:05.881: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Jan 24 19:57:05.881: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Jan 24 19:57:05.881: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Jan 24 19:57:05.881: INFO: Checking APIGroup: node.k8s.io
Jan 24 19:57:05.884: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Jan 24 19:57:05.886: INFO: Versions found [{node.k8s.io/v1 v1}]
Jan 24 19:57:05.886: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Jan 24 19:57:05.886: INFO: Checking APIGroup: discovery.k8s.io
Jan 24 19:57:05.891: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Jan 24 19:57:05.891: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Jan 24 19:57:05.891: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Jan 24 19:57:05.891: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Jan 24 19:57:05.895: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Jan 24 19:57:05.895: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Jan 24 19:57:05.895: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Jan 24 19:57:05.895: INFO: Checking APIGroup: crd.projectcalico.org
Jan 24 19:57:05.898: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Jan 24 19:57:05.898: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Jan 24 19:57:05.898: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Jan 24 19:57:05.898: INFO: Checking APIGroup: security.nirmata.io
Jan 24 19:57:05.902: INFO: PreferredVersion.GroupVersion: security.nirmata.io/v1
Jan 24 19:57:05.902: INFO: Versions found [{security.nirmata.io/v1 v1}]
Jan 24 19:57:05.902: INFO: security.nirmata.io/v1 matches security.nirmata.io/v1
Jan 24 19:57:05.902: INFO: Checking APIGroup: metrics.k8s.io
Jan 24 19:57:05.905: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Jan 24 19:57:05.905: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Jan 24 19:57:05.905: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Jan 24 19:57:05.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-9399" for this suite. 01/24/23 19:57:05.915
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":229,"skipped":4311,"failed":0}
------------------------------
• [2.822 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:57:03.109
    Jan 24 19:57:03.114: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename discovery 01/24/23 19:57:03.118
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:03.242
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:03.264
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 01/24/23 19:57:03.376
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Jan 24 19:57:05.842: INFO: Checking APIGroup: apiregistration.k8s.io
    Jan 24 19:57:05.845: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Jan 24 19:57:05.845: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Jan 24 19:57:05.845: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Jan 24 19:57:05.845: INFO: Checking APIGroup: apps
    Jan 24 19:57:05.847: INFO: PreferredVersion.GroupVersion: apps/v1
    Jan 24 19:57:05.847: INFO: Versions found [{apps/v1 v1}]
    Jan 24 19:57:05.847: INFO: apps/v1 matches apps/v1
    Jan 24 19:57:05.847: INFO: Checking APIGroup: events.k8s.io
    Jan 24 19:57:05.849: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Jan 24 19:57:05.849: INFO: Versions found [{events.k8s.io/v1 v1}]
    Jan 24 19:57:05.849: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Jan 24 19:57:05.849: INFO: Checking APIGroup: authentication.k8s.io
    Jan 24 19:57:05.850: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Jan 24 19:57:05.850: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Jan 24 19:57:05.850: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Jan 24 19:57:05.850: INFO: Checking APIGroup: authorization.k8s.io
    Jan 24 19:57:05.853: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Jan 24 19:57:05.853: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Jan 24 19:57:05.853: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Jan 24 19:57:05.853: INFO: Checking APIGroup: autoscaling
    Jan 24 19:57:05.856: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Jan 24 19:57:05.856: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Jan 24 19:57:05.856: INFO: autoscaling/v2 matches autoscaling/v2
    Jan 24 19:57:05.856: INFO: Checking APIGroup: batch
    Jan 24 19:57:05.858: INFO: PreferredVersion.GroupVersion: batch/v1
    Jan 24 19:57:05.858: INFO: Versions found [{batch/v1 v1}]
    Jan 24 19:57:05.858: INFO: batch/v1 matches batch/v1
    Jan 24 19:57:05.858: INFO: Checking APIGroup: certificates.k8s.io
    Jan 24 19:57:05.862: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Jan 24 19:57:05.862: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Jan 24 19:57:05.862: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Jan 24 19:57:05.862: INFO: Checking APIGroup: networking.k8s.io
    Jan 24 19:57:05.864: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Jan 24 19:57:05.864: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Jan 24 19:57:05.864: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Jan 24 19:57:05.864: INFO: Checking APIGroup: policy
    Jan 24 19:57:05.866: INFO: PreferredVersion.GroupVersion: policy/v1
    Jan 24 19:57:05.866: INFO: Versions found [{policy/v1 v1}]
    Jan 24 19:57:05.866: INFO: policy/v1 matches policy/v1
    Jan 24 19:57:05.866: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Jan 24 19:57:05.869: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Jan 24 19:57:05.869: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Jan 24 19:57:05.869: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Jan 24 19:57:05.869: INFO: Checking APIGroup: storage.k8s.io
    Jan 24 19:57:05.871: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Jan 24 19:57:05.871: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Jan 24 19:57:05.871: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Jan 24 19:57:05.871: INFO: Checking APIGroup: admissionregistration.k8s.io
    Jan 24 19:57:05.873: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Jan 24 19:57:05.874: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Jan 24 19:57:05.874: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Jan 24 19:57:05.874: INFO: Checking APIGroup: apiextensions.k8s.io
    Jan 24 19:57:05.877: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Jan 24 19:57:05.877: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Jan 24 19:57:05.877: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Jan 24 19:57:05.877: INFO: Checking APIGroup: scheduling.k8s.io
    Jan 24 19:57:05.879: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Jan 24 19:57:05.879: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Jan 24 19:57:05.879: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Jan 24 19:57:05.879: INFO: Checking APIGroup: coordination.k8s.io
    Jan 24 19:57:05.881: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Jan 24 19:57:05.881: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Jan 24 19:57:05.881: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Jan 24 19:57:05.881: INFO: Checking APIGroup: node.k8s.io
    Jan 24 19:57:05.884: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Jan 24 19:57:05.886: INFO: Versions found [{node.k8s.io/v1 v1}]
    Jan 24 19:57:05.886: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Jan 24 19:57:05.886: INFO: Checking APIGroup: discovery.k8s.io
    Jan 24 19:57:05.891: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Jan 24 19:57:05.891: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Jan 24 19:57:05.891: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Jan 24 19:57:05.891: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Jan 24 19:57:05.895: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Jan 24 19:57:05.895: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Jan 24 19:57:05.895: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Jan 24 19:57:05.895: INFO: Checking APIGroup: crd.projectcalico.org
    Jan 24 19:57:05.898: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Jan 24 19:57:05.898: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Jan 24 19:57:05.898: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Jan 24 19:57:05.898: INFO: Checking APIGroup: security.nirmata.io
    Jan 24 19:57:05.902: INFO: PreferredVersion.GroupVersion: security.nirmata.io/v1
    Jan 24 19:57:05.902: INFO: Versions found [{security.nirmata.io/v1 v1}]
    Jan 24 19:57:05.902: INFO: security.nirmata.io/v1 matches security.nirmata.io/v1
    Jan 24 19:57:05.902: INFO: Checking APIGroup: metrics.k8s.io
    Jan 24 19:57:05.905: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Jan 24 19:57:05.905: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Jan 24 19:57:05.905: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Jan 24 19:57:05.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-9399" for this suite. 01/24/23 19:57:05.915
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:57:05.93
Jan 24 19:57:05.931: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 19:57:05.934
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:05.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:05.991
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 01/24/23 19:57:06.012
STEP: watching for Pod to be ready 01/24/23 19:57:06.03
Jan 24 19:57:06.036: INFO: observed Pod pod-test in namespace pods-9033 in phase Pending with labels: map[test-pod-static:true] & conditions []
Jan 24 19:57:06.041: INFO: observed Pod pod-test in namespace pods-9033 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  }]
Jan 24 19:57:06.093: INFO: observed Pod pod-test in namespace pods-9033 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  }]
Jan 24 19:57:07.099: INFO: observed Pod pod-test in namespace pods-9033 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  }]
Jan 24 19:57:08.079: INFO: Found Pod pod-test in namespace pods-9033 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 01/24/23 19:57:08.095
STEP: getting the Pod and ensuring that it's patched 01/24/23 19:57:08.184
STEP: replacing the Pod's status Ready condition to False 01/24/23 19:57:08.289
STEP: check the Pod again to ensure its Ready conditions are False 01/24/23 19:57:08.436
STEP: deleting the Pod via a Collection with a LabelSelector 01/24/23 19:57:08.437
STEP: watching for the Pod to be deleted 01/24/23 19:57:08.506
Jan 24 19:57:08.529: INFO: observed event type MODIFIED
Jan 24 19:57:10.159: INFO: observed event type MODIFIED
Jan 24 19:57:10.871: INFO: observed event type MODIFIED
Jan 24 19:57:12.274: INFO: observed event type MODIFIED
Jan 24 19:57:12.315: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 24 19:57:12.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9033" for this suite. 01/24/23 19:57:12.423
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":230,"skipped":4318,"failed":0}
------------------------------
• [SLOW TEST] [6.555 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:57:05.93
    Jan 24 19:57:05.931: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 19:57:05.934
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:05.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:05.991
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 01/24/23 19:57:06.012
    STEP: watching for Pod to be ready 01/24/23 19:57:06.03
    Jan 24 19:57:06.036: INFO: observed Pod pod-test in namespace pods-9033 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Jan 24 19:57:06.041: INFO: observed Pod pod-test in namespace pods-9033 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  }]
    Jan 24 19:57:06.093: INFO: observed Pod pod-test in namespace pods-9033 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  }]
    Jan 24 19:57:07.099: INFO: observed Pod pod-test in namespace pods-9033 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  }]
    Jan 24 19:57:08.079: INFO: Found Pod pod-test in namespace pods-9033 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-01-24 19:57:06 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 01/24/23 19:57:08.095
    STEP: getting the Pod and ensuring that it's patched 01/24/23 19:57:08.184
    STEP: replacing the Pod's status Ready condition to False 01/24/23 19:57:08.289
    STEP: check the Pod again to ensure its Ready conditions are False 01/24/23 19:57:08.436
    STEP: deleting the Pod via a Collection with a LabelSelector 01/24/23 19:57:08.437
    STEP: watching for the Pod to be deleted 01/24/23 19:57:08.506
    Jan 24 19:57:08.529: INFO: observed event type MODIFIED
    Jan 24 19:57:10.159: INFO: observed event type MODIFIED
    Jan 24 19:57:10.871: INFO: observed event type MODIFIED
    Jan 24 19:57:12.274: INFO: observed event type MODIFIED
    Jan 24 19:57:12.315: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 24 19:57:12.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9033" for this suite. 01/24/23 19:57:12.423
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:57:12.553
Jan 24 19:57:12.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 19:57:12.565
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:12.892
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:12.995
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-2e1b792c-f271-47a0-97bc-b6e01fbfdddc 01/24/23 19:57:13.201
STEP: Creating the pod 01/24/23 19:57:13.242
Jan 24 19:57:13.330: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2" in namespace "projected-4514" to be "running and ready"
Jan 24 19:57:13.392: INFO: Pod "pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2": Phase="Pending", Reason="", readiness=false. Elapsed: 62.404615ms
Jan 24 19:57:13.392: INFO: The phase of Pod pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:57:15.410: INFO: Pod "pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080210835s
Jan 24 19:57:15.410: INFO: The phase of Pod pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 19:57:17.407: INFO: Pod "pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2": Phase="Running", Reason="", readiness=true. Elapsed: 4.077424964s
Jan 24 19:57:17.408: INFO: The phase of Pod pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2 is Running (Ready = true)
Jan 24 19:57:17.408: INFO: Pod "pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-2e1b792c-f271-47a0-97bc-b6e01fbfdddc 01/24/23 19:57:17.444
STEP: waiting to observe update in volume 01/24/23 19:57:17.461
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 24 19:57:19.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4514" for this suite. 01/24/23 19:57:19.533
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":231,"skipped":4333,"failed":0}
------------------------------
• [SLOW TEST] [7.031 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:57:12.553
    Jan 24 19:57:12.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 19:57:12.565
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:12.892
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:12.995
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-2e1b792c-f271-47a0-97bc-b6e01fbfdddc 01/24/23 19:57:13.201
    STEP: Creating the pod 01/24/23 19:57:13.242
    Jan 24 19:57:13.330: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2" in namespace "projected-4514" to be "running and ready"
    Jan 24 19:57:13.392: INFO: Pod "pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2": Phase="Pending", Reason="", readiness=false. Elapsed: 62.404615ms
    Jan 24 19:57:13.392: INFO: The phase of Pod pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:57:15.410: INFO: Pod "pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080210835s
    Jan 24 19:57:15.410: INFO: The phase of Pod pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 19:57:17.407: INFO: Pod "pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2": Phase="Running", Reason="", readiness=true. Elapsed: 4.077424964s
    Jan 24 19:57:17.408: INFO: The phase of Pod pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2 is Running (Ready = true)
    Jan 24 19:57:17.408: INFO: Pod "pod-projected-configmaps-e844275b-65af-413d-a1ca-d162f3389bc2" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-2e1b792c-f271-47a0-97bc-b6e01fbfdddc 01/24/23 19:57:17.444
    STEP: waiting to observe update in volume 01/24/23 19:57:17.461
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 24 19:57:19.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4514" for this suite. 01/24/23 19:57:19.533
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:57:19.587
Jan 24 19:57:19.588: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 19:57:19.591
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:19.734
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:19.763
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 01/24/23 19:57:19.783
Jan 24 19:57:19.783: INFO: Creating e2e-svc-a-qvdpq
Jan 24 19:57:19.839: INFO: Creating e2e-svc-b-zgpwv
Jan 24 19:57:19.894: INFO: Creating e2e-svc-c-jvdbz
STEP: deleting service collection 01/24/23 19:57:19.978
Jan 24 19:57:20.469: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 19:57:20.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8190" for this suite. 01/24/23 19:57:21.012
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":232,"skipped":4343,"failed":0}
------------------------------
• [1.585 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:57:19.587
    Jan 24 19:57:19.588: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 19:57:19.591
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:19.734
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:19.763
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 01/24/23 19:57:19.783
    Jan 24 19:57:19.783: INFO: Creating e2e-svc-a-qvdpq
    Jan 24 19:57:19.839: INFO: Creating e2e-svc-b-zgpwv
    Jan 24 19:57:19.894: INFO: Creating e2e-svc-c-jvdbz
    STEP: deleting service collection 01/24/23 19:57:19.978
    Jan 24 19:57:20.469: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 19:57:20.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8190" for this suite. 01/24/23 19:57:21.012
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:57:21.447
Jan 24 19:57:21.449: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replicaset 01/24/23 19:57:21.472
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:21.725
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:21.762
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 01/24/23 19:57:21.82
STEP: Verify that the required pods have come up 01/24/23 19:57:22.023
Jan 24 19:57:22.112: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 01/24/23 19:57:22.112
Jan 24 19:57:22.112: INFO: Waiting up to 5m0s for pod "test-rs-thgzg" in namespace "replicaset-4278" to be "running"
Jan 24 19:57:22.116: INFO: Waiting up to 5m0s for pod "test-rs-7h9wh" in namespace "replicaset-4278" to be "running"
Jan 24 19:57:22.127: INFO: Pod "test-rs-thgzg": Phase="Pending", Reason="", readiness=false. Elapsed: 14.278945ms
Jan 24 19:57:22.142: INFO: Waiting up to 5m0s for pod "test-rs-6h78m" in namespace "replicaset-4278" to be "running"
Jan 24 19:57:22.152: INFO: Pod "test-rs-6h78m": Phase="Pending", Reason="", readiness=false. Elapsed: 10.074523ms
Jan 24 19:57:22.197: INFO: Pod "test-rs-7h9wh": Phase="Pending", Reason="", readiness=false. Elapsed: 80.600169ms
Jan 24 19:57:24.203: INFO: Pod "test-rs-thgzg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090464703s
Jan 24 19:57:24.222: INFO: Pod "test-rs-6h78m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080475473s
Jan 24 19:57:24.279: INFO: Pod "test-rs-7h9wh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.163202975s
Jan 24 19:57:26.142: INFO: Pod "test-rs-thgzg": Phase="Running", Reason="", readiness=true. Elapsed: 4.029326915s
Jan 24 19:57:26.142: INFO: Pod "test-rs-thgzg" satisfied condition "running"
Jan 24 19:57:26.194: INFO: Pod "test-rs-6h78m": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052322735s
Jan 24 19:57:26.218: INFO: Pod "test-rs-7h9wh": Phase="Pending", Reason="", readiness=false. Elapsed: 4.102039316s
Jan 24 19:57:28.164: INFO: Pod "test-rs-6h78m": Phase="Running", Reason="", readiness=true. Elapsed: 6.022421692s
Jan 24 19:57:28.164: INFO: Pod "test-rs-6h78m" satisfied condition "running"
Jan 24 19:57:28.220: INFO: Pod "test-rs-7h9wh": Phase="Pending", Reason="", readiness=false. Elapsed: 6.103895612s
Jan 24 19:57:30.215: INFO: Pod "test-rs-7h9wh": Phase="Running", Reason="", readiness=true. Elapsed: 8.098510397s
Jan 24 19:57:30.215: INFO: Pod "test-rs-7h9wh" satisfied condition "running"
Jan 24 19:57:30.229: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 01/24/23 19:57:30.229
STEP: DeleteCollection of the ReplicaSets 01/24/23 19:57:30.269
STEP: After DeleteCollection verify that ReplicaSets have been deleted 01/24/23 19:57:30.315
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 24 19:57:30.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4278" for this suite. 01/24/23 19:57:30.395
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":233,"skipped":4360,"failed":0}
------------------------------
• [SLOW TEST] [9.269 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:57:21.447
    Jan 24 19:57:21.449: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replicaset 01/24/23 19:57:21.472
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:21.725
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:21.762
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 01/24/23 19:57:21.82
    STEP: Verify that the required pods have come up 01/24/23 19:57:22.023
    Jan 24 19:57:22.112: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 01/24/23 19:57:22.112
    Jan 24 19:57:22.112: INFO: Waiting up to 5m0s for pod "test-rs-thgzg" in namespace "replicaset-4278" to be "running"
    Jan 24 19:57:22.116: INFO: Waiting up to 5m0s for pod "test-rs-7h9wh" in namespace "replicaset-4278" to be "running"
    Jan 24 19:57:22.127: INFO: Pod "test-rs-thgzg": Phase="Pending", Reason="", readiness=false. Elapsed: 14.278945ms
    Jan 24 19:57:22.142: INFO: Waiting up to 5m0s for pod "test-rs-6h78m" in namespace "replicaset-4278" to be "running"
    Jan 24 19:57:22.152: INFO: Pod "test-rs-6h78m": Phase="Pending", Reason="", readiness=false. Elapsed: 10.074523ms
    Jan 24 19:57:22.197: INFO: Pod "test-rs-7h9wh": Phase="Pending", Reason="", readiness=false. Elapsed: 80.600169ms
    Jan 24 19:57:24.203: INFO: Pod "test-rs-thgzg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090464703s
    Jan 24 19:57:24.222: INFO: Pod "test-rs-6h78m": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080475473s
    Jan 24 19:57:24.279: INFO: Pod "test-rs-7h9wh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.163202975s
    Jan 24 19:57:26.142: INFO: Pod "test-rs-thgzg": Phase="Running", Reason="", readiness=true. Elapsed: 4.029326915s
    Jan 24 19:57:26.142: INFO: Pod "test-rs-thgzg" satisfied condition "running"
    Jan 24 19:57:26.194: INFO: Pod "test-rs-6h78m": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052322735s
    Jan 24 19:57:26.218: INFO: Pod "test-rs-7h9wh": Phase="Pending", Reason="", readiness=false. Elapsed: 4.102039316s
    Jan 24 19:57:28.164: INFO: Pod "test-rs-6h78m": Phase="Running", Reason="", readiness=true. Elapsed: 6.022421692s
    Jan 24 19:57:28.164: INFO: Pod "test-rs-6h78m" satisfied condition "running"
    Jan 24 19:57:28.220: INFO: Pod "test-rs-7h9wh": Phase="Pending", Reason="", readiness=false. Elapsed: 6.103895612s
    Jan 24 19:57:30.215: INFO: Pod "test-rs-7h9wh": Phase="Running", Reason="", readiness=true. Elapsed: 8.098510397s
    Jan 24 19:57:30.215: INFO: Pod "test-rs-7h9wh" satisfied condition "running"
    Jan 24 19:57:30.229: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 01/24/23 19:57:30.229
    STEP: DeleteCollection of the ReplicaSets 01/24/23 19:57:30.269
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 01/24/23 19:57:30.315
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 24 19:57:30.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4278" for this suite. 01/24/23 19:57:30.395
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:57:30.927
Jan 24 19:57:30.931: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 19:57:30.936
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:31.065
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:31.255
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Jan 24 19:57:31.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/24/23 19:57:47.972
Jan 24 19:57:47.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-3116 --namespace=crd-publish-openapi-3116 create -f -'
Jan 24 19:57:54.032: INFO: stderr: ""
Jan 24 19:57:54.032: INFO: stdout: "e2e-test-crd-publish-openapi-789-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jan 24 19:57:54.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-3116 --namespace=crd-publish-openapi-3116 delete e2e-test-crd-publish-openapi-789-crds test-cr'
Jan 24 19:57:54.830: INFO: stderr: ""
Jan 24 19:57:54.830: INFO: stdout: "e2e-test-crd-publish-openapi-789-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Jan 24 19:57:54.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-3116 --namespace=crd-publish-openapi-3116 apply -f -'
Jan 24 19:57:55.925: INFO: stderr: ""
Jan 24 19:57:55.926: INFO: stdout: "e2e-test-crd-publish-openapi-789-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jan 24 19:57:55.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-3116 --namespace=crd-publish-openapi-3116 delete e2e-test-crd-publish-openapi-789-crds test-cr'
Jan 24 19:57:56.295: INFO: stderr: ""
Jan 24 19:57:56.295: INFO: stdout: "e2e-test-crd-publish-openapi-789-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 01/24/23 19:57:56.295
Jan 24 19:57:56.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-3116 explain e2e-test-crd-publish-openapi-789-crds'
Jan 24 19:57:57.426: INFO: stderr: ""
Jan 24 19:57:57.426: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-789-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 19:58:17.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3116" for this suite. 01/24/23 19:58:17.327
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":234,"skipped":4378,"failed":0}
------------------------------
• [SLOW TEST] [46.420 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:57:30.927
    Jan 24 19:57:30.931: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 19:57:30.936
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:57:31.065
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:57:31.255
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Jan 24 19:57:31.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/24/23 19:57:47.972
    Jan 24 19:57:47.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-3116 --namespace=crd-publish-openapi-3116 create -f -'
    Jan 24 19:57:54.032: INFO: stderr: ""
    Jan 24 19:57:54.032: INFO: stdout: "e2e-test-crd-publish-openapi-789-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Jan 24 19:57:54.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-3116 --namespace=crd-publish-openapi-3116 delete e2e-test-crd-publish-openapi-789-crds test-cr'
    Jan 24 19:57:54.830: INFO: stderr: ""
    Jan 24 19:57:54.830: INFO: stdout: "e2e-test-crd-publish-openapi-789-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Jan 24 19:57:54.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-3116 --namespace=crd-publish-openapi-3116 apply -f -'
    Jan 24 19:57:55.925: INFO: stderr: ""
    Jan 24 19:57:55.926: INFO: stdout: "e2e-test-crd-publish-openapi-789-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Jan 24 19:57:55.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-3116 --namespace=crd-publish-openapi-3116 delete e2e-test-crd-publish-openapi-789-crds test-cr'
    Jan 24 19:57:56.295: INFO: stderr: ""
    Jan 24 19:57:56.295: INFO: stdout: "e2e-test-crd-publish-openapi-789-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 01/24/23 19:57:56.295
    Jan 24 19:57:56.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-3116 explain e2e-test-crd-publish-openapi-789-crds'
    Jan 24 19:57:57.426: INFO: stderr: ""
    Jan 24 19:57:57.426: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-789-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 19:58:17.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3116" for this suite. 01/24/23 19:58:17.327
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:58:17.387
Jan 24 19:58:17.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename runtimeclass 01/24/23 19:58:17.391
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:58:17.431
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:58:17.444
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-6069-delete-me 01/24/23 19:58:17.467
STEP: Waiting for the RuntimeClass to disappear 01/24/23 19:58:17.479
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jan 24 19:58:17.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6069" for this suite. 01/24/23 19:58:17.515
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":235,"skipped":4434,"failed":0}
------------------------------
• [0.143 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:58:17.387
    Jan 24 19:58:17.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename runtimeclass 01/24/23 19:58:17.391
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:58:17.431
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:58:17.444
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-6069-delete-me 01/24/23 19:58:17.467
    STEP: Waiting for the RuntimeClass to disappear 01/24/23 19:58:17.479
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jan 24 19:58:17.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6069" for this suite. 01/24/23 19:58:17.515
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:58:17.533
Jan 24 19:58:17.534: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename job 01/24/23 19:58:17.538
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:58:17.581
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:58:17.597
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 01/24/23 19:58:17.604
STEP: Ensuring active pods == parallelism 01/24/23 19:58:17.63
STEP: delete a job 01/24/23 19:58:21.715
STEP: deleting Job.batch foo in namespace job-2222, will wait for the garbage collector to delete the pods 01/24/23 19:58:21.716
Jan 24 19:58:21.842: INFO: Deleting Job.batch foo took: 58.676493ms
Jan 24 19:58:22.244: INFO: Terminating Job.batch foo pods took: 402.141748ms
STEP: Ensuring job was deleted 01/24/23 19:58:56.147
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 24 19:58:56.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2222" for this suite. 01/24/23 19:58:56.247
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":236,"skipped":4441,"failed":0}
------------------------------
• [SLOW TEST] [38.792 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:58:17.533
    Jan 24 19:58:17.534: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename job 01/24/23 19:58:17.538
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:58:17.581
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:58:17.597
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 01/24/23 19:58:17.604
    STEP: Ensuring active pods == parallelism 01/24/23 19:58:17.63
    STEP: delete a job 01/24/23 19:58:21.715
    STEP: deleting Job.batch foo in namespace job-2222, will wait for the garbage collector to delete the pods 01/24/23 19:58:21.716
    Jan 24 19:58:21.842: INFO: Deleting Job.batch foo took: 58.676493ms
    Jan 24 19:58:22.244: INFO: Terminating Job.batch foo pods took: 402.141748ms
    STEP: Ensuring job was deleted 01/24/23 19:58:56.147
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 24 19:58:56.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2222" for this suite. 01/24/23 19:58:56.247
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:58:56.335
Jan 24 19:58:56.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 19:58:56.339
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:58:56.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:58:56.467
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Jan 24 19:58:56.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 create -f -'
Jan 24 19:59:01.980: INFO: stderr: ""
Jan 24 19:59:01.980: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Jan 24 19:59:01.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 create -f -'
Jan 24 19:59:06.582: INFO: stderr: ""
Jan 24 19:59:06.582: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 01/24/23 19:59:06.582
Jan 24 19:59:07.591: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 19:59:07.591: INFO: Found 1 / 1
Jan 24 19:59:07.591: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 24 19:59:07.599: INFO: Selector matched 1 pods for map[app:agnhost]
Jan 24 19:59:07.599: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 24 19:59:07.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 describe pod agnhost-primary-4z5rx'
Jan 24 19:59:07.832: INFO: stderr: ""
Jan 24 19:59:07.832: INFO: stdout: "Name:             agnhost-primary-4z5rx\nNamespace:        kubectl-5560\nPriority:         0\nService Account:  default\nNode:             vikash-v125latest-conf-71087/10.10.1.127\nStart Time:       Tue, 24 Jan 2023 19:59:02 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: cb38c3f59065f4ced2b71f9d6646de6681dcb0f19cb6b3a14632837966b73a3d\n                  cni.projectcalico.org/podIP: 10.244.71.234/32\n                  cni.projectcalico.org/podIPs: 10.244.71.234/32\nStatus:           Running\nIP:               10.244.71.234\nIPs:\n  IP:           10.244.71.234\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://72b0b9561faf7c2214d3cf4ed07702b47348c9d87e3bf61797e722a7796ddb4e\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 24 Jan 2023 19:59:04 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-d98wp (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-d98wp:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  5s    default-scheduler  Successfully assigned kubectl-5560/agnhost-primary-4z5rx to vikash-v125latest-conf-71087\n  Normal  Pulled     3s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    3s    kubelet            Created container agnhost-primary\n  Normal  Started    3s    kubelet            Started container agnhost-primary\n"
Jan 24 19:59:07.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 describe rc agnhost-primary'
Jan 24 19:59:08.014: INFO: stderr: ""
Jan 24 19:59:08.014: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5560\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  6s    replication-controller  Created pod: agnhost-primary-4z5rx\n"
Jan 24 19:59:08.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 describe service agnhost-primary'
Jan 24 19:59:08.332: INFO: stderr: ""
Jan 24 19:59:08.332: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5560\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.10.139.240\nIPs:               10.10.139.240\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.71.234:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 24 19:59:08.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 describe node vikash-v125latest-conf-59870'
Jan 24 19:59:08.600: INFO: stderr: ""
Jan 24 19:59:08.600: INFO: stdout: "Name:               vikash-v125latest-conf-59870\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=vikash-v125latest-conf-59870\n                    kubernetes.io/os=linux\n                    nirmata.io/cluster.name=k8s-1255-cluster-tgrhpp\n                    nirmata.io/cluster.role=control-plane\n                    nirmata.io/host.hostid=vikash-v125latest-conf-59870\n                    nirmata.io/host.name=vikash-v125latest-conf-59870\n                    nirmata.io/host.privatednsname=vikash-v125latest-conf-59870\n                    nirmata.io/host.privateipaddress=10.10.1.213\n                    nirmata.io/host.publicdnsname=vikash-v125latest-conf-59870\n                    nirmata.io/host.publicipaddress=10.10.1.213\n                    nirmata.io/node.name=vikash-v125latest-conf-59870\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.10.1.213/16\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.244.47.64\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 24 Jan 2023 08:32:33 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  vikash-v125latest-conf-59870\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 24 Jan 2023 19:59:00 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 24 Jan 2023 18:21:25 +0000   Tue, 24 Jan 2023 18:21:25 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 24 Jan 2023 19:54:43 +0000   Tue, 24 Jan 2023 08:32:33 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 24 Jan 2023 19:54:43 +0000   Tue, 24 Jan 2023 08:32:33 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 24 Jan 2023 19:54:43 +0000   Tue, 24 Jan 2023 08:32:33 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 24 Jan 2023 19:54:43 +0000   Tue, 24 Jan 2023 08:49:41 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.10.1.213\n  Hostname:    vikash-v125latest-conf-59870\nCapacity:\n  cpu:                    4\n  ephemeral-storage:      13706Mi\n  hugepages-2Mi:          0\n  memory:                 8149844Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    4\n  ephemeral-storage:      12934604369\n  hugepages-2Mi:          0\n  memory:                 8047444Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 11d33abb7ae54f9ba1b93c14970302c3\n  System UUID:                c76e3442-8c09-8667-934b-7affbd77c388\n  Boot ID:                    fab2b68e-237d-424e-b5f5-062febd2bc64\n  Kernel Version:             5.16.12-1.el7.elrepo.x86_64\n  OS Image:                   Debian GNU/Linux 9 (stretch)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.4.12\n  Kubelet Version:            v1.25.5\n  Kube-Proxy Version:         v1.25.5\nPodCIDR:                      192.168.1.0/24\nPodCIDRs:                     192.168.1.0/24\nNon-terminated Pods:          (12 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-haproxy             haproxy-ingress-cb855dc7c-smnf7                            10m (0%)      0 (0%)      20Mi (0%)        100Mi (1%)     96m\n  ingress-haproxy             ingress-default-backend-6f4477b7bc-qg2sz                   250m (6%)     0 (0%)      200Mi (2%)       250Mi (3%)     96m\n  kube-system                 calico-kube-controllers-74677b4c5f-zd5w8                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         98m\n  kube-system                 calico-node-45c9d                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         99m\n  kube-system                 coredns-94487f57-9zlwt                                     100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     84m\n  kube-system                 coredns-94487f57-qldwh                                     100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     84m\n  nirmata                     kyverno-operator-5c87dbd458-txhlw                          15m (0%)      1 (25%)     128Mi (1%)       256Mi (3%)     96m\n  nirmata                     nirmata-cni-installer-6skzt                                250m (6%)     0 (0%)      100Mi (1%)       200Mi (2%)     11h\n  nirmata                     otel-agent-6dfc8d44b6-6kj5q                                100m (2%)     100m (2%)   200Mi (2%)       200Mi (2%)     96m\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\n  sonobuoy                    sonobuoy-e2e-job-d94c6e71d257417d                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq    0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests     Limits\n  --------               --------     ------\n  cpu                    1075m (26%)  1100m (27%)\n  memory                 788Mi (10%)  1346Mi (17%)\n  ephemeral-storage      0 (0%)       0 (0%)\n  hugepages-2Mi          0 (0%)       0 (0%)\n  scheduling.k8s.io/foo  0            0\nEvents:\n  Type     Reason               Age                From     Message\n  ----     ------               ----               ----     -------\n  Warning  InvalidDiskCapacity  3s (x115 over 9h)  kubelet  invalid capacity 0 on image filesystem\n"
Jan 24 19:59:08.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 describe namespace kubectl-5560'
Jan 24 19:59:08.786: INFO: stderr: ""
Jan 24 19:59:08.786: INFO: stdout: "Name:         kubectl-5560\nLabels:       e2e-framework=kubectl\n              e2e-run=617be119-0c88-4374-8e10-e5fff9ed44b0\n              kubernetes.io/metadata.name=kubectl-5560\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 19:59:08.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5560" for this suite. 01/24/23 19:59:08.798
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":237,"skipped":4442,"failed":0}
------------------------------
• [SLOW TEST] [12.484 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:58:56.335
    Jan 24 19:58:56.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 19:58:56.339
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:58:56.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:58:56.467
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Jan 24 19:58:56.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 create -f -'
    Jan 24 19:59:01.980: INFO: stderr: ""
    Jan 24 19:59:01.980: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Jan 24 19:59:01.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 create -f -'
    Jan 24 19:59:06.582: INFO: stderr: ""
    Jan 24 19:59:06.582: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 01/24/23 19:59:06.582
    Jan 24 19:59:07.591: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 19:59:07.591: INFO: Found 1 / 1
    Jan 24 19:59:07.591: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Jan 24 19:59:07.599: INFO: Selector matched 1 pods for map[app:agnhost]
    Jan 24 19:59:07.599: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Jan 24 19:59:07.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 describe pod agnhost-primary-4z5rx'
    Jan 24 19:59:07.832: INFO: stderr: ""
    Jan 24 19:59:07.832: INFO: stdout: "Name:             agnhost-primary-4z5rx\nNamespace:        kubectl-5560\nPriority:         0\nService Account:  default\nNode:             vikash-v125latest-conf-71087/10.10.1.127\nStart Time:       Tue, 24 Jan 2023 19:59:02 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: cb38c3f59065f4ced2b71f9d6646de6681dcb0f19cb6b3a14632837966b73a3d\n                  cni.projectcalico.org/podIP: 10.244.71.234/32\n                  cni.projectcalico.org/podIPs: 10.244.71.234/32\nStatus:           Running\nIP:               10.244.71.234\nIPs:\n  IP:           10.244.71.234\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://72b0b9561faf7c2214d3cf4ed07702b47348c9d87e3bf61797e722a7796ddb4e\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 24 Jan 2023 19:59:04 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-d98wp (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-d98wp:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  5s    default-scheduler  Successfully assigned kubectl-5560/agnhost-primary-4z5rx to vikash-v125latest-conf-71087\n  Normal  Pulled     3s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    3s    kubelet            Created container agnhost-primary\n  Normal  Started    3s    kubelet            Started container agnhost-primary\n"
    Jan 24 19:59:07.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 describe rc agnhost-primary'
    Jan 24 19:59:08.014: INFO: stderr: ""
    Jan 24 19:59:08.014: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5560\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  6s    replication-controller  Created pod: agnhost-primary-4z5rx\n"
    Jan 24 19:59:08.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 describe service agnhost-primary'
    Jan 24 19:59:08.332: INFO: stderr: ""
    Jan 24 19:59:08.332: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5560\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.10.139.240\nIPs:               10.10.139.240\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.244.71.234:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Jan 24 19:59:08.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 describe node vikash-v125latest-conf-59870'
    Jan 24 19:59:08.600: INFO: stderr: ""
    Jan 24 19:59:08.600: INFO: stdout: "Name:               vikash-v125latest-conf-59870\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=vikash-v125latest-conf-59870\n                    kubernetes.io/os=linux\n                    nirmata.io/cluster.name=k8s-1255-cluster-tgrhpp\n                    nirmata.io/cluster.role=control-plane\n                    nirmata.io/host.hostid=vikash-v125latest-conf-59870\n                    nirmata.io/host.name=vikash-v125latest-conf-59870\n                    nirmata.io/host.privatednsname=vikash-v125latest-conf-59870\n                    nirmata.io/host.privateipaddress=10.10.1.213\n                    nirmata.io/host.publicdnsname=vikash-v125latest-conf-59870\n                    nirmata.io/host.publicipaddress=10.10.1.213\n                    nirmata.io/node.name=vikash-v125latest-conf-59870\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.10.1.213/16\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.244.47.64\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 24 Jan 2023 08:32:33 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  vikash-v125latest-conf-59870\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 24 Jan 2023 19:59:00 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 24 Jan 2023 18:21:25 +0000   Tue, 24 Jan 2023 18:21:25 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 24 Jan 2023 19:54:43 +0000   Tue, 24 Jan 2023 08:32:33 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 24 Jan 2023 19:54:43 +0000   Tue, 24 Jan 2023 08:32:33 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 24 Jan 2023 19:54:43 +0000   Tue, 24 Jan 2023 08:32:33 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 24 Jan 2023 19:54:43 +0000   Tue, 24 Jan 2023 08:49:41 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.10.1.213\n  Hostname:    vikash-v125latest-conf-59870\nCapacity:\n  cpu:                    4\n  ephemeral-storage:      13706Mi\n  hugepages-2Mi:          0\n  memory:                 8149844Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    4\n  ephemeral-storage:      12934604369\n  hugepages-2Mi:          0\n  memory:                 8047444Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                 11d33abb7ae54f9ba1b93c14970302c3\n  System UUID:                c76e3442-8c09-8667-934b-7affbd77c388\n  Boot ID:                    fab2b68e-237d-424e-b5f5-062febd2bc64\n  Kernel Version:             5.16.12-1.el7.elrepo.x86_64\n  OS Image:                   Debian GNU/Linux 9 (stretch)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.4.12\n  Kubelet Version:            v1.25.5\n  Kube-Proxy Version:         v1.25.5\nPodCIDR:                      192.168.1.0/24\nPodCIDRs:                     192.168.1.0/24\nNon-terminated Pods:          (12 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-haproxy             haproxy-ingress-cb855dc7c-smnf7                            10m (0%)      0 (0%)      20Mi (0%)        100Mi (1%)     96m\n  ingress-haproxy             ingress-default-backend-6f4477b7bc-qg2sz                   250m (6%)     0 (0%)      200Mi (2%)       250Mi (3%)     96m\n  kube-system                 calico-kube-controllers-74677b4c5f-zd5w8                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         98m\n  kube-system                 calico-node-45c9d                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         99m\n  kube-system                 coredns-94487f57-9zlwt                                     100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     84m\n  kube-system                 coredns-94487f57-qldwh                                     100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     84m\n  nirmata                     kyverno-operator-5c87dbd458-txhlw                          15m (0%)      1 (25%)     128Mi (1%)       256Mi (3%)     96m\n  nirmata                     nirmata-cni-installer-6skzt                                250m (6%)     0 (0%)      100Mi (1%)       200Mi (2%)     11h\n  nirmata                     otel-agent-6dfc8d44b6-6kj5q                                100m (2%)     100m (2%)   200Mi (2%)       200Mi (2%)     96m\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\n  sonobuoy                    sonobuoy-e2e-job-d94c6e71d257417d                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq    0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests     Limits\n  --------               --------     ------\n  cpu                    1075m (26%)  1100m (27%)\n  memory                 788Mi (10%)  1346Mi (17%)\n  ephemeral-storage      0 (0%)       0 (0%)\n  hugepages-2Mi          0 (0%)       0 (0%)\n  scheduling.k8s.io/foo  0            0\nEvents:\n  Type     Reason               Age                From     Message\n  ----     ------               ----               ----     -------\n  Warning  InvalidDiskCapacity  3s (x115 over 9h)  kubelet  invalid capacity 0 on image filesystem\n"
    Jan 24 19:59:08.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-5560 describe namespace kubectl-5560'
    Jan 24 19:59:08.786: INFO: stderr: ""
    Jan 24 19:59:08.786: INFO: stdout: "Name:         kubectl-5560\nLabels:       e2e-framework=kubectl\n              e2e-run=617be119-0c88-4374-8e10-e5fff9ed44b0\n              kubernetes.io/metadata.name=kubectl-5560\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 19:59:08.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5560" for this suite. 01/24/23 19:59:08.798
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:59:08.82
Jan 24 19:59:08.823: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename proxy 01/24/23 19:59:08.825
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:59:08.854
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:59:08.86
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Jan 24 19:59:08.869: INFO: Creating pod...
Jan 24 19:59:08.898: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7279" to be "running"
Jan 24 19:59:08.925: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 26.672666ms
Jan 24 19:59:10.937: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038852922s
Jan 24 19:59:12.964: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.065225715s
Jan 24 19:59:12.964: INFO: Pod "agnhost" satisfied condition "running"
Jan 24 19:59:12.964: INFO: Creating service...
Jan 24 19:59:13.001: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=DELETE
Jan 24 19:59:13.042: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jan 24 19:59:13.042: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=OPTIONS
Jan 24 19:59:13.078: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jan 24 19:59:13.078: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=PATCH
Jan 24 19:59:13.135: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jan 24 19:59:13.135: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=POST
Jan 24 19:59:13.195: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jan 24 19:59:13.195: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=PUT
Jan 24 19:59:13.253: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jan 24 19:59:13.253: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=DELETE
Jan 24 19:59:13.316: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jan 24 19:59:13.316: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=OPTIONS
Jan 24 19:59:13.334: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jan 24 19:59:13.334: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=PATCH
Jan 24 19:59:13.356: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jan 24 19:59:13.358: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=POST
Jan 24 19:59:13.381: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jan 24 19:59:13.394: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=PUT
Jan 24 19:59:13.410: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jan 24 19:59:13.410: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=GET
Jan 24 19:59:13.419: INFO: http.Client request:GET StatusCode:301
Jan 24 19:59:13.419: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=GET
Jan 24 19:59:13.431: INFO: http.Client request:GET StatusCode:301
Jan 24 19:59:13.432: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=HEAD
Jan 24 19:59:13.446: INFO: http.Client request:HEAD StatusCode:301
Jan 24 19:59:13.447: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=HEAD
Jan 24 19:59:13.478: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Jan 24 19:59:13.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7279" for this suite. 01/24/23 19:59:13.511
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":238,"skipped":4477,"failed":0}
------------------------------
• [4.736 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:59:08.82
    Jan 24 19:59:08.823: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename proxy 01/24/23 19:59:08.825
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:59:08.854
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:59:08.86
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Jan 24 19:59:08.869: INFO: Creating pod...
    Jan 24 19:59:08.898: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7279" to be "running"
    Jan 24 19:59:08.925: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 26.672666ms
    Jan 24 19:59:10.937: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038852922s
    Jan 24 19:59:12.964: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.065225715s
    Jan 24 19:59:12.964: INFO: Pod "agnhost" satisfied condition "running"
    Jan 24 19:59:12.964: INFO: Creating service...
    Jan 24 19:59:13.001: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=DELETE
    Jan 24 19:59:13.042: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jan 24 19:59:13.042: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=OPTIONS
    Jan 24 19:59:13.078: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jan 24 19:59:13.078: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=PATCH
    Jan 24 19:59:13.135: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jan 24 19:59:13.135: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=POST
    Jan 24 19:59:13.195: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jan 24 19:59:13.195: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=PUT
    Jan 24 19:59:13.253: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Jan 24 19:59:13.253: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=DELETE
    Jan 24 19:59:13.316: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jan 24 19:59:13.316: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Jan 24 19:59:13.334: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jan 24 19:59:13.334: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=PATCH
    Jan 24 19:59:13.356: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jan 24 19:59:13.358: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=POST
    Jan 24 19:59:13.381: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jan 24 19:59:13.394: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=PUT
    Jan 24 19:59:13.410: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Jan 24 19:59:13.410: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=GET
    Jan 24 19:59:13.419: INFO: http.Client request:GET StatusCode:301
    Jan 24 19:59:13.419: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=GET
    Jan 24 19:59:13.431: INFO: http.Client request:GET StatusCode:301
    Jan 24 19:59:13.432: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/pods/agnhost/proxy?method=HEAD
    Jan 24 19:59:13.446: INFO: http.Client request:HEAD StatusCode:301
    Jan 24 19:59:13.447: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-7279/services/e2e-proxy-test-service/proxy?method=HEAD
    Jan 24 19:59:13.478: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Jan 24 19:59:13.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-7279" for this suite. 01/24/23 19:59:13.511
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:59:13.564
Jan 24 19:59:13.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename endpointslice 01/24/23 19:59:13.569
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:59:13.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:59:13.645
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 01/24/23 19:59:19.563
STEP: referencing matching pods with named port 01/24/23 19:59:24.631
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 01/24/23 19:59:29.688
STEP: recreating EndpointSlices after they've been deleted 01/24/23 19:59:34.746
Jan 24 19:59:34.935: INFO: EndpointSlice for Service endpointslice-661/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Jan 24 19:59:44.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-661" for this suite. 01/24/23 19:59:45.032
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":239,"skipped":4478,"failed":0}
------------------------------
• [SLOW TEST] [31.544 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:59:13.564
    Jan 24 19:59:13.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename endpointslice 01/24/23 19:59:13.569
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:59:13.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:59:13.645
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 01/24/23 19:59:19.563
    STEP: referencing matching pods with named port 01/24/23 19:59:24.631
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 01/24/23 19:59:29.688
    STEP: recreating EndpointSlices after they've been deleted 01/24/23 19:59:34.746
    Jan 24 19:59:34.935: INFO: EndpointSlice for Service endpointslice-661/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Jan 24 19:59:44.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-661" for this suite. 01/24/23 19:59:45.032
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:59:45.156
Jan 24 19:59:45.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 19:59:45.163
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:59:45.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:59:45.492
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-e26b026e-8616-4f28-87de-3df2d0c953b1 01/24/23 19:59:45.721
STEP: Creating a pod to test consume secrets 01/24/23 19:59:45.808
Jan 24 19:59:45.944: INFO: Waiting up to 5m0s for pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea" in namespace "secrets-3402" to be "Succeeded or Failed"
Jan 24 19:59:46.017: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 69.760182ms
Jan 24 19:59:48.031: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08370473s
Jan 24 19:59:50.032: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.084502424s
Jan 24 19:59:52.042: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.094271902s
Jan 24 19:59:54.158: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.210209702s
STEP: Saw pod success 01/24/23 19:59:54.16
Jan 24 19:59:54.222: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea" satisfied condition "Succeeded or Failed"
Jan 24 19:59:54.259: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea container secret-volume-test: <nil>
STEP: delete the pod 01/24/23 19:59:54.493
Jan 24 19:59:54.579: INFO: Waiting for pod pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea to disappear
Jan 24 19:59:54.638: INFO: Pod pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Jan 24 19:59:54.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3402" for this suite. 01/24/23 19:59:54.701
STEP: Destroying namespace "secret-namespace-4442" for this suite. 01/24/23 19:59:54.73
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":240,"skipped":4483,"failed":0}
------------------------------
• [SLOW TEST] [9.609 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:59:45.156
    Jan 24 19:59:45.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 19:59:45.163
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:59:45.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:59:45.492
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-e26b026e-8616-4f28-87de-3df2d0c953b1 01/24/23 19:59:45.721
    STEP: Creating a pod to test consume secrets 01/24/23 19:59:45.808
    Jan 24 19:59:45.944: INFO: Waiting up to 5m0s for pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea" in namespace "secrets-3402" to be "Succeeded or Failed"
    Jan 24 19:59:46.017: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 69.760182ms
    Jan 24 19:59:48.031: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08370473s
    Jan 24 19:59:50.032: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.084502424s
    Jan 24 19:59:52.042: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.094271902s
    Jan 24 19:59:54.158: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.210209702s
    STEP: Saw pod success 01/24/23 19:59:54.16
    Jan 24 19:59:54.222: INFO: Pod "pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea" satisfied condition "Succeeded or Failed"
    Jan 24 19:59:54.259: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea container secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 19:59:54.493
    Jan 24 19:59:54.579: INFO: Waiting for pod pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea to disappear
    Jan 24 19:59:54.638: INFO: Pod pod-secrets-01e7c2ac-75f5-40da-ac63-5d3daec0a4ea no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 19:59:54.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3402" for this suite. 01/24/23 19:59:54.701
    STEP: Destroying namespace "secret-namespace-4442" for this suite. 01/24/23 19:59:54.73
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:59:54.803
Jan 24 19:59:54.804: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 19:59:54.827
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:59:55.019
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:59:55.081
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 01/24/23 19:59:55.255
Jan 24 19:59:55.274: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-2017 proxy --unix-socket=/tmp/kubectl-proxy-unix576643614/test'
STEP: retrieving proxy /api/ output 01/24/23 19:59:55.969
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 19:59:55.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2017" for this suite. 01/24/23 19:59:56.015
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":241,"skipped":4494,"failed":0}
------------------------------
• [1.242 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:59:54.803
    Jan 24 19:59:54.804: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 19:59:54.827
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:59:55.019
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:59:55.081
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 01/24/23 19:59:55.255
    Jan 24 19:59:55.274: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-2017 proxy --unix-socket=/tmp/kubectl-proxy-unix576643614/test'
    STEP: retrieving proxy /api/ output 01/24/23 19:59:55.969
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 19:59:55.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2017" for this suite. 01/24/23 19:59:56.015
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 19:59:56.099
Jan 24 19:59:56.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename watch 01/24/23 19:59:56.108
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:59:56.161
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:59:56.189
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 01/24/23 19:59:56.207
STEP: creating a watch on configmaps with label B 01/24/23 19:59:56.212
STEP: creating a watch on configmaps with label A or B 01/24/23 19:59:56.221
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 01/24/23 19:59:56.229
Jan 24 19:59:56.249: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34617 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 19:59:56.249: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34617 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 01/24/23 19:59:56.25
Jan 24 19:59:56.279: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34618 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 19:59:56.280: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34618 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 01/24/23 19:59:56.28
Jan 24 19:59:56.376: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34620 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 19:59:56.378: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34620 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 01/24/23 19:59:56.379
Jan 24 19:59:56.408: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34623 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 19:59:56.408: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34623 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 01/24/23 19:59:56.408
Jan 24 19:59:56.422: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2910  ae66b077-31bc-4e65-8555-30789a16aec6 34624 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 19:59:56.423: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2910  ae66b077-31bc-4e65-8555-30789a16aec6 34624 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 01/24/23 20:00:06.424
Jan 24 20:00:06.437: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2910  ae66b077-31bc-4e65-8555-30789a16aec6 34651 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 20:00:06.437: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2910  ae66b077-31bc-4e65-8555-30789a16aec6 34651 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jan 24 20:00:16.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2910" for this suite. 01/24/23 20:00:16.451
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":242,"skipped":4525,"failed":0}
------------------------------
• [SLOW TEST] [20.381 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 19:59:56.099
    Jan 24 19:59:56.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename watch 01/24/23 19:59:56.108
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 19:59:56.161
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 19:59:56.189
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 01/24/23 19:59:56.207
    STEP: creating a watch on configmaps with label B 01/24/23 19:59:56.212
    STEP: creating a watch on configmaps with label A or B 01/24/23 19:59:56.221
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 01/24/23 19:59:56.229
    Jan 24 19:59:56.249: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34617 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 19:59:56.249: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34617 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 01/24/23 19:59:56.25
    Jan 24 19:59:56.279: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34618 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 19:59:56.280: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34618 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 01/24/23 19:59:56.28
    Jan 24 19:59:56.376: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34620 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 19:59:56.378: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34620 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 01/24/23 19:59:56.379
    Jan 24 19:59:56.408: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34623 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 19:59:56.408: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2910  f542e253-10f2-470f-8761-e662e0f9175a 34623 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 01/24/23 19:59:56.408
    Jan 24 19:59:56.422: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2910  ae66b077-31bc-4e65-8555-30789a16aec6 34624 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 19:59:56.423: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2910  ae66b077-31bc-4e65-8555-30789a16aec6 34624 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 01/24/23 20:00:06.424
    Jan 24 20:00:06.437: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2910  ae66b077-31bc-4e65-8555-30789a16aec6 34651 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 20:00:06.437: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2910  ae66b077-31bc-4e65-8555-30789a16aec6 34651 0 2023-01-24 19:59:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-01-24 19:59:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jan 24 20:00:16.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2910" for this suite. 01/24/23 20:00:16.451
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:00:16.487
Jan 24 20:00:16.488: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 20:00:16.493
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:00:16.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:00:16.606
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 01/24/23 20:00:16.623
Jan 24 20:00:16.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 create -f -'
Jan 24 20:00:17.551: INFO: stderr: ""
Jan 24 20:00:17.551: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 01/24/23 20:00:17.551
Jan 24 20:00:17.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:00:17.997: INFO: stderr: ""
Jan 24 20:00:17.997: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
Jan 24 20:00:17.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:00:18.245: INFO: stderr: ""
Jan 24 20:00:18.245: INFO: stdout: ""
Jan 24 20:00:18.245: INFO: update-demo-nautilus-8rpbw is created but not running
Jan 24 20:00:23.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:00:23.560: INFO: stderr: ""
Jan 24 20:00:23.560: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
Jan 24 20:00:23.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:00:23.876: INFO: stderr: ""
Jan 24 20:00:23.876: INFO: stdout: ""
Jan 24 20:00:23.877: INFO: update-demo-nautilus-8rpbw is created but not running
Jan 24 20:00:28.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:00:29.541: INFO: stderr: ""
Jan 24 20:00:29.541: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
Jan 24 20:00:29.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:00:29.855: INFO: stderr: ""
Jan 24 20:00:29.855: INFO: stdout: ""
Jan 24 20:00:29.855: INFO: update-demo-nautilus-8rpbw is created but not running
Jan 24 20:00:34.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:00:35.476: INFO: stderr: ""
Jan 24 20:00:35.476: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
Jan 24 20:00:35.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:00:35.885: INFO: stderr: ""
Jan 24 20:00:35.885: INFO: stdout: ""
Jan 24 20:00:35.885: INFO: update-demo-nautilus-8rpbw is created but not running
Jan 24 20:00:40.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:00:41.160: INFO: stderr: ""
Jan 24 20:00:41.160: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
Jan 24 20:00:41.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:00:41.559: INFO: stderr: ""
Jan 24 20:00:41.559: INFO: stdout: ""
Jan 24 20:00:41.559: INFO: update-demo-nautilus-8rpbw is created but not running
Jan 24 20:00:46.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:00:47.210: INFO: stderr: ""
Jan 24 20:00:47.210: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
Jan 24 20:00:47.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:00:47.697: INFO: stderr: ""
Jan 24 20:00:47.697: INFO: stdout: "true"
Jan 24 20:00:47.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 24 20:00:48.159: INFO: stderr: ""
Jan 24 20:00:48.159: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 24 20:00:48.159: INFO: validating pod update-demo-nautilus-8rpbw
Jan 24 20:00:48.177: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 24 20:00:48.177: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 24 20:00:48.177: INFO: update-demo-nautilus-8rpbw is verified up and running
Jan 24 20:00:48.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:00:48.683: INFO: stderr: ""
Jan 24 20:00:48.684: INFO: stdout: "true"
Jan 24 20:00:48.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 24 20:00:49.389: INFO: stderr: ""
Jan 24 20:00:49.389: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 24 20:00:49.389: INFO: validating pod update-demo-nautilus-m7gkc
Jan 24 20:00:49.406: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 24 20:00:49.406: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 24 20:00:49.406: INFO: update-demo-nautilus-m7gkc is verified up and running
STEP: scaling down the replication controller 01/24/23 20:00:49.406
Jan 24 20:00:49.418: INFO: scanned /root for discovery docs: <nil>
Jan 24 20:00:49.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Jan 24 20:00:50.912: INFO: stderr: ""
Jan 24 20:00:50.912: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 01/24/23 20:00:50.912
Jan 24 20:00:50.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:00:51.316: INFO: stderr: ""
Jan 24 20:00:51.316: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
STEP: Replicas for name=update-demo: expected=1 actual=2 01/24/23 20:00:51.316
Jan 24 20:00:56.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:00:56.893: INFO: stderr: ""
Jan 24 20:00:56.893: INFO: stdout: "update-demo-nautilus-m7gkc "
Jan 24 20:00:56.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:00:57.594: INFO: stderr: ""
Jan 24 20:00:57.594: INFO: stdout: "true"
Jan 24 20:00:57.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 24 20:00:58.589: INFO: stderr: ""
Jan 24 20:00:58.589: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 24 20:00:58.589: INFO: validating pod update-demo-nautilus-m7gkc
Jan 24 20:00:58.601: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 24 20:00:58.601: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 24 20:00:58.602: INFO: update-demo-nautilus-m7gkc is verified up and running
STEP: scaling up the replication controller 01/24/23 20:00:58.602
Jan 24 20:00:58.627: INFO: scanned /root for discovery docs: <nil>
Jan 24 20:00:58.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Jan 24 20:01:00.832: INFO: stderr: ""
Jan 24 20:01:00.832: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 01/24/23 20:01:00.833
Jan 24 20:01:00.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:01:02.142: INFO: stderr: ""
Jan 24 20:01:02.142: INFO: stdout: "update-demo-nautilus-htwl8 update-demo-nautilus-m7gkc "
Jan 24 20:01:02.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-htwl8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:01:02.379: INFO: stderr: ""
Jan 24 20:01:02.381: INFO: stdout: ""
Jan 24 20:01:02.381: INFO: update-demo-nautilus-htwl8 is created but not running
Jan 24 20:01:07.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:01:07.597: INFO: stderr: ""
Jan 24 20:01:07.597: INFO: stdout: "update-demo-nautilus-htwl8 update-demo-nautilus-m7gkc "
Jan 24 20:01:07.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-htwl8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:01:07.798: INFO: stderr: ""
Jan 24 20:01:07.798: INFO: stdout: "true"
Jan 24 20:01:07.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-htwl8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 24 20:01:07.988: INFO: stderr: ""
Jan 24 20:01:07.988: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 24 20:01:07.988: INFO: validating pod update-demo-nautilus-htwl8
Jan 24 20:01:07.999: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 24 20:01:07.999: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 24 20:01:08.000: INFO: update-demo-nautilus-htwl8 is verified up and running
Jan 24 20:01:08.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:01:08.208: INFO: stderr: ""
Jan 24 20:01:08.208: INFO: stdout: "true"
Jan 24 20:01:08.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 24 20:01:08.408: INFO: stderr: ""
Jan 24 20:01:08.408: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 24 20:01:08.408: INFO: validating pod update-demo-nautilus-m7gkc
Jan 24 20:01:08.417: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 24 20:01:08.417: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 24 20:01:08.417: INFO: update-demo-nautilus-m7gkc is verified up and running
STEP: using delete to clean up resources 01/24/23 20:01:08.417
Jan 24 20:01:08.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 delete --grace-period=0 --force -f -'
Jan 24 20:01:08.625: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 24 20:01:08.625: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 24 20:01:08.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get rc,svc -l name=update-demo --no-headers'
Jan 24 20:01:09.104: INFO: stderr: "No resources found in kubectl-3443 namespace.\n"
Jan 24 20:01:09.104: INFO: stdout: ""
Jan 24 20:01:09.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 24 20:01:09.600: INFO: stderr: ""
Jan 24 20:01:09.600: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 20:01:09.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3443" for this suite. 01/24/23 20:01:09.607
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":243,"skipped":4532,"failed":0}
------------------------------
• [SLOW TEST] [53.137 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:00:16.487
    Jan 24 20:00:16.488: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 20:00:16.493
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:00:16.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:00:16.606
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 01/24/23 20:00:16.623
    Jan 24 20:00:16.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 create -f -'
    Jan 24 20:00:17.551: INFO: stderr: ""
    Jan 24 20:00:17.551: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 01/24/23 20:00:17.551
    Jan 24 20:00:17.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:00:17.997: INFO: stderr: ""
    Jan 24 20:00:17.997: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
    Jan 24 20:00:17.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:00:18.245: INFO: stderr: ""
    Jan 24 20:00:18.245: INFO: stdout: ""
    Jan 24 20:00:18.245: INFO: update-demo-nautilus-8rpbw is created but not running
    Jan 24 20:00:23.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:00:23.560: INFO: stderr: ""
    Jan 24 20:00:23.560: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
    Jan 24 20:00:23.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:00:23.876: INFO: stderr: ""
    Jan 24 20:00:23.876: INFO: stdout: ""
    Jan 24 20:00:23.877: INFO: update-demo-nautilus-8rpbw is created but not running
    Jan 24 20:00:28.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:00:29.541: INFO: stderr: ""
    Jan 24 20:00:29.541: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
    Jan 24 20:00:29.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:00:29.855: INFO: stderr: ""
    Jan 24 20:00:29.855: INFO: stdout: ""
    Jan 24 20:00:29.855: INFO: update-demo-nautilus-8rpbw is created but not running
    Jan 24 20:00:34.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:00:35.476: INFO: stderr: ""
    Jan 24 20:00:35.476: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
    Jan 24 20:00:35.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:00:35.885: INFO: stderr: ""
    Jan 24 20:00:35.885: INFO: stdout: ""
    Jan 24 20:00:35.885: INFO: update-demo-nautilus-8rpbw is created but not running
    Jan 24 20:00:40.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:00:41.160: INFO: stderr: ""
    Jan 24 20:00:41.160: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
    Jan 24 20:00:41.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:00:41.559: INFO: stderr: ""
    Jan 24 20:00:41.559: INFO: stdout: ""
    Jan 24 20:00:41.559: INFO: update-demo-nautilus-8rpbw is created but not running
    Jan 24 20:00:46.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:00:47.210: INFO: stderr: ""
    Jan 24 20:00:47.210: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
    Jan 24 20:00:47.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:00:47.697: INFO: stderr: ""
    Jan 24 20:00:47.697: INFO: stdout: "true"
    Jan 24 20:00:47.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-8rpbw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 24 20:00:48.159: INFO: stderr: ""
    Jan 24 20:00:48.159: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 24 20:00:48.159: INFO: validating pod update-demo-nautilus-8rpbw
    Jan 24 20:00:48.177: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 24 20:00:48.177: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 24 20:00:48.177: INFO: update-demo-nautilus-8rpbw is verified up and running
    Jan 24 20:00:48.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:00:48.683: INFO: stderr: ""
    Jan 24 20:00:48.684: INFO: stdout: "true"
    Jan 24 20:00:48.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 24 20:00:49.389: INFO: stderr: ""
    Jan 24 20:00:49.389: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 24 20:00:49.389: INFO: validating pod update-demo-nautilus-m7gkc
    Jan 24 20:00:49.406: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 24 20:00:49.406: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 24 20:00:49.406: INFO: update-demo-nautilus-m7gkc is verified up and running
    STEP: scaling down the replication controller 01/24/23 20:00:49.406
    Jan 24 20:00:49.418: INFO: scanned /root for discovery docs: <nil>
    Jan 24 20:00:49.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Jan 24 20:00:50.912: INFO: stderr: ""
    Jan 24 20:00:50.912: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 01/24/23 20:00:50.912
    Jan 24 20:00:50.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:00:51.316: INFO: stderr: ""
    Jan 24 20:00:51.316: INFO: stdout: "update-demo-nautilus-8rpbw update-demo-nautilus-m7gkc "
    STEP: Replicas for name=update-demo: expected=1 actual=2 01/24/23 20:00:51.316
    Jan 24 20:00:56.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:00:56.893: INFO: stderr: ""
    Jan 24 20:00:56.893: INFO: stdout: "update-demo-nautilus-m7gkc "
    Jan 24 20:00:56.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:00:57.594: INFO: stderr: ""
    Jan 24 20:00:57.594: INFO: stdout: "true"
    Jan 24 20:00:57.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 24 20:00:58.589: INFO: stderr: ""
    Jan 24 20:00:58.589: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 24 20:00:58.589: INFO: validating pod update-demo-nautilus-m7gkc
    Jan 24 20:00:58.601: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 24 20:00:58.601: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 24 20:00:58.602: INFO: update-demo-nautilus-m7gkc is verified up and running
    STEP: scaling up the replication controller 01/24/23 20:00:58.602
    Jan 24 20:00:58.627: INFO: scanned /root for discovery docs: <nil>
    Jan 24 20:00:58.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Jan 24 20:01:00.832: INFO: stderr: ""
    Jan 24 20:01:00.832: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 01/24/23 20:01:00.833
    Jan 24 20:01:00.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:01:02.142: INFO: stderr: ""
    Jan 24 20:01:02.142: INFO: stdout: "update-demo-nautilus-htwl8 update-demo-nautilus-m7gkc "
    Jan 24 20:01:02.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-htwl8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:01:02.379: INFO: stderr: ""
    Jan 24 20:01:02.381: INFO: stdout: ""
    Jan 24 20:01:02.381: INFO: update-demo-nautilus-htwl8 is created but not running
    Jan 24 20:01:07.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:01:07.597: INFO: stderr: ""
    Jan 24 20:01:07.597: INFO: stdout: "update-demo-nautilus-htwl8 update-demo-nautilus-m7gkc "
    Jan 24 20:01:07.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-htwl8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:01:07.798: INFO: stderr: ""
    Jan 24 20:01:07.798: INFO: stdout: "true"
    Jan 24 20:01:07.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-htwl8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 24 20:01:07.988: INFO: stderr: ""
    Jan 24 20:01:07.988: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 24 20:01:07.988: INFO: validating pod update-demo-nautilus-htwl8
    Jan 24 20:01:07.999: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 24 20:01:07.999: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 24 20:01:08.000: INFO: update-demo-nautilus-htwl8 is verified up and running
    Jan 24 20:01:08.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:01:08.208: INFO: stderr: ""
    Jan 24 20:01:08.208: INFO: stdout: "true"
    Jan 24 20:01:08.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods update-demo-nautilus-m7gkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 24 20:01:08.408: INFO: stderr: ""
    Jan 24 20:01:08.408: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 24 20:01:08.408: INFO: validating pod update-demo-nautilus-m7gkc
    Jan 24 20:01:08.417: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 24 20:01:08.417: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 24 20:01:08.417: INFO: update-demo-nautilus-m7gkc is verified up and running
    STEP: using delete to clean up resources 01/24/23 20:01:08.417
    Jan 24 20:01:08.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 delete --grace-period=0 --force -f -'
    Jan 24 20:01:08.625: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 24 20:01:08.625: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Jan 24 20:01:08.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get rc,svc -l name=update-demo --no-headers'
    Jan 24 20:01:09.104: INFO: stderr: "No resources found in kubectl-3443 namespace.\n"
    Jan 24 20:01:09.104: INFO: stdout: ""
    Jan 24 20:01:09.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-3443 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Jan 24 20:01:09.600: INFO: stderr: ""
    Jan 24 20:01:09.600: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 20:01:09.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3443" for this suite. 01/24/23 20:01:09.607
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:01:09.625
Jan 24 20:01:09.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 20:01:09.628
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:09.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:09.697
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-6438 01/24/23 20:01:09.703
STEP: creating service affinity-nodeport-transition in namespace services-6438 01/24/23 20:01:09.703
STEP: creating replication controller affinity-nodeport-transition in namespace services-6438 01/24/23 20:01:09.747
I0124 20:01:09.772112      22 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-6438, replica count: 3
I0124 20:01:12.881832      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 20:01:15.884153      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 20:01:15.915: INFO: Creating new exec pod
Jan 24 20:01:15.939: INFO: Waiting up to 5m0s for pod "execpod-affinityb942d" in namespace "services-6438" to be "running"
Jan 24 20:01:16.001: INFO: Pod "execpod-affinityb942d": Phase="Pending", Reason="", readiness=false. Elapsed: 62.337354ms
Jan 24 20:01:18.016: INFO: Pod "execpod-affinityb942d": Phase="Running", Reason="", readiness=true. Elapsed: 2.077341043s
Jan 24 20:01:18.016: INFO: Pod "execpod-affinityb942d" satisfied condition "running"
Jan 24 20:01:19.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Jan 24 20:01:19.620: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Jan 24 20:01:19.620: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 20:01:19.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.91.103 80'
Jan 24 20:01:20.108: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.91.103 80\nConnection to 10.10.91.103 80 port [tcp/http] succeeded!\n"
Jan 24 20:01:20.108: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 20:01:20.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 31423'
Jan 24 20:01:20.774: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 31423\nConnection to 10.10.1.213 31423 port [tcp/*] succeeded!\n"
Jan 24 20:01:20.774: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 20:01:20.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.127 31423'
Jan 24 20:01:21.338: INFO: stderr: "+ nc -v -t -w 2 10.10.1.127 31423\n+ echo hostName\nConnection to 10.10.1.127 31423 port [tcp/*] succeeded!\n"
Jan 24 20:01:21.338: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 20:01:21.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.1.213:31423/ ; done'
Jan 24 20:01:22.195: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n"
Jan 24 20:01:22.195: INFO: stdout: "\naffinity-nodeport-transition-dczn7\naffinity-nodeport-transition-ftf4c\naffinity-nodeport-transition-dczn7\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-ftf4c\naffinity-nodeport-transition-dczn7\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-ftf4c\naffinity-nodeport-transition-ftf4c\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr"
Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-dczn7
Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-ftf4c
Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-dczn7
Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-ftf4c
Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-dczn7
Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-ftf4c
Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-ftf4c
Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:22.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.1.213:31423/ ; done'
Jan 24 20:01:23.256: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n"
Jan 24 20:01:23.257: INFO: stdout: "\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr"
Jan 24 20:01:23.257: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
Jan 24 20:01:23.258: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6438, will wait for the garbage collector to delete the pods 01/24/23 20:01:23.315
Jan 24 20:01:23.400: INFO: Deleting ReplicationController affinity-nodeport-transition took: 14.908125ms
Jan 24 20:01:23.614: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 213.201607ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 20:01:27.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6438" for this suite. 01/24/23 20:01:27.465
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":244,"skipped":4541,"failed":0}
------------------------------
• [SLOW TEST] [17.885 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:01:09.625
    Jan 24 20:01:09.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 20:01:09.628
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:09.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:09.697
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-6438 01/24/23 20:01:09.703
    STEP: creating service affinity-nodeport-transition in namespace services-6438 01/24/23 20:01:09.703
    STEP: creating replication controller affinity-nodeport-transition in namespace services-6438 01/24/23 20:01:09.747
    I0124 20:01:09.772112      22 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-6438, replica count: 3
    I0124 20:01:12.881832      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 20:01:15.884153      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 20:01:15.915: INFO: Creating new exec pod
    Jan 24 20:01:15.939: INFO: Waiting up to 5m0s for pod "execpod-affinityb942d" in namespace "services-6438" to be "running"
    Jan 24 20:01:16.001: INFO: Pod "execpod-affinityb942d": Phase="Pending", Reason="", readiness=false. Elapsed: 62.337354ms
    Jan 24 20:01:18.016: INFO: Pod "execpod-affinityb942d": Phase="Running", Reason="", readiness=true. Elapsed: 2.077341043s
    Jan 24 20:01:18.016: INFO: Pod "execpod-affinityb942d" satisfied condition "running"
    Jan 24 20:01:19.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Jan 24 20:01:19.620: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Jan 24 20:01:19.620: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 20:01:19.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.91.103 80'
    Jan 24 20:01:20.108: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.91.103 80\nConnection to 10.10.91.103 80 port [tcp/http] succeeded!\n"
    Jan 24 20:01:20.108: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 20:01:20.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 31423'
    Jan 24 20:01:20.774: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 31423\nConnection to 10.10.1.213 31423 port [tcp/*] succeeded!\n"
    Jan 24 20:01:20.774: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 20:01:20.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.127 31423'
    Jan 24 20:01:21.338: INFO: stderr: "+ nc -v -t -w 2 10.10.1.127 31423\n+ echo hostName\nConnection to 10.10.1.127 31423 port [tcp/*] succeeded!\n"
    Jan 24 20:01:21.338: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 20:01:21.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.1.213:31423/ ; done'
    Jan 24 20:01:22.195: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n"
    Jan 24 20:01:22.195: INFO: stdout: "\naffinity-nodeport-transition-dczn7\naffinity-nodeport-transition-ftf4c\naffinity-nodeport-transition-dczn7\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-ftf4c\naffinity-nodeport-transition-dczn7\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-ftf4c\naffinity-nodeport-transition-ftf4c\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr"
    Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-dczn7
    Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-ftf4c
    Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-dczn7
    Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-ftf4c
    Jan 24 20:01:22.195: INFO: Received response from host: affinity-nodeport-transition-dczn7
    Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-ftf4c
    Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-ftf4c
    Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:22.196: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:22.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-6438 exec execpod-affinityb942d -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.10.1.213:31423/ ; done'
    Jan 24 20:01:23.256: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.10.1.213:31423/\n"
    Jan 24 20:01:23.257: INFO: stdout: "\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr\naffinity-nodeport-transition-rxnnr"
    Jan 24 20:01:23.257: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Received response from host: affinity-nodeport-transition-rxnnr
    Jan 24 20:01:23.258: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-6438, will wait for the garbage collector to delete the pods 01/24/23 20:01:23.315
    Jan 24 20:01:23.400: INFO: Deleting ReplicationController affinity-nodeport-transition took: 14.908125ms
    Jan 24 20:01:23.614: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 213.201607ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 20:01:27.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6438" for this suite. 01/24/23 20:01:27.465
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:01:27.546
Jan 24 20:01:27.547: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 20:01:27.555
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:27.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:27.626
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Jan 24 20:01:27.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: creating the pod 01/24/23 20:01:27.646
STEP: submitting the pod to kubernetes 01/24/23 20:01:27.648
Jan 24 20:01:27.687: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f" in namespace "pods-1887" to be "running and ready"
Jan 24 20:01:27.696: INFO: Pod "pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.523578ms
Jan 24 20:01:27.697: INFO: The phase of Pod pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:01:29.711: INFO: Pod "pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023982651s
Jan 24 20:01:29.711: INFO: The phase of Pod pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:01:31.721: INFO: Pod "pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f": Phase="Running", Reason="", readiness=true. Elapsed: 4.03367292s
Jan 24 20:01:31.721: INFO: The phase of Pod pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f is Running (Ready = true)
Jan 24 20:01:31.721: INFO: Pod "pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 24 20:01:31.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1887" for this suite. 01/24/23 20:01:31.92
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":245,"skipped":4547,"failed":0}
------------------------------
• [4.403 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:01:27.546
    Jan 24 20:01:27.547: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 20:01:27.555
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:27.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:27.626
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Jan 24 20:01:27.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: creating the pod 01/24/23 20:01:27.646
    STEP: submitting the pod to kubernetes 01/24/23 20:01:27.648
    Jan 24 20:01:27.687: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f" in namespace "pods-1887" to be "running and ready"
    Jan 24 20:01:27.696: INFO: Pod "pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.523578ms
    Jan 24 20:01:27.697: INFO: The phase of Pod pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:01:29.711: INFO: Pod "pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023982651s
    Jan 24 20:01:29.711: INFO: The phase of Pod pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:01:31.721: INFO: Pod "pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f": Phase="Running", Reason="", readiness=true. Elapsed: 4.03367292s
    Jan 24 20:01:31.721: INFO: The phase of Pod pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f is Running (Ready = true)
    Jan 24 20:01:31.721: INFO: Pod "pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 24 20:01:31.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1887" for this suite. 01/24/23 20:01:31.92
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:01:31.969
Jan 24 20:01:31.970: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename podtemplate 01/24/23 20:01:31.974
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:32.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:32.06
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 01/24/23 20:01:32.076
STEP: Replace a pod template 01/24/23 20:01:32.102
Jan 24 20:01:32.142: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Jan 24 20:01:32.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-1710" for this suite. 01/24/23 20:01:32.166
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":246,"skipped":4610,"failed":0}
------------------------------
• [0.231 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:01:31.969
    Jan 24 20:01:31.970: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename podtemplate 01/24/23 20:01:31.974
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:32.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:32.06
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 01/24/23 20:01:32.076
    STEP: Replace a pod template 01/24/23 20:01:32.102
    Jan 24 20:01:32.142: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Jan 24 20:01:32.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-1710" for this suite. 01/24/23 20:01:32.166
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:01:32.282
Jan 24 20:01:32.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:01:32.315
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:32.578
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:32.644
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:01:32.8
Jan 24 20:01:32.888: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b" in namespace "projected-2910" to be "Succeeded or Failed"
Jan 24 20:01:32.910: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.175466ms
Jan 24 20:01:35.000: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110691576s
Jan 24 20:01:36.922: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032639686s
Jan 24 20:01:38.983: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.093896239s
Jan 24 20:01:40.931: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04135663s
STEP: Saw pod success 01/24/23 20:01:40.931
Jan 24 20:01:40.932: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b" satisfied condition "Succeeded or Failed"
Jan 24 20:01:40.952: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b container client-container: <nil>
STEP: delete the pod 01/24/23 20:01:41.019
Jan 24 20:01:41.227: INFO: Waiting for pod downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b to disappear
Jan 24 20:01:41.252: INFO: Pod downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 20:01:41.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2910" for this suite. 01/24/23 20:01:41.322
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":247,"skipped":4610,"failed":0}
------------------------------
• [SLOW TEST] [9.167 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:01:32.282
    Jan 24 20:01:32.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:01:32.315
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:32.578
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:32.644
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:01:32.8
    Jan 24 20:01:32.888: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b" in namespace "projected-2910" to be "Succeeded or Failed"
    Jan 24 20:01:32.910: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.175466ms
    Jan 24 20:01:35.000: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110691576s
    Jan 24 20:01:36.922: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032639686s
    Jan 24 20:01:38.983: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.093896239s
    Jan 24 20:01:40.931: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04135663s
    STEP: Saw pod success 01/24/23 20:01:40.931
    Jan 24 20:01:40.932: INFO: Pod "downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b" satisfied condition "Succeeded or Failed"
    Jan 24 20:01:40.952: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b container client-container: <nil>
    STEP: delete the pod 01/24/23 20:01:41.019
    Jan 24 20:01:41.227: INFO: Waiting for pod downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b to disappear
    Jan 24 20:01:41.252: INFO: Pod downwardapi-volume-f4d1c66b-e47c-4782-a35c-d849f712a15b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 20:01:41.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2910" for this suite. 01/24/23 20:01:41.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:01:41.478
Jan 24 20:01:41.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 20:01:41.482
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:41.564
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:41.59
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 01/24/23 20:01:41.627
STEP: Creating a ResourceQuota 01/24/23 20:01:46.637
STEP: Ensuring resource quota status is calculated 01/24/23 20:01:46.659
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 20:01:48.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7400" for this suite. 01/24/23 20:01:48.703
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":248,"skipped":4645,"failed":0}
------------------------------
• [SLOW TEST] [7.252 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:01:41.478
    Jan 24 20:01:41.478: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 20:01:41.482
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:41.564
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:41.59
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 01/24/23 20:01:41.627
    STEP: Creating a ResourceQuota 01/24/23 20:01:46.637
    STEP: Ensuring resource quota status is calculated 01/24/23 20:01:46.659
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 20:01:48.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7400" for this suite. 01/24/23 20:01:48.703
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:01:48.75
Jan 24 20:01:48.751: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sched-pred 01/24/23 20:01:48.754
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:48.794
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:48.803
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jan 24 20:01:48.818: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 24 20:01:48.839: INFO: Waiting for terminating namespaces to be deleted...
Jan 24 20:01:48.854: INFO: 
Logging pods the apiserver thinks is on node vikash-v125latest-conf-59870 before test
Jan 24 20:01:48.881: INFO: haproxy-ingress-cb855dc7c-smnf7 from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.881: INFO: 	Container haproxy-ingress ready: true, restart count 0
Jan 24 20:01:48.881: INFO: ingress-default-backend-6f4477b7bc-qg2sz from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.881: INFO: 	Container ingress-default-backend ready: true, restart count 0
Jan 24 20:01:48.881: INFO: calico-kube-controllers-74677b4c5f-zd5w8 from kube-system started at 2023-01-24 18:20:11 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.881: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 24 20:01:48.881: INFO: calico-node-45c9d from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.881: INFO: 	Container calico-node ready: true, restart count 0
Jan 24 20:01:48.881: INFO: coredns-94487f57-9zlwt from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.881: INFO: 	Container coredns ready: true, restart count 0
Jan 24 20:01:48.881: INFO: coredns-94487f57-qldwh from kube-system started at 2023-01-24 18:34:25 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.881: INFO: 	Container coredns ready: true, restart count 0
Jan 24 20:01:48.881: INFO: kyverno-operator-5c87dbd458-txhlw from nirmata started at 2023-01-24 18:22:35 +0000 UTC (2 container statuses recorded)
Jan 24 20:01:48.881: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jan 24 20:01:48.881: INFO: 	Container manager ready: true, restart count 0
Jan 24 20:01:48.881: INFO: nirmata-cni-installer-6skzt from nirmata started at 2023-01-24 08:32:34 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.881: INFO: 	Container install-cni ready: true, restart count 0
Jan 24 20:01:48.881: INFO: otel-agent-6dfc8d44b6-6kj5q from nirmata started at 2023-01-24 18:22:32 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.881: INFO: 	Container otel-agent ready: true, restart count 0
Jan 24 20:01:48.881: INFO: sonobuoy from sonobuoy started at 2023-01-24 18:32:49 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.882: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 24 20:01:48.882: INFO: sonobuoy-e2e-job-d94c6e71d257417d from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 20:01:48.882: INFO: 	Container e2e ready: true, restart count 0
Jan 24 20:01:48.882: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 20:01:48.882: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 20:01:48.882: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 20:01:48.882: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 24 20:01:48.882: INFO: 
Logging pods the apiserver thinks is on node vikash-v125latest-conf-71087 before test
Jan 24 20:01:48.905: INFO: calico-node-kfjch from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.905: INFO: 	Container calico-node ready: true, restart count 0
Jan 24 20:01:48.905: INFO: metrics-server-696f4844bb-xklrk from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.905: INFO: 	Container metrics-server ready: true, restart count 0
Jan 24 20:01:48.905: INFO: nirmata-cni-installer-swjzc from nirmata started at 2023-01-24 18:34:55 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.905: INFO: 	Container install-cni ready: true, restart count 0
Jan 24 20:01:48.905: INFO: nirmata-kube-controller-df864cd5c-bz5gj from nirmata started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.905: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
Jan 24 20:01:48.905: INFO: pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f from pods-1887 started at 2023-01-24 20:01:27 +0000 UTC (1 container statuses recorded)
Jan 24 20:01:48.905: INFO: 	Container main ready: true, restart count 0
Jan 24 20:01:48.905: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-x86sk from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 20:01:48.905: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 20:01:48.905: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 01/24/23 20:01:48.905
Jan 24 20:01:48.936: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9378" to be "running"
Jan 24 20:01:48.958: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 21.628343ms
Jan 24 20:01:50.981: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044691486s
Jan 24 20:01:52.974: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.037416624s
Jan 24 20:01:52.974: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 01/24/23 20:01:52.982
STEP: Trying to apply a random label on the found node. 01/24/23 20:01:53.043
STEP: verifying the node has the label kubernetes.io/e2e-7838bb8d-b5ab-4265-85f7-aee5d306ae9e 95 01/24/23 20:01:53.1
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 01/24/23 20:01:53.23
Jan 24 20:01:53.320: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9378" to be "not pending"
Jan 24 20:01:53.335: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.652148ms
Jan 24 20:01:55.353: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033198564s
Jan 24 20:01:57.361: INFO: Pod "pod4": Phase="Running", Reason="", readiness=false. Elapsed: 4.040978518s
Jan 24 20:01:57.361: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.10.1.127 on the node which pod4 resides and expect not scheduled 01/24/23 20:01:57.361
Jan 24 20:01:57.395: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9378" to be "not pending"
Jan 24 20:01:57.434: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.569105ms
Jan 24 20:01:59.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051435055s
Jan 24 20:02:01.479: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.083574882s
Jan 24 20:02:03.478: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.082742793s
Jan 24 20:02:05.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.068442557s
Jan 24 20:02:07.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.057240027s
Jan 24 20:02:09.530: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.135291618s
Jan 24 20:02:11.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.058399558s
Jan 24 20:02:13.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.065846291s
Jan 24 20:02:15.487: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.092551042s
Jan 24 20:02:17.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.057431577s
Jan 24 20:02:19.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.05432394s
Jan 24 20:02:21.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.053905914s
Jan 24 20:02:23.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.050092974s
Jan 24 20:02:25.455: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.060314726s
Jan 24 20:02:27.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.057886858s
Jan 24 20:02:29.451: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.05597971s
Jan 24 20:02:31.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.054632114s
Jan 24 20:02:33.455: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.059602262s
Jan 24 20:02:35.582: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.186659978s
Jan 24 20:02:37.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.05264242s
Jan 24 20:02:39.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.054010404s
Jan 24 20:02:41.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.062505354s
Jan 24 20:02:43.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.053512611s
Jan 24 20:02:45.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.058526314s
Jan 24 20:02:47.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.057228648s
Jan 24 20:02:49.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.051742777s
Jan 24 20:02:51.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.066127204s
Jan 24 20:02:53.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.062169551s
Jan 24 20:02:55.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.057289194s
Jan 24 20:02:57.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.068923268s
Jan 24 20:02:59.509: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.114361751s
Jan 24 20:03:01.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.053117805s
Jan 24 20:03:03.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.054190467s
Jan 24 20:03:05.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.050643719s
Jan 24 20:03:07.444: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.049090631s
Jan 24 20:03:09.465: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.070370139s
Jan 24 20:03:11.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.060930753s
Jan 24 20:03:13.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.058916361s
Jan 24 20:03:15.524: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.128820714s
Jan 24 20:03:17.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.050816887s
Jan 24 20:03:19.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.061678567s
Jan 24 20:03:21.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.049851114s
Jan 24 20:03:23.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.073110109s
Jan 24 20:03:25.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.059561884s
Jan 24 20:03:27.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.053318094s
Jan 24 20:03:29.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.055532917s
Jan 24 20:03:31.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.051121852s
Jan 24 20:03:33.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.053559243s
Jan 24 20:03:35.549: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.153823313s
Jan 24 20:03:37.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.053964738s
Jan 24 20:03:39.473: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.077657011s
Jan 24 20:03:41.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.06188458s
Jan 24 20:03:43.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.052541937s
Jan 24 20:03:45.458: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.063280452s
Jan 24 20:03:47.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.051532085s
Jan 24 20:03:49.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.050243635s
Jan 24 20:03:51.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.065992551s
Jan 24 20:03:53.451: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.056545754s
Jan 24 20:03:55.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.059022083s
Jan 24 20:03:57.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.184040367s
Jan 24 20:03:59.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.060603089s
Jan 24 20:04:01.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.064956214s
Jan 24 20:04:03.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.05128852s
Jan 24 20:04:05.473: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.078433621s
Jan 24 20:04:07.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.061694525s
Jan 24 20:04:09.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.052735784s
Jan 24 20:04:11.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.065212005s
Jan 24 20:04:13.444: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.048702132s
Jan 24 20:04:15.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.051240832s
Jan 24 20:04:17.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.052953828s
Jan 24 20:04:19.444: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.049032703s
Jan 24 20:04:21.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.050614221s
Jan 24 20:04:23.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.053536481s
Jan 24 20:04:25.504: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.109515592s
Jan 24 20:04:27.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.061497446s
Jan 24 20:04:29.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.052293299s
Jan 24 20:04:31.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.050209237s
Jan 24 20:04:33.474: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.078575461s
Jan 24 20:04:35.455: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.060533406s
Jan 24 20:04:37.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.05854643s
Jan 24 20:04:39.479: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.084178418s
Jan 24 20:04:41.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.061377115s
Jan 24 20:04:43.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.057980215s
Jan 24 20:04:45.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.057844586s
Jan 24 20:04:47.465: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.070439219s
Jan 24 20:04:49.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.058358061s
Jan 24 20:04:51.466: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.07089591s
Jan 24 20:04:53.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.050910021s
Jan 24 20:04:55.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.056644527s
Jan 24 20:04:57.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.051828043s
Jan 24 20:04:59.486: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.090939053s
Jan 24 20:05:01.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.073840114s
Jan 24 20:05:03.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.051353574s
Jan 24 20:05:05.506: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.110767635s
Jan 24 20:05:07.455: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.059575692s
Jan 24 20:05:09.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.057354315s
Jan 24 20:05:11.534: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.138909665s
Jan 24 20:05:13.482: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.087423633s
Jan 24 20:05:15.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.073575423s
Jan 24 20:05:17.444: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.048909717s
Jan 24 20:05:19.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.053396169s
Jan 24 20:05:21.465: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.06985348s
Jan 24 20:05:23.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.054138408s
Jan 24 20:05:25.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.064770658s
Jan 24 20:05:27.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.05171736s
Jan 24 20:05:29.479: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.084084848s
Jan 24 20:05:31.451: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.056337027s
Jan 24 20:05:33.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.052732638s
Jan 24 20:05:35.459: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.063643956s
Jan 24 20:05:37.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.049861998s
Jan 24 20:05:39.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.057709653s
Jan 24 20:05:41.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.053246597s
Jan 24 20:05:43.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.051520369s
Jan 24 20:05:45.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.0613368s
Jan 24 20:05:47.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.051048325s
Jan 24 20:05:49.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.054658469s
Jan 24 20:05:51.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.051193918s
Jan 24 20:05:53.487: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.091707403s
Jan 24 20:05:55.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.064751791s
Jan 24 20:05:57.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.058825478s
Jan 24 20:05:59.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.065256313s
Jan 24 20:06:01.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.057293086s
Jan 24 20:06:03.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.053237548s
Jan 24 20:06:05.490: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.094771041s
Jan 24 20:06:07.473: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.077985773s
Jan 24 20:06:09.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.061811266s
Jan 24 20:06:11.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.05540852s
Jan 24 20:06:13.458: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.063253989s
Jan 24 20:06:15.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.062452272s
Jan 24 20:06:17.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.052436511s
Jan 24 20:06:19.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.05160236s
Jan 24 20:06:21.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.058589279s
Jan 24 20:06:23.441: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.045988716s
Jan 24 20:06:25.444: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.048686517s
Jan 24 20:06:27.443: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.047999608s
Jan 24 20:06:29.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.050026511s
Jan 24 20:06:31.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.0501194s
Jan 24 20:06:33.451: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.056263615s
Jan 24 20:06:35.500: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.105217016s
Jan 24 20:06:37.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.049682514s
Jan 24 20:06:39.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.055151098s
Jan 24 20:06:41.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.059159758s
Jan 24 20:06:43.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.061219075s
Jan 24 20:06:45.586: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.191302141s
Jan 24 20:06:47.443: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.048364461s
Jan 24 20:06:49.440: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.044852403s
Jan 24 20:06:51.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.053785179s
Jan 24 20:06:53.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.057673401s
Jan 24 20:06:55.477: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.081975336s
Jan 24 20:06:57.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.054814342s
Jan 24 20:06:57.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.074643859s
STEP: removing the label kubernetes.io/e2e-7838bb8d-b5ab-4265-85f7-aee5d306ae9e off the node vikash-v125latest-conf-71087 01/24/23 20:06:57.471
STEP: verifying the node doesn't have the label kubernetes.io/e2e-7838bb8d-b5ab-4265-85f7-aee5d306ae9e 01/24/23 20:06:57.532
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jan 24 20:06:57.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9378" for this suite. 01/24/23 20:06:57.581
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":249,"skipped":4670,"failed":0}
------------------------------
• [SLOW TEST] [308.866 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:01:48.75
    Jan 24 20:01:48.751: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sched-pred 01/24/23 20:01:48.754
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:01:48.794
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:01:48.803
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jan 24 20:01:48.818: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jan 24 20:01:48.839: INFO: Waiting for terminating namespaces to be deleted...
    Jan 24 20:01:48.854: INFO: 
    Logging pods the apiserver thinks is on node vikash-v125latest-conf-59870 before test
    Jan 24 20:01:48.881: INFO: haproxy-ingress-cb855dc7c-smnf7 from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.881: INFO: 	Container haproxy-ingress ready: true, restart count 0
    Jan 24 20:01:48.881: INFO: ingress-default-backend-6f4477b7bc-qg2sz from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.881: INFO: 	Container ingress-default-backend ready: true, restart count 0
    Jan 24 20:01:48.881: INFO: calico-kube-controllers-74677b4c5f-zd5w8 from kube-system started at 2023-01-24 18:20:11 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.881: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Jan 24 20:01:48.881: INFO: calico-node-45c9d from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.881: INFO: 	Container calico-node ready: true, restart count 0
    Jan 24 20:01:48.881: INFO: coredns-94487f57-9zlwt from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.881: INFO: 	Container coredns ready: true, restart count 0
    Jan 24 20:01:48.881: INFO: coredns-94487f57-qldwh from kube-system started at 2023-01-24 18:34:25 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.881: INFO: 	Container coredns ready: true, restart count 0
    Jan 24 20:01:48.881: INFO: kyverno-operator-5c87dbd458-txhlw from nirmata started at 2023-01-24 18:22:35 +0000 UTC (2 container statuses recorded)
    Jan 24 20:01:48.881: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
    Jan 24 20:01:48.881: INFO: 	Container manager ready: true, restart count 0
    Jan 24 20:01:48.881: INFO: nirmata-cni-installer-6skzt from nirmata started at 2023-01-24 08:32:34 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.881: INFO: 	Container install-cni ready: true, restart count 0
    Jan 24 20:01:48.881: INFO: otel-agent-6dfc8d44b6-6kj5q from nirmata started at 2023-01-24 18:22:32 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.881: INFO: 	Container otel-agent ready: true, restart count 0
    Jan 24 20:01:48.881: INFO: sonobuoy from sonobuoy started at 2023-01-24 18:32:49 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.882: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jan 24 20:01:48.882: INFO: sonobuoy-e2e-job-d94c6e71d257417d from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 20:01:48.882: INFO: 	Container e2e ready: true, restart count 0
    Jan 24 20:01:48.882: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 20:01:48.882: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 20:01:48.882: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 20:01:48.882: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 24 20:01:48.882: INFO: 
    Logging pods the apiserver thinks is on node vikash-v125latest-conf-71087 before test
    Jan 24 20:01:48.905: INFO: calico-node-kfjch from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.905: INFO: 	Container calico-node ready: true, restart count 0
    Jan 24 20:01:48.905: INFO: metrics-server-696f4844bb-xklrk from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.905: INFO: 	Container metrics-server ready: true, restart count 0
    Jan 24 20:01:48.905: INFO: nirmata-cni-installer-swjzc from nirmata started at 2023-01-24 18:34:55 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.905: INFO: 	Container install-cni ready: true, restart count 0
    Jan 24 20:01:48.905: INFO: nirmata-kube-controller-df864cd5c-bz5gj from nirmata started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.905: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
    Jan 24 20:01:48.905: INFO: pod-logs-websocket-e1ee6bd5-e11a-403b-9fdb-7ed9f9dc057f from pods-1887 started at 2023-01-24 20:01:27 +0000 UTC (1 container statuses recorded)
    Jan 24 20:01:48.905: INFO: 	Container main ready: true, restart count 0
    Jan 24 20:01:48.905: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-x86sk from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 20:01:48.905: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 20:01:48.905: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 01/24/23 20:01:48.905
    Jan 24 20:01:48.936: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9378" to be "running"
    Jan 24 20:01:48.958: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 21.628343ms
    Jan 24 20:01:50.981: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044691486s
    Jan 24 20:01:52.974: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.037416624s
    Jan 24 20:01:52.974: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 01/24/23 20:01:52.982
    STEP: Trying to apply a random label on the found node. 01/24/23 20:01:53.043
    STEP: verifying the node has the label kubernetes.io/e2e-7838bb8d-b5ab-4265-85f7-aee5d306ae9e 95 01/24/23 20:01:53.1
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 01/24/23 20:01:53.23
    Jan 24 20:01:53.320: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9378" to be "not pending"
    Jan 24 20:01:53.335: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.652148ms
    Jan 24 20:01:55.353: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033198564s
    Jan 24 20:01:57.361: INFO: Pod "pod4": Phase="Running", Reason="", readiness=false. Elapsed: 4.040978518s
    Jan 24 20:01:57.361: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.10.1.127 on the node which pod4 resides and expect not scheduled 01/24/23 20:01:57.361
    Jan 24 20:01:57.395: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9378" to be "not pending"
    Jan 24 20:01:57.434: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.569105ms
    Jan 24 20:01:59.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051435055s
    Jan 24 20:02:01.479: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.083574882s
    Jan 24 20:02:03.478: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.082742793s
    Jan 24 20:02:05.463: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.068442557s
    Jan 24 20:02:07.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.057240027s
    Jan 24 20:02:09.530: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.135291618s
    Jan 24 20:02:11.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.058399558s
    Jan 24 20:02:13.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.065846291s
    Jan 24 20:02:15.487: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.092551042s
    Jan 24 20:02:17.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.057431577s
    Jan 24 20:02:19.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.05432394s
    Jan 24 20:02:21.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.053905914s
    Jan 24 20:02:23.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.050092974s
    Jan 24 20:02:25.455: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.060314726s
    Jan 24 20:02:27.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.057886858s
    Jan 24 20:02:29.451: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.05597971s
    Jan 24 20:02:31.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.054632114s
    Jan 24 20:02:33.455: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.059602262s
    Jan 24 20:02:35.582: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.186659978s
    Jan 24 20:02:37.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.05264242s
    Jan 24 20:02:39.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.054010404s
    Jan 24 20:02:41.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.062505354s
    Jan 24 20:02:43.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.053512611s
    Jan 24 20:02:45.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.058526314s
    Jan 24 20:02:47.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.057228648s
    Jan 24 20:02:49.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.051742777s
    Jan 24 20:02:51.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.066127204s
    Jan 24 20:02:53.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.062169551s
    Jan 24 20:02:55.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.057289194s
    Jan 24 20:02:57.464: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.068923268s
    Jan 24 20:02:59.509: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.114361751s
    Jan 24 20:03:01.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.053117805s
    Jan 24 20:03:03.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.054190467s
    Jan 24 20:03:05.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.050643719s
    Jan 24 20:03:07.444: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.049090631s
    Jan 24 20:03:09.465: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.070370139s
    Jan 24 20:03:11.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.060930753s
    Jan 24 20:03:13.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.058916361s
    Jan 24 20:03:15.524: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.128820714s
    Jan 24 20:03:17.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.050816887s
    Jan 24 20:03:19.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.061678567s
    Jan 24 20:03:21.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.049851114s
    Jan 24 20:03:23.468: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.073110109s
    Jan 24 20:03:25.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.059561884s
    Jan 24 20:03:27.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.053318094s
    Jan 24 20:03:29.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.055532917s
    Jan 24 20:03:31.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.051121852s
    Jan 24 20:03:33.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.053559243s
    Jan 24 20:03:35.549: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.153823313s
    Jan 24 20:03:37.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.053964738s
    Jan 24 20:03:39.473: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.077657011s
    Jan 24 20:03:41.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.06188458s
    Jan 24 20:03:43.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.052541937s
    Jan 24 20:03:45.458: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.063280452s
    Jan 24 20:03:47.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.051532085s
    Jan 24 20:03:49.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.050243635s
    Jan 24 20:03:51.461: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.065992551s
    Jan 24 20:03:53.451: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.056545754s
    Jan 24 20:03:55.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.059022083s
    Jan 24 20:03:57.579: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.184040367s
    Jan 24 20:03:59.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.060603089s
    Jan 24 20:04:01.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.064956214s
    Jan 24 20:04:03.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.05128852s
    Jan 24 20:04:05.473: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.078433621s
    Jan 24 20:04:07.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.061694525s
    Jan 24 20:04:09.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.052735784s
    Jan 24 20:04:11.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.065212005s
    Jan 24 20:04:13.444: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.048702132s
    Jan 24 20:04:15.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.051240832s
    Jan 24 20:04:17.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.052953828s
    Jan 24 20:04:19.444: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.049032703s
    Jan 24 20:04:21.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.050614221s
    Jan 24 20:04:23.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.053536481s
    Jan 24 20:04:25.504: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.109515592s
    Jan 24 20:04:27.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.061497446s
    Jan 24 20:04:29.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.052293299s
    Jan 24 20:04:31.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.050209237s
    Jan 24 20:04:33.474: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.078575461s
    Jan 24 20:04:35.455: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.060533406s
    Jan 24 20:04:37.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.05854643s
    Jan 24 20:04:39.479: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.084178418s
    Jan 24 20:04:41.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.061377115s
    Jan 24 20:04:43.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.057980215s
    Jan 24 20:04:45.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.057844586s
    Jan 24 20:04:47.465: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.070439219s
    Jan 24 20:04:49.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.058358061s
    Jan 24 20:04:51.466: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.07089591s
    Jan 24 20:04:53.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.050910021s
    Jan 24 20:04:55.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.056644527s
    Jan 24 20:04:57.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.051828043s
    Jan 24 20:04:59.486: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.090939053s
    Jan 24 20:05:01.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.073840114s
    Jan 24 20:05:03.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.051353574s
    Jan 24 20:05:05.506: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.110767635s
    Jan 24 20:05:07.455: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.059575692s
    Jan 24 20:05:09.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.057354315s
    Jan 24 20:05:11.534: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.138909665s
    Jan 24 20:05:13.482: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.087423633s
    Jan 24 20:05:15.469: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.073575423s
    Jan 24 20:05:17.444: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.048909717s
    Jan 24 20:05:19.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.053396169s
    Jan 24 20:05:21.465: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.06985348s
    Jan 24 20:05:23.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.054138408s
    Jan 24 20:05:25.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.064770658s
    Jan 24 20:05:27.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.05171736s
    Jan 24 20:05:29.479: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.084084848s
    Jan 24 20:05:31.451: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.056337027s
    Jan 24 20:05:33.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.052732638s
    Jan 24 20:05:35.459: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.063643956s
    Jan 24 20:05:37.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.049861998s
    Jan 24 20:05:39.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.057709653s
    Jan 24 20:05:41.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.053246597s
    Jan 24 20:05:43.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.051520369s
    Jan 24 20:05:45.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.0613368s
    Jan 24 20:05:47.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.051048325s
    Jan 24 20:05:49.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.054658469s
    Jan 24 20:05:51.446: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.051193918s
    Jan 24 20:05:53.487: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.091707403s
    Jan 24 20:05:55.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.064751791s
    Jan 24 20:05:57.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.058825478s
    Jan 24 20:05:59.460: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.065256313s
    Jan 24 20:06:01.452: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.057293086s
    Jan 24 20:06:03.448: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.053237548s
    Jan 24 20:06:05.490: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.094771041s
    Jan 24 20:06:07.473: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.077985773s
    Jan 24 20:06:09.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.061811266s
    Jan 24 20:06:11.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.05540852s
    Jan 24 20:06:13.458: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.063253989s
    Jan 24 20:06:15.457: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.062452272s
    Jan 24 20:06:17.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.052436511s
    Jan 24 20:06:19.447: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.05160236s
    Jan 24 20:06:21.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.058589279s
    Jan 24 20:06:23.441: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.045988716s
    Jan 24 20:06:25.444: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.048686517s
    Jan 24 20:06:27.443: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.047999608s
    Jan 24 20:06:29.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.050026511s
    Jan 24 20:06:31.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.0501194s
    Jan 24 20:06:33.451: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.056263615s
    Jan 24 20:06:35.500: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.105217016s
    Jan 24 20:06:37.445: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.049682514s
    Jan 24 20:06:39.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.055151098s
    Jan 24 20:06:41.454: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.059159758s
    Jan 24 20:06:43.456: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.061219075s
    Jan 24 20:06:45.586: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.191302141s
    Jan 24 20:06:47.443: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.048364461s
    Jan 24 20:06:49.440: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.044852403s
    Jan 24 20:06:51.449: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.053785179s
    Jan 24 20:06:53.453: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.057673401s
    Jan 24 20:06:55.477: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.081975336s
    Jan 24 20:06:57.450: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.054814342s
    Jan 24 20:06:57.470: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.074643859s
    STEP: removing the label kubernetes.io/e2e-7838bb8d-b5ab-4265-85f7-aee5d306ae9e off the node vikash-v125latest-conf-71087 01/24/23 20:06:57.471
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-7838bb8d-b5ab-4265-85f7-aee5d306ae9e 01/24/23 20:06:57.532
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 20:06:57.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-9378" for this suite. 01/24/23 20:06:57.581
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:06:57.628
Jan 24 20:06:57.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 20:06:57.636
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:06:57.714
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:06:57.724
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 01/24/23 20:06:57.738
STEP: fetching the ConfigMap 01/24/23 20:06:57.751
STEP: patching the ConfigMap 01/24/23 20:06:57.767
STEP: listing all ConfigMaps in all namespaces with a label selector 01/24/23 20:06:57.786
STEP: deleting the ConfigMap by collection with a label selector 01/24/23 20:06:57.798
STEP: listing all ConfigMaps in test namespace 01/24/23 20:06:57.819
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 20:06:57.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-642" for this suite. 01/24/23 20:06:57.836
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":250,"skipped":4670,"failed":0}
------------------------------
• [0.238 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:06:57.628
    Jan 24 20:06:57.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 20:06:57.636
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:06:57.714
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:06:57.724
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 01/24/23 20:06:57.738
    STEP: fetching the ConfigMap 01/24/23 20:06:57.751
    STEP: patching the ConfigMap 01/24/23 20:06:57.767
    STEP: listing all ConfigMaps in all namespaces with a label selector 01/24/23 20:06:57.786
    STEP: deleting the ConfigMap by collection with a label selector 01/24/23 20:06:57.798
    STEP: listing all ConfigMaps in test namespace 01/24/23 20:06:57.819
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 20:06:57.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-642" for this suite. 01/24/23 20:06:57.836
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:06:57.874
Jan 24 20:06:57.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 20:06:57.877
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:06:57.936
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:06:57.946
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 01/24/23 20:06:57.956
STEP: Getting a ResourceQuota 01/24/23 20:06:57.97
STEP: Listing all ResourceQuotas with LabelSelector 01/24/23 20:06:57.982
STEP: Patching the ResourceQuota 01/24/23 20:06:57.991
STEP: Deleting a Collection of ResourceQuotas 01/24/23 20:06:58.022
STEP: Verifying the deleted ResourceQuota 01/24/23 20:06:58.053
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 20:06:58.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6291" for this suite. 01/24/23 20:06:58.082
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":251,"skipped":4677,"failed":0}
------------------------------
• [0.237 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:06:57.874
    Jan 24 20:06:57.874: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 20:06:57.877
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:06:57.936
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:06:57.946
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 01/24/23 20:06:57.956
    STEP: Getting a ResourceQuota 01/24/23 20:06:57.97
    STEP: Listing all ResourceQuotas with LabelSelector 01/24/23 20:06:57.982
    STEP: Patching the ResourceQuota 01/24/23 20:06:57.991
    STEP: Deleting a Collection of ResourceQuotas 01/24/23 20:06:58.022
    STEP: Verifying the deleted ResourceQuota 01/24/23 20:06:58.053
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 20:06:58.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6291" for this suite. 01/24/23 20:06:58.082
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:06:58.111
Jan 24 20:06:58.112: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename aggregator 01/24/23 20:06:58.116
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:06:58.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:06:58.258
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Jan 24 20:06:58.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 01/24/23 20:06:58.289
Jan 24 20:06:59.852: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jan 24 20:07:02.220: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:04.313: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:06.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:08.226: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:10.240: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:12.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:14.231: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:16.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:18.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:20.235: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:22.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:24.232: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:26.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:28.227: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:30.241: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:32.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:34.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:36.257: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:38.238: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:40.246: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:42.231: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:44.288: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:46.285: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:48.237: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:50.330: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:52.235: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:54.278: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:56.232: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:07:58.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:08:00.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:08:02.611: INFO: Waited 335.770398ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 01/24/23 20:08:02.903
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 01/24/23 20:08:02.911
STEP: List APIServices 01/24/23 20:08:02.933
Jan 24 20:08:02.962: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Jan 24 20:08:03.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-206" for this suite. 01/24/23 20:08:03.823
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":252,"skipped":4677,"failed":0}
------------------------------
• [SLOW TEST] [65.772 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:06:58.111
    Jan 24 20:06:58.112: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename aggregator 01/24/23 20:06:58.116
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:06:58.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:06:58.258
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Jan 24 20:06:58.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 01/24/23 20:06:58.289
    Jan 24 20:06:59.852: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Jan 24 20:07:02.220: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:04.313: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:06.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:08.226: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:10.240: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:12.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:14.231: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:16.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:18.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:20.235: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:22.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:24.232: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:26.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:28.227: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:30.241: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:32.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:34.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:36.257: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:38.238: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:40.246: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:42.231: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:44.288: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:46.285: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:48.237: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:50.330: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:52.235: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:54.278: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:56.232: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:07:58.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:08:00.244: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 7, 0, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 6, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:08:02.611: INFO: Waited 335.770398ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 01/24/23 20:08:02.903
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 01/24/23 20:08:02.911
    STEP: List APIServices 01/24/23 20:08:02.933
    Jan 24 20:08:02.962: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Jan 24 20:08:03.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-206" for this suite. 01/24/23 20:08:03.823
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:08:03.892
Jan 24 20:08:03.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubelet-test 01/24/23 20:08:03.899
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:03.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:04.026
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Jan 24 20:08:08.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-258" for this suite. 01/24/23 20:08:08.208
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":253,"skipped":4681,"failed":0}
------------------------------
• [4.402 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:08:03.892
    Jan 24 20:08:03.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubelet-test 01/24/23 20:08:03.899
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:03.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:04.026
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Jan 24 20:08:08.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-258" for this suite. 01/24/23 20:08:08.208
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:08:08.302
Jan 24 20:08:08.302: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:08:08.324
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:08.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:08.564
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-0d81cfa9-08d9-436f-be84-2daa3d9449f2 01/24/23 20:08:08.599
STEP: Creating a pod to test consume configMaps 01/24/23 20:08:08.65
Jan 24 20:08:08.717: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a" in namespace "projected-7400" to be "Succeeded or Failed"
Jan 24 20:08:08.766: INFO: Pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a": Phase="Pending", Reason="", readiness=false. Elapsed: 49.55258ms
Jan 24 20:08:10.782: INFO: Pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065226313s
Jan 24 20:08:12.787: INFO: Pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.070141228s
Jan 24 20:08:14.826: INFO: Pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.109578323s
STEP: Saw pod success 01/24/23 20:08:14.826
Jan 24 20:08:14.827: INFO: Pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a" satisfied condition "Succeeded or Failed"
Jan 24 20:08:14.837: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a container agnhost-container: <nil>
STEP: delete the pod 01/24/23 20:08:14.901
Jan 24 20:08:14.951: INFO: Waiting for pod pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a to disappear
Jan 24 20:08:14.964: INFO: Pod pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 24 20:08:14.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7400" for this suite. 01/24/23 20:08:14.977
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":254,"skipped":4694,"failed":0}
------------------------------
• [SLOW TEST] [6.708 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:08:08.302
    Jan 24 20:08:08.302: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:08:08.324
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:08.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:08.564
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-0d81cfa9-08d9-436f-be84-2daa3d9449f2 01/24/23 20:08:08.599
    STEP: Creating a pod to test consume configMaps 01/24/23 20:08:08.65
    Jan 24 20:08:08.717: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a" in namespace "projected-7400" to be "Succeeded or Failed"
    Jan 24 20:08:08.766: INFO: Pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a": Phase="Pending", Reason="", readiness=false. Elapsed: 49.55258ms
    Jan 24 20:08:10.782: INFO: Pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065226313s
    Jan 24 20:08:12.787: INFO: Pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.070141228s
    Jan 24 20:08:14.826: INFO: Pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.109578323s
    STEP: Saw pod success 01/24/23 20:08:14.826
    Jan 24 20:08:14.827: INFO: Pod "pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a" satisfied condition "Succeeded or Failed"
    Jan 24 20:08:14.837: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 20:08:14.901
    Jan 24 20:08:14.951: INFO: Waiting for pod pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a to disappear
    Jan 24 20:08:14.964: INFO: Pod pod-projected-configmaps-01b81daa-e006-4506-b16b-091c767f7a0a no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 24 20:08:14.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7400" for this suite. 01/24/23 20:08:14.977
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:08:15.028
Jan 24 20:08:15.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 20:08:15.035
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:15.112
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:15.132
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 01/24/23 20:08:15.147
Jan 24 20:08:15.239: INFO: Waiting up to 5m0s for pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f" in namespace "emptydir-9594" to be "Succeeded or Failed"
Jan 24 20:08:15.284: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f": Phase="Pending", Reason="", readiness=false. Elapsed: 44.566275ms
Jan 24 20:08:17.473: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.233711704s
Jan 24 20:08:19.297: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f": Phase="Running", Reason="", readiness=false. Elapsed: 4.058050144s
Jan 24 20:08:21.377: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f": Phase="Running", Reason="", readiness=false. Elapsed: 6.13787054s
Jan 24 20:08:23.485: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.245773152s
STEP: Saw pod success 01/24/23 20:08:23.485
Jan 24 20:08:23.485: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f" satisfied condition "Succeeded or Failed"
Jan 24 20:08:23.537: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-b378d42a-eab1-465b-8da5-c17635bed05f container test-container: <nil>
STEP: delete the pod 01/24/23 20:08:23.595
Jan 24 20:08:23.669: INFO: Waiting for pod pod-b378d42a-eab1-465b-8da5-c17635bed05f to disappear
Jan 24 20:08:23.685: INFO: Pod pod-b378d42a-eab1-465b-8da5-c17635bed05f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 20:08:23.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9594" for this suite. 01/24/23 20:08:23.727
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":255,"skipped":4701,"failed":0}
------------------------------
• [SLOW TEST] [9.160 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:08:15.028
    Jan 24 20:08:15.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 20:08:15.035
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:15.112
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:15.132
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 01/24/23 20:08:15.147
    Jan 24 20:08:15.239: INFO: Waiting up to 5m0s for pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f" in namespace "emptydir-9594" to be "Succeeded or Failed"
    Jan 24 20:08:15.284: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f": Phase="Pending", Reason="", readiness=false. Elapsed: 44.566275ms
    Jan 24 20:08:17.473: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.233711704s
    Jan 24 20:08:19.297: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f": Phase="Running", Reason="", readiness=false. Elapsed: 4.058050144s
    Jan 24 20:08:21.377: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f": Phase="Running", Reason="", readiness=false. Elapsed: 6.13787054s
    Jan 24 20:08:23.485: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.245773152s
    STEP: Saw pod success 01/24/23 20:08:23.485
    Jan 24 20:08:23.485: INFO: Pod "pod-b378d42a-eab1-465b-8da5-c17635bed05f" satisfied condition "Succeeded or Failed"
    Jan 24 20:08:23.537: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-b378d42a-eab1-465b-8da5-c17635bed05f container test-container: <nil>
    STEP: delete the pod 01/24/23 20:08:23.595
    Jan 24 20:08:23.669: INFO: Waiting for pod pod-b378d42a-eab1-465b-8da5-c17635bed05f to disappear
    Jan 24 20:08:23.685: INFO: Pod pod-b378d42a-eab1-465b-8da5-c17635bed05f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 20:08:23.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9594" for this suite. 01/24/23 20:08:23.727
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:08:24.4
Jan 24 20:08:24.400: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename csistoragecapacity 01/24/23 20:08:24.465
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:24.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:24.665
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 01/24/23 20:08:24.695
STEP: getting /apis/storage.k8s.io 01/24/23 20:08:24.709
STEP: getting /apis/storage.k8s.io/v1 01/24/23 20:08:24.767
STEP: creating 01/24/23 20:08:24.87
STEP: watching 01/24/23 20:08:25.017
Jan 24 20:08:25.027: INFO: starting watch
STEP: getting 01/24/23 20:08:25.126
STEP: listing in namespace 01/24/23 20:08:25.157
STEP: listing across namespaces 01/24/23 20:08:25.182
STEP: patching 01/24/23 20:08:25.241
STEP: updating 01/24/23 20:08:25.26
Jan 24 20:08:25.285: INFO: waiting for watch events with expected annotations in namespace
Jan 24 20:08:25.287: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 01/24/23 20:08:25.287
STEP: deleting a collection 01/24/23 20:08:25.338
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Jan 24 20:08:25.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-5160" for this suite. 01/24/23 20:08:25.428
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":256,"skipped":4704,"failed":0}
------------------------------
• [1.060 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:08:24.4
    Jan 24 20:08:24.400: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename csistoragecapacity 01/24/23 20:08:24.465
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:24.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:24.665
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 01/24/23 20:08:24.695
    STEP: getting /apis/storage.k8s.io 01/24/23 20:08:24.709
    STEP: getting /apis/storage.k8s.io/v1 01/24/23 20:08:24.767
    STEP: creating 01/24/23 20:08:24.87
    STEP: watching 01/24/23 20:08:25.017
    Jan 24 20:08:25.027: INFO: starting watch
    STEP: getting 01/24/23 20:08:25.126
    STEP: listing in namespace 01/24/23 20:08:25.157
    STEP: listing across namespaces 01/24/23 20:08:25.182
    STEP: patching 01/24/23 20:08:25.241
    STEP: updating 01/24/23 20:08:25.26
    Jan 24 20:08:25.285: INFO: waiting for watch events with expected annotations in namespace
    Jan 24 20:08:25.287: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 01/24/23 20:08:25.287
    STEP: deleting a collection 01/24/23 20:08:25.338
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Jan 24 20:08:25.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-5160" for this suite. 01/24/23 20:08:25.428
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:08:25.467
Jan 24 20:08:25.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename ephemeral-containers-test 01/24/23 20:08:25.472
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:25.6
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:25.652
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 01/24/23 20:08:25.708
Jan 24 20:08:25.804: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2083" to be "running and ready"
Jan 24 20:08:25.899: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 95.096012ms
Jan 24 20:08:25.900: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:08:27.907: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.102985811s
Jan 24 20:08:27.907: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Jan 24 20:08:27.907: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 01/24/23 20:08:27.913
Jan 24 20:08:27.942: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2083" to be "container debugger running"
Jan 24 20:08:27.952: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 9.536046ms
Jan 24 20:08:29.960: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.017731741s
Jan 24 20:08:31.975: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.032671879s
Jan 24 20:08:31.976: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 01/24/23 20:08:31.976
Jan 24 20:08:31.976: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-2083 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 20:08:31.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 20:08:31.986: INFO: ExecWithOptions: Clientset creation
Jan 24 20:08:31.986: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/ephemeral-containers-test-2083/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Jan 24 20:08:32.145: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Jan 24 20:08:32.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-2083" for this suite. 01/24/23 20:08:32.176
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":257,"skipped":4717,"failed":0}
------------------------------
• [SLOW TEST] [6.739 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:08:25.467
    Jan 24 20:08:25.468: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename ephemeral-containers-test 01/24/23 20:08:25.472
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:25.6
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:25.652
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 01/24/23 20:08:25.708
    Jan 24 20:08:25.804: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2083" to be "running and ready"
    Jan 24 20:08:25.899: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 95.096012ms
    Jan 24 20:08:25.900: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:08:27.907: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.102985811s
    Jan 24 20:08:27.907: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Jan 24 20:08:27.907: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 01/24/23 20:08:27.913
    Jan 24 20:08:27.942: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2083" to be "container debugger running"
    Jan 24 20:08:27.952: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 9.536046ms
    Jan 24 20:08:29.960: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.017731741s
    Jan 24 20:08:31.975: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.032671879s
    Jan 24 20:08:31.976: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 01/24/23 20:08:31.976
    Jan 24 20:08:31.976: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-2083 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 20:08:31.977: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 20:08:31.986: INFO: ExecWithOptions: Clientset creation
    Jan 24 20:08:31.986: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/ephemeral-containers-test-2083/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Jan 24 20:08:32.145: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Jan 24 20:08:32.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-2083" for this suite. 01/24/23 20:08:32.176
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:08:32.209
Jan 24 20:08:32.210: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:08:32.214
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:32.259
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:32.287
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:08:32.298
Jan 24 20:08:32.315: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e" in namespace "projected-4867" to be "Succeeded or Failed"
Jan 24 20:08:32.333: INFO: Pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.41318ms
Jan 24 20:08:34.345: INFO: Pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030080959s
Jan 24 20:08:36.342: INFO: Pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027014805s
Jan 24 20:08:38.353: INFO: Pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037994798s
STEP: Saw pod success 01/24/23 20:08:38.353
Jan 24 20:08:38.354: INFO: Pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e" satisfied condition "Succeeded or Failed"
Jan 24 20:08:38.376: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e container client-container: <nil>
STEP: delete the pod 01/24/23 20:08:38.412
Jan 24 20:08:38.481: INFO: Waiting for pod downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e to disappear
Jan 24 20:08:38.504: INFO: Pod downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 20:08:38.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4867" for this suite. 01/24/23 20:08:38.527
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":258,"skipped":4727,"failed":0}
------------------------------
• [SLOW TEST] [6.340 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:08:32.209
    Jan 24 20:08:32.210: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:08:32.214
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:32.259
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:32.287
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:08:32.298
    Jan 24 20:08:32.315: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e" in namespace "projected-4867" to be "Succeeded or Failed"
    Jan 24 20:08:32.333: INFO: Pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.41318ms
    Jan 24 20:08:34.345: INFO: Pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030080959s
    Jan 24 20:08:36.342: INFO: Pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027014805s
    Jan 24 20:08:38.353: INFO: Pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037994798s
    STEP: Saw pod success 01/24/23 20:08:38.353
    Jan 24 20:08:38.354: INFO: Pod "downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e" satisfied condition "Succeeded or Failed"
    Jan 24 20:08:38.376: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e container client-container: <nil>
    STEP: delete the pod 01/24/23 20:08:38.412
    Jan 24 20:08:38.481: INFO: Waiting for pod downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e to disappear
    Jan 24 20:08:38.504: INFO: Pod downwardapi-volume-d01514ff-7b50-4a9d-9a0d-830639c3be6e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 20:08:38.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4867" for this suite. 01/24/23 20:08:38.527
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:08:38.565
Jan 24 20:08:38.565: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename deployment 01/24/23 20:08:38.57
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:38.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:38.743
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Jan 24 20:08:38.836: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 24 20:08:43.843: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/24/23 20:08:43.843
Jan 24 20:08:43.844: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 01/24/23 20:08:43.861
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 24 20:08:43.879: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-460  7280b8c7-c4f6-4dba-9c22-b80aaa531ac9 35611 1 2023-01-24 20:08:43 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-01-24 20:08:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005bb1978 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Jan 24 20:08:43.885: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jan 24 20:08:43.885: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan 24 20:08:43.886: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-460  a3d6909c-8ca3-4332-93d7-95a2675edffa 35612 1 2023-01-24 20:08:38 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 7280b8c7-c4f6-4dba-9c22-b80aaa531ac9 0xc0026baed7 0xc0026baed8}] [] [{e2e.test Update apps/v1 2023-01-24 20:08:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:08:41 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-01-24 20:08:43 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"7280b8c7-c4f6-4dba-9c22-b80aaa531ac9\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0026bb278 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jan 24 20:08:43.894: INFO: Pod "test-cleanup-controller-zpwjr" is available:
&Pod{ObjectMeta:{test-cleanup-controller-zpwjr test-cleanup-controller- deployment-460  b954b1cd-0f52-424c-b198-3905c4acc10f 35603 0 2023-01-24 20:08:38 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:0e3c22a0ffb6a2b9205f5861347174ae1a1d12032b2cc46523f24e39653ed42c cni.projectcalico.org/podIP:10.244.71.232/32 cni.projectcalico.org/podIPs:10.244.71.232/32] [{apps/v1 ReplicaSet test-cleanup-controller a3d6909c-8ca3-4332-93d7-95a2675edffa 0xc005bb1ce7 0xc005bb1ce8}] [] [{kube-controller-manager Update v1 2023-01-24 20:08:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a3d6909c-8ca3-4332-93d7-95a2675edffa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 20:08:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 20:08:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.232\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sn67f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sn67f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:08:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:08:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:08:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:08:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.232,StartTime:2023-01-24 20:08:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 20:08:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bff567db45e02bf572509cad598ba5cbaa89b9ec1d3e2f1bbcedc4b09495ffc9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.232,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 24 20:08:43.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-460" for this suite. 01/24/23 20:08:43.903
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":259,"skipped":4758,"failed":0}
------------------------------
• [SLOW TEST] [5.356 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:08:38.565
    Jan 24 20:08:38.565: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename deployment 01/24/23 20:08:38.57
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:38.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:38.743
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Jan 24 20:08:38.836: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Jan 24 20:08:43.843: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/24/23 20:08:43.843
    Jan 24 20:08:43.844: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 01/24/23 20:08:43.861
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 24 20:08:43.879: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-460  7280b8c7-c4f6-4dba-9c22-b80aaa531ac9 35611 1 2023-01-24 20:08:43 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2023-01-24 20:08:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005bb1978 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Jan 24 20:08:43.885: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
    Jan 24 20:08:43.885: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Jan 24 20:08:43.886: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-460  a3d6909c-8ca3-4332-93d7-95a2675edffa 35612 1 2023-01-24 20:08:38 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 7280b8c7-c4f6-4dba-9c22-b80aaa531ac9 0xc0026baed7 0xc0026baed8}] [] [{e2e.test Update apps/v1 2023-01-24 20:08:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:08:41 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2023-01-24 20:08:43 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"7280b8c7-c4f6-4dba-9c22-b80aaa531ac9\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0026bb278 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 20:08:43.894: INFO: Pod "test-cleanup-controller-zpwjr" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-zpwjr test-cleanup-controller- deployment-460  b954b1cd-0f52-424c-b198-3905c4acc10f 35603 0 2023-01-24 20:08:38 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/containerID:0e3c22a0ffb6a2b9205f5861347174ae1a1d12032b2cc46523f24e39653ed42c cni.projectcalico.org/podIP:10.244.71.232/32 cni.projectcalico.org/podIPs:10.244.71.232/32] [{apps/v1 ReplicaSet test-cleanup-controller a3d6909c-8ca3-4332-93d7-95a2675edffa 0xc005bb1ce7 0xc005bb1ce8}] [] [{kube-controller-manager Update v1 2023-01-24 20:08:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a3d6909c-8ca3-4332-93d7-95a2675edffa\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 20:08:40 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 20:08:41 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.232\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sn67f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sn67f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:08:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:08:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:08:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:08:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.232,StartTime:2023-01-24 20:08:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 20:08:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bff567db45e02bf572509cad598ba5cbaa89b9ec1d3e2f1bbcedc4b09495ffc9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.232,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 24 20:08:43.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-460" for this suite. 01/24/23 20:08:43.903
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:08:43.949
Jan 24 20:08:43.949: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 20:08:43.952
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:43.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:44.003
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 01/24/23 20:08:44.01
STEP: submitting the pod to kubernetes 01/24/23 20:08:44.011
Jan 24 20:08:44.027: INFO: Waiting up to 5m0s for pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a" in namespace "pods-6247" to be "running and ready"
Jan 24 20:08:44.033: INFO: Pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.507613ms
Jan 24 20:08:44.033: INFO: The phase of Pod pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:08:46.040: INFO: Pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a": Phase="Running", Reason="", readiness=true. Elapsed: 2.012961495s
Jan 24 20:08:46.040: INFO: The phase of Pod pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a is Running (Ready = true)
Jan 24 20:08:46.040: INFO: Pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 01/24/23 20:08:46.042
STEP: updating the pod 01/24/23 20:08:46.046
Jan 24 20:08:46.567: INFO: Successfully updated pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a"
Jan 24 20:08:46.568: INFO: Waiting up to 5m0s for pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a" in namespace "pods-6247" to be "running"
Jan 24 20:08:46.573: INFO: Pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a": Phase="Running", Reason="", readiness=true. Elapsed: 4.825228ms
Jan 24 20:08:46.573: INFO: Pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 01/24/23 20:08:46.573
Jan 24 20:08:46.576: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 24 20:08:46.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6247" for this suite. 01/24/23 20:08:46.581
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":260,"skipped":4780,"failed":0}
------------------------------
• [2.647 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:08:43.949
    Jan 24 20:08:43.949: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 20:08:43.952
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:43.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:44.003
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 01/24/23 20:08:44.01
    STEP: submitting the pod to kubernetes 01/24/23 20:08:44.011
    Jan 24 20:08:44.027: INFO: Waiting up to 5m0s for pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a" in namespace "pods-6247" to be "running and ready"
    Jan 24 20:08:44.033: INFO: Pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.507613ms
    Jan 24 20:08:44.033: INFO: The phase of Pod pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:08:46.040: INFO: Pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a": Phase="Running", Reason="", readiness=true. Elapsed: 2.012961495s
    Jan 24 20:08:46.040: INFO: The phase of Pod pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a is Running (Ready = true)
    Jan 24 20:08:46.040: INFO: Pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 01/24/23 20:08:46.042
    STEP: updating the pod 01/24/23 20:08:46.046
    Jan 24 20:08:46.567: INFO: Successfully updated pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a"
    Jan 24 20:08:46.568: INFO: Waiting up to 5m0s for pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a" in namespace "pods-6247" to be "running"
    Jan 24 20:08:46.573: INFO: Pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a": Phase="Running", Reason="", readiness=true. Elapsed: 4.825228ms
    Jan 24 20:08:46.573: INFO: Pod "pod-update-4c489a30-8880-4a4f-b26f-e313cae0e09a" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 01/24/23 20:08:46.573
    Jan 24 20:08:46.576: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 24 20:08:46.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6247" for this suite. 01/24/23 20:08:46.581
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:08:46.597
Jan 24 20:08:46.597: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 20:08:46.599
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:46.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:46.629
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 20:08:46.66
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 20:08:47.83
STEP: Deploying the webhook pod 01/24/23 20:08:47.847
STEP: Wait for the deployment to be ready 01/24/23 20:08:47.869
Jan 24 20:08:47.879: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Jan 24 20:08:49.944: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 8, 47, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 8, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 8, 47, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 8, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 20:08:51.965
STEP: Verifying the service has paired with the endpoint 01/24/23 20:08:51.99
Jan 24 20:08:52.992: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Jan 24 20:08:53.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3344-crds.webhook.example.com via the AdmissionRegistration API 01/24/23 20:08:53.523
STEP: Creating a custom resource that should be mutated by the webhook 01/24/23 20:08:53.562
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:08:56.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7534" for this suite. 01/24/23 20:08:56.236
STEP: Destroying namespace "webhook-7534-markers" for this suite. 01/24/23 20:08:56.251
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":261,"skipped":4784,"failed":0}
------------------------------
• [SLOW TEST] [9.782 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:08:46.597
    Jan 24 20:08:46.597: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 20:08:46.599
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:46.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:46.629
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 20:08:46.66
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 20:08:47.83
    STEP: Deploying the webhook pod 01/24/23 20:08:47.847
    STEP: Wait for the deployment to be ready 01/24/23 20:08:47.869
    Jan 24 20:08:47.879: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Jan 24 20:08:49.944: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 8, 47, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 8, 47, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 8, 47, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 8, 47, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 20:08:51.965
    STEP: Verifying the service has paired with the endpoint 01/24/23 20:08:51.99
    Jan 24 20:08:52.992: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Jan 24 20:08:53.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3344-crds.webhook.example.com via the AdmissionRegistration API 01/24/23 20:08:53.523
    STEP: Creating a custom resource that should be mutated by the webhook 01/24/23 20:08:53.562
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:08:56.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7534" for this suite. 01/24/23 20:08:56.236
    STEP: Destroying namespace "webhook-7534-markers" for this suite. 01/24/23 20:08:56.251
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:08:56.381
Jan 24 20:08:56.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 20:08:56.382
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:56.445
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:56.462
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 01/24/23 20:08:56.489
Jan 24 20:08:56.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: mark a version not serverd 01/24/23 20:09:28.563
STEP: check the unserved version gets removed 01/24/23 20:09:28.606
STEP: check the other version is not changed 01/24/23 20:09:35.229
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:09:58.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6300" for this suite. 01/24/23 20:09:58.09
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":262,"skipped":4789,"failed":0}
------------------------------
• [SLOW TEST] [61.727 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:08:56.381
    Jan 24 20:08:56.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 20:08:56.382
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:08:56.445
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:08:56.462
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 01/24/23 20:08:56.489
    Jan 24 20:08:56.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: mark a version not serverd 01/24/23 20:09:28.563
    STEP: check the unserved version gets removed 01/24/23 20:09:28.606
    STEP: check the other version is not changed 01/24/23 20:09:35.229
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:09:58.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6300" for this suite. 01/24/23 20:09:58.09
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:09:58.125
Jan 24 20:09:58.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 20:09:58.129
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:09:58.175
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:09:58.193
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 01/24/23 20:09:58.214
Jan 24 20:09:58.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9409 api-versions'
Jan 24 20:09:58.515: INFO: stderr: ""
Jan 24 20:09:58.515: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsecurity.nirmata.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 20:09:58.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9409" for this suite. 01/24/23 20:09:58.546
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":263,"skipped":4793,"failed":0}
------------------------------
• [0.438 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:09:58.125
    Jan 24 20:09:58.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 20:09:58.129
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:09:58.175
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:09:58.193
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 01/24/23 20:09:58.214
    Jan 24 20:09:58.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9409 api-versions'
    Jan 24 20:09:58.515: INFO: stderr: ""
    Jan 24 20:09:58.515: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsecurity.nirmata.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 20:09:58.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9409" for this suite. 01/24/23 20:09:58.546
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:09:58.566
Jan 24 20:09:58.570: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 20:09:58.581
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:09:58.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:09:58.661
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 01/24/23 20:09:58.671
Jan 24 20:09:58.705: INFO: Waiting up to 5m0s for pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6" in namespace "downward-api-1098" to be "Succeeded or Failed"
Jan 24 20:09:58.720: INFO: Pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.320099ms
Jan 24 20:10:00.978: INFO: Pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.272269794s
Jan 24 20:10:02.799: INFO: Pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093347967s
Jan 24 20:10:04.777: INFO: Pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.071711365s
STEP: Saw pod success 01/24/23 20:10:04.777
Jan 24 20:10:04.783: INFO: Pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6" satisfied condition "Succeeded or Failed"
Jan 24 20:10:04.815: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6 container dapi-container: <nil>
STEP: delete the pod 01/24/23 20:10:04.842
Jan 24 20:10:04.890: INFO: Waiting for pod downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6 to disappear
Jan 24 20:10:04.903: INFO: Pod downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Jan 24 20:10:04.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1098" for this suite. 01/24/23 20:10:04.922
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":264,"skipped":4794,"failed":0}
------------------------------
• [SLOW TEST] [6.403 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:09:58.566
    Jan 24 20:09:58.570: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 20:09:58.581
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:09:58.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:09:58.661
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 01/24/23 20:09:58.671
    Jan 24 20:09:58.705: INFO: Waiting up to 5m0s for pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6" in namespace "downward-api-1098" to be "Succeeded or Failed"
    Jan 24 20:09:58.720: INFO: Pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.320099ms
    Jan 24 20:10:00.978: INFO: Pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.272269794s
    Jan 24 20:10:02.799: INFO: Pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093347967s
    Jan 24 20:10:04.777: INFO: Pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.071711365s
    STEP: Saw pod success 01/24/23 20:10:04.777
    Jan 24 20:10:04.783: INFO: Pod "downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6" satisfied condition "Succeeded or Failed"
    Jan 24 20:10:04.815: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6 container dapi-container: <nil>
    STEP: delete the pod 01/24/23 20:10:04.842
    Jan 24 20:10:04.890: INFO: Waiting for pod downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6 to disappear
    Jan 24 20:10:04.903: INFO: Pod downward-api-cd73cfb0-1347-436a-b8ce-1ed999e05fb6 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Jan 24 20:10:04.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1098" for this suite. 01/24/23 20:10:04.922
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:10:05.04
Jan 24 20:10:05.040: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 20:10:05.045
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:05.18
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:05.215
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 01/24/23 20:10:05.239
Jan 24 20:10:05.323: INFO: Waiting up to 5m0s for pod "pod-67834edf-216e-4b8c-9456-cf8a27081598" in namespace "emptydir-8174" to be "Succeeded or Failed"
Jan 24 20:10:05.424: INFO: Pod "pod-67834edf-216e-4b8c-9456-cf8a27081598": Phase="Pending", Reason="", readiness=false. Elapsed: 61.013989ms
Jan 24 20:10:07.439: INFO: Pod "pod-67834edf-216e-4b8c-9456-cf8a27081598": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075935927s
Jan 24 20:10:09.441: INFO: Pod "pod-67834edf-216e-4b8c-9456-cf8a27081598": Phase="Pending", Reason="", readiness=false. Elapsed: 4.077884964s
Jan 24 20:10:11.447: INFO: Pod "pod-67834edf-216e-4b8c-9456-cf8a27081598": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.083314661s
STEP: Saw pod success 01/24/23 20:10:11.447
Jan 24 20:10:11.447: INFO: Pod "pod-67834edf-216e-4b8c-9456-cf8a27081598" satisfied condition "Succeeded or Failed"
Jan 24 20:10:11.467: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-67834edf-216e-4b8c-9456-cf8a27081598 container test-container: <nil>
STEP: delete the pod 01/24/23 20:10:11.514
Jan 24 20:10:11.555: INFO: Waiting for pod pod-67834edf-216e-4b8c-9456-cf8a27081598 to disappear
Jan 24 20:10:11.566: INFO: Pod pod-67834edf-216e-4b8c-9456-cf8a27081598 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 20:10:11.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8174" for this suite. 01/24/23 20:10:11.578
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":265,"skipped":4805,"failed":0}
------------------------------
• [SLOW TEST] [6.558 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:10:05.04
    Jan 24 20:10:05.040: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 20:10:05.045
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:05.18
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:05.215
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 01/24/23 20:10:05.239
    Jan 24 20:10:05.323: INFO: Waiting up to 5m0s for pod "pod-67834edf-216e-4b8c-9456-cf8a27081598" in namespace "emptydir-8174" to be "Succeeded or Failed"
    Jan 24 20:10:05.424: INFO: Pod "pod-67834edf-216e-4b8c-9456-cf8a27081598": Phase="Pending", Reason="", readiness=false. Elapsed: 61.013989ms
    Jan 24 20:10:07.439: INFO: Pod "pod-67834edf-216e-4b8c-9456-cf8a27081598": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075935927s
    Jan 24 20:10:09.441: INFO: Pod "pod-67834edf-216e-4b8c-9456-cf8a27081598": Phase="Pending", Reason="", readiness=false. Elapsed: 4.077884964s
    Jan 24 20:10:11.447: INFO: Pod "pod-67834edf-216e-4b8c-9456-cf8a27081598": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.083314661s
    STEP: Saw pod success 01/24/23 20:10:11.447
    Jan 24 20:10:11.447: INFO: Pod "pod-67834edf-216e-4b8c-9456-cf8a27081598" satisfied condition "Succeeded or Failed"
    Jan 24 20:10:11.467: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-67834edf-216e-4b8c-9456-cf8a27081598 container test-container: <nil>
    STEP: delete the pod 01/24/23 20:10:11.514
    Jan 24 20:10:11.555: INFO: Waiting for pod pod-67834edf-216e-4b8c-9456-cf8a27081598 to disappear
    Jan 24 20:10:11.566: INFO: Pod pod-67834edf-216e-4b8c-9456-cf8a27081598 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 20:10:11.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8174" for this suite. 01/24/23 20:10:11.578
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:10:11.606
Jan 24 20:10:11.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename dns 01/24/23 20:10:11.609
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:11.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:11.707
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 01/24/23 20:10:11.746
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 01/24/23 20:10:11.746
STEP: creating a pod to probe DNS 01/24/23 20:10:11.747
STEP: submitting the pod to kubernetes 01/24/23 20:10:11.747
Jan 24 20:10:11.812: INFO: Waiting up to 15m0s for pod "dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772" in namespace "dns-8727" to be "running"
Jan 24 20:10:11.829: INFO: Pod "dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772": Phase="Pending", Reason="", readiness=false. Elapsed: 16.690181ms
Jan 24 20:10:13.856: INFO: Pod "dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044406544s
Jan 24 20:10:15.893: INFO: Pod "dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772": Phase="Running", Reason="", readiness=true. Elapsed: 4.080996577s
Jan 24 20:10:15.893: INFO: Pod "dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772" satisfied condition "running"
STEP: retrieving the pod 01/24/23 20:10:15.893
STEP: looking for the results for each expected name from probers 01/24/23 20:10:15.927
Jan 24 20:10:16.060: INFO: DNS probes using dns-8727/dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772 succeeded

STEP: deleting the pod 01/24/23 20:10:16.06
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 24 20:10:16.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8727" for this suite. 01/24/23 20:10:16.15
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":266,"skipped":4845,"failed":0}
------------------------------
• [4.591 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:10:11.606
    Jan 24 20:10:11.607: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename dns 01/24/23 20:10:11.609
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:11.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:11.707
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     01/24/23 20:10:11.746
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     01/24/23 20:10:11.746
    STEP: creating a pod to probe DNS 01/24/23 20:10:11.747
    STEP: submitting the pod to kubernetes 01/24/23 20:10:11.747
    Jan 24 20:10:11.812: INFO: Waiting up to 15m0s for pod "dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772" in namespace "dns-8727" to be "running"
    Jan 24 20:10:11.829: INFO: Pod "dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772": Phase="Pending", Reason="", readiness=false. Elapsed: 16.690181ms
    Jan 24 20:10:13.856: INFO: Pod "dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044406544s
    Jan 24 20:10:15.893: INFO: Pod "dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772": Phase="Running", Reason="", readiness=true. Elapsed: 4.080996577s
    Jan 24 20:10:15.893: INFO: Pod "dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772" satisfied condition "running"
    STEP: retrieving the pod 01/24/23 20:10:15.893
    STEP: looking for the results for each expected name from probers 01/24/23 20:10:15.927
    Jan 24 20:10:16.060: INFO: DNS probes using dns-8727/dns-test-a3c72d2a-df6b-4522-858a-c0bc2ac63772 succeeded

    STEP: deleting the pod 01/24/23 20:10:16.06
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 24 20:10:16.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8727" for this suite. 01/24/23 20:10:16.15
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:10:16.199
Jan 24 20:10:16.199: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:10:16.207
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:16.315
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:16.329
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-4f051016-fafc-4869-bcab-b4c7fa99e2f6 01/24/23 20:10:16.348
STEP: Creating a pod to test consume configMaps 01/24/23 20:10:16.37
Jan 24 20:10:16.446: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7" in namespace "projected-4465" to be "Succeeded or Failed"
Jan 24 20:10:16.458: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Pending", Reason="", readiness=false. Elapsed: 11.764247ms
Jan 24 20:10:18.497: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050783791s
Jan 24 20:10:20.514: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068134387s
Jan 24 20:10:22.479: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033164241s
Jan 24 20:10:24.478: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.031974173s
Jan 24 20:10:26.477: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.03140806s
STEP: Saw pod success 01/24/23 20:10:26.478
Jan 24 20:10:26.480: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7" satisfied condition "Succeeded or Failed"
Jan 24 20:10:26.491: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 20:10:26.513
Jan 24 20:10:26.550: INFO: Waiting for pod pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7 to disappear
Jan 24 20:10:26.558: INFO: Pod pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 24 20:10:26.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4465" for this suite. 01/24/23 20:10:26.569
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":267,"skipped":4848,"failed":0}
------------------------------
• [SLOW TEST] [10.393 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:10:16.199
    Jan 24 20:10:16.199: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:10:16.207
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:16.315
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:16.329
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-4f051016-fafc-4869-bcab-b4c7fa99e2f6 01/24/23 20:10:16.348
    STEP: Creating a pod to test consume configMaps 01/24/23 20:10:16.37
    Jan 24 20:10:16.446: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7" in namespace "projected-4465" to be "Succeeded or Failed"
    Jan 24 20:10:16.458: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Pending", Reason="", readiness=false. Elapsed: 11.764247ms
    Jan 24 20:10:18.497: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050783791s
    Jan 24 20:10:20.514: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068134387s
    Jan 24 20:10:22.479: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033164241s
    Jan 24 20:10:24.478: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.031974173s
    Jan 24 20:10:26.477: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.03140806s
    STEP: Saw pod success 01/24/23 20:10:26.478
    Jan 24 20:10:26.480: INFO: Pod "pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7" satisfied condition "Succeeded or Failed"
    Jan 24 20:10:26.491: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 20:10:26.513
    Jan 24 20:10:26.550: INFO: Waiting for pod pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7 to disappear
    Jan 24 20:10:26.558: INFO: Pod pod-projected-configmaps-348e0b50-01fa-4d5a-b4b5-71b4eabd7ae7 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 24 20:10:26.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4465" for this suite. 01/24/23 20:10:26.569
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:10:26.606
Jan 24 20:10:26.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 20:10:26.609
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:26.668
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:26.68
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:10:26.691
Jan 24 20:10:26.742: INFO: Waiting up to 5m0s for pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5" in namespace "downward-api-4124" to be "Succeeded or Failed"
Jan 24 20:10:26.757: INFO: Pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.228835ms
Jan 24 20:10:28.849: INFO: Pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106892738s
Jan 24 20:10:30.786: INFO: Pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5": Phase="Running", Reason="", readiness=false. Elapsed: 4.043323081s
Jan 24 20:10:32.777: INFO: Pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03429842s
STEP: Saw pod success 01/24/23 20:10:32.777
Jan 24 20:10:32.777: INFO: Pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5" satisfied condition "Succeeded or Failed"
Jan 24 20:10:32.797: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5 container client-container: <nil>
STEP: delete the pod 01/24/23 20:10:32.813
Jan 24 20:10:32.838: INFO: Waiting for pod downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5 to disappear
Jan 24 20:10:32.845: INFO: Pod downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 20:10:32.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4124" for this suite. 01/24/23 20:10:32.852
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":268,"skipped":4888,"failed":0}
------------------------------
• [SLOW TEST] [6.256 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:10:26.606
    Jan 24 20:10:26.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 20:10:26.609
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:26.668
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:26.68
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:10:26.691
    Jan 24 20:10:26.742: INFO: Waiting up to 5m0s for pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5" in namespace "downward-api-4124" to be "Succeeded or Failed"
    Jan 24 20:10:26.757: INFO: Pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.228835ms
    Jan 24 20:10:28.849: INFO: Pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106892738s
    Jan 24 20:10:30.786: INFO: Pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5": Phase="Running", Reason="", readiness=false. Elapsed: 4.043323081s
    Jan 24 20:10:32.777: INFO: Pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03429842s
    STEP: Saw pod success 01/24/23 20:10:32.777
    Jan 24 20:10:32.777: INFO: Pod "downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5" satisfied condition "Succeeded or Failed"
    Jan 24 20:10:32.797: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5 container client-container: <nil>
    STEP: delete the pod 01/24/23 20:10:32.813
    Jan 24 20:10:32.838: INFO: Waiting for pod downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5 to disappear
    Jan 24 20:10:32.845: INFO: Pod downwardapi-volume-064689b3-f91c-4d7a-9e8d-a8f8848477d5 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 20:10:32.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4124" for this suite. 01/24/23 20:10:32.852
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:10:32.864
Jan 24 20:10:32.864: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 20:10:32.866
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:32.884
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:32.892
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 20:10:32.912
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 20:10:33.863
STEP: Deploying the webhook pod 01/24/23 20:10:33.881
STEP: Wait for the deployment to be ready 01/24/23 20:10:33.91
Jan 24 20:10:33.935: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 01/24/23 20:10:35.959
STEP: Verifying the service has paired with the endpoint 01/24/23 20:10:35.98
Jan 24 20:10:36.982: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 01/24/23 20:10:37.127
STEP: Creating a configMap that does not comply to the validation webhook rules 01/24/23 20:10:37.22
STEP: Deleting the collection of validation webhooks 01/24/23 20:10:37.281
STEP: Creating a configMap that does not comply to the validation webhook rules 01/24/23 20:10:37.378
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:10:37.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9890" for this suite. 01/24/23 20:10:37.434
STEP: Destroying namespace "webhook-9890-markers" for this suite. 01/24/23 20:10:37.457
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":269,"skipped":4888,"failed":0}
------------------------------
• [4.806 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:10:32.864
    Jan 24 20:10:32.864: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 20:10:32.866
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:32.884
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:32.892
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 20:10:32.912
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 20:10:33.863
    STEP: Deploying the webhook pod 01/24/23 20:10:33.881
    STEP: Wait for the deployment to be ready 01/24/23 20:10:33.91
    Jan 24 20:10:33.935: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 01/24/23 20:10:35.959
    STEP: Verifying the service has paired with the endpoint 01/24/23 20:10:35.98
    Jan 24 20:10:36.982: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 01/24/23 20:10:37.127
    STEP: Creating a configMap that does not comply to the validation webhook rules 01/24/23 20:10:37.22
    STEP: Deleting the collection of validation webhooks 01/24/23 20:10:37.281
    STEP: Creating a configMap that does not comply to the validation webhook rules 01/24/23 20:10:37.378
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:10:37.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9890" for this suite. 01/24/23 20:10:37.434
    STEP: Destroying namespace "webhook-9890-markers" for this suite. 01/24/23 20:10:37.457
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:10:37.715
Jan 24 20:10:37.715: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 20:10:37.729
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:37.833
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:37.848
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:10:37.926
Jan 24 20:10:37.969: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4" in namespace "downward-api-4067" to be "Succeeded or Failed"
Jan 24 20:10:37.990: INFO: Pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.11088ms
Jan 24 20:10:40.011: INFO: Pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4": Phase="Running", Reason="", readiness=true. Elapsed: 2.041365048s
Jan 24 20:10:42.009: INFO: Pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4": Phase="Running", Reason="", readiness=false. Elapsed: 4.039367488s
Jan 24 20:10:44.000: INFO: Pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030799845s
STEP: Saw pod success 01/24/23 20:10:44.001
Jan 24 20:10:44.001: INFO: Pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4" satisfied condition "Succeeded or Failed"
Jan 24 20:10:44.028: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4 container client-container: <nil>
STEP: delete the pod 01/24/23 20:10:44.061
Jan 24 20:10:44.194: INFO: Waiting for pod downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4 to disappear
Jan 24 20:10:44.235: INFO: Pod downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 20:10:44.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4067" for this suite. 01/24/23 20:10:44.265
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":270,"skipped":4889,"failed":0}
------------------------------
• [SLOW TEST] [6.602 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:10:37.715
    Jan 24 20:10:37.715: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 20:10:37.729
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:37.833
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:37.848
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:10:37.926
    Jan 24 20:10:37.969: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4" in namespace "downward-api-4067" to be "Succeeded or Failed"
    Jan 24 20:10:37.990: INFO: Pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.11088ms
    Jan 24 20:10:40.011: INFO: Pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4": Phase="Running", Reason="", readiness=true. Elapsed: 2.041365048s
    Jan 24 20:10:42.009: INFO: Pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4": Phase="Running", Reason="", readiness=false. Elapsed: 4.039367488s
    Jan 24 20:10:44.000: INFO: Pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030799845s
    STEP: Saw pod success 01/24/23 20:10:44.001
    Jan 24 20:10:44.001: INFO: Pod "downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4" satisfied condition "Succeeded or Failed"
    Jan 24 20:10:44.028: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4 container client-container: <nil>
    STEP: delete the pod 01/24/23 20:10:44.061
    Jan 24 20:10:44.194: INFO: Waiting for pod downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4 to disappear
    Jan 24 20:10:44.235: INFO: Pod downwardapi-volume-c54b6f9e-6691-4461-a4fb-5f45fce6e9e4 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 20:10:44.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4067" for this suite. 01/24/23 20:10:44.265
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:10:44.435
Jan 24 20:10:44.436: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:10:44.439
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:44.577
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:44.6
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-be5d1b44-2159-41be-a5f9-62bde49f5dda 01/24/23 20:10:44.63
STEP: Creating a pod to test consume secrets 01/24/23 20:10:44.753
Jan 24 20:10:44.821: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407" in namespace "projected-4765" to be "Succeeded or Failed"
Jan 24 20:10:44.871: INFO: Pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407": Phase="Pending", Reason="", readiness=false. Elapsed: 50.608426ms
Jan 24 20:10:46.896: INFO: Pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075661954s
Jan 24 20:10:48.883: INFO: Pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062772453s
Jan 24 20:10:50.886: INFO: Pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.065428977s
STEP: Saw pod success 01/24/23 20:10:50.887
Jan 24 20:10:50.888: INFO: Pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407" satisfied condition "Succeeded or Failed"
Jan 24 20:10:50.901: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407 container projected-secret-volume-test: <nil>
STEP: delete the pod 01/24/23 20:10:50.934
Jan 24 20:10:51.036: INFO: Waiting for pod pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407 to disappear
Jan 24 20:10:51.044: INFO: Pod pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 24 20:10:51.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4765" for this suite. 01/24/23 20:10:51.107
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":271,"skipped":4953,"failed":0}
------------------------------
• [SLOW TEST] [6.717 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:10:44.435
    Jan 24 20:10:44.436: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:10:44.439
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:44.577
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:44.6
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-be5d1b44-2159-41be-a5f9-62bde49f5dda 01/24/23 20:10:44.63
    STEP: Creating a pod to test consume secrets 01/24/23 20:10:44.753
    Jan 24 20:10:44.821: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407" in namespace "projected-4765" to be "Succeeded or Failed"
    Jan 24 20:10:44.871: INFO: Pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407": Phase="Pending", Reason="", readiness=false. Elapsed: 50.608426ms
    Jan 24 20:10:46.896: INFO: Pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075661954s
    Jan 24 20:10:48.883: INFO: Pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062772453s
    Jan 24 20:10:50.886: INFO: Pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.065428977s
    STEP: Saw pod success 01/24/23 20:10:50.887
    Jan 24 20:10:50.888: INFO: Pod "pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407" satisfied condition "Succeeded or Failed"
    Jan 24 20:10:50.901: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407 container projected-secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 20:10:50.934
    Jan 24 20:10:51.036: INFO: Waiting for pod pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407 to disappear
    Jan 24 20:10:51.044: INFO: Pod pod-projected-secrets-ff10ef27-9a58-45d0-b2ad-1c2e4b48d407 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 24 20:10:51.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4765" for this suite. 01/24/23 20:10:51.107
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:10:51.21
Jan 24 20:10:51.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:10:51.22
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:51.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:51.37
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 01/24/23 20:10:51.384
Jan 24 20:10:51.420: INFO: Waiting up to 5m0s for pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac" in namespace "projected-4145" to be "running and ready"
Jan 24 20:10:51.447: INFO: Pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac": Phase="Pending", Reason="", readiness=false. Elapsed: 26.685055ms
Jan 24 20:10:51.447: INFO: The phase of Pod labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:10:53.460: INFO: Pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039870408s
Jan 24 20:10:53.461: INFO: The phase of Pod labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:10:55.465: INFO: Pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac": Phase="Running", Reason="", readiness=true. Elapsed: 4.044112935s
Jan 24 20:10:55.467: INFO: The phase of Pod labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac is Running (Ready = true)
Jan 24 20:10:55.472: INFO: Pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac" satisfied condition "running and ready"
Jan 24 20:10:56.060: INFO: Successfully updated pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 20:10:58.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4145" for this suite. 01/24/23 20:10:58.136
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":272,"skipped":4953,"failed":0}
------------------------------
• [SLOW TEST] [6.958 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:10:51.21
    Jan 24 20:10:51.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:10:51.22
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:51.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:51.37
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 01/24/23 20:10:51.384
    Jan 24 20:10:51.420: INFO: Waiting up to 5m0s for pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac" in namespace "projected-4145" to be "running and ready"
    Jan 24 20:10:51.447: INFO: Pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac": Phase="Pending", Reason="", readiness=false. Elapsed: 26.685055ms
    Jan 24 20:10:51.447: INFO: The phase of Pod labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:10:53.460: INFO: Pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039870408s
    Jan 24 20:10:53.461: INFO: The phase of Pod labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:10:55.465: INFO: Pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac": Phase="Running", Reason="", readiness=true. Elapsed: 4.044112935s
    Jan 24 20:10:55.467: INFO: The phase of Pod labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac is Running (Ready = true)
    Jan 24 20:10:55.472: INFO: Pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac" satisfied condition "running and ready"
    Jan 24 20:10:56.060: INFO: Successfully updated pod "labelsupdated1aca65b-e783-48bb-bad0-26840b3166ac"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 20:10:58.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4145" for this suite. 01/24/23 20:10:58.136
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:10:58.181
Jan 24 20:10:58.182: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename dns 01/24/23 20:10:58.187
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:58.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:58.382
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 01/24/23 20:10:58.408
Jan 24 20:10:58.517: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-5279  98bd5f29-ea0b-4046-914a-7d1cbe630bf7 36203 0 2023-01-24 20:10:58 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-01-24 20:10:58 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gg5kt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gg5kt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jan 24 20:10:58.548: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-5279" to be "running and ready"
Jan 24 20:10:58.598: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 50.140112ms
Jan 24 20:10:58.599: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:11:00.833: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.285390699s
Jan 24 20:11:00.844: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:11:02.683: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 4.134963045s
Jan 24 20:11:02.688: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Jan 24 20:11:02.688: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 01/24/23 20:11:02.689
Jan 24 20:11:02.689: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-5279 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 20:11:02.689: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 20:11:02.695: INFO: ExecWithOptions: Clientset creation
Jan 24 20:11:02.695: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/dns-5279/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 01/24/23 20:11:03.298
Jan 24 20:11:03.298: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-5279 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 20:11:03.298: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 20:11:03.360: INFO: ExecWithOptions: Clientset creation
Jan 24 20:11:03.361: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/dns-5279/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jan 24 20:11:03.741: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 24 20:11:03.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5279" for this suite. 01/24/23 20:11:03.964
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":273,"skipped":4953,"failed":0}
------------------------------
• [SLOW TEST] [5.941 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:10:58.181
    Jan 24 20:10:58.182: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename dns 01/24/23 20:10:58.187
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:10:58.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:10:58.382
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 01/24/23 20:10:58.408
    Jan 24 20:10:58.517: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-5279  98bd5f29-ea0b-4046-914a-7d1cbe630bf7 36203 0 2023-01-24 20:10:58 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-01-24 20:10:58 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gg5kt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gg5kt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Jan 24 20:10:58.548: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-5279" to be "running and ready"
    Jan 24 20:10:58.598: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 50.140112ms
    Jan 24 20:10:58.599: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:11:00.833: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.285390699s
    Jan 24 20:11:00.844: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:11:02.683: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 4.134963045s
    Jan 24 20:11:02.688: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Jan 24 20:11:02.688: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 01/24/23 20:11:02.689
    Jan 24 20:11:02.689: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-5279 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 20:11:02.689: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 20:11:02.695: INFO: ExecWithOptions: Clientset creation
    Jan 24 20:11:02.695: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/dns-5279/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 01/24/23 20:11:03.298
    Jan 24 20:11:03.298: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-5279 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 20:11:03.298: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 20:11:03.360: INFO: ExecWithOptions: Clientset creation
    Jan 24 20:11:03.361: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/dns-5279/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Jan 24 20:11:03.741: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 24 20:11:03.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5279" for this suite. 01/24/23 20:11:03.964
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:11:04.133
Jan 24 20:11:04.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename tables 01/24/23 20:11:04.137
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:04.443
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:04.469
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Jan 24 20:11:04.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-7574" for this suite. 01/24/23 20:11:04.551
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":274,"skipped":4964,"failed":0}
------------------------------
• [0.444 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:11:04.133
    Jan 24 20:11:04.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename tables 01/24/23 20:11:04.137
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:04.443
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:04.469
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Jan 24 20:11:04.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-7574" for this suite. 01/24/23 20:11:04.551
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:11:04.579
Jan 24 20:11:04.579: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename var-expansion 01/24/23 20:11:04.593
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:04.819
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:04.838
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 01/24/23 20:11:04.933
Jan 24 20:11:05.100: INFO: Waiting up to 5m0s for pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d" in namespace "var-expansion-9724" to be "Succeeded or Failed"
Jan 24 20:11:05.361: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 260.657912ms
Jan 24 20:11:07.376: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.275704648s
Jan 24 20:11:09.393: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.292378248s
Jan 24 20:11:11.435: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.334435434s
Jan 24 20:11:13.376: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.275997671s
STEP: Saw pod success 01/24/23 20:11:13.376
Jan 24 20:11:13.377: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d" satisfied condition "Succeeded or Failed"
Jan 24 20:11:13.386: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d container dapi-container: <nil>
STEP: delete the pod 01/24/23 20:11:13.407
Jan 24 20:11:13.451: INFO: Waiting for pod var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d to disappear
Jan 24 20:11:13.466: INFO: Pod var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 24 20:11:13.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9724" for this suite. 01/24/23 20:11:13.482
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":275,"skipped":4966,"failed":0}
------------------------------
• [SLOW TEST] [8.936 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:11:04.579
    Jan 24 20:11:04.579: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename var-expansion 01/24/23 20:11:04.593
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:04.819
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:04.838
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 01/24/23 20:11:04.933
    Jan 24 20:11:05.100: INFO: Waiting up to 5m0s for pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d" in namespace "var-expansion-9724" to be "Succeeded or Failed"
    Jan 24 20:11:05.361: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 260.657912ms
    Jan 24 20:11:07.376: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.275704648s
    Jan 24 20:11:09.393: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.292378248s
    Jan 24 20:11:11.435: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.334435434s
    Jan 24 20:11:13.376: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.275997671s
    STEP: Saw pod success 01/24/23 20:11:13.376
    Jan 24 20:11:13.377: INFO: Pod "var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d" satisfied condition "Succeeded or Failed"
    Jan 24 20:11:13.386: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d container dapi-container: <nil>
    STEP: delete the pod 01/24/23 20:11:13.407
    Jan 24 20:11:13.451: INFO: Waiting for pod var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d to disappear
    Jan 24 20:11:13.466: INFO: Pod var-expansion-3d3a4c2b-81b9-45ed-a0c6-24931c6a9a8d no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 24 20:11:13.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-9724" for this suite. 01/24/23 20:11:13.482
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:11:13.519
Jan 24 20:11:13.520: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename statefulset 01/24/23 20:11:13.525
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:13.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:13.629
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7454 01/24/23 20:11:13.653
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-7454 01/24/23 20:11:13.699
Jan 24 20:11:13.775: INFO: Found 0 stateful pods, waiting for 1
Jan 24 20:11:23.806: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 01/24/23 20:11:23.831
STEP: Getting /status 01/24/23 20:11:23.862
Jan 24 20:11:23.882: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 01/24/23 20:11:23.882
Jan 24 20:11:23.934: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 01/24/23 20:11:23.934
Jan 24 20:11:23.946: INFO: Observed &StatefulSet event: ADDED
Jan 24 20:11:23.947: INFO: Found Statefulset ss in namespace statefulset-7454 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jan 24 20:11:23.948: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 01/24/23 20:11:23.95
Jan 24 20:11:23.953: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jan 24 20:11:24.030: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 01/24/23 20:11:24.03
Jan 24 20:11:24.069: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 24 20:11:24.069: INFO: Deleting all statefulset in ns statefulset-7454
Jan 24 20:11:24.089: INFO: Scaling statefulset ss to 0
Jan 24 20:11:34.243: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 20:11:34.248: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 24 20:11:34.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7454" for this suite. 01/24/23 20:11:34.283
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":276,"skipped":4979,"failed":0}
------------------------------
• [SLOW TEST] [20.769 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:11:13.519
    Jan 24 20:11:13.520: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename statefulset 01/24/23 20:11:13.525
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:13.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:13.629
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7454 01/24/23 20:11:13.653
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-7454 01/24/23 20:11:13.699
    Jan 24 20:11:13.775: INFO: Found 0 stateful pods, waiting for 1
    Jan 24 20:11:23.806: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 01/24/23 20:11:23.831
    STEP: Getting /status 01/24/23 20:11:23.862
    Jan 24 20:11:23.882: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 01/24/23 20:11:23.882
    Jan 24 20:11:23.934: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 01/24/23 20:11:23.934
    Jan 24 20:11:23.946: INFO: Observed &StatefulSet event: ADDED
    Jan 24 20:11:23.947: INFO: Found Statefulset ss in namespace statefulset-7454 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jan 24 20:11:23.948: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 01/24/23 20:11:23.95
    Jan 24 20:11:23.953: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Jan 24 20:11:24.030: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 01/24/23 20:11:24.03
    Jan 24 20:11:24.069: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 24 20:11:24.069: INFO: Deleting all statefulset in ns statefulset-7454
    Jan 24 20:11:24.089: INFO: Scaling statefulset ss to 0
    Jan 24 20:11:34.243: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 20:11:34.248: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 24 20:11:34.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7454" for this suite. 01/24/23 20:11:34.283
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:11:34.293
Jan 24 20:11:34.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename watch 01/24/23 20:11:34.295
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:34.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:34.324
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 01/24/23 20:11:34.328
STEP: creating a new configmap 01/24/23 20:11:34.33
STEP: modifying the configmap once 01/24/23 20:11:34.338
STEP: closing the watch once it receives two notifications 01/24/23 20:11:34.348
Jan 24 20:11:34.349: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5115  d2c187e8-3312-4440-9b39-42a0401bb30a 36360 0 2023-01-24 20:11:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-24 20:11:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 20:11:34.349: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5115  d2c187e8-3312-4440-9b39-42a0401bb30a 36361 0 2023-01-24 20:11:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-24 20:11:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 01/24/23 20:11:34.35
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 01/24/23 20:11:34.36
STEP: deleting the configmap 01/24/23 20:11:34.363
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 01/24/23 20:11:34.368
Jan 24 20:11:34.368: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5115  d2c187e8-3312-4440-9b39-42a0401bb30a 36362 0 2023-01-24 20:11:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-24 20:11:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jan 24 20:11:34.368: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5115  d2c187e8-3312-4440-9b39-42a0401bb30a 36363 0 2023-01-24 20:11:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-24 20:11:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jan 24 20:11:34.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5115" for this suite. 01/24/23 20:11:34.373
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":277,"skipped":4994,"failed":0}
------------------------------
• [0.086 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:11:34.293
    Jan 24 20:11:34.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename watch 01/24/23 20:11:34.295
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:34.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:34.324
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 01/24/23 20:11:34.328
    STEP: creating a new configmap 01/24/23 20:11:34.33
    STEP: modifying the configmap once 01/24/23 20:11:34.338
    STEP: closing the watch once it receives two notifications 01/24/23 20:11:34.348
    Jan 24 20:11:34.349: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5115  d2c187e8-3312-4440-9b39-42a0401bb30a 36360 0 2023-01-24 20:11:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-24 20:11:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 20:11:34.349: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5115  d2c187e8-3312-4440-9b39-42a0401bb30a 36361 0 2023-01-24 20:11:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-24 20:11:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 01/24/23 20:11:34.35
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 01/24/23 20:11:34.36
    STEP: deleting the configmap 01/24/23 20:11:34.363
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 01/24/23 20:11:34.368
    Jan 24 20:11:34.368: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5115  d2c187e8-3312-4440-9b39-42a0401bb30a 36362 0 2023-01-24 20:11:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-24 20:11:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Jan 24 20:11:34.368: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5115  d2c187e8-3312-4440-9b39-42a0401bb30a 36363 0 2023-01-24 20:11:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-01-24 20:11:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jan 24 20:11:34.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-5115" for this suite. 01/24/23 20:11:34.373
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:11:34.381
Jan 24 20:11:34.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename daemonsets 01/24/23 20:11:34.383
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:34.406
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:34.41
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Jan 24 20:11:34.433: INFO: Create a RollingUpdate DaemonSet
Jan 24 20:11:34.440: INFO: Check that daemon pods launch on every node of the cluster
Jan 24 20:11:34.450: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 20:11:34.450: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:11:35.468: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 20:11:35.468: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:11:36.469: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 20:11:36.469: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:11:37.476: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 24 20:11:37.477: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
Jan 24 20:11:37.478: INFO: Update the DaemonSet to trigger a rollout
Jan 24 20:11:37.512: INFO: Updating DaemonSet daemon-set
Jan 24 20:11:41.598: INFO: Roll back the DaemonSet before rollout is complete
Jan 24 20:11:41.617: INFO: Updating DaemonSet daemon-set
Jan 24 20:11:41.617: INFO: Make sure DaemonSet rollback is complete
Jan 24 20:11:41.628: INFO: Wrong image for pod: daemon-set-ptlpd. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Jan 24 20:11:41.628: INFO: Pod daemon-set-ptlpd is not available
Jan 24 20:11:47.687: INFO: Pod daemon-set-b995l is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 01/24/23 20:11:47.733
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-55, will wait for the garbage collector to delete the pods 01/24/23 20:11:47.733
Jan 24 20:11:47.837: INFO: Deleting DaemonSet.extensions daemon-set took: 18.671843ms
Jan 24 20:11:47.937: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.461307ms
Jan 24 20:11:53.447: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 20:11:53.448: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jan 24 20:11:53.456: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"36500"},"items":null}

Jan 24 20:11:53.464: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"36500"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 24 20:11:53.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-55" for this suite. 01/24/23 20:11:53.532
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":278,"skipped":5008,"failed":0}
------------------------------
• [SLOW TEST] [19.180 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:11:34.381
    Jan 24 20:11:34.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename daemonsets 01/24/23 20:11:34.383
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:34.406
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:34.41
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Jan 24 20:11:34.433: INFO: Create a RollingUpdate DaemonSet
    Jan 24 20:11:34.440: INFO: Check that daemon pods launch on every node of the cluster
    Jan 24 20:11:34.450: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 20:11:34.450: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:11:35.468: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 20:11:35.468: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:11:36.469: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 20:11:36.469: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:11:37.476: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 24 20:11:37.477: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    Jan 24 20:11:37.478: INFO: Update the DaemonSet to trigger a rollout
    Jan 24 20:11:37.512: INFO: Updating DaemonSet daemon-set
    Jan 24 20:11:41.598: INFO: Roll back the DaemonSet before rollout is complete
    Jan 24 20:11:41.617: INFO: Updating DaemonSet daemon-set
    Jan 24 20:11:41.617: INFO: Make sure DaemonSet rollback is complete
    Jan 24 20:11:41.628: INFO: Wrong image for pod: daemon-set-ptlpd. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Jan 24 20:11:41.628: INFO: Pod daemon-set-ptlpd is not available
    Jan 24 20:11:47.687: INFO: Pod daemon-set-b995l is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 01/24/23 20:11:47.733
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-55, will wait for the garbage collector to delete the pods 01/24/23 20:11:47.733
    Jan 24 20:11:47.837: INFO: Deleting DaemonSet.extensions daemon-set took: 18.671843ms
    Jan 24 20:11:47.937: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.461307ms
    Jan 24 20:11:53.447: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 20:11:53.448: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Jan 24 20:11:53.456: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"36500"},"items":null}

    Jan 24 20:11:53.464: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"36500"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 20:11:53.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-55" for this suite. 01/24/23 20:11:53.532
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:11:53.583
Jan 24 20:11:53.584: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 20:11:53.586
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:53.659
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:53.671
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-f01f144b-85d1-4a53-bb53-0089c23bd51a 01/24/23 20:11:53.688
STEP: Creating a pod to test consume configMaps 01/24/23 20:11:53.705
Jan 24 20:11:53.729: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578" in namespace "configmap-2651" to be "Succeeded or Failed"
Jan 24 20:11:53.782: INFO: Pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578": Phase="Pending", Reason="", readiness=false. Elapsed: 51.695451ms
Jan 24 20:11:55.808: INFO: Pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077515139s
Jan 24 20:11:57.795: INFO: Pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578": Phase="Running", Reason="", readiness=false. Elapsed: 4.064130766s
Jan 24 20:11:59.826: INFO: Pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.095922038s
STEP: Saw pod success 01/24/23 20:11:59.827
Jan 24 20:11:59.827: INFO: Pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578" satisfied condition "Succeeded or Failed"
Jan 24 20:11:59.852: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578 container configmap-volume-test: <nil>
STEP: delete the pod 01/24/23 20:11:59.878
Jan 24 20:11:59.933: INFO: Waiting for pod pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578 to disappear
Jan 24 20:11:59.942: INFO: Pod pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 20:11:59.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2651" for this suite. 01/24/23 20:11:59.977
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":279,"skipped":5019,"failed":0}
------------------------------
• [SLOW TEST] [6.433 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:11:53.583
    Jan 24 20:11:53.584: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 20:11:53.586
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:11:53.659
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:11:53.671
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-f01f144b-85d1-4a53-bb53-0089c23bd51a 01/24/23 20:11:53.688
    STEP: Creating a pod to test consume configMaps 01/24/23 20:11:53.705
    Jan 24 20:11:53.729: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578" in namespace "configmap-2651" to be "Succeeded or Failed"
    Jan 24 20:11:53.782: INFO: Pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578": Phase="Pending", Reason="", readiness=false. Elapsed: 51.695451ms
    Jan 24 20:11:55.808: INFO: Pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077515139s
    Jan 24 20:11:57.795: INFO: Pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578": Phase="Running", Reason="", readiness=false. Elapsed: 4.064130766s
    Jan 24 20:11:59.826: INFO: Pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.095922038s
    STEP: Saw pod success 01/24/23 20:11:59.827
    Jan 24 20:11:59.827: INFO: Pod "pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578" satisfied condition "Succeeded or Failed"
    Jan 24 20:11:59.852: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578 container configmap-volume-test: <nil>
    STEP: delete the pod 01/24/23 20:11:59.878
    Jan 24 20:11:59.933: INFO: Waiting for pod pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578 to disappear
    Jan 24 20:11:59.942: INFO: Pod pod-configmaps-3ab51fb7-273f-43f8-b58f-43b3c7165578 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 20:11:59.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2651" for this suite. 01/24/23 20:11:59.977
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:12:00.017
Jan 24 20:12:00.020: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 20:12:00.067
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:00.384
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:00.534
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 01/24/23 20:12:00.548
Jan 24 20:12:00.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 create -f -'
Jan 24 20:12:03.630: INFO: stderr: ""
Jan 24 20:12:03.630: INFO: stdout: "pod/pause created\n"
Jan 24 20:12:03.630: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 24 20:12:03.630: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-465" to be "running and ready"
Jan 24 20:12:03.642: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.823437ms
Jan 24 20:12:03.642: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'vikash-v125latest-conf-71087' to be 'Running' but was 'Pending'
Jan 24 20:12:05.676: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045323869s
Jan 24 20:12:05.676: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'vikash-v125latest-conf-71087' to be 'Running' but was 'Pending'
Jan 24 20:12:07.656: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.02545182s
Jan 24 20:12:07.656: INFO: Pod "pause" satisfied condition "running and ready"
Jan 24 20:12:07.656: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 01/24/23 20:12:07.657
Jan 24 20:12:07.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 label pods pause testing-label=testing-label-value'
Jan 24 20:12:08.023: INFO: stderr: ""
Jan 24 20:12:08.023: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 01/24/23 20:12:08.023
Jan 24 20:12:08.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 get pod pause -L testing-label'
Jan 24 20:12:08.791: INFO: stderr: ""
Jan 24 20:12:08.791: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod 01/24/23 20:12:08.791
Jan 24 20:12:08.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 label pods pause testing-label-'
Jan 24 20:12:09.479: INFO: stderr: ""
Jan 24 20:12:09.479: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 01/24/23 20:12:09.479
Jan 24 20:12:09.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 get pod pause -L testing-label'
Jan 24 20:12:10.166: INFO: stderr: ""
Jan 24 20:12:10.167: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          7s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 01/24/23 20:12:10.168
Jan 24 20:12:10.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 delete --grace-period=0 --force -f -'
Jan 24 20:12:14.164: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 24 20:12:14.164: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 24 20:12:14.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 get rc,svc -l name=pause --no-headers'
Jan 24 20:12:17.130: INFO: stderr: "No resources found in kubectl-465 namespace.\n"
Jan 24 20:12:17.130: INFO: stdout: ""
Jan 24 20:12:17.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 24 20:12:17.525: INFO: stderr: ""
Jan 24 20:12:17.525: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 20:12:17.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-465" for this suite. 01/24/23 20:12:17.539
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":280,"skipped":5020,"failed":0}
------------------------------
• [SLOW TEST] [17.549 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:12:00.017
    Jan 24 20:12:00.020: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 20:12:00.067
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:00.384
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:00.534
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 01/24/23 20:12:00.548
    Jan 24 20:12:00.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 create -f -'
    Jan 24 20:12:03.630: INFO: stderr: ""
    Jan 24 20:12:03.630: INFO: stdout: "pod/pause created\n"
    Jan 24 20:12:03.630: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Jan 24 20:12:03.630: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-465" to be "running and ready"
    Jan 24 20:12:03.642: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.823437ms
    Jan 24 20:12:03.642: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'vikash-v125latest-conf-71087' to be 'Running' but was 'Pending'
    Jan 24 20:12:05.676: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045323869s
    Jan 24 20:12:05.676: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'vikash-v125latest-conf-71087' to be 'Running' but was 'Pending'
    Jan 24 20:12:07.656: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.02545182s
    Jan 24 20:12:07.656: INFO: Pod "pause" satisfied condition "running and ready"
    Jan 24 20:12:07.656: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 01/24/23 20:12:07.657
    Jan 24 20:12:07.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 label pods pause testing-label=testing-label-value'
    Jan 24 20:12:08.023: INFO: stderr: ""
    Jan 24 20:12:08.023: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 01/24/23 20:12:08.023
    Jan 24 20:12:08.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 get pod pause -L testing-label'
    Jan 24 20:12:08.791: INFO: stderr: ""
    Jan 24 20:12:08.791: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 01/24/23 20:12:08.791
    Jan 24 20:12:08.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 label pods pause testing-label-'
    Jan 24 20:12:09.479: INFO: stderr: ""
    Jan 24 20:12:09.479: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 01/24/23 20:12:09.479
    Jan 24 20:12:09.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 get pod pause -L testing-label'
    Jan 24 20:12:10.166: INFO: stderr: ""
    Jan 24 20:12:10.167: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          7s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 01/24/23 20:12:10.168
    Jan 24 20:12:10.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 delete --grace-period=0 --force -f -'
    Jan 24 20:12:14.164: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 24 20:12:14.164: INFO: stdout: "pod \"pause\" force deleted\n"
    Jan 24 20:12:14.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 get rc,svc -l name=pause --no-headers'
    Jan 24 20:12:17.130: INFO: stderr: "No resources found in kubectl-465 namespace.\n"
    Jan 24 20:12:17.130: INFO: stdout: ""
    Jan 24 20:12:17.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-465 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Jan 24 20:12:17.525: INFO: stderr: ""
    Jan 24 20:12:17.525: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 20:12:17.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-465" for this suite. 01/24/23 20:12:17.539
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:12:17.569
Jan 24 20:12:17.569: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename pods 01/24/23 20:12:17.573
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:17.674
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:17.702
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Jan 24 20:12:17.719: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: creating the pod 01/24/23 20:12:17.725
STEP: submitting the pod to kubernetes 01/24/23 20:12:17.725
Jan 24 20:12:17.805: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b" in namespace "pods-4101" to be "running and ready"
Jan 24 20:12:17.828: INFO: Pod "pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.787712ms
Jan 24 20:12:17.828: INFO: The phase of Pod pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:12:19.907: INFO: Pod "pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101212955s
Jan 24 20:12:19.907: INFO: The phase of Pod pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:12:22.074: INFO: Pod "pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b": Phase="Running", Reason="", readiness=true. Elapsed: 4.268728595s
Jan 24 20:12:22.074: INFO: The phase of Pod pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b is Running (Ready = true)
Jan 24 20:12:22.074: INFO: Pod "pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Jan 24 20:12:22.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4101" for this suite. 01/24/23 20:12:22.842
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":281,"skipped":5031,"failed":0}
------------------------------
• [SLOW TEST] [5.361 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:12:17.569
    Jan 24 20:12:17.569: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename pods 01/24/23 20:12:17.573
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:17.674
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:17.702
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Jan 24 20:12:17.719: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: creating the pod 01/24/23 20:12:17.725
    STEP: submitting the pod to kubernetes 01/24/23 20:12:17.725
    Jan 24 20:12:17.805: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b" in namespace "pods-4101" to be "running and ready"
    Jan 24 20:12:17.828: INFO: Pod "pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.787712ms
    Jan 24 20:12:17.828: INFO: The phase of Pod pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:12:19.907: INFO: Pod "pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101212955s
    Jan 24 20:12:19.907: INFO: The phase of Pod pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:12:22.074: INFO: Pod "pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b": Phase="Running", Reason="", readiness=true. Elapsed: 4.268728595s
    Jan 24 20:12:22.074: INFO: The phase of Pod pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b is Running (Ready = true)
    Jan 24 20:12:22.074: INFO: Pod "pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Jan 24 20:12:22.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4101" for this suite. 01/24/23 20:12:22.842
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:12:23.082
Jan 24 20:12:23.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename containers 01/24/23 20:12:23.133
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:23.5
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:23.541
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 01/24/23 20:12:23.616
Jan 24 20:12:23.741: INFO: Waiting up to 5m0s for pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709" in namespace "containers-2812" to be "Succeeded or Failed"
Jan 24 20:12:24.018: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709": Phase="Pending", Reason="", readiness=false. Elapsed: 239.794898ms
Jan 24 20:12:26.157: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709": Phase="Pending", Reason="", readiness=false. Elapsed: 2.379324788s
Jan 24 20:12:28.086: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709": Phase="Pending", Reason="", readiness=false. Elapsed: 4.307608967s
Jan 24 20:12:30.170: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709": Phase="Pending", Reason="", readiness=false. Elapsed: 6.392385475s
Jan 24 20:12:32.091: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.313030606s
STEP: Saw pod success 01/24/23 20:12:32.092
Jan 24 20:12:32.096: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709" satisfied condition "Succeeded or Failed"
Jan 24 20:12:32.109: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 20:12:32.129
Jan 24 20:12:32.180: INFO: Waiting for pod client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709 to disappear
Jan 24 20:12:32.191: INFO: Pod client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Jan 24 20:12:32.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2812" for this suite. 01/24/23 20:12:32.204
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":282,"skipped":5072,"failed":0}
------------------------------
• [SLOW TEST] [9.143 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:12:23.082
    Jan 24 20:12:23.082: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename containers 01/24/23 20:12:23.133
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:23.5
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:23.541
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 01/24/23 20:12:23.616
    Jan 24 20:12:23.741: INFO: Waiting up to 5m0s for pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709" in namespace "containers-2812" to be "Succeeded or Failed"
    Jan 24 20:12:24.018: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709": Phase="Pending", Reason="", readiness=false. Elapsed: 239.794898ms
    Jan 24 20:12:26.157: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709": Phase="Pending", Reason="", readiness=false. Elapsed: 2.379324788s
    Jan 24 20:12:28.086: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709": Phase="Pending", Reason="", readiness=false. Elapsed: 4.307608967s
    Jan 24 20:12:30.170: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709": Phase="Pending", Reason="", readiness=false. Elapsed: 6.392385475s
    Jan 24 20:12:32.091: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.313030606s
    STEP: Saw pod success 01/24/23 20:12:32.092
    Jan 24 20:12:32.096: INFO: Pod "client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709" satisfied condition "Succeeded or Failed"
    Jan 24 20:12:32.109: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 20:12:32.129
    Jan 24 20:12:32.180: INFO: Waiting for pod client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709 to disappear
    Jan 24 20:12:32.191: INFO: Pod client-containers-34d23e74-c458-4dc0-94e2-3bbd8b6c3709 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Jan 24 20:12:32.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-2812" for this suite. 01/24/23 20:12:32.204
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:12:32.226
Jan 24 20:12:32.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sched-pred 01/24/23 20:12:32.23
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:32.3
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:32.312
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jan 24 20:12:32.326: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 24 20:12:32.364: INFO: Waiting for terminating namespaces to be deleted...
Jan 24 20:12:32.382: INFO: 
Logging pods the apiserver thinks is on node vikash-v125latest-conf-59870 before test
Jan 24 20:12:32.412: INFO: haproxy-ingress-cb855dc7c-smnf7 from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container haproxy-ingress ready: true, restart count 0
Jan 24 20:12:32.412: INFO: ingress-default-backend-6f4477b7bc-qg2sz from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container ingress-default-backend ready: true, restart count 0
Jan 24 20:12:32.412: INFO: calico-kube-controllers-74677b4c5f-zd5w8 from kube-system started at 2023-01-24 18:20:11 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 24 20:12:32.412: INFO: calico-node-45c9d from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container calico-node ready: true, restart count 0
Jan 24 20:12:32.412: INFO: coredns-94487f57-9zlwt from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container coredns ready: true, restart count 0
Jan 24 20:12:32.412: INFO: coredns-94487f57-qldwh from kube-system started at 2023-01-24 18:34:25 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container coredns ready: true, restart count 0
Jan 24 20:12:32.412: INFO: kyverno-operator-5c87dbd458-txhlw from nirmata started at 2023-01-24 18:22:35 +0000 UTC (2 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jan 24 20:12:32.412: INFO: 	Container manager ready: true, restart count 0
Jan 24 20:12:32.412: INFO: nirmata-cni-installer-6skzt from nirmata started at 2023-01-24 08:32:34 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container install-cni ready: true, restart count 0
Jan 24 20:12:32.412: INFO: otel-agent-6dfc8d44b6-6kj5q from nirmata started at 2023-01-24 18:22:32 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container otel-agent ready: true, restart count 0
Jan 24 20:12:32.412: INFO: sonobuoy from sonobuoy started at 2023-01-24 18:32:49 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 24 20:12:32.412: INFO: sonobuoy-e2e-job-d94c6e71d257417d from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container e2e ready: true, restart count 0
Jan 24 20:12:32.412: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 20:12:32.412: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 20:12:32.412: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 20:12:32.412: INFO: 	Container systemd-logs ready: true, restart count 0
Jan 24 20:12:32.412: INFO: 
Logging pods the apiserver thinks is on node vikash-v125latest-conf-71087 before test
Jan 24 20:12:32.437: INFO: calico-node-kfjch from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.438: INFO: 	Container calico-node ready: true, restart count 0
Jan 24 20:12:32.439: INFO: metrics-server-696f4844bb-xklrk from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.439: INFO: 	Container metrics-server ready: true, restart count 0
Jan 24 20:12:32.439: INFO: nirmata-cni-installer-swjzc from nirmata started at 2023-01-24 18:34:55 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.439: INFO: 	Container install-cni ready: true, restart count 0
Jan 24 20:12:32.439: INFO: nirmata-kube-controller-df864cd5c-bz5gj from nirmata started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.439: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
Jan 24 20:12:32.439: INFO: pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b from pods-4101 started at 2023-01-24 20:12:17 +0000 UTC (1 container statuses recorded)
Jan 24 20:12:32.439: INFO: 	Container main ready: true, restart count 0
Jan 24 20:12:32.439: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-x86sk from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
Jan 24 20:12:32.439: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 24 20:12:32.439: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node vikash-v125latest-conf-59870 01/24/23 20:12:32.579
STEP: verifying the node has the label node vikash-v125latest-conf-71087 01/24/23 20:12:32.799
Jan 24 20:12:33.166: INFO: Pod haproxy-ingress-cb855dc7c-smnf7 requesting resource cpu=10m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.166: INFO: Pod ingress-default-backend-6f4477b7bc-qg2sz requesting resource cpu=250m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.166: INFO: Pod calico-kube-controllers-74677b4c5f-zd5w8 requesting resource cpu=0m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.166: INFO: Pod calico-node-45c9d requesting resource cpu=250m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.166: INFO: Pod calico-node-kfjch requesting resource cpu=250m on Node vikash-v125latest-conf-71087
Jan 24 20:12:33.166: INFO: Pod coredns-94487f57-9zlwt requesting resource cpu=100m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.166: INFO: Pod coredns-94487f57-qldwh requesting resource cpu=100m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.166: INFO: Pod metrics-server-696f4844bb-xklrk requesting resource cpu=100m on Node vikash-v125latest-conf-71087
Jan 24 20:12:33.166: INFO: Pod kyverno-operator-5c87dbd458-txhlw requesting resource cpu=15m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.167: INFO: Pod nirmata-cni-installer-6skzt requesting resource cpu=250m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.167: INFO: Pod nirmata-cni-installer-swjzc requesting resource cpu=250m on Node vikash-v125latest-conf-71087
Jan 24 20:12:33.167: INFO: Pod nirmata-kube-controller-df864cd5c-bz5gj requesting resource cpu=250m on Node vikash-v125latest-conf-71087
Jan 24 20:12:33.167: INFO: Pod otel-agent-6dfc8d44b6-6kj5q requesting resource cpu=100m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.167: INFO: Pod pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b requesting resource cpu=0m on Node vikash-v125latest-conf-71087
Jan 24 20:12:33.167: INFO: Pod sonobuoy requesting resource cpu=0m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.167: INFO: Pod sonobuoy-e2e-job-d94c6e71d257417d requesting resource cpu=0m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.167: INFO: Pod sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq requesting resource cpu=0m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.167: INFO: Pod sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-x86sk requesting resource cpu=0m on Node vikash-v125latest-conf-71087
STEP: Starting Pods to consume most of the cluster CPU. 01/24/23 20:12:33.167
Jan 24 20:12:33.167: INFO: Creating a pod which consumes cpu=2205m on Node vikash-v125latest-conf-71087
Jan 24 20:12:33.205: INFO: Creating a pod which consumes cpu=2047m on Node vikash-v125latest-conf-59870
Jan 24 20:12:33.228: INFO: Waiting up to 5m0s for pod "filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2" in namespace "sched-pred-2070" to be "running"
Jan 24 20:12:33.258: INFO: Pod "filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2": Phase="Pending", Reason="", readiness=false. Elapsed: 29.779067ms
Jan 24 20:12:35.350: INFO: Pod "filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121594627s
Jan 24 20:12:37.288: INFO: Pod "filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2": Phase="Running", Reason="", readiness=true. Elapsed: 4.059391059s
Jan 24 20:12:37.288: INFO: Pod "filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2" satisfied condition "running"
Jan 24 20:12:37.288: INFO: Waiting up to 5m0s for pod "filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668" in namespace "sched-pred-2070" to be "running"
Jan 24 20:12:37.309: INFO: Pod "filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668": Phase="Pending", Reason="", readiness=false. Elapsed: 20.686002ms
Jan 24 20:12:39.320: INFO: Pod "filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668": Phase="Running", Reason="", readiness=true. Elapsed: 2.032251974s
Jan 24 20:12:39.320: INFO: Pod "filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 01/24/23 20:12:39.32
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2.173d57c81334cfeb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2070/filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2 to vikash-v125latest-conf-71087] 01/24/23 20:12:39.336
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2.173d57c8a013b06e], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 01/24/23 20:12:39.336
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2.173d57c8a90e0e38], Reason = [Created], Message = [Created container filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2] 01/24/23 20:12:39.337
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2.173d57c8c8123f9d], Reason = [Started], Message = [Started container filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2] 01/24/23 20:12:39.337
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668.173d57c8158ef6e4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2070/filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668 to vikash-v125latest-conf-59870] 01/24/23 20:12:39.337
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668.173d57c908a8bbad], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 01/24/23 20:12:39.338
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668.173d57c912b2b4d0], Reason = [Created], Message = [Created container filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668] 01/24/23 20:12:39.339
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668.173d57c9578f3319], Reason = [Started], Message = [Started container filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668] 01/24/23 20:12:39.34
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.173d57c97dd46b68], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] 01/24/23 20:12:39.379
STEP: removing the label node off the node vikash-v125latest-conf-59870 01/24/23 20:12:40.399
STEP: verifying the node doesn't have the label node 01/24/23 20:12:40.517
STEP: removing the label node off the node vikash-v125latest-conf-71087 01/24/23 20:12:40.532
STEP: verifying the node doesn't have the label node 01/24/23 20:12:40.648
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Jan 24 20:12:40.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2070" for this suite. 01/24/23 20:12:41.055
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":283,"skipped":5072,"failed":0}
------------------------------
• [SLOW TEST] [8.867 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:12:32.226
    Jan 24 20:12:32.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sched-pred 01/24/23 20:12:32.23
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:32.3
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:32.312
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Jan 24 20:12:32.326: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Jan 24 20:12:32.364: INFO: Waiting for terminating namespaces to be deleted...
    Jan 24 20:12:32.382: INFO: 
    Logging pods the apiserver thinks is on node vikash-v125latest-conf-59870 before test
    Jan 24 20:12:32.412: INFO: haproxy-ingress-cb855dc7c-smnf7 from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container haproxy-ingress ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: ingress-default-backend-6f4477b7bc-qg2sz from ingress-haproxy started at 2023-01-24 18:22:31 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container ingress-default-backend ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: calico-kube-controllers-74677b4c5f-zd5w8 from kube-system started at 2023-01-24 18:20:11 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: calico-node-45c9d from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container calico-node ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: coredns-94487f57-9zlwt from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container coredns ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: coredns-94487f57-qldwh from kube-system started at 2023-01-24 18:34:25 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container coredns ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: kyverno-operator-5c87dbd458-txhlw from nirmata started at 2023-01-24 18:22:35 +0000 UTC (2 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: 	Container manager ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: nirmata-cni-installer-6skzt from nirmata started at 2023-01-24 08:32:34 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container install-cni ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: otel-agent-6dfc8d44b6-6kj5q from nirmata started at 2023-01-24 18:22:32 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container otel-agent ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: sonobuoy from sonobuoy started at 2023-01-24 18:32:49 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: sonobuoy-e2e-job-d94c6e71d257417d from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container e2e ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 20:12:32.412: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: 	Container systemd-logs ready: true, restart count 0
    Jan 24 20:12:32.412: INFO: 
    Logging pods the apiserver thinks is on node vikash-v125latest-conf-71087 before test
    Jan 24 20:12:32.437: INFO: calico-node-kfjch from kube-system started at 2023-01-24 18:20:09 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.438: INFO: 	Container calico-node ready: true, restart count 0
    Jan 24 20:12:32.439: INFO: metrics-server-696f4844bb-xklrk from kube-system started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.439: INFO: 	Container metrics-server ready: true, restart count 0
    Jan 24 20:12:32.439: INFO: nirmata-cni-installer-swjzc from nirmata started at 2023-01-24 18:34:55 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.439: INFO: 	Container install-cni ready: true, restart count 0
    Jan 24 20:12:32.439: INFO: nirmata-kube-controller-df864cd5c-bz5gj from nirmata started at 2023-01-24 18:34:24 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.439: INFO: 	Container nirmata-kube-controller ready: true, restart count 0
    Jan 24 20:12:32.439: INFO: pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b from pods-4101 started at 2023-01-24 20:12:17 +0000 UTC (1 container statuses recorded)
    Jan 24 20:12:32.439: INFO: 	Container main ready: true, restart count 0
    Jan 24 20:12:32.439: INFO: sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-x86sk from sonobuoy started at 2023-01-24 18:32:54 +0000 UTC (2 container statuses recorded)
    Jan 24 20:12:32.439: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Jan 24 20:12:32.439: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node vikash-v125latest-conf-59870 01/24/23 20:12:32.579
    STEP: verifying the node has the label node vikash-v125latest-conf-71087 01/24/23 20:12:32.799
    Jan 24 20:12:33.166: INFO: Pod haproxy-ingress-cb855dc7c-smnf7 requesting resource cpu=10m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.166: INFO: Pod ingress-default-backend-6f4477b7bc-qg2sz requesting resource cpu=250m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.166: INFO: Pod calico-kube-controllers-74677b4c5f-zd5w8 requesting resource cpu=0m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.166: INFO: Pod calico-node-45c9d requesting resource cpu=250m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.166: INFO: Pod calico-node-kfjch requesting resource cpu=250m on Node vikash-v125latest-conf-71087
    Jan 24 20:12:33.166: INFO: Pod coredns-94487f57-9zlwt requesting resource cpu=100m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.166: INFO: Pod coredns-94487f57-qldwh requesting resource cpu=100m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.166: INFO: Pod metrics-server-696f4844bb-xklrk requesting resource cpu=100m on Node vikash-v125latest-conf-71087
    Jan 24 20:12:33.166: INFO: Pod kyverno-operator-5c87dbd458-txhlw requesting resource cpu=15m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.167: INFO: Pod nirmata-cni-installer-6skzt requesting resource cpu=250m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.167: INFO: Pod nirmata-cni-installer-swjzc requesting resource cpu=250m on Node vikash-v125latest-conf-71087
    Jan 24 20:12:33.167: INFO: Pod nirmata-kube-controller-df864cd5c-bz5gj requesting resource cpu=250m on Node vikash-v125latest-conf-71087
    Jan 24 20:12:33.167: INFO: Pod otel-agent-6dfc8d44b6-6kj5q requesting resource cpu=100m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.167: INFO: Pod pod-exec-websocket-0a64cf93-6d45-4dd0-9aee-785d3f04fb3b requesting resource cpu=0m on Node vikash-v125latest-conf-71087
    Jan 24 20:12:33.167: INFO: Pod sonobuoy requesting resource cpu=0m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.167: INFO: Pod sonobuoy-e2e-job-d94c6e71d257417d requesting resource cpu=0m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.167: INFO: Pod sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-wq2rq requesting resource cpu=0m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.167: INFO: Pod sonobuoy-systemd-logs-daemon-set-af9900aa59b4495d-x86sk requesting resource cpu=0m on Node vikash-v125latest-conf-71087
    STEP: Starting Pods to consume most of the cluster CPU. 01/24/23 20:12:33.167
    Jan 24 20:12:33.167: INFO: Creating a pod which consumes cpu=2205m on Node vikash-v125latest-conf-71087
    Jan 24 20:12:33.205: INFO: Creating a pod which consumes cpu=2047m on Node vikash-v125latest-conf-59870
    Jan 24 20:12:33.228: INFO: Waiting up to 5m0s for pod "filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2" in namespace "sched-pred-2070" to be "running"
    Jan 24 20:12:33.258: INFO: Pod "filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2": Phase="Pending", Reason="", readiness=false. Elapsed: 29.779067ms
    Jan 24 20:12:35.350: INFO: Pod "filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121594627s
    Jan 24 20:12:37.288: INFO: Pod "filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2": Phase="Running", Reason="", readiness=true. Elapsed: 4.059391059s
    Jan 24 20:12:37.288: INFO: Pod "filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2" satisfied condition "running"
    Jan 24 20:12:37.288: INFO: Waiting up to 5m0s for pod "filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668" in namespace "sched-pred-2070" to be "running"
    Jan 24 20:12:37.309: INFO: Pod "filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668": Phase="Pending", Reason="", readiness=false. Elapsed: 20.686002ms
    Jan 24 20:12:39.320: INFO: Pod "filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668": Phase="Running", Reason="", readiness=true. Elapsed: 2.032251974s
    Jan 24 20:12:39.320: INFO: Pod "filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 01/24/23 20:12:39.32
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2.173d57c81334cfeb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2070/filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2 to vikash-v125latest-conf-71087] 01/24/23 20:12:39.336
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2.173d57c8a013b06e], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 01/24/23 20:12:39.336
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2.173d57c8a90e0e38], Reason = [Created], Message = [Created container filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2] 01/24/23 20:12:39.337
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2.173d57c8c8123f9d], Reason = [Started], Message = [Started container filler-pod-acc3d66e-048c-4bc4-866d-137004e20be2] 01/24/23 20:12:39.337
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668.173d57c8158ef6e4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2070/filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668 to vikash-v125latest-conf-59870] 01/24/23 20:12:39.337
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668.173d57c908a8bbad], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 01/24/23 20:12:39.338
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668.173d57c912b2b4d0], Reason = [Created], Message = [Created container filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668] 01/24/23 20:12:39.339
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668.173d57c9578f3319], Reason = [Started], Message = [Started container filler-pod-d8ccb160-bf70-4bbd-9af9-53ea1e97a668] 01/24/23 20:12:39.34
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.173d57c97dd46b68], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] 01/24/23 20:12:39.379
    STEP: removing the label node off the node vikash-v125latest-conf-59870 01/24/23 20:12:40.399
    STEP: verifying the node doesn't have the label node 01/24/23 20:12:40.517
    STEP: removing the label node off the node vikash-v125latest-conf-71087 01/24/23 20:12:40.532
    STEP: verifying the node doesn't have the label node 01/24/23 20:12:40.648
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 20:12:40.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2070" for this suite. 01/24/23 20:12:41.055
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:12:41.385
Jan 24 20:12:41.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 20:12:41.396
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:41.535
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:41.558
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 01/24/23 20:12:41.575
Jan 24 20:12:41.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-2292 cluster-info'
Jan 24 20:12:42.129: INFO: stderr: ""
Jan 24 20:12:42.129: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.10.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 20:12:42.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2292" for this suite. 01/24/23 20:12:42.146
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":284,"skipped":5126,"failed":0}
------------------------------
• [0.779 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:12:41.385
    Jan 24 20:12:41.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 20:12:41.396
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:41.535
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:41.558
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 01/24/23 20:12:41.575
    Jan 24 20:12:41.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-2292 cluster-info'
    Jan 24 20:12:42.129: INFO: stderr: ""
    Jan 24 20:12:42.129: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.10.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 20:12:42.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2292" for this suite. 01/24/23 20:12:42.146
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:12:42.175
Jan 24 20:12:42.177: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename watch 01/24/23 20:12:42.18
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:42.23
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:42.261
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 01/24/23 20:12:42.277
STEP: starting a background goroutine to produce watch events 01/24/23 20:12:42.286
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 01/24/23 20:12:42.287
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Jan 24 20:12:45.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8602" for this suite. 01/24/23 20:12:45.571
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":285,"skipped":5208,"failed":0}
------------------------------
• [3.411 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:12:42.175
    Jan 24 20:12:42.177: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename watch 01/24/23 20:12:42.18
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:42.23
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:42.261
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 01/24/23 20:12:42.277
    STEP: starting a background goroutine to produce watch events 01/24/23 20:12:42.286
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 01/24/23 20:12:42.287
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Jan 24 20:12:45.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8602" for this suite. 01/24/23 20:12:45.571
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:12:45.594
Jan 24 20:12:45.597: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 20:12:45.6
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:45.682
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:45.714
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-0d7d6288-22bf-4ee0-a259-87f91eb19aa7 01/24/23 20:12:45.737
STEP: Creating a pod to test consume configMaps 01/24/23 20:12:45.755
Jan 24 20:12:45.795: INFO: Waiting up to 5m0s for pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac" in namespace "configmap-5957" to be "Succeeded or Failed"
Jan 24 20:12:45.817: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 21.957559ms
Jan 24 20:12:47.950: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.154832299s
Jan 24 20:12:49.934: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 4.139615579s
Jan 24 20:12:51.851: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056045187s
Jan 24 20:12:53.848: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.05363196s
STEP: Saw pod success 01/24/23 20:12:53.848
Jan 24 20:12:53.849: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac" satisfied condition "Succeeded or Failed"
Jan 24 20:12:53.857: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac container agnhost-container: <nil>
STEP: delete the pod 01/24/23 20:12:53.88
Jan 24 20:12:53.926: INFO: Waiting for pod pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac to disappear
Jan 24 20:12:53.940: INFO: Pod pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 20:12:53.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5957" for this suite. 01/24/23 20:12:53.955
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":286,"skipped":5209,"failed":0}
------------------------------
• [SLOW TEST] [8.378 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:12:45.594
    Jan 24 20:12:45.597: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 20:12:45.6
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:45.682
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:45.714
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-0d7d6288-22bf-4ee0-a259-87f91eb19aa7 01/24/23 20:12:45.737
    STEP: Creating a pod to test consume configMaps 01/24/23 20:12:45.755
    Jan 24 20:12:45.795: INFO: Waiting up to 5m0s for pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac" in namespace "configmap-5957" to be "Succeeded or Failed"
    Jan 24 20:12:45.817: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 21.957559ms
    Jan 24 20:12:47.950: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.154832299s
    Jan 24 20:12:49.934: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 4.139615579s
    Jan 24 20:12:51.851: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056045187s
    Jan 24 20:12:53.848: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.05363196s
    STEP: Saw pod success 01/24/23 20:12:53.848
    Jan 24 20:12:53.849: INFO: Pod "pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac" satisfied condition "Succeeded or Failed"
    Jan 24 20:12:53.857: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 20:12:53.88
    Jan 24 20:12:53.926: INFO: Waiting for pod pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac to disappear
    Jan 24 20:12:53.940: INFO: Pod pod-configmaps-b30d595c-88b9-4057-b592-a003c003f9ac no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 20:12:53.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5957" for this suite. 01/24/23 20:12:53.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:12:53.984
Jan 24 20:12:53.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 20:12:53.988
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:54.046
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:54.058
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:12:54.068
Jan 24 20:12:54.091: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012" in namespace "downward-api-9036" to be "Succeeded or Failed"
Jan 24 20:12:54.100: INFO: Pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012": Phase="Pending", Reason="", readiness=false. Elapsed: 9.389185ms
Jan 24 20:12:56.111: INFO: Pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020422594s
Jan 24 20:12:58.114: INFO: Pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023112073s
Jan 24 20:13:00.168: INFO: Pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.077513599s
STEP: Saw pod success 01/24/23 20:13:00.168
Jan 24 20:13:00.169: INFO: Pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012" satisfied condition "Succeeded or Failed"
Jan 24 20:13:00.260: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012 container client-container: <nil>
STEP: delete the pod 01/24/23 20:13:00.342
Jan 24 20:13:00.410: INFO: Waiting for pod downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012 to disappear
Jan 24 20:13:00.420: INFO: Pod downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 20:13:00.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9036" for this suite. 01/24/23 20:13:00.444
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":287,"skipped":5236,"failed":0}
------------------------------
• [SLOW TEST] [6.478 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:12:53.984
    Jan 24 20:12:53.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 20:12:53.988
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:12:54.046
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:12:54.058
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:12:54.068
    Jan 24 20:12:54.091: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012" in namespace "downward-api-9036" to be "Succeeded or Failed"
    Jan 24 20:12:54.100: INFO: Pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012": Phase="Pending", Reason="", readiness=false. Elapsed: 9.389185ms
    Jan 24 20:12:56.111: INFO: Pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020422594s
    Jan 24 20:12:58.114: INFO: Pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023112073s
    Jan 24 20:13:00.168: INFO: Pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.077513599s
    STEP: Saw pod success 01/24/23 20:13:00.168
    Jan 24 20:13:00.169: INFO: Pod "downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012" satisfied condition "Succeeded or Failed"
    Jan 24 20:13:00.260: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012 container client-container: <nil>
    STEP: delete the pod 01/24/23 20:13:00.342
    Jan 24 20:13:00.410: INFO: Waiting for pod downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012 to disappear
    Jan 24 20:13:00.420: INFO: Pod downwardapi-volume-8fbbe565-b00e-47c0-a0b3-1182de03f012 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 20:13:00.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9036" for this suite. 01/24/23 20:13:00.444
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:13:00.476
Jan 24 20:13:00.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replicaset 01/24/23 20:13:00.514
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:13:00.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:13:00.61
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Jan 24 20:13:00.633: INFO: Creating ReplicaSet my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90
Jan 24 20:13:00.746: INFO: Pod name my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90: Found 1 pods out of 1
Jan 24 20:13:00.747: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90" is running
Jan 24 20:13:00.750: INFO: Waiting up to 5m0s for pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2" in namespace "replicaset-3372" to be "running"
Jan 24 20:13:00.809: INFO: Pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2": Phase="Pending", Reason="", readiness=false. Elapsed: 59.383711ms
Jan 24 20:13:02.843: INFO: Pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093194672s
Jan 24 20:13:04.849: INFO: Pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2": Phase="Running", Reason="", readiness=true. Elapsed: 4.099119638s
Jan 24 20:13:04.849: INFO: Pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2" satisfied condition "running"
Jan 24 20:13:04.850: INFO: Pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2" is running (conditions: [])
Jan 24 20:13:04.850: INFO: Trying to dial the pod
Jan 24 20:13:09.920: INFO: Controller my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90: Got expected result from replica 1 [my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2]: "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 24 20:13:09.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3372" for this suite. 01/24/23 20:13:09.935
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":288,"skipped":5258,"failed":0}
------------------------------
• [SLOW TEST] [9.483 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:13:00.476
    Jan 24 20:13:00.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replicaset 01/24/23 20:13:00.514
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:13:00.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:13:00.61
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Jan 24 20:13:00.633: INFO: Creating ReplicaSet my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90
    Jan 24 20:13:00.746: INFO: Pod name my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90: Found 1 pods out of 1
    Jan 24 20:13:00.747: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90" is running
    Jan 24 20:13:00.750: INFO: Waiting up to 5m0s for pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2" in namespace "replicaset-3372" to be "running"
    Jan 24 20:13:00.809: INFO: Pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2": Phase="Pending", Reason="", readiness=false. Elapsed: 59.383711ms
    Jan 24 20:13:02.843: INFO: Pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093194672s
    Jan 24 20:13:04.849: INFO: Pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2": Phase="Running", Reason="", readiness=true. Elapsed: 4.099119638s
    Jan 24 20:13:04.849: INFO: Pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2" satisfied condition "running"
    Jan 24 20:13:04.850: INFO: Pod "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2" is running (conditions: [])
    Jan 24 20:13:04.850: INFO: Trying to dial the pod
    Jan 24 20:13:09.920: INFO: Controller my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90: Got expected result from replica 1 [my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2]: "my-hostname-basic-f23f7553-f63e-44d3-9652-7f6ef2b33c90-dsww2", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 24 20:13:09.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-3372" for this suite. 01/24/23 20:13:09.935
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:13:09.973
Jan 24 20:13:09.973: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename subpath 01/24/23 20:13:09.978
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:13:10.088
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:13:10.124
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 01/24/23 20:13:10.167
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-bml7 01/24/23 20:13:10.246
STEP: Creating a pod to test atomic-volume-subpath 01/24/23 20:13:10.247
Jan 24 20:13:10.538: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bml7" in namespace "subpath-678" to be "Succeeded or Failed"
Jan 24 20:13:10.687: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Pending", Reason="", readiness=false. Elapsed: 149.146323ms
Jan 24 20:13:12.967: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.42847703s
Jan 24 20:13:14.749: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 4.211036269s
Jan 24 20:13:16.694: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 6.155471642s
Jan 24 20:13:18.697: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 8.159156506s
Jan 24 20:13:20.695: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 10.156399164s
Jan 24 20:13:22.705: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 12.166466738s
Jan 24 20:13:24.701: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 14.162823915s
Jan 24 20:13:26.697: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 16.158389701s
Jan 24 20:13:28.712: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 18.173470375s
Jan 24 20:13:30.717: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 20.178209623s
Jan 24 20:13:32.719: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 22.180218511s
Jan 24 20:13:34.707: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 24.168195562s
Jan 24 20:13:36.706: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=false. Elapsed: 26.167599318s
Jan 24 20:13:38.705: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.166246966s
STEP: Saw pod success 01/24/23 20:13:38.705
Jan 24 20:13:38.705: INFO: Pod "pod-subpath-test-projected-bml7" satisfied condition "Succeeded or Failed"
Jan 24 20:13:38.723: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-subpath-test-projected-bml7 container test-container-subpath-projected-bml7: <nil>
STEP: delete the pod 01/24/23 20:13:38.776
Jan 24 20:13:38.832: INFO: Waiting for pod pod-subpath-test-projected-bml7 to disappear
Jan 24 20:13:38.846: INFO: Pod pod-subpath-test-projected-bml7 no longer exists
STEP: Deleting pod pod-subpath-test-projected-bml7 01/24/23 20:13:38.846
Jan 24 20:13:38.846: INFO: Deleting pod "pod-subpath-test-projected-bml7" in namespace "subpath-678"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jan 24 20:13:38.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-678" for this suite. 01/24/23 20:13:38.893
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":289,"skipped":5285,"failed":0}
------------------------------
• [SLOW TEST] [28.951 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:13:09.973
    Jan 24 20:13:09.973: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename subpath 01/24/23 20:13:09.978
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:13:10.088
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:13:10.124
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 01/24/23 20:13:10.167
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-bml7 01/24/23 20:13:10.246
    STEP: Creating a pod to test atomic-volume-subpath 01/24/23 20:13:10.247
    Jan 24 20:13:10.538: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bml7" in namespace "subpath-678" to be "Succeeded or Failed"
    Jan 24 20:13:10.687: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Pending", Reason="", readiness=false. Elapsed: 149.146323ms
    Jan 24 20:13:12.967: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.42847703s
    Jan 24 20:13:14.749: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 4.211036269s
    Jan 24 20:13:16.694: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 6.155471642s
    Jan 24 20:13:18.697: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 8.159156506s
    Jan 24 20:13:20.695: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 10.156399164s
    Jan 24 20:13:22.705: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 12.166466738s
    Jan 24 20:13:24.701: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 14.162823915s
    Jan 24 20:13:26.697: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 16.158389701s
    Jan 24 20:13:28.712: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 18.173470375s
    Jan 24 20:13:30.717: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 20.178209623s
    Jan 24 20:13:32.719: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 22.180218511s
    Jan 24 20:13:34.707: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=true. Elapsed: 24.168195562s
    Jan 24 20:13:36.706: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Running", Reason="", readiness=false. Elapsed: 26.167599318s
    Jan 24 20:13:38.705: INFO: Pod "pod-subpath-test-projected-bml7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.166246966s
    STEP: Saw pod success 01/24/23 20:13:38.705
    Jan 24 20:13:38.705: INFO: Pod "pod-subpath-test-projected-bml7" satisfied condition "Succeeded or Failed"
    Jan 24 20:13:38.723: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-subpath-test-projected-bml7 container test-container-subpath-projected-bml7: <nil>
    STEP: delete the pod 01/24/23 20:13:38.776
    Jan 24 20:13:38.832: INFO: Waiting for pod pod-subpath-test-projected-bml7 to disappear
    Jan 24 20:13:38.846: INFO: Pod pod-subpath-test-projected-bml7 no longer exists
    STEP: Deleting pod pod-subpath-test-projected-bml7 01/24/23 20:13:38.846
    Jan 24 20:13:38.846: INFO: Deleting pod "pod-subpath-test-projected-bml7" in namespace "subpath-678"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jan 24 20:13:38.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-678" for this suite. 01/24/23 20:13:38.893
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:13:38.984
Jan 24 20:13:38.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:13:38.995
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:13:39.089
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:13:39.118
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-61ae0619-9a2d-46e1-8f82-8b599b07d1eb 01/24/23 20:13:39.153
STEP: Creating a pod to test consume secrets 01/24/23 20:13:39.197
Jan 24 20:13:39.232: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2" in namespace "projected-1797" to be "Succeeded or Failed"
Jan 24 20:13:39.255: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2": Phase="Pending", Reason="", readiness=false. Elapsed: 21.979047ms
Jan 24 20:13:41.309: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075846102s
Jan 24 20:13:43.274: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040446923s
Jan 24 20:13:45.306: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.072612208s
Jan 24 20:13:47.265: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.0320399s
STEP: Saw pod success 01/24/23 20:13:47.266
Jan 24 20:13:47.266: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2" satisfied condition "Succeeded or Failed"
Jan 24 20:13:47.277: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2 container projected-secret-volume-test: <nil>
STEP: delete the pod 01/24/23 20:13:47.289
Jan 24 20:13:47.334: INFO: Waiting for pod pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2 to disappear
Jan 24 20:13:47.351: INFO: Pod pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Jan 24 20:13:47.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1797" for this suite. 01/24/23 20:13:47.364
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":290,"skipped":5304,"failed":0}
------------------------------
• [SLOW TEST] [8.392 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:13:38.984
    Jan 24 20:13:38.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:13:38.995
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:13:39.089
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:13:39.118
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-61ae0619-9a2d-46e1-8f82-8b599b07d1eb 01/24/23 20:13:39.153
    STEP: Creating a pod to test consume secrets 01/24/23 20:13:39.197
    Jan 24 20:13:39.232: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2" in namespace "projected-1797" to be "Succeeded or Failed"
    Jan 24 20:13:39.255: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2": Phase="Pending", Reason="", readiness=false. Elapsed: 21.979047ms
    Jan 24 20:13:41.309: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075846102s
    Jan 24 20:13:43.274: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040446923s
    Jan 24 20:13:45.306: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.072612208s
    Jan 24 20:13:47.265: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.0320399s
    STEP: Saw pod success 01/24/23 20:13:47.266
    Jan 24 20:13:47.266: INFO: Pod "pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2" satisfied condition "Succeeded or Failed"
    Jan 24 20:13:47.277: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2 container projected-secret-volume-test: <nil>
    STEP: delete the pod 01/24/23 20:13:47.289
    Jan 24 20:13:47.334: INFO: Waiting for pod pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2 to disappear
    Jan 24 20:13:47.351: INFO: Pod pod-projected-secrets-e40d9012-6a8c-42e2-b064-71c521e0ffe2 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Jan 24 20:13:47.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1797" for this suite. 01/24/23 20:13:47.364
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:13:47.377
Jan 24 20:13:47.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename gc 01/24/23 20:13:47.385
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:13:47.494
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:13:47.517
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 01/24/23 20:13:47.547
STEP: delete the rc 01/24/23 20:13:58.635
STEP: wait for the rc to be deleted 01/24/23 20:14:02.864
Jan 24 20:14:10.410: INFO: 37 pods remaining
Jan 24 20:14:10.410: INFO: 37 pods has nil DeletionTimestamp
Jan 24 20:14:10.410: INFO: 
STEP: Gathering metrics 01/24/23 20:14:13.836
W0124 20:14:17.204870      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 24 20:14:17.206: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 24 20:14:17.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8961" for this suite. 01/24/23 20:14:19.589
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":291,"skipped":5304,"failed":0}
------------------------------
• [SLOW TEST] [32.225 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:13:47.377
    Jan 24 20:13:47.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename gc 01/24/23 20:13:47.385
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:13:47.494
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:13:47.517
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 01/24/23 20:13:47.547
    STEP: delete the rc 01/24/23 20:13:58.635
    STEP: wait for the rc to be deleted 01/24/23 20:14:02.864
    Jan 24 20:14:10.410: INFO: 37 pods remaining
    Jan 24 20:14:10.410: INFO: 37 pods has nil DeletionTimestamp
    Jan 24 20:14:10.410: INFO: 
    STEP: Gathering metrics 01/24/23 20:14:13.836
    W0124 20:14:17.204870      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 24 20:14:17.206: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 24 20:14:17.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8961" for this suite. 01/24/23 20:14:19.589
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:14:19.655
Jan 24 20:14:19.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename deployment 01/24/23 20:14:19.657
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:14:22.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:14:22.523
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Jan 24 20:14:23.548: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 24 20:14:29.030: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/24/23 20:14:29.031
Jan 24 20:14:29.035: INFO: Waiting up to 5m0s for pod "test-rollover-controller-cdlw2" in namespace "deployment-1282" to be "running"
Jan 24 20:14:29.048: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.08981ms
Jan 24 20:14:31.137: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101796088s
Jan 24 20:14:33.258: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.223249026s
Jan 24 20:14:35.086: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051361363s
Jan 24 20:14:37.059: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024412129s
Jan 24 20:14:39.064: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.029059673s
Jan 24 20:14:41.085: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.049782454s
Jan 24 20:14:43.058: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.023211322s
Jan 24 20:14:45.061: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.025792319s
Jan 24 20:14:47.066: INFO: Pod "test-rollover-controller-cdlw2": Phase="Running", Reason="", readiness=true. Elapsed: 18.031067059s
Jan 24 20:14:47.066: INFO: Pod "test-rollover-controller-cdlw2" satisfied condition "running"
Jan 24 20:14:47.066: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 24 20:14:49.109: INFO: Creating deployment "test-rollover-deployment"
Jan 24 20:14:49.182: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 24 20:14:51.355: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 24 20:14:51.547: INFO: Ensure that both replica sets have 1 created replica
Jan 24 20:14:51.597: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 24 20:14:51.665: INFO: Updating deployment test-rollover-deployment
Jan 24 20:14:51.666: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 24 20:14:53.687: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 24 20:14:53.711: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 24 20:14:53.741: INFO: all replica sets need to contain the pod-template-hash label
Jan 24 20:14:53.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:14:55.803: INFO: all replica sets need to contain the pod-template-hash label
Jan 24 20:14:55.805: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:14:57.789: INFO: all replica sets need to contain the pod-template-hash label
Jan 24 20:14:57.790: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:14:59.789: INFO: all replica sets need to contain the pod-template-hash label
Jan 24 20:14:59.789: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:15:01.770: INFO: all replica sets need to contain the pod-template-hash label
Jan 24 20:15:01.771: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:15:03.816: INFO: all replica sets need to contain the pod-template-hash label
Jan 24 20:15:03.817: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:15:06.079: INFO: 
Jan 24 20:15:06.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 15, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 24 20:15:07.776: INFO: 
Jan 24 20:15:07.777: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jan 24 20:15:07.821: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-1282  08a63e39-e6c5-4d89-9a8f-b134ff2db82e 38388 2 2023-01-24 20:14:49 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-24 20:14:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:15:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005610008 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-24 20:14:49 +0000 UTC,LastTransitionTime:2023-01-24 20:14:49 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-01-24 20:15:06 +0000 UTC,LastTransitionTime:2023-01-24 20:14:49 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jan 24 20:15:07.840: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-1282  263a29dd-4052-4be4-8920-3cdac94c4814 38377 2 2023-01-24 20:14:51 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 08a63e39-e6c5-4d89-9a8f-b134ff2db82e 0xc0056105f7 0xc0056105f8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 20:14:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a63e39-e6c5-4d89-9a8f-b134ff2db82e\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:15:05 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0056106a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jan 24 20:15:07.840: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 24 20:15:07.842: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1282  b792f1d2-d051-47ac-922c-2909a793b6a5 38387 2 2023-01-24 20:14:23 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 08a63e39-e6c5-4d89-9a8f-b134ff2db82e 0xc0056103a7 0xc0056103a8}] [] [{e2e.test Update apps/v1 2023-01-24 20:14:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:15:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a63e39-e6c5-4d89-9a8f-b134ff2db82e\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:15:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005610468 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 24 20:15:07.842: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-1282  bb0407ec-4a58-4d85-8a7e-e07098b6913f 38352 2 2023-01-24 20:14:49 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 08a63e39-e6c5-4d89-9a8f-b134ff2db82e 0xc0056104d7 0xc0056104d8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 20:14:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a63e39-e6c5-4d89-9a8f-b134ff2db82e\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:14:51 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005610588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jan 24 20:15:07.858: INFO: Pod "test-rollover-deployment-6d45fd857b-wvpfv" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-wvpfv test-rollover-deployment-6d45fd857b- deployment-1282  e8508be1-6372-4757-9616-3580fd061b9e 38370 0 2023-01-24 20:14:51 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:f36f850996e829c9d5a6477c961b6619411731a19120417d71c4db4254b9bb9e cni.projectcalico.org/podIP:10.244.71.248/32 cni.projectcalico.org/podIPs:10.244.71.248/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 263a29dd-4052-4be4-8920-3cdac94c4814 0xc0056baa07 0xc0056baa08}] [] [{kube-controller-manager Update v1 2023-01-24 20:14:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"263a29dd-4052-4be4-8920-3cdac94c4814\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 20:14:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 20:14:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.248\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-65f6d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-65f6d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:14:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:14:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:14:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:14:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.248,StartTime:2023-01-24 20:14:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 20:14:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://e07b379fb7eb53cdadd25f266d128ff1cc8564908549538a27a0564f41b1deae,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.248,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Jan 24 20:15:07.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1282" for this suite. 01/24/23 20:15:07.873
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":292,"skipped":5313,"failed":0}
------------------------------
• [SLOW TEST] [48.236 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:14:19.655
    Jan 24 20:14:19.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename deployment 01/24/23 20:14:19.657
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:14:22.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:14:22.523
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Jan 24 20:14:23.548: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Jan 24 20:14:29.030: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/24/23 20:14:29.031
    Jan 24 20:14:29.035: INFO: Waiting up to 5m0s for pod "test-rollover-controller-cdlw2" in namespace "deployment-1282" to be "running"
    Jan 24 20:14:29.048: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.08981ms
    Jan 24 20:14:31.137: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101796088s
    Jan 24 20:14:33.258: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.223249026s
    Jan 24 20:14:35.086: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051361363s
    Jan 24 20:14:37.059: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024412129s
    Jan 24 20:14:39.064: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.029059673s
    Jan 24 20:14:41.085: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.049782454s
    Jan 24 20:14:43.058: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.023211322s
    Jan 24 20:14:45.061: INFO: Pod "test-rollover-controller-cdlw2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.025792319s
    Jan 24 20:14:47.066: INFO: Pod "test-rollover-controller-cdlw2": Phase="Running", Reason="", readiness=true. Elapsed: 18.031067059s
    Jan 24 20:14:47.066: INFO: Pod "test-rollover-controller-cdlw2" satisfied condition "running"
    Jan 24 20:14:47.066: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Jan 24 20:14:49.109: INFO: Creating deployment "test-rollover-deployment"
    Jan 24 20:14:49.182: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Jan 24 20:14:51.355: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Jan 24 20:14:51.547: INFO: Ensure that both replica sets have 1 created replica
    Jan 24 20:14:51.597: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Jan 24 20:14:51.665: INFO: Updating deployment test-rollover-deployment
    Jan 24 20:14:51.666: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Jan 24 20:14:53.687: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Jan 24 20:14:53.711: INFO: Make sure deployment "test-rollover-deployment" is complete
    Jan 24 20:14:53.741: INFO: all replica sets need to contain the pod-template-hash label
    Jan 24 20:14:53.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:14:55.803: INFO: all replica sets need to contain the pod-template-hash label
    Jan 24 20:14:55.805: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:14:57.789: INFO: all replica sets need to contain the pod-template-hash label
    Jan 24 20:14:57.790: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:14:59.789: INFO: all replica sets need to contain the pod-template-hash label
    Jan 24 20:14:59.789: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:15:01.770: INFO: all replica sets need to contain the pod-template-hash label
    Jan 24 20:15:01.771: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:15:03.816: INFO: all replica sets need to contain the pod-template-hash label
    Jan 24 20:15:03.817: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 55, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:15:06.079: INFO: 
    Jan 24 20:15:06.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 15, 5, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 14, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Jan 24 20:15:07.776: INFO: 
    Jan 24 20:15:07.777: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Jan 24 20:15:07.821: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-1282  08a63e39-e6c5-4d89-9a8f-b134ff2db82e 38388 2 2023-01-24 20:14:49 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-01-24 20:14:51 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:15:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005610008 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-01-24 20:14:49 +0000 UTC,LastTransitionTime:2023-01-24 20:14:49 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-01-24 20:15:06 +0000 UTC,LastTransitionTime:2023-01-24 20:14:49 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Jan 24 20:15:07.840: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-1282  263a29dd-4052-4be4-8920-3cdac94c4814 38377 2 2023-01-24 20:14:51 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 08a63e39-e6c5-4d89-9a8f-b134ff2db82e 0xc0056105f7 0xc0056105f8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 20:14:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a63e39-e6c5-4d89-9a8f-b134ff2db82e\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:15:05 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0056106a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 20:15:07.840: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Jan 24 20:15:07.842: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1282  b792f1d2-d051-47ac-922c-2909a793b6a5 38387 2 2023-01-24 20:14:23 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 08a63e39-e6c5-4d89-9a8f-b134ff2db82e 0xc0056103a7 0xc0056103a8}] [] [{e2e.test Update apps/v1 2023-01-24 20:14:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:15:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a63e39-e6c5-4d89-9a8f-b134ff2db82e\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:15:06 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005610468 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 20:15:07.842: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-1282  bb0407ec-4a58-4d85-8a7e-e07098b6913f 38352 2 2023-01-24 20:14:49 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 08a63e39-e6c5-4d89-9a8f-b134ff2db82e 0xc0056104d7 0xc0056104d8}] [] [{kube-controller-manager Update apps/v1 2023-01-24 20:14:51 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a63e39-e6c5-4d89-9a8f-b134ff2db82e\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-01-24 20:14:51 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005610588 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Jan 24 20:15:07.858: INFO: Pod "test-rollover-deployment-6d45fd857b-wvpfv" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-wvpfv test-rollover-deployment-6d45fd857b- deployment-1282  e8508be1-6372-4757-9616-3580fd061b9e 38370 0 2023-01-24 20:14:51 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:f36f850996e829c9d5a6477c961b6619411731a19120417d71c4db4254b9bb9e cni.projectcalico.org/podIP:10.244.71.248/32 cni.projectcalico.org/podIPs:10.244.71.248/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 263a29dd-4052-4be4-8920-3cdac94c4814 0xc0056baa07 0xc0056baa08}] [] [{kube-controller-manager Update v1 2023-01-24 20:14:51 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"263a29dd-4052-4be4-8920-3cdac94c4814\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-01-24 20:14:53 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-01-24 20:14:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.248\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-65f6d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-65f6d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vikash-v125latest-conf-71087,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:14:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:14:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:14:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-01-24 20:14:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.10.1.127,PodIP:10.244.71.248,StartTime:2023-01-24 20:14:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-01-24 20:14:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://e07b379fb7eb53cdadd25f266d128ff1cc8564908549538a27a0564f41b1deae,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.71.248,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Jan 24 20:15:07.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1282" for this suite. 01/24/23 20:15:07.873
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:15:07.897
Jan 24 20:15:07.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:15:07.914
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:15:07.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:15:07.99
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:15:08.009
Jan 24 20:15:08.045: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065" in namespace "projected-4609" to be "Succeeded or Failed"
Jan 24 20:15:08.066: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Pending", Reason="", readiness=false. Elapsed: 20.583644ms
Jan 24 20:15:10.179: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Pending", Reason="", readiness=false. Elapsed: 2.134264718s
Jan 24 20:15:12.183: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Pending", Reason="", readiness=false. Elapsed: 4.137645269s
Jan 24 20:15:14.184: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Pending", Reason="", readiness=false. Elapsed: 6.138628103s
Jan 24 20:15:16.291: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Pending", Reason="", readiness=false. Elapsed: 8.245819183s
Jan 24 20:15:18.084: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.039555009s
STEP: Saw pod success 01/24/23 20:15:18.085
Jan 24 20:15:18.086: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065" satisfied condition "Succeeded or Failed"
Jan 24 20:15:18.100: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065 container client-container: <nil>
STEP: delete the pod 01/24/23 20:15:18.181
Jan 24 20:15:18.260: INFO: Waiting for pod downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065 to disappear
Jan 24 20:15:18.295: INFO: Pod downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 20:15:18.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4609" for this suite. 01/24/23 20:15:18.32
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":293,"skipped":5316,"failed":0}
------------------------------
• [SLOW TEST] [10.476 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:15:07.897
    Jan 24 20:15:07.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:15:07.914
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:15:07.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:15:07.99
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:15:08.009
    Jan 24 20:15:08.045: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065" in namespace "projected-4609" to be "Succeeded or Failed"
    Jan 24 20:15:08.066: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Pending", Reason="", readiness=false. Elapsed: 20.583644ms
    Jan 24 20:15:10.179: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Pending", Reason="", readiness=false. Elapsed: 2.134264718s
    Jan 24 20:15:12.183: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Pending", Reason="", readiness=false. Elapsed: 4.137645269s
    Jan 24 20:15:14.184: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Pending", Reason="", readiness=false. Elapsed: 6.138628103s
    Jan 24 20:15:16.291: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Pending", Reason="", readiness=false. Elapsed: 8.245819183s
    Jan 24 20:15:18.084: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.039555009s
    STEP: Saw pod success 01/24/23 20:15:18.085
    Jan 24 20:15:18.086: INFO: Pod "downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065" satisfied condition "Succeeded or Failed"
    Jan 24 20:15:18.100: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065 container client-container: <nil>
    STEP: delete the pod 01/24/23 20:15:18.181
    Jan 24 20:15:18.260: INFO: Waiting for pod downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065 to disappear
    Jan 24 20:15:18.295: INFO: Pod downwardapi-volume-ef67ccdd-1208-4c39-a89b-e0016ecfb065 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 20:15:18.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4609" for this suite. 01/24/23 20:15:18.32
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:15:18.378
Jan 24 20:15:18.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename gc 01/24/23 20:15:18.396
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:15:18.468
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:15:18.501
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 01/24/23 20:15:18.553
STEP: delete the rc 01/24/23 20:15:29.255
STEP: wait for the rc to be deleted 01/24/23 20:15:30.236
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 01/24/23 20:15:36.114
STEP: Gathering metrics 01/24/23 20:16:06.164
W0124 20:16:06.184141      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jan 24 20:16:06.184: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Jan 24 20:16:06.184: INFO: Deleting pod "simpletest.rc-24zhp" in namespace "gc-2160"
Jan 24 20:16:06.219: INFO: Deleting pod "simpletest.rc-256bd" in namespace "gc-2160"
Jan 24 20:16:06.237: INFO: Deleting pod "simpletest.rc-28jdn" in namespace "gc-2160"
Jan 24 20:16:06.288: INFO: Deleting pod "simpletest.rc-29l7p" in namespace "gc-2160"
Jan 24 20:16:06.303: INFO: Deleting pod "simpletest.rc-2l8ht" in namespace "gc-2160"
Jan 24 20:16:06.316: INFO: Deleting pod "simpletest.rc-2m4d6" in namespace "gc-2160"
Jan 24 20:16:06.333: INFO: Deleting pod "simpletest.rc-2xf54" in namespace "gc-2160"
Jan 24 20:16:06.351: INFO: Deleting pod "simpletest.rc-2xxl2" in namespace "gc-2160"
Jan 24 20:16:06.375: INFO: Deleting pod "simpletest.rc-4c7gp" in namespace "gc-2160"
Jan 24 20:16:06.404: INFO: Deleting pod "simpletest.rc-4zldx" in namespace "gc-2160"
Jan 24 20:16:06.433: INFO: Deleting pod "simpletest.rc-5684w" in namespace "gc-2160"
Jan 24 20:16:06.494: INFO: Deleting pod "simpletest.rc-5dkmd" in namespace "gc-2160"
Jan 24 20:16:06.532: INFO: Deleting pod "simpletest.rc-5qhqs" in namespace "gc-2160"
Jan 24 20:16:06.552: INFO: Deleting pod "simpletest.rc-5r697" in namespace "gc-2160"
Jan 24 20:16:06.573: INFO: Deleting pod "simpletest.rc-5tnsj" in namespace "gc-2160"
Jan 24 20:16:06.624: INFO: Deleting pod "simpletest.rc-5xlsj" in namespace "gc-2160"
Jan 24 20:16:06.718: INFO: Deleting pod "simpletest.rc-66wl2" in namespace "gc-2160"
Jan 24 20:16:06.743: INFO: Deleting pod "simpletest.rc-7b64l" in namespace "gc-2160"
Jan 24 20:16:06.775: INFO: Deleting pod "simpletest.rc-7bcqc" in namespace "gc-2160"
Jan 24 20:16:06.817: INFO: Deleting pod "simpletest.rc-7bpvc" in namespace "gc-2160"
Jan 24 20:16:06.849: INFO: Deleting pod "simpletest.rc-7dmnp" in namespace "gc-2160"
Jan 24 20:16:06.872: INFO: Deleting pod "simpletest.rc-7xlrw" in namespace "gc-2160"
Jan 24 20:16:06.939: INFO: Deleting pod "simpletest.rc-857d4" in namespace "gc-2160"
Jan 24 20:16:06.994: INFO: Deleting pod "simpletest.rc-8rg6t" in namespace "gc-2160"
Jan 24 20:16:07.039: INFO: Deleting pod "simpletest.rc-8t4j2" in namespace "gc-2160"
Jan 24 20:16:07.104: INFO: Deleting pod "simpletest.rc-94vlp" in namespace "gc-2160"
Jan 24 20:16:07.217: INFO: Deleting pod "simpletest.rc-98rjc" in namespace "gc-2160"
Jan 24 20:16:07.272: INFO: Deleting pod "simpletest.rc-9crdd" in namespace "gc-2160"
Jan 24 20:16:07.331: INFO: Deleting pod "simpletest.rc-9nsv9" in namespace "gc-2160"
Jan 24 20:16:07.364: INFO: Deleting pod "simpletest.rc-9rn5n" in namespace "gc-2160"
Jan 24 20:16:07.401: INFO: Deleting pod "simpletest.rc-9x726" in namespace "gc-2160"
Jan 24 20:16:07.418: INFO: Deleting pod "simpletest.rc-b5nfc" in namespace "gc-2160"
Jan 24 20:16:07.538: INFO: Deleting pod "simpletest.rc-crfcb" in namespace "gc-2160"
Jan 24 20:16:07.596: INFO: Deleting pod "simpletest.rc-cxl2j" in namespace "gc-2160"
Jan 24 20:16:07.624: INFO: Deleting pod "simpletest.rc-ddl5m" in namespace "gc-2160"
Jan 24 20:16:07.674: INFO: Deleting pod "simpletest.rc-df6vq" in namespace "gc-2160"
Jan 24 20:16:07.733: INFO: Deleting pod "simpletest.rc-dhhbc" in namespace "gc-2160"
Jan 24 20:16:07.776: INFO: Deleting pod "simpletest.rc-dlzq4" in namespace "gc-2160"
Jan 24 20:16:07.798: INFO: Deleting pod "simpletest.rc-dmp82" in namespace "gc-2160"
Jan 24 20:16:07.830: INFO: Deleting pod "simpletest.rc-dn9hz" in namespace "gc-2160"
Jan 24 20:16:07.885: INFO: Deleting pod "simpletest.rc-fcggb" in namespace "gc-2160"
Jan 24 20:16:07.930: INFO: Deleting pod "simpletest.rc-fgpwc" in namespace "gc-2160"
Jan 24 20:16:07.946: INFO: Deleting pod "simpletest.rc-fxmdp" in namespace "gc-2160"
Jan 24 20:16:08.058: INFO: Deleting pod "simpletest.rc-g9xh4" in namespace "gc-2160"
Jan 24 20:16:08.101: INFO: Deleting pod "simpletest.rc-gdf2f" in namespace "gc-2160"
Jan 24 20:16:08.120: INFO: Deleting pod "simpletest.rc-gg8k9" in namespace "gc-2160"
Jan 24 20:16:08.142: INFO: Deleting pod "simpletest.rc-grgd2" in namespace "gc-2160"
Jan 24 20:16:08.162: INFO: Deleting pod "simpletest.rc-hwt69" in namespace "gc-2160"
Jan 24 20:16:08.267: INFO: Deleting pod "simpletest.rc-j5cx7" in namespace "gc-2160"
Jan 24 20:16:08.304: INFO: Deleting pod "simpletest.rc-jklhv" in namespace "gc-2160"
Jan 24 20:16:08.331: INFO: Deleting pod "simpletest.rc-kh8lw" in namespace "gc-2160"
Jan 24 20:16:08.375: INFO: Deleting pod "simpletest.rc-km4dk" in namespace "gc-2160"
Jan 24 20:16:08.394: INFO: Deleting pod "simpletest.rc-kqfcr" in namespace "gc-2160"
Jan 24 20:16:08.414: INFO: Deleting pod "simpletest.rc-kskc5" in namespace "gc-2160"
Jan 24 20:16:08.475: INFO: Deleting pod "simpletest.rc-kx7mz" in namespace "gc-2160"
Jan 24 20:16:08.605: INFO: Deleting pod "simpletest.rc-lbwqk" in namespace "gc-2160"
Jan 24 20:16:08.635: INFO: Deleting pod "simpletest.rc-lpfmt" in namespace "gc-2160"
Jan 24 20:16:08.671: INFO: Deleting pod "simpletest.rc-lqvhd" in namespace "gc-2160"
Jan 24 20:16:08.712: INFO: Deleting pod "simpletest.rc-mk6bm" in namespace "gc-2160"
Jan 24 20:16:08.742: INFO: Deleting pod "simpletest.rc-mmxcp" in namespace "gc-2160"
Jan 24 20:16:08.792: INFO: Deleting pod "simpletest.rc-mqgmz" in namespace "gc-2160"
Jan 24 20:16:09.194: INFO: Deleting pod "simpletest.rc-mxc72" in namespace "gc-2160"
Jan 24 20:16:09.337: INFO: Deleting pod "simpletest.rc-n85ml" in namespace "gc-2160"
Jan 24 20:16:09.426: INFO: Deleting pod "simpletest.rc-n8bl9" in namespace "gc-2160"
Jan 24 20:16:09.791: INFO: Deleting pod "simpletest.rc-n9xb9" in namespace "gc-2160"
Jan 24 20:16:09.850: INFO: Deleting pod "simpletest.rc-ncxlq" in namespace "gc-2160"
Jan 24 20:16:09.875: INFO: Deleting pod "simpletest.rc-ndqwg" in namespace "gc-2160"
Jan 24 20:16:09.912: INFO: Deleting pod "simpletest.rc-nf6rd" in namespace "gc-2160"
Jan 24 20:16:09.957: INFO: Deleting pod "simpletest.rc-nj64v" in namespace "gc-2160"
Jan 24 20:16:09.984: INFO: Deleting pod "simpletest.rc-nnkd6" in namespace "gc-2160"
Jan 24 20:16:10.118: INFO: Deleting pod "simpletest.rc-p5xg4" in namespace "gc-2160"
Jan 24 20:16:10.162: INFO: Deleting pod "simpletest.rc-p8djk" in namespace "gc-2160"
Jan 24 20:16:10.584: INFO: Deleting pod "simpletest.rc-pblx5" in namespace "gc-2160"
Jan 24 20:16:10.871: INFO: Deleting pod "simpletest.rc-psk4p" in namespace "gc-2160"
Jan 24 20:16:10.902: INFO: Deleting pod "simpletest.rc-q5v78" in namespace "gc-2160"
Jan 24 20:16:11.143: INFO: Deleting pod "simpletest.rc-qgf8z" in namespace "gc-2160"
Jan 24 20:16:11.198: INFO: Deleting pod "simpletest.rc-rg79p" in namespace "gc-2160"
Jan 24 20:16:11.217: INFO: Deleting pod "simpletest.rc-rhpmb" in namespace "gc-2160"
Jan 24 20:16:11.240: INFO: Deleting pod "simpletest.rc-smtdb" in namespace "gc-2160"
Jan 24 20:16:11.278: INFO: Deleting pod "simpletest.rc-sn6qh" in namespace "gc-2160"
Jan 24 20:16:11.412: INFO: Deleting pod "simpletest.rc-sqv72" in namespace "gc-2160"
Jan 24 20:16:11.618: INFO: Deleting pod "simpletest.rc-sx7sp" in namespace "gc-2160"
Jan 24 20:16:11.874: INFO: Deleting pod "simpletest.rc-t26gr" in namespace "gc-2160"
Jan 24 20:16:12.309: INFO: Deleting pod "simpletest.rc-t5rw8" in namespace "gc-2160"
Jan 24 20:16:12.434: INFO: Deleting pod "simpletest.rc-t5xng" in namespace "gc-2160"
Jan 24 20:16:12.542: INFO: Deleting pod "simpletest.rc-t94zz" in namespace "gc-2160"
Jan 24 20:16:12.901: INFO: Deleting pod "simpletest.rc-tgtn5" in namespace "gc-2160"
Jan 24 20:16:12.955: INFO: Deleting pod "simpletest.rc-tmql8" in namespace "gc-2160"
Jan 24 20:16:13.206: INFO: Deleting pod "simpletest.rc-vcmhf" in namespace "gc-2160"
Jan 24 20:16:13.228: INFO: Deleting pod "simpletest.rc-vlhcr" in namespace "gc-2160"
Jan 24 20:16:13.329: INFO: Deleting pod "simpletest.rc-vmc8d" in namespace "gc-2160"
Jan 24 20:16:13.355: INFO: Deleting pod "simpletest.rc-vsm5l" in namespace "gc-2160"
Jan 24 20:16:13.418: INFO: Deleting pod "simpletest.rc-vwdzk" in namespace "gc-2160"
Jan 24 20:16:13.453: INFO: Deleting pod "simpletest.rc-wwjbw" in namespace "gc-2160"
Jan 24 20:16:13.525: INFO: Deleting pod "simpletest.rc-x2m65" in namespace "gc-2160"
Jan 24 20:16:13.563: INFO: Deleting pod "simpletest.rc-x8sf2" in namespace "gc-2160"
Jan 24 20:16:13.711: INFO: Deleting pod "simpletest.rc-xvkhh" in namespace "gc-2160"
Jan 24 20:16:13.774: INFO: Deleting pod "simpletest.rc-zgpmc" in namespace "gc-2160"
Jan 24 20:16:14.003: INFO: Deleting pod "simpletest.rc-zl8jl" in namespace "gc-2160"
Jan 24 20:16:14.259: INFO: Deleting pod "simpletest.rc-zshhf" in namespace "gc-2160"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Jan 24 20:16:14.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2160" for this suite. 01/24/23 20:16:14.505
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":294,"skipped":5328,"failed":0}
------------------------------
• [SLOW TEST] [56.168 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:15:18.378
    Jan 24 20:15:18.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename gc 01/24/23 20:15:18.396
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:15:18.468
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:15:18.501
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 01/24/23 20:15:18.553
    STEP: delete the rc 01/24/23 20:15:29.255
    STEP: wait for the rc to be deleted 01/24/23 20:15:30.236
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 01/24/23 20:15:36.114
    STEP: Gathering metrics 01/24/23 20:16:06.164
    W0124 20:16:06.184141      22 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Jan 24 20:16:06.184: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Jan 24 20:16:06.184: INFO: Deleting pod "simpletest.rc-24zhp" in namespace "gc-2160"
    Jan 24 20:16:06.219: INFO: Deleting pod "simpletest.rc-256bd" in namespace "gc-2160"
    Jan 24 20:16:06.237: INFO: Deleting pod "simpletest.rc-28jdn" in namespace "gc-2160"
    Jan 24 20:16:06.288: INFO: Deleting pod "simpletest.rc-29l7p" in namespace "gc-2160"
    Jan 24 20:16:06.303: INFO: Deleting pod "simpletest.rc-2l8ht" in namespace "gc-2160"
    Jan 24 20:16:06.316: INFO: Deleting pod "simpletest.rc-2m4d6" in namespace "gc-2160"
    Jan 24 20:16:06.333: INFO: Deleting pod "simpletest.rc-2xf54" in namespace "gc-2160"
    Jan 24 20:16:06.351: INFO: Deleting pod "simpletest.rc-2xxl2" in namespace "gc-2160"
    Jan 24 20:16:06.375: INFO: Deleting pod "simpletest.rc-4c7gp" in namespace "gc-2160"
    Jan 24 20:16:06.404: INFO: Deleting pod "simpletest.rc-4zldx" in namespace "gc-2160"
    Jan 24 20:16:06.433: INFO: Deleting pod "simpletest.rc-5684w" in namespace "gc-2160"
    Jan 24 20:16:06.494: INFO: Deleting pod "simpletest.rc-5dkmd" in namespace "gc-2160"
    Jan 24 20:16:06.532: INFO: Deleting pod "simpletest.rc-5qhqs" in namespace "gc-2160"
    Jan 24 20:16:06.552: INFO: Deleting pod "simpletest.rc-5r697" in namespace "gc-2160"
    Jan 24 20:16:06.573: INFO: Deleting pod "simpletest.rc-5tnsj" in namespace "gc-2160"
    Jan 24 20:16:06.624: INFO: Deleting pod "simpletest.rc-5xlsj" in namespace "gc-2160"
    Jan 24 20:16:06.718: INFO: Deleting pod "simpletest.rc-66wl2" in namespace "gc-2160"
    Jan 24 20:16:06.743: INFO: Deleting pod "simpletest.rc-7b64l" in namespace "gc-2160"
    Jan 24 20:16:06.775: INFO: Deleting pod "simpletest.rc-7bcqc" in namespace "gc-2160"
    Jan 24 20:16:06.817: INFO: Deleting pod "simpletest.rc-7bpvc" in namespace "gc-2160"
    Jan 24 20:16:06.849: INFO: Deleting pod "simpletest.rc-7dmnp" in namespace "gc-2160"
    Jan 24 20:16:06.872: INFO: Deleting pod "simpletest.rc-7xlrw" in namespace "gc-2160"
    Jan 24 20:16:06.939: INFO: Deleting pod "simpletest.rc-857d4" in namespace "gc-2160"
    Jan 24 20:16:06.994: INFO: Deleting pod "simpletest.rc-8rg6t" in namespace "gc-2160"
    Jan 24 20:16:07.039: INFO: Deleting pod "simpletest.rc-8t4j2" in namespace "gc-2160"
    Jan 24 20:16:07.104: INFO: Deleting pod "simpletest.rc-94vlp" in namespace "gc-2160"
    Jan 24 20:16:07.217: INFO: Deleting pod "simpletest.rc-98rjc" in namespace "gc-2160"
    Jan 24 20:16:07.272: INFO: Deleting pod "simpletest.rc-9crdd" in namespace "gc-2160"
    Jan 24 20:16:07.331: INFO: Deleting pod "simpletest.rc-9nsv9" in namespace "gc-2160"
    Jan 24 20:16:07.364: INFO: Deleting pod "simpletest.rc-9rn5n" in namespace "gc-2160"
    Jan 24 20:16:07.401: INFO: Deleting pod "simpletest.rc-9x726" in namespace "gc-2160"
    Jan 24 20:16:07.418: INFO: Deleting pod "simpletest.rc-b5nfc" in namespace "gc-2160"
    Jan 24 20:16:07.538: INFO: Deleting pod "simpletest.rc-crfcb" in namespace "gc-2160"
    Jan 24 20:16:07.596: INFO: Deleting pod "simpletest.rc-cxl2j" in namespace "gc-2160"
    Jan 24 20:16:07.624: INFO: Deleting pod "simpletest.rc-ddl5m" in namespace "gc-2160"
    Jan 24 20:16:07.674: INFO: Deleting pod "simpletest.rc-df6vq" in namespace "gc-2160"
    Jan 24 20:16:07.733: INFO: Deleting pod "simpletest.rc-dhhbc" in namespace "gc-2160"
    Jan 24 20:16:07.776: INFO: Deleting pod "simpletest.rc-dlzq4" in namespace "gc-2160"
    Jan 24 20:16:07.798: INFO: Deleting pod "simpletest.rc-dmp82" in namespace "gc-2160"
    Jan 24 20:16:07.830: INFO: Deleting pod "simpletest.rc-dn9hz" in namespace "gc-2160"
    Jan 24 20:16:07.885: INFO: Deleting pod "simpletest.rc-fcggb" in namespace "gc-2160"
    Jan 24 20:16:07.930: INFO: Deleting pod "simpletest.rc-fgpwc" in namespace "gc-2160"
    Jan 24 20:16:07.946: INFO: Deleting pod "simpletest.rc-fxmdp" in namespace "gc-2160"
    Jan 24 20:16:08.058: INFO: Deleting pod "simpletest.rc-g9xh4" in namespace "gc-2160"
    Jan 24 20:16:08.101: INFO: Deleting pod "simpletest.rc-gdf2f" in namespace "gc-2160"
    Jan 24 20:16:08.120: INFO: Deleting pod "simpletest.rc-gg8k9" in namespace "gc-2160"
    Jan 24 20:16:08.142: INFO: Deleting pod "simpletest.rc-grgd2" in namespace "gc-2160"
    Jan 24 20:16:08.162: INFO: Deleting pod "simpletest.rc-hwt69" in namespace "gc-2160"
    Jan 24 20:16:08.267: INFO: Deleting pod "simpletest.rc-j5cx7" in namespace "gc-2160"
    Jan 24 20:16:08.304: INFO: Deleting pod "simpletest.rc-jklhv" in namespace "gc-2160"
    Jan 24 20:16:08.331: INFO: Deleting pod "simpletest.rc-kh8lw" in namespace "gc-2160"
    Jan 24 20:16:08.375: INFO: Deleting pod "simpletest.rc-km4dk" in namespace "gc-2160"
    Jan 24 20:16:08.394: INFO: Deleting pod "simpletest.rc-kqfcr" in namespace "gc-2160"
    Jan 24 20:16:08.414: INFO: Deleting pod "simpletest.rc-kskc5" in namespace "gc-2160"
    Jan 24 20:16:08.475: INFO: Deleting pod "simpletest.rc-kx7mz" in namespace "gc-2160"
    Jan 24 20:16:08.605: INFO: Deleting pod "simpletest.rc-lbwqk" in namespace "gc-2160"
    Jan 24 20:16:08.635: INFO: Deleting pod "simpletest.rc-lpfmt" in namespace "gc-2160"
    Jan 24 20:16:08.671: INFO: Deleting pod "simpletest.rc-lqvhd" in namespace "gc-2160"
    Jan 24 20:16:08.712: INFO: Deleting pod "simpletest.rc-mk6bm" in namespace "gc-2160"
    Jan 24 20:16:08.742: INFO: Deleting pod "simpletest.rc-mmxcp" in namespace "gc-2160"
    Jan 24 20:16:08.792: INFO: Deleting pod "simpletest.rc-mqgmz" in namespace "gc-2160"
    Jan 24 20:16:09.194: INFO: Deleting pod "simpletest.rc-mxc72" in namespace "gc-2160"
    Jan 24 20:16:09.337: INFO: Deleting pod "simpletest.rc-n85ml" in namespace "gc-2160"
    Jan 24 20:16:09.426: INFO: Deleting pod "simpletest.rc-n8bl9" in namespace "gc-2160"
    Jan 24 20:16:09.791: INFO: Deleting pod "simpletest.rc-n9xb9" in namespace "gc-2160"
    Jan 24 20:16:09.850: INFO: Deleting pod "simpletest.rc-ncxlq" in namespace "gc-2160"
    Jan 24 20:16:09.875: INFO: Deleting pod "simpletest.rc-ndqwg" in namespace "gc-2160"
    Jan 24 20:16:09.912: INFO: Deleting pod "simpletest.rc-nf6rd" in namespace "gc-2160"
    Jan 24 20:16:09.957: INFO: Deleting pod "simpletest.rc-nj64v" in namespace "gc-2160"
    Jan 24 20:16:09.984: INFO: Deleting pod "simpletest.rc-nnkd6" in namespace "gc-2160"
    Jan 24 20:16:10.118: INFO: Deleting pod "simpletest.rc-p5xg4" in namespace "gc-2160"
    Jan 24 20:16:10.162: INFO: Deleting pod "simpletest.rc-p8djk" in namespace "gc-2160"
    Jan 24 20:16:10.584: INFO: Deleting pod "simpletest.rc-pblx5" in namespace "gc-2160"
    Jan 24 20:16:10.871: INFO: Deleting pod "simpletest.rc-psk4p" in namespace "gc-2160"
    Jan 24 20:16:10.902: INFO: Deleting pod "simpletest.rc-q5v78" in namespace "gc-2160"
    Jan 24 20:16:11.143: INFO: Deleting pod "simpletest.rc-qgf8z" in namespace "gc-2160"
    Jan 24 20:16:11.198: INFO: Deleting pod "simpletest.rc-rg79p" in namespace "gc-2160"
    Jan 24 20:16:11.217: INFO: Deleting pod "simpletest.rc-rhpmb" in namespace "gc-2160"
    Jan 24 20:16:11.240: INFO: Deleting pod "simpletest.rc-smtdb" in namespace "gc-2160"
    Jan 24 20:16:11.278: INFO: Deleting pod "simpletest.rc-sn6qh" in namespace "gc-2160"
    Jan 24 20:16:11.412: INFO: Deleting pod "simpletest.rc-sqv72" in namespace "gc-2160"
    Jan 24 20:16:11.618: INFO: Deleting pod "simpletest.rc-sx7sp" in namespace "gc-2160"
    Jan 24 20:16:11.874: INFO: Deleting pod "simpletest.rc-t26gr" in namespace "gc-2160"
    Jan 24 20:16:12.309: INFO: Deleting pod "simpletest.rc-t5rw8" in namespace "gc-2160"
    Jan 24 20:16:12.434: INFO: Deleting pod "simpletest.rc-t5xng" in namespace "gc-2160"
    Jan 24 20:16:12.542: INFO: Deleting pod "simpletest.rc-t94zz" in namespace "gc-2160"
    Jan 24 20:16:12.901: INFO: Deleting pod "simpletest.rc-tgtn5" in namespace "gc-2160"
    Jan 24 20:16:12.955: INFO: Deleting pod "simpletest.rc-tmql8" in namespace "gc-2160"
    Jan 24 20:16:13.206: INFO: Deleting pod "simpletest.rc-vcmhf" in namespace "gc-2160"
    Jan 24 20:16:13.228: INFO: Deleting pod "simpletest.rc-vlhcr" in namespace "gc-2160"
    Jan 24 20:16:13.329: INFO: Deleting pod "simpletest.rc-vmc8d" in namespace "gc-2160"
    Jan 24 20:16:13.355: INFO: Deleting pod "simpletest.rc-vsm5l" in namespace "gc-2160"
    Jan 24 20:16:13.418: INFO: Deleting pod "simpletest.rc-vwdzk" in namespace "gc-2160"
    Jan 24 20:16:13.453: INFO: Deleting pod "simpletest.rc-wwjbw" in namespace "gc-2160"
    Jan 24 20:16:13.525: INFO: Deleting pod "simpletest.rc-x2m65" in namespace "gc-2160"
    Jan 24 20:16:13.563: INFO: Deleting pod "simpletest.rc-x8sf2" in namespace "gc-2160"
    Jan 24 20:16:13.711: INFO: Deleting pod "simpletest.rc-xvkhh" in namespace "gc-2160"
    Jan 24 20:16:13.774: INFO: Deleting pod "simpletest.rc-zgpmc" in namespace "gc-2160"
    Jan 24 20:16:14.003: INFO: Deleting pod "simpletest.rc-zl8jl" in namespace "gc-2160"
    Jan 24 20:16:14.259: INFO: Deleting pod "simpletest.rc-zshhf" in namespace "gc-2160"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Jan 24 20:16:14.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2160" for this suite. 01/24/23 20:16:14.505
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:16:14.567
Jan 24 20:16:14.567: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename security-context 01/24/23 20:16:14.583
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:16:15.154
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:16:15.243
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 01/24/23 20:16:15.438
Jan 24 20:16:15.463: INFO: Waiting up to 5m0s for pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3" in namespace "security-context-4116" to be "Succeeded or Failed"
Jan 24 20:16:15.490: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 26.497499ms
Jan 24 20:16:17.505: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042091058s
Jan 24 20:16:19.550: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0865603s
Jan 24 20:16:21.586: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.122630703s
Jan 24 20:16:23.547: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Running", Reason="", readiness=true. Elapsed: 8.084327541s
Jan 24 20:16:25.608: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Running", Reason="", readiness=true. Elapsed: 10.145248924s
Jan 24 20:16:27.520: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Running", Reason="", readiness=false. Elapsed: 12.056634712s
Jan 24 20:16:29.515: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.051861617s
STEP: Saw pod success 01/24/23 20:16:29.516
Jan 24 20:16:29.516: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3" satisfied condition "Succeeded or Failed"
Jan 24 20:16:29.579: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3 container test-container: <nil>
STEP: delete the pod 01/24/23 20:16:29.601
Jan 24 20:16:29.656: INFO: Waiting for pod security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3 to disappear
Jan 24 20:16:29.675: INFO: Pod security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 24 20:16:29.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-4116" for this suite. 01/24/23 20:16:29.842
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":295,"skipped":5335,"failed":0}
------------------------------
• [SLOW TEST] [15.339 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:16:14.567
    Jan 24 20:16:14.567: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename security-context 01/24/23 20:16:14.583
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:16:15.154
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:16:15.243
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 01/24/23 20:16:15.438
    Jan 24 20:16:15.463: INFO: Waiting up to 5m0s for pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3" in namespace "security-context-4116" to be "Succeeded or Failed"
    Jan 24 20:16:15.490: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 26.497499ms
    Jan 24 20:16:17.505: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042091058s
    Jan 24 20:16:19.550: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0865603s
    Jan 24 20:16:21.586: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.122630703s
    Jan 24 20:16:23.547: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Running", Reason="", readiness=true. Elapsed: 8.084327541s
    Jan 24 20:16:25.608: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Running", Reason="", readiness=true. Elapsed: 10.145248924s
    Jan 24 20:16:27.520: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Running", Reason="", readiness=false. Elapsed: 12.056634712s
    Jan 24 20:16:29.515: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.051861617s
    STEP: Saw pod success 01/24/23 20:16:29.516
    Jan 24 20:16:29.516: INFO: Pod "security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3" satisfied condition "Succeeded or Failed"
    Jan 24 20:16:29.579: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3 container test-container: <nil>
    STEP: delete the pod 01/24/23 20:16:29.601
    Jan 24 20:16:29.656: INFO: Waiting for pod security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3 to disappear
    Jan 24 20:16:29.675: INFO: Pod security-context-7ed58d94-5827-45e8-a38f-4e6cdde47ad3 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 24 20:16:29.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-4116" for this suite. 01/24/23 20:16:29.842
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:16:30.368
Jan 24 20:16:30.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename runtimeclass 01/24/23 20:16:31.259
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:16:31.635
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:16:32.016
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 01/24/23 20:16:32.669
STEP: getting /apis/node.k8s.io 01/24/23 20:16:32.691
STEP: getting /apis/node.k8s.io/v1 01/24/23 20:16:32.841
STEP: creating 01/24/23 20:16:32.892
STEP: watching 01/24/23 20:16:32.951
Jan 24 20:16:32.951: INFO: starting watch
STEP: getting 01/24/23 20:16:33.017
STEP: listing 01/24/23 20:16:33.129
STEP: patching 01/24/23 20:16:33.887
STEP: updating 01/24/23 20:16:34.279
Jan 24 20:16:34.324: INFO: waiting for watch events with expected annotations
STEP: deleting 01/24/23 20:16:34.324
STEP: deleting a collection 01/24/23 20:16:34.384
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Jan 24 20:16:34.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4634" for this suite. 01/24/23 20:16:34.62
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":296,"skipped":5335,"failed":0}
------------------------------
• [4.976 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:16:30.368
    Jan 24 20:16:30.641: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename runtimeclass 01/24/23 20:16:31.259
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:16:31.635
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:16:32.016
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 01/24/23 20:16:32.669
    STEP: getting /apis/node.k8s.io 01/24/23 20:16:32.691
    STEP: getting /apis/node.k8s.io/v1 01/24/23 20:16:32.841
    STEP: creating 01/24/23 20:16:32.892
    STEP: watching 01/24/23 20:16:32.951
    Jan 24 20:16:32.951: INFO: starting watch
    STEP: getting 01/24/23 20:16:33.017
    STEP: listing 01/24/23 20:16:33.129
    STEP: patching 01/24/23 20:16:33.887
    STEP: updating 01/24/23 20:16:34.279
    Jan 24 20:16:34.324: INFO: waiting for watch events with expected annotations
    STEP: deleting 01/24/23 20:16:34.324
    STEP: deleting a collection 01/24/23 20:16:34.384
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Jan 24 20:16:34.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4634" for this suite. 01/24/23 20:16:34.62
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:16:35.359
Jan 24 20:16:35.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename job 01/24/23 20:16:35.365
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:16:37.19
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:16:37.299
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 01/24/23 20:16:37.448
STEP: Ensuring job reaches completions 01/24/23 20:16:37.469
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Jan 24 20:16:57.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7536" for this suite. 01/24/23 20:16:57.502
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":297,"skipped":5350,"failed":0}
------------------------------
• [SLOW TEST] [22.181 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:16:35.359
    Jan 24 20:16:35.360: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename job 01/24/23 20:16:35.365
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:16:37.19
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:16:37.299
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 01/24/23 20:16:37.448
    STEP: Ensuring job reaches completions 01/24/23 20:16:37.469
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Jan 24 20:16:57.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7536" for this suite. 01/24/23 20:16:57.502
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:16:57.564
Jan 24 20:16:57.569: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 20:16:57.578
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:16:57.656
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:16:57.787
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-5187/configmap-test-9d03c491-f06d-46c0-99d7-3ef970d900fd 01/24/23 20:16:57.843
STEP: Creating a pod to test consume configMaps 01/24/23 20:16:57.869
Jan 24 20:16:57.916: INFO: Waiting up to 5m0s for pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3" in namespace "configmap-5187" to be "Succeeded or Failed"
Jan 24 20:16:57.945: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3": Phase="Pending", Reason="", readiness=false. Elapsed: 21.827948ms
Jan 24 20:16:59.991: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067510213s
Jan 24 20:17:01.968: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044488099s
Jan 24 20:17:03.959: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035814541s
Jan 24 20:17:05.958: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.033915134s
STEP: Saw pod success 01/24/23 20:17:05.958
Jan 24 20:17:05.958: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3" satisfied condition "Succeeded or Failed"
Jan 24 20:17:05.974: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3 container env-test: <nil>
STEP: delete the pod 01/24/23 20:17:05.995
Jan 24 20:17:06.041: INFO: Waiting for pod pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3 to disappear
Jan 24 20:17:06.051: INFO: Pod pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 20:17:06.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5187" for this suite. 01/24/23 20:17:06.066
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":298,"skipped":5380,"failed":0}
------------------------------
• [SLOW TEST] [8.522 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:16:57.564
    Jan 24 20:16:57.569: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 20:16:57.578
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:16:57.656
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:16:57.787
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-5187/configmap-test-9d03c491-f06d-46c0-99d7-3ef970d900fd 01/24/23 20:16:57.843
    STEP: Creating a pod to test consume configMaps 01/24/23 20:16:57.869
    Jan 24 20:16:57.916: INFO: Waiting up to 5m0s for pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3" in namespace "configmap-5187" to be "Succeeded or Failed"
    Jan 24 20:16:57.945: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3": Phase="Pending", Reason="", readiness=false. Elapsed: 21.827948ms
    Jan 24 20:16:59.991: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067510213s
    Jan 24 20:17:01.968: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044488099s
    Jan 24 20:17:03.959: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035814541s
    Jan 24 20:17:05.958: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.033915134s
    STEP: Saw pod success 01/24/23 20:17:05.958
    Jan 24 20:17:05.958: INFO: Pod "pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3" satisfied condition "Succeeded or Failed"
    Jan 24 20:17:05.974: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3 container env-test: <nil>
    STEP: delete the pod 01/24/23 20:17:05.995
    Jan 24 20:17:06.041: INFO: Waiting for pod pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3 to disappear
    Jan 24 20:17:06.051: INFO: Pod pod-configmaps-18f61afd-c850-4f92-b2dc-85b37667baa3 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 20:17:06.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5187" for this suite. 01/24/23 20:17:06.066
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:17:06.089
Jan 24 20:17:06.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename custom-resource-definition 01/24/23 20:17:06.093
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:06.195
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:06.21
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Jan 24 20:17:06.223: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:17:06.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7552" for this suite. 01/24/23 20:17:06.929
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":299,"skipped":5396,"failed":0}
------------------------------
• [0.871 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:17:06.089
    Jan 24 20:17:06.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename custom-resource-definition 01/24/23 20:17:06.093
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:06.195
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:06.21
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Jan 24 20:17:06.223: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:17:06.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7552" for this suite. 01/24/23 20:17:06.929
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:17:06.968
Jan 24 20:17:06.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 20:17:06.972
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:07.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:07.065
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 20:17:07.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-275" for this suite. 01/24/23 20:17:07.097
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":300,"skipped":5406,"failed":0}
------------------------------
• [0.167 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:17:06.968
    Jan 24 20:17:06.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 20:17:06.972
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:07.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:07.065
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 20:17:07.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-275" for this suite. 01/24/23 20:17:07.097
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:17:07.166
Jan 24 20:17:07.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 20:17:07.171
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:07.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:07.243
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-d1675bdc-f3a4-4786-a5cd-74b1734b4fb2 01/24/23 20:17:07.253
STEP: Creating a pod to test consume configMaps 01/24/23 20:17:07.263
Jan 24 20:17:07.293: INFO: Waiting up to 5m0s for pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690" in namespace "configmap-3494" to be "Succeeded or Failed"
Jan 24 20:17:07.312: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690": Phase="Pending", Reason="", readiness=false. Elapsed: 18.99794ms
Jan 24 20:17:09.327: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033544548s
Jan 24 20:17:11.328: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690": Phase="Running", Reason="", readiness=false. Elapsed: 4.034990528s
Jan 24 20:17:13.327: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690": Phase="Running", Reason="", readiness=false. Elapsed: 6.033422419s
Jan 24 20:17:15.381: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.088275099s
STEP: Saw pod success 01/24/23 20:17:15.382
Jan 24 20:17:15.382: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690" satisfied condition "Succeeded or Failed"
Jan 24 20:17:15.394: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 20:17:15.439
Jan 24 20:17:15.497: INFO: Waiting for pod pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690 to disappear
Jan 24 20:17:15.503: INFO: Pod pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 20:17:15.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3494" for this suite. 01/24/23 20:17:15.512
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":301,"skipped":5446,"failed":0}
------------------------------
• [SLOW TEST] [8.368 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:17:07.166
    Jan 24 20:17:07.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 20:17:07.171
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:07.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:07.243
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-d1675bdc-f3a4-4786-a5cd-74b1734b4fb2 01/24/23 20:17:07.253
    STEP: Creating a pod to test consume configMaps 01/24/23 20:17:07.263
    Jan 24 20:17:07.293: INFO: Waiting up to 5m0s for pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690" in namespace "configmap-3494" to be "Succeeded or Failed"
    Jan 24 20:17:07.312: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690": Phase="Pending", Reason="", readiness=false. Elapsed: 18.99794ms
    Jan 24 20:17:09.327: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033544548s
    Jan 24 20:17:11.328: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690": Phase="Running", Reason="", readiness=false. Elapsed: 4.034990528s
    Jan 24 20:17:13.327: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690": Phase="Running", Reason="", readiness=false. Elapsed: 6.033422419s
    Jan 24 20:17:15.381: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.088275099s
    STEP: Saw pod success 01/24/23 20:17:15.382
    Jan 24 20:17:15.382: INFO: Pod "pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690" satisfied condition "Succeeded or Failed"
    Jan 24 20:17:15.394: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 20:17:15.439
    Jan 24 20:17:15.497: INFO: Waiting for pod pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690 to disappear
    Jan 24 20:17:15.503: INFO: Pod pod-configmaps-904f0156-1ea2-49c9-b719-b9f1f0de9690 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 20:17:15.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3494" for this suite. 01/24/23 20:17:15.512
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:17:15.546
Jan 24 20:17:15.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 20:17:15.553
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:15.621
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:15.632
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 01/24/23 20:17:15.641
STEP: Ensuring ResourceQuota status is calculated 01/24/23 20:17:15.654
STEP: Creating a ResourceQuota with not best effort scope 01/24/23 20:17:18.082
STEP: Ensuring ResourceQuota status is calculated 01/24/23 20:17:18.154
STEP: Creating a best-effort pod 01/24/23 20:17:20.173
STEP: Ensuring resource quota with best effort scope captures the pod usage 01/24/23 20:17:20.266
STEP: Ensuring resource quota with not best effort ignored the pod usage 01/24/23 20:17:22.282
STEP: Deleting the pod 01/24/23 20:17:24.299
STEP: Ensuring resource quota status released the pod usage 01/24/23 20:17:24.333
STEP: Creating a not best-effort pod 01/24/23 20:17:26.346
STEP: Ensuring resource quota with not best effort scope captures the pod usage 01/24/23 20:17:26.385
STEP: Ensuring resource quota with best effort scope ignored the pod usage 01/24/23 20:17:28.406
STEP: Deleting the pod 01/24/23 20:17:30.45
STEP: Ensuring resource quota status released the pod usage 01/24/23 20:17:30.563
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 20:17:32.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4098" for this suite. 01/24/23 20:17:32.593
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":302,"skipped":5457,"failed":0}
------------------------------
• [SLOW TEST] [17.080 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:17:15.546
    Jan 24 20:17:15.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 20:17:15.553
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:15.621
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:15.632
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 01/24/23 20:17:15.641
    STEP: Ensuring ResourceQuota status is calculated 01/24/23 20:17:15.654
    STEP: Creating a ResourceQuota with not best effort scope 01/24/23 20:17:18.082
    STEP: Ensuring ResourceQuota status is calculated 01/24/23 20:17:18.154
    STEP: Creating a best-effort pod 01/24/23 20:17:20.173
    STEP: Ensuring resource quota with best effort scope captures the pod usage 01/24/23 20:17:20.266
    STEP: Ensuring resource quota with not best effort ignored the pod usage 01/24/23 20:17:22.282
    STEP: Deleting the pod 01/24/23 20:17:24.299
    STEP: Ensuring resource quota status released the pod usage 01/24/23 20:17:24.333
    STEP: Creating a not best-effort pod 01/24/23 20:17:26.346
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 01/24/23 20:17:26.385
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 01/24/23 20:17:28.406
    STEP: Deleting the pod 01/24/23 20:17:30.45
    STEP: Ensuring resource quota status released the pod usage 01/24/23 20:17:30.563
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 20:17:32.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4098" for this suite. 01/24/23 20:17:32.593
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:17:32.632
Jan 24 20:17:32.633: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 20:17:32.637
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:32.707
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:32.726
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:17:32.736
Jan 24 20:17:32.756: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a" in namespace "downward-api-8607" to be "Succeeded or Failed"
Jan 24 20:17:32.773: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.746632ms
Jan 24 20:17:34.793: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03677447s
Jan 24 20:17:36.793: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037175689s
Jan 24 20:17:38.802: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.045614261s
Jan 24 20:17:40.791: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.035136816s
STEP: Saw pod success 01/24/23 20:17:40.792
Jan 24 20:17:40.792: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a" satisfied condition "Succeeded or Failed"
Jan 24 20:17:40.798: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a container client-container: <nil>
STEP: delete the pod 01/24/23 20:17:40.818
Jan 24 20:17:40.850: INFO: Waiting for pod downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a to disappear
Jan 24 20:17:40.864: INFO: Pod downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 20:17:40.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8607" for this suite. 01/24/23 20:17:40.873
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":303,"skipped":5471,"failed":0}
------------------------------
• [SLOW TEST] [8.264 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:17:32.632
    Jan 24 20:17:32.633: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 20:17:32.637
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:32.707
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:32.726
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:17:32.736
    Jan 24 20:17:32.756: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a" in namespace "downward-api-8607" to be "Succeeded or Failed"
    Jan 24 20:17:32.773: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.746632ms
    Jan 24 20:17:34.793: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03677447s
    Jan 24 20:17:36.793: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037175689s
    Jan 24 20:17:38.802: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.045614261s
    Jan 24 20:17:40.791: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.035136816s
    STEP: Saw pod success 01/24/23 20:17:40.792
    Jan 24 20:17:40.792: INFO: Pod "downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a" satisfied condition "Succeeded or Failed"
    Jan 24 20:17:40.798: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a container client-container: <nil>
    STEP: delete the pod 01/24/23 20:17:40.818
    Jan 24 20:17:40.850: INFO: Waiting for pod downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a to disappear
    Jan 24 20:17:40.864: INFO: Pod downwardapi-volume-5a25befe-562e-4a3a-b78a-4d1915eb6a6a no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 20:17:40.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8607" for this suite. 01/24/23 20:17:40.873
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:17:40.898
Jan 24 20:17:40.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 20:17:40.902
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:40.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:40.933
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 01/24/23 20:17:40.939
Jan 24 20:17:40.961: INFO: Waiting up to 5m0s for pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d" in namespace "downward-api-6470" to be "running and ready"
Jan 24 20:17:40.985: INFO: Pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d": Phase="Pending", Reason="", readiness=false. Elapsed: 21.965796ms
Jan 24 20:17:40.985: INFO: The phase of Pod annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:17:42.995: INFO: Pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032355382s
Jan 24 20:17:42.995: INFO: The phase of Pod annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:17:44.995: INFO: Pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d": Phase="Running", Reason="", readiness=true. Elapsed: 4.031883246s
Jan 24 20:17:44.995: INFO: The phase of Pod annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d is Running (Ready = true)
Jan 24 20:17:44.995: INFO: Pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d" satisfied condition "running and ready"
Jan 24 20:17:45.546: INFO: Successfully updated pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 20:17:49.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6470" for this suite. 01/24/23 20:17:49.633
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":304,"skipped":5475,"failed":0}
------------------------------
• [SLOW TEST] [8.750 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:17:40.898
    Jan 24 20:17:40.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 20:17:40.902
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:40.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:40.933
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 01/24/23 20:17:40.939
    Jan 24 20:17:40.961: INFO: Waiting up to 5m0s for pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d" in namespace "downward-api-6470" to be "running and ready"
    Jan 24 20:17:40.985: INFO: Pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d": Phase="Pending", Reason="", readiness=false. Elapsed: 21.965796ms
    Jan 24 20:17:40.985: INFO: The phase of Pod annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:17:42.995: INFO: Pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032355382s
    Jan 24 20:17:42.995: INFO: The phase of Pod annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:17:44.995: INFO: Pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d": Phase="Running", Reason="", readiness=true. Elapsed: 4.031883246s
    Jan 24 20:17:44.995: INFO: The phase of Pod annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d is Running (Ready = true)
    Jan 24 20:17:44.995: INFO: Pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d" satisfied condition "running and ready"
    Jan 24 20:17:45.546: INFO: Successfully updated pod "annotationupdate4dfa1731-c5f0-4e64-8e75-d681996ed88d"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 20:17:49.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6470" for this suite. 01/24/23 20:17:49.633
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:17:49.673
Jan 24 20:17:49.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:17:49.677
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:49.705
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:49.711
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-60f2c289-33ad-4448-be94-8d0df8f438d4 01/24/23 20:17:49.716
STEP: Creating a pod to test consume configMaps 01/24/23 20:17:49.726
Jan 24 20:17:49.745: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3" in namespace "projected-1067" to be "Succeeded or Failed"
Jan 24 20:17:49.755: INFO: Pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.375491ms
Jan 24 20:17:51.775: INFO: Pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030104225s
Jan 24 20:17:53.772: INFO: Pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027662977s
Jan 24 20:17:55.764: INFO: Pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018780381s
STEP: Saw pod success 01/24/23 20:17:55.764
Jan 24 20:17:55.764: INFO: Pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3" satisfied condition "Succeeded or Failed"
Jan 24 20:17:55.769: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 20:17:55.785
Jan 24 20:17:55.809: INFO: Waiting for pod pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3 to disappear
Jan 24 20:17:55.813: INFO: Pod pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 24 20:17:55.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1067" for this suite. 01/24/23 20:17:55.819
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":305,"skipped":5533,"failed":0}
------------------------------
• [SLOW TEST] [6.156 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:17:49.673
    Jan 24 20:17:49.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:17:49.677
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:49.705
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:49.711
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-60f2c289-33ad-4448-be94-8d0df8f438d4 01/24/23 20:17:49.716
    STEP: Creating a pod to test consume configMaps 01/24/23 20:17:49.726
    Jan 24 20:17:49.745: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3" in namespace "projected-1067" to be "Succeeded or Failed"
    Jan 24 20:17:49.755: INFO: Pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.375491ms
    Jan 24 20:17:51.775: INFO: Pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030104225s
    Jan 24 20:17:53.772: INFO: Pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027662977s
    Jan 24 20:17:55.764: INFO: Pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018780381s
    STEP: Saw pod success 01/24/23 20:17:55.764
    Jan 24 20:17:55.764: INFO: Pod "pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3" satisfied condition "Succeeded or Failed"
    Jan 24 20:17:55.769: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 20:17:55.785
    Jan 24 20:17:55.809: INFO: Waiting for pod pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3 to disappear
    Jan 24 20:17:55.813: INFO: Pod pod-projected-configmaps-daa6508f-8214-4b46-b8dc-c4296ca52ea3 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 24 20:17:55.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1067" for this suite. 01/24/23 20:17:55.819
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:17:55.834
Jan 24 20:17:55.834: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 20:17:55.836
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:55.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:55.873
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 01/24/23 20:17:55.878
STEP: Counting existing ResourceQuota 01/24/23 20:18:00.881
STEP: Creating a ResourceQuota 01/24/23 20:18:05.888
STEP: Ensuring resource quota status is calculated 01/24/23 20:18:05.905
STEP: Creating a Secret 01/24/23 20:18:07.913
STEP: Ensuring resource quota status captures secret creation 01/24/23 20:18:07.938
STEP: Deleting a secret 01/24/23 20:18:09.947
STEP: Ensuring resource quota status released usage 01/24/23 20:18:09.975
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 20:18:11.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5199" for this suite. 01/24/23 20:18:11.99
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":306,"skipped":5555,"failed":0}
------------------------------
• [SLOW TEST] [16.167 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:17:55.834
    Jan 24 20:17:55.834: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 20:17:55.836
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:17:55.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:17:55.873
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 01/24/23 20:17:55.878
    STEP: Counting existing ResourceQuota 01/24/23 20:18:00.881
    STEP: Creating a ResourceQuota 01/24/23 20:18:05.888
    STEP: Ensuring resource quota status is calculated 01/24/23 20:18:05.905
    STEP: Creating a Secret 01/24/23 20:18:07.913
    STEP: Ensuring resource quota status captures secret creation 01/24/23 20:18:07.938
    STEP: Deleting a secret 01/24/23 20:18:09.947
    STEP: Ensuring resource quota status released usage 01/24/23 20:18:09.975
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 20:18:11.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5199" for this suite. 01/24/23 20:18:11.99
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:18:12.008
Jan 24 20:18:12.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename dns 01/24/23 20:18:12.014
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:18:12.046
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:18:12.056
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 01/24/23 20:18:12.076
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1800.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1800.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 01/24/23 20:18:12.113
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1800.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1800.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 01/24/23 20:18:12.12
STEP: creating a pod to probe DNS 01/24/23 20:18:12.12
STEP: submitting the pod to kubernetes 01/24/23 20:18:12.121
Jan 24 20:18:12.145: INFO: Waiting up to 15m0s for pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed" in namespace "dns-1800" to be "running"
Jan 24 20:18:12.198: INFO: Pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed": Phase="Pending", Reason="", readiness=false. Elapsed: 53.023186ms
Jan 24 20:18:14.233: INFO: Pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087559498s
Jan 24 20:18:16.214: INFO: Pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068500405s
Jan 24 20:18:18.231: INFO: Pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed": Phase="Running", Reason="", readiness=true. Elapsed: 6.085740487s
Jan 24 20:18:18.231: INFO: Pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed" satisfied condition "running"
STEP: retrieving the pod 01/24/23 20:18:18.231
STEP: looking for the results for each expected name from probers 01/24/23 20:18:18.296
Jan 24 20:18:18.351: INFO: DNS probes using dns-1800/dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed succeeded

STEP: deleting the pod 01/24/23 20:18:18.351
STEP: deleting the test headless service 01/24/23 20:18:18.382
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 24 20:18:18.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1800" for this suite. 01/24/23 20:18:18.532
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":307,"skipped":5581,"failed":0}
------------------------------
• [SLOW TEST] [6.537 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:18:12.008
    Jan 24 20:18:12.008: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename dns 01/24/23 20:18:12.014
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:18:12.046
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:18:12.056
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 01/24/23 20:18:12.076
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1800.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1800.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     01/24/23 20:18:12.113
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1800.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1800.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     01/24/23 20:18:12.12
    STEP: creating a pod to probe DNS 01/24/23 20:18:12.12
    STEP: submitting the pod to kubernetes 01/24/23 20:18:12.121
    Jan 24 20:18:12.145: INFO: Waiting up to 15m0s for pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed" in namespace "dns-1800" to be "running"
    Jan 24 20:18:12.198: INFO: Pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed": Phase="Pending", Reason="", readiness=false. Elapsed: 53.023186ms
    Jan 24 20:18:14.233: INFO: Pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087559498s
    Jan 24 20:18:16.214: INFO: Pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068500405s
    Jan 24 20:18:18.231: INFO: Pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed": Phase="Running", Reason="", readiness=true. Elapsed: 6.085740487s
    Jan 24 20:18:18.231: INFO: Pod "dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed" satisfied condition "running"
    STEP: retrieving the pod 01/24/23 20:18:18.231
    STEP: looking for the results for each expected name from probers 01/24/23 20:18:18.296
    Jan 24 20:18:18.351: INFO: DNS probes using dns-1800/dns-test-d3924c96-4f80-444a-bb7d-244d9aabb4ed succeeded

    STEP: deleting the pod 01/24/23 20:18:18.351
    STEP: deleting the test headless service 01/24/23 20:18:18.382
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 24 20:18:18.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1800" for this suite. 01/24/23 20:18:18.532
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:18:18.562
Jan 24 20:18:18.562: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 20:18:18.572
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:18:18.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:18:18.81
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 20:18:19.125
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 20:18:21.239
STEP: Deploying the webhook pod 01/24/23 20:18:21.325
STEP: Wait for the deployment to be ready 01/24/23 20:18:21.383
Jan 24 20:18:21.434: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 24 20:18:23.474: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 18, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 18, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 18, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 18, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 20:18:25.496
STEP: Verifying the service has paired with the endpoint 01/24/23 20:18:25.708
Jan 24 20:18:26.710: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Jan 24 20:18:26.740: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Registering the custom resource webhook via the AdmissionRegistration API 01/24/23 20:18:27.274
STEP: Creating a custom resource that should be denied by the webhook 01/24/23 20:18:27.366
STEP: Creating a custom resource whose deletion would be denied by the webhook 01/24/23 20:18:29.7
STEP: Updating the custom resource with disallowed data should be denied 01/24/23 20:18:29.726
STEP: Deleting the custom resource should be denied 01/24/23 20:18:29.78
STEP: Remove the offending key and value from the custom resource data 01/24/23 20:18:29.838
STEP: Deleting the updated custom resource should be successful 01/24/23 20:18:29.885
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:18:30.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1982" for this suite. 01/24/23 20:18:30.562
STEP: Destroying namespace "webhook-1982-markers" for this suite. 01/24/23 20:18:30.66
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":308,"skipped":5595,"failed":0}
------------------------------
• [SLOW TEST] [12.981 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:18:18.562
    Jan 24 20:18:18.562: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 20:18:18.572
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:18:18.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:18:18.81
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 20:18:19.125
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 20:18:21.239
    STEP: Deploying the webhook pod 01/24/23 20:18:21.325
    STEP: Wait for the deployment to be ready 01/24/23 20:18:21.383
    Jan 24 20:18:21.434: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 24 20:18:23.474: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 18, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 18, 21, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 18, 21, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 18, 21, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 20:18:25.496
    STEP: Verifying the service has paired with the endpoint 01/24/23 20:18:25.708
    Jan 24 20:18:26.710: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Jan 24 20:18:26.740: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 01/24/23 20:18:27.274
    STEP: Creating a custom resource that should be denied by the webhook 01/24/23 20:18:27.366
    STEP: Creating a custom resource whose deletion would be denied by the webhook 01/24/23 20:18:29.7
    STEP: Updating the custom resource with disallowed data should be denied 01/24/23 20:18:29.726
    STEP: Deleting the custom resource should be denied 01/24/23 20:18:29.78
    STEP: Remove the offending key and value from the custom resource data 01/24/23 20:18:29.838
    STEP: Deleting the updated custom resource should be successful 01/24/23 20:18:29.885
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:18:30.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1982" for this suite. 01/24/23 20:18:30.562
    STEP: Destroying namespace "webhook-1982-markers" for this suite. 01/24/23 20:18:30.66
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:18:31.548
Jan 24 20:18:31.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 20:18:31.611
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:18:31.919
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:18:31.956
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-6ac41d8b-0427-41f5-8c9d-e8c058ad94a2 01/24/23 20:18:32.157
STEP: Creating the pod 01/24/23 20:18:32.195
Jan 24 20:18:32.269: INFO: Waiting up to 5m0s for pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1" in namespace "configmap-4710" to be "running and ready"
Jan 24 20:18:32.316: INFO: Pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1": Phase="Pending", Reason="", readiness=false. Elapsed: 45.821572ms
Jan 24 20:18:32.316: INFO: The phase of Pod pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:18:34.352: INFO: Pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081811271s
Jan 24 20:18:34.352: INFO: The phase of Pod pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:18:36.354: INFO: Pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.084089542s
Jan 24 20:18:36.356: INFO: The phase of Pod pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:18:38.346: INFO: Pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1": Phase="Running", Reason="", readiness=true. Elapsed: 6.076090487s
Jan 24 20:18:38.346: INFO: The phase of Pod pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1 is Running (Ready = true)
Jan 24 20:18:38.346: INFO: Pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-6ac41d8b-0427-41f5-8c9d-e8c058ad94a2 01/24/23 20:18:38.483
STEP: waiting to observe update in volume 01/24/23 20:18:38.578
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 20:19:56.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4710" for this suite. 01/24/23 20:19:56.803
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":309,"skipped":5607,"failed":0}
------------------------------
• [SLOW TEST] [85.277 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:18:31.548
    Jan 24 20:18:31.548: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 20:18:31.611
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:18:31.919
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:18:31.956
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-6ac41d8b-0427-41f5-8c9d-e8c058ad94a2 01/24/23 20:18:32.157
    STEP: Creating the pod 01/24/23 20:18:32.195
    Jan 24 20:18:32.269: INFO: Waiting up to 5m0s for pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1" in namespace "configmap-4710" to be "running and ready"
    Jan 24 20:18:32.316: INFO: Pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1": Phase="Pending", Reason="", readiness=false. Elapsed: 45.821572ms
    Jan 24 20:18:32.316: INFO: The phase of Pod pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:18:34.352: INFO: Pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081811271s
    Jan 24 20:18:34.352: INFO: The phase of Pod pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:18:36.354: INFO: Pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.084089542s
    Jan 24 20:18:36.356: INFO: The phase of Pod pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:18:38.346: INFO: Pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1": Phase="Running", Reason="", readiness=true. Elapsed: 6.076090487s
    Jan 24 20:18:38.346: INFO: The phase of Pod pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1 is Running (Ready = true)
    Jan 24 20:18:38.346: INFO: Pod "pod-configmaps-cdff5aec-3c92-4981-8a31-6b06677683e1" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-6ac41d8b-0427-41f5-8c9d-e8c058ad94a2 01/24/23 20:18:38.483
    STEP: waiting to observe update in volume 01/24/23 20:18:38.578
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 20:19:56.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4710" for this suite. 01/24/23 20:19:56.803
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:19:56.843
Jan 24 20:19:56.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 20:19:56.847
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:19:56.889
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:19:56.9
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 01/24/23 20:19:56.911
Jan 24 20:19:56.912: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9783 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 01/24/23 20:19:57.195
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 20:19:57.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9783" for this suite. 01/24/23 20:19:57.247
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":310,"skipped":5628,"failed":0}
------------------------------
• [0.442 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:19:56.843
    Jan 24 20:19:56.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 20:19:56.847
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:19:56.889
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:19:56.9
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 01/24/23 20:19:56.911
    Jan 24 20:19:56.912: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-9783 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 01/24/23 20:19:57.195
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 20:19:57.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9783" for this suite. 01/24/23 20:19:57.247
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:19:57.286
Jan 24 20:19:57.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename dns 01/24/23 20:19:57.291
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:19:57.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:19:57.364
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 01/24/23 20:19:57.376
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local;sleep 1; done
 01/24/23 20:19:57.424
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local;sleep 1; done
 01/24/23 20:19:57.427
STEP: creating a pod to probe DNS 01/24/23 20:19:57.429
STEP: submitting the pod to kubernetes 01/24/23 20:19:57.429
Jan 24 20:19:57.470: INFO: Waiting up to 15m0s for pod "dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8" in namespace "dns-8127" to be "running"
Jan 24 20:19:57.490: INFO: Pod "dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 19.2954ms
Jan 24 20:19:59.516: INFO: Pod "dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046026232s
Jan 24 20:20:01.507: INFO: Pod "dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8": Phase="Running", Reason="", readiness=true. Elapsed: 4.036271255s
Jan 24 20:20:01.507: INFO: Pod "dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8" satisfied condition "running"
STEP: retrieving the pod 01/24/23 20:20:01.507
STEP: looking for the results for each expected name from probers 01/24/23 20:20:01.521
Jan 24 20:20:01.537: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:01.553: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:01.565: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:01.580: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:01.593: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:01.613: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:01.646: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:01.666: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:01.666: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

Jan 24 20:20:06.680: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:06.704: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:06.714: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:06.725: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:06.741: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:06.765: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:06.778: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:06.795: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:06.795: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

Jan 24 20:20:11.713: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:11.730: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:11.744: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:11.757: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:11.778: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:11.789: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:11.798: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:11.811: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:11.812: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

Jan 24 20:20:16.682: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:16.699: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:16.717: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:16.730: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:16.742: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:16.755: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:16.765: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:16.775: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:16.775: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

Jan 24 20:20:21.800: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:21.837: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:21.859: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:21.871: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:21.886: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:21.921: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:21.982: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:21.997: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:21.998: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

Jan 24 20:20:26.680: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:26.691: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:26.702: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:26.715: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:26.726: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:26.745: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:26.760: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:26.775: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
Jan 24 20:20:26.775: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

Jan 24 20:20:32.701: INFO: DNS probes using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 succeeded

STEP: deleting the pod 01/24/23 20:20:32.702
STEP: deleting the test headless service 01/24/23 20:20:33.493
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 24 20:20:34.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8127" for this suite. 01/24/23 20:20:34.482
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":311,"skipped":5629,"failed":0}
------------------------------
• [SLOW TEST] [37.396 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:19:57.286
    Jan 24 20:19:57.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename dns 01/24/23 20:19:57.291
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:19:57.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:19:57.364
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 01/24/23 20:19:57.376
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local;sleep 1; done
     01/24/23 20:19:57.424
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8127.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local;sleep 1; done
     01/24/23 20:19:57.427
    STEP: creating a pod to probe DNS 01/24/23 20:19:57.429
    STEP: submitting the pod to kubernetes 01/24/23 20:19:57.429
    Jan 24 20:19:57.470: INFO: Waiting up to 15m0s for pod "dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8" in namespace "dns-8127" to be "running"
    Jan 24 20:19:57.490: INFO: Pod "dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 19.2954ms
    Jan 24 20:19:59.516: INFO: Pod "dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046026232s
    Jan 24 20:20:01.507: INFO: Pod "dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8": Phase="Running", Reason="", readiness=true. Elapsed: 4.036271255s
    Jan 24 20:20:01.507: INFO: Pod "dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8" satisfied condition "running"
    STEP: retrieving the pod 01/24/23 20:20:01.507
    STEP: looking for the results for each expected name from probers 01/24/23 20:20:01.521
    Jan 24 20:20:01.537: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:01.553: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:01.565: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:01.580: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:01.593: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:01.613: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:01.646: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:01.666: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:01.666: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

    Jan 24 20:20:06.680: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:06.704: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:06.714: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:06.725: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:06.741: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:06.765: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:06.778: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:06.795: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:06.795: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

    Jan 24 20:20:11.713: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:11.730: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:11.744: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:11.757: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:11.778: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:11.789: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:11.798: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:11.811: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:11.812: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

    Jan 24 20:20:16.682: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:16.699: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:16.717: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:16.730: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:16.742: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:16.755: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:16.765: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:16.775: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:16.775: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

    Jan 24 20:20:21.800: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:21.837: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:21.859: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:21.871: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:21.886: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:21.921: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:21.982: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:21.997: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:21.998: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

    Jan 24 20:20:26.680: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:26.691: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:26.702: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:26.715: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:26.726: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:26.745: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:26.760: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:26.775: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local from pod dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8: the server could not find the requested resource (get pods dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8)
    Jan 24 20:20:26.775: INFO: Lookups using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8127.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8127.svc.cluster.local jessie_udp@dns-test-service-2.dns-8127.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8127.svc.cluster.local]

    Jan 24 20:20:32.701: INFO: DNS probes using dns-8127/dns-test-22beeaa3-9796-4bf0-9ee0-3f57f622d9d8 succeeded

    STEP: deleting the pod 01/24/23 20:20:32.702
    STEP: deleting the test headless service 01/24/23 20:20:33.493
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 24 20:20:34.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8127" for this suite. 01/24/23 20:20:34.482
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:20:35.679
Jan 24 20:20:35.916: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 20:20:35.956
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:20:36.655
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:20:36.678
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 01/24/23 20:20:36.703
Jan 24 20:20:36.704: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Jan 24 20:20:36.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
Jan 24 20:20:38.692: INFO: stderr: ""
Jan 24 20:20:38.692: INFO: stdout: "service/agnhost-replica created\n"
Jan 24 20:20:38.692: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Jan 24 20:20:38.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
Jan 24 20:20:39.261: INFO: stderr: ""
Jan 24 20:20:39.261: INFO: stdout: "service/agnhost-primary created\n"
Jan 24 20:20:39.261: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 24 20:20:39.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
Jan 24 20:20:39.750: INFO: stderr: ""
Jan 24 20:20:39.750: INFO: stdout: "service/frontend created\n"
Jan 24 20:20:39.751: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Jan 24 20:20:39.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
Jan 24 20:20:40.461: INFO: stderr: ""
Jan 24 20:20:40.462: INFO: stdout: "deployment.apps/frontend created\n"
Jan 24 20:20:40.463: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 24 20:20:40.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
Jan 24 20:20:41.249: INFO: stderr: ""
Jan 24 20:20:41.249: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Jan 24 20:20:41.250: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 24 20:20:41.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
Jan 24 20:20:42.462: INFO: stderr: ""
Jan 24 20:20:42.462: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 01/24/23 20:20:42.462
Jan 24 20:20:42.464: INFO: Waiting for all frontend pods to be Running.
Jan 24 20:20:47.576: INFO: Waiting for frontend to serve content.
Jan 24 20:20:47.604: INFO: Trying to add a new entry to the guestbook.
Jan 24 20:20:47.632: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 01/24/23 20:20:47.652
Jan 24 20:20:47.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
Jan 24 20:20:47.868: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 24 20:20:47.868: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 01/24/23 20:20:47.868
Jan 24 20:20:47.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
Jan 24 20:20:48.099: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 24 20:20:48.099: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 01/24/23 20:20:48.1
Jan 24 20:20:48.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
Jan 24 20:20:48.313: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 24 20:20:48.314: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 01/24/23 20:20:48.314
Jan 24 20:20:48.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
Jan 24 20:20:48.519: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 24 20:20:48.519: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 01/24/23 20:20:48.519
Jan 24 20:20:48.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
Jan 24 20:20:48.860: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 24 20:20:48.860: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 01/24/23 20:20:48.864
Jan 24 20:20:48.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
Jan 24 20:20:49.366: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 24 20:20:49.366: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 20:20:49.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1557" for this suite. 01/24/23 20:20:49.379
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":312,"skipped":5638,"failed":0}
------------------------------
• [SLOW TEST] [14.426 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:20:35.679
    Jan 24 20:20:35.916: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 20:20:35.956
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:20:36.655
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:20:36.678
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 01/24/23 20:20:36.703
    Jan 24 20:20:36.704: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Jan 24 20:20:36.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
    Jan 24 20:20:38.692: INFO: stderr: ""
    Jan 24 20:20:38.692: INFO: stdout: "service/agnhost-replica created\n"
    Jan 24 20:20:38.692: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Jan 24 20:20:38.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
    Jan 24 20:20:39.261: INFO: stderr: ""
    Jan 24 20:20:39.261: INFO: stdout: "service/agnhost-primary created\n"
    Jan 24 20:20:39.261: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Jan 24 20:20:39.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
    Jan 24 20:20:39.750: INFO: stderr: ""
    Jan 24 20:20:39.750: INFO: stdout: "service/frontend created\n"
    Jan 24 20:20:39.751: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Jan 24 20:20:39.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
    Jan 24 20:20:40.461: INFO: stderr: ""
    Jan 24 20:20:40.462: INFO: stdout: "deployment.apps/frontend created\n"
    Jan 24 20:20:40.463: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Jan 24 20:20:40.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
    Jan 24 20:20:41.249: INFO: stderr: ""
    Jan 24 20:20:41.249: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Jan 24 20:20:41.250: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Jan 24 20:20:41.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 create -f -'
    Jan 24 20:20:42.462: INFO: stderr: ""
    Jan 24 20:20:42.462: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 01/24/23 20:20:42.462
    Jan 24 20:20:42.464: INFO: Waiting for all frontend pods to be Running.
    Jan 24 20:20:47.576: INFO: Waiting for frontend to serve content.
    Jan 24 20:20:47.604: INFO: Trying to add a new entry to the guestbook.
    Jan 24 20:20:47.632: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 01/24/23 20:20:47.652
    Jan 24 20:20:47.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
    Jan 24 20:20:47.868: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 24 20:20:47.868: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 01/24/23 20:20:47.868
    Jan 24 20:20:47.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
    Jan 24 20:20:48.099: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 24 20:20:48.099: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 01/24/23 20:20:48.1
    Jan 24 20:20:48.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
    Jan 24 20:20:48.313: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 24 20:20:48.314: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 01/24/23 20:20:48.314
    Jan 24 20:20:48.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
    Jan 24 20:20:48.519: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 24 20:20:48.519: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 01/24/23 20:20:48.519
    Jan 24 20:20:48.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
    Jan 24 20:20:48.860: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 24 20:20:48.860: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 01/24/23 20:20:48.864
    Jan 24 20:20:48.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-1557 delete --grace-period=0 --force -f -'
    Jan 24 20:20:49.366: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 24 20:20:49.366: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 20:20:49.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1557" for this suite. 01/24/23 20:20:49.379
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:20:49.414
Jan 24 20:20:49.415: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sched-preemption 01/24/23 20:20:49.419
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:20:49.453
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:20:49.465
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jan 24 20:20:49.538: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 24 20:21:49.689: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:21:49.698
Jan 24 20:21:49.699: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename sched-preemption-path 01/24/23 20:21:49.704
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:21:49.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:21:49.77
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 01/24/23 20:21:49.79
STEP: Trying to launch a pod without a label to get a node which can launch it. 01/24/23 20:21:49.791
Jan 24 20:21:49.817: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-7531" to be "running"
Jan 24 20:21:49.834: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 16.163775ms
Jan 24 20:21:51.846: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028301734s
Jan 24 20:21:53.897: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.080048249s
Jan 24 20:21:53.898: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 01/24/23 20:21:53.941
Jan 24 20:21:54.027: INFO: found a healthy node: vikash-v125latest-conf-71087
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Jan 24 20:22:12.603: INFO: pods created so far: [1 1 1]
Jan 24 20:22:12.603: INFO: length of pods created so far: 3
Jan 24 20:22:16.636: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Jan 24 20:22:23.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-7531" for this suite. 01/24/23 20:22:23.656
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Jan 24 20:22:23.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-1809" for this suite. 01/24/23 20:22:23.902
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":313,"skipped":5642,"failed":0}
------------------------------
• [SLOW TEST] [94.879 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:20:49.414
    Jan 24 20:20:49.415: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sched-preemption 01/24/23 20:20:49.419
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:20:49.453
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:20:49.465
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Jan 24 20:20:49.538: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 24 20:21:49.689: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:21:49.698
    Jan 24 20:21:49.699: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename sched-preemption-path 01/24/23 20:21:49.704
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:21:49.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:21:49.77
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 01/24/23 20:21:49.79
    STEP: Trying to launch a pod without a label to get a node which can launch it. 01/24/23 20:21:49.791
    Jan 24 20:21:49.817: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-7531" to be "running"
    Jan 24 20:21:49.834: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 16.163775ms
    Jan 24 20:21:51.846: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028301734s
    Jan 24 20:21:53.897: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.080048249s
    Jan 24 20:21:53.898: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 01/24/23 20:21:53.941
    Jan 24 20:21:54.027: INFO: found a healthy node: vikash-v125latest-conf-71087
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Jan 24 20:22:12.603: INFO: pods created so far: [1 1 1]
    Jan 24 20:22:12.603: INFO: length of pods created so far: 3
    Jan 24 20:22:16.636: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Jan 24 20:22:23.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-7531" for this suite. 01/24/23 20:22:23.656
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 20:22:23.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-1809" for this suite. 01/24/23 20:22:23.902
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:22:24.334
Jan 24 20:22:24.335: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename proxy 01/24/23 20:22:24.366
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:22:24.453
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:22:24.484
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Jan 24 20:22:24.510: INFO: Creating pod...
Jan 24 20:22:24.571: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-71" to be "running"
Jan 24 20:22:24.622: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 50.206298ms
Jan 24 20:22:26.637: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.065358652s
Jan 24 20:22:26.637: INFO: Pod "agnhost" satisfied condition "running"
Jan 24 20:22:26.637: INFO: Creating service...
Jan 24 20:22:26.669: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/DELETE
Jan 24 20:22:26.720: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jan 24 20:22:26.721: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/GET
Jan 24 20:22:26.750: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Jan 24 20:22:26.750: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/HEAD
Jan 24 20:22:26.776: INFO: http.Client request:HEAD | StatusCode:200
Jan 24 20:22:26.777: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/OPTIONS
Jan 24 20:22:26.785: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jan 24 20:22:26.785: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/PATCH
Jan 24 20:22:26.792: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jan 24 20:22:26.792: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/POST
Jan 24 20:22:26.803: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jan 24 20:22:26.803: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/PUT
Jan 24 20:22:26.813: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jan 24 20:22:26.813: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/DELETE
Jan 24 20:22:26.832: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jan 24 20:22:26.832: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/GET
Jan 24 20:22:26.850: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Jan 24 20:22:26.850: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/HEAD
Jan 24 20:22:26.865: INFO: http.Client request:HEAD | StatusCode:200
Jan 24 20:22:26.865: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/OPTIONS
Jan 24 20:22:26.881: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jan 24 20:22:26.881: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/PATCH
Jan 24 20:22:26.897: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jan 24 20:22:26.897: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/POST
Jan 24 20:22:26.910: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jan 24 20:22:26.911: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/PUT
Jan 24 20:22:26.940: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Jan 24 20:22:26.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-71" for this suite. 01/24/23 20:22:26.958
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":314,"skipped":5665,"failed":0}
------------------------------
• [2.657 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:22:24.334
    Jan 24 20:22:24.335: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename proxy 01/24/23 20:22:24.366
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:22:24.453
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:22:24.484
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Jan 24 20:22:24.510: INFO: Creating pod...
    Jan 24 20:22:24.571: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-71" to be "running"
    Jan 24 20:22:24.622: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 50.206298ms
    Jan 24 20:22:26.637: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.065358652s
    Jan 24 20:22:26.637: INFO: Pod "agnhost" satisfied condition "running"
    Jan 24 20:22:26.637: INFO: Creating service...
    Jan 24 20:22:26.669: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/DELETE
    Jan 24 20:22:26.720: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jan 24 20:22:26.721: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/GET
    Jan 24 20:22:26.750: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Jan 24 20:22:26.750: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/HEAD
    Jan 24 20:22:26.776: INFO: http.Client request:HEAD | StatusCode:200
    Jan 24 20:22:26.777: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/OPTIONS
    Jan 24 20:22:26.785: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jan 24 20:22:26.785: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/PATCH
    Jan 24 20:22:26.792: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jan 24 20:22:26.792: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/POST
    Jan 24 20:22:26.803: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jan 24 20:22:26.803: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/pods/agnhost/proxy/some/path/with/PUT
    Jan 24 20:22:26.813: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Jan 24 20:22:26.813: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/DELETE
    Jan 24 20:22:26.832: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Jan 24 20:22:26.832: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/GET
    Jan 24 20:22:26.850: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Jan 24 20:22:26.850: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/HEAD
    Jan 24 20:22:26.865: INFO: http.Client request:HEAD | StatusCode:200
    Jan 24 20:22:26.865: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/OPTIONS
    Jan 24 20:22:26.881: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Jan 24 20:22:26.881: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/PATCH
    Jan 24 20:22:26.897: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Jan 24 20:22:26.897: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/POST
    Jan 24 20:22:26.910: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Jan 24 20:22:26.911: INFO: Starting http.Client for https://10.10.0.1:443/api/v1/namespaces/proxy-71/services/test-service/proxy/some/path/with/PUT
    Jan 24 20:22:26.940: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Jan 24 20:22:26.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-71" for this suite. 01/24/23 20:22:26.958
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:22:27.023
Jan 24 20:22:27.024: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 20:22:27.029
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:22:27.107
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:22:27.12
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-bd758bbc-f2e0-479c-ab16-ba2a03e27a28 01/24/23 20:22:27.13
STEP: Creating a pod to test consume configMaps 01/24/23 20:22:27.144
Jan 24 20:22:27.173: INFO: Waiting up to 5m0s for pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101" in namespace "configmap-1865" to be "Succeeded or Failed"
Jan 24 20:22:27.194: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101": Phase="Pending", Reason="", readiness=false. Elapsed: 20.977951ms
Jan 24 20:22:29.226: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0531003s
Jan 24 20:22:31.252: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101": Phase="Pending", Reason="", readiness=false. Elapsed: 4.078751374s
Jan 24 20:22:33.279: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101": Phase="Pending", Reason="", readiness=false. Elapsed: 6.105842613s
Jan 24 20:22:35.217: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.043905005s
STEP: Saw pod success 01/24/23 20:22:35.218
Jan 24 20:22:35.219: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101" satisfied condition "Succeeded or Failed"
Jan 24 20:22:35.230: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 20:22:35.289
Jan 24 20:22:35.327: INFO: Waiting for pod pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101 to disappear
Jan 24 20:22:35.334: INFO: Pod pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 20:22:35.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1865" for this suite. 01/24/23 20:22:35.343
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":315,"skipped":5700,"failed":0}
------------------------------
• [SLOW TEST] [8.345 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:22:27.023
    Jan 24 20:22:27.024: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 20:22:27.029
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:22:27.107
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:22:27.12
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-bd758bbc-f2e0-479c-ab16-ba2a03e27a28 01/24/23 20:22:27.13
    STEP: Creating a pod to test consume configMaps 01/24/23 20:22:27.144
    Jan 24 20:22:27.173: INFO: Waiting up to 5m0s for pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101" in namespace "configmap-1865" to be "Succeeded or Failed"
    Jan 24 20:22:27.194: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101": Phase="Pending", Reason="", readiness=false. Elapsed: 20.977951ms
    Jan 24 20:22:29.226: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0531003s
    Jan 24 20:22:31.252: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101": Phase="Pending", Reason="", readiness=false. Elapsed: 4.078751374s
    Jan 24 20:22:33.279: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101": Phase="Pending", Reason="", readiness=false. Elapsed: 6.105842613s
    Jan 24 20:22:35.217: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.043905005s
    STEP: Saw pod success 01/24/23 20:22:35.218
    Jan 24 20:22:35.219: INFO: Pod "pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101" satisfied condition "Succeeded or Failed"
    Jan 24 20:22:35.230: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 20:22:35.289
    Jan 24 20:22:35.327: INFO: Waiting for pod pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101 to disappear
    Jan 24 20:22:35.334: INFO: Pod pod-configmaps-10a47576-2cd9-454c-b09c-1f60b801e101 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 20:22:35.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1865" for this suite. 01/24/23 20:22:35.343
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:22:35.373
Jan 24 20:22:35.373: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 20:22:35.377
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:22:35.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:22:35.432
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Jan 24 20:22:35.446: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 01/24/23 20:22:53.012
Jan 24 20:22:53.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 create -f -'
Jan 24 20:22:57.298: INFO: stderr: ""
Jan 24 20:22:57.298: INFO: stdout: "e2e-test-crd-publish-openapi-6790-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jan 24 20:22:57.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 delete e2e-test-crd-publish-openapi-6790-crds test-foo'
Jan 24 20:22:57.669: INFO: stderr: ""
Jan 24 20:22:57.670: INFO: stdout: "e2e-test-crd-publish-openapi-6790-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Jan 24 20:22:57.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 apply -f -'
Jan 24 20:22:59.743: INFO: stderr: ""
Jan 24 20:22:59.743: INFO: stdout: "e2e-test-crd-publish-openapi-6790-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jan 24 20:22:59.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 delete e2e-test-crd-publish-openapi-6790-crds test-foo'
Jan 24 20:23:00.735: INFO: stderr: ""
Jan 24 20:23:00.735: INFO: stdout: "e2e-test-crd-publish-openapi-6790-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 01/24/23 20:23:00.735
Jan 24 20:23:00.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 create -f -'
Jan 24 20:23:02.208: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 01/24/23 20:23:02.209
Jan 24 20:23:02.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 create -f -'
Jan 24 20:23:03.499: INFO: rc: 1
Jan 24 20:23:03.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 apply -f -'
Jan 24 20:23:05.309: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 01/24/23 20:23:05.309
Jan 24 20:23:05.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 create -f -'
Jan 24 20:23:06.910: INFO: rc: 1
Jan 24 20:23:06.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 apply -f -'
Jan 24 20:23:08.230: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 01/24/23 20:23:08.231
Jan 24 20:23:08.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 explain e2e-test-crd-publish-openapi-6790-crds'
Jan 24 20:23:10.008: INFO: stderr: ""
Jan 24 20:23:10.008: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6790-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 01/24/23 20:23:10.009
Jan 24 20:23:10.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 explain e2e-test-crd-publish-openapi-6790-crds.metadata'
Jan 24 20:23:11.846: INFO: stderr: ""
Jan 24 20:23:11.846: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6790-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Jan 24 20:23:11.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 explain e2e-test-crd-publish-openapi-6790-crds.spec'
Jan 24 20:23:13.142: INFO: stderr: ""
Jan 24 20:23:13.142: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6790-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Jan 24 20:23:13.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 explain e2e-test-crd-publish-openapi-6790-crds.spec.bars'
Jan 24 20:23:14.413: INFO: stderr: ""
Jan 24 20:23:14.413: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6790-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 01/24/23 20:23:14.414
Jan 24 20:23:14.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 explain e2e-test-crd-publish-openapi-6790-crds.spec.bars2'
Jan 24 20:23:16.413: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:23:33.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9102" for this suite. 01/24/23 20:23:33.664
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":316,"skipped":5707,"failed":0}
------------------------------
• [SLOW TEST] [58.314 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:22:35.373
    Jan 24 20:22:35.373: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 20:22:35.377
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:22:35.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:22:35.432
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Jan 24 20:22:35.446: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 01/24/23 20:22:53.012
    Jan 24 20:22:53.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 create -f -'
    Jan 24 20:22:57.298: INFO: stderr: ""
    Jan 24 20:22:57.298: INFO: stdout: "e2e-test-crd-publish-openapi-6790-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Jan 24 20:22:57.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 delete e2e-test-crd-publish-openapi-6790-crds test-foo'
    Jan 24 20:22:57.669: INFO: stderr: ""
    Jan 24 20:22:57.670: INFO: stdout: "e2e-test-crd-publish-openapi-6790-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Jan 24 20:22:57.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 apply -f -'
    Jan 24 20:22:59.743: INFO: stderr: ""
    Jan 24 20:22:59.743: INFO: stdout: "e2e-test-crd-publish-openapi-6790-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Jan 24 20:22:59.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 delete e2e-test-crd-publish-openapi-6790-crds test-foo'
    Jan 24 20:23:00.735: INFO: stderr: ""
    Jan 24 20:23:00.735: INFO: stdout: "e2e-test-crd-publish-openapi-6790-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 01/24/23 20:23:00.735
    Jan 24 20:23:00.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 create -f -'
    Jan 24 20:23:02.208: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 01/24/23 20:23:02.209
    Jan 24 20:23:02.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 create -f -'
    Jan 24 20:23:03.499: INFO: rc: 1
    Jan 24 20:23:03.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 apply -f -'
    Jan 24 20:23:05.309: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 01/24/23 20:23:05.309
    Jan 24 20:23:05.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 create -f -'
    Jan 24 20:23:06.910: INFO: rc: 1
    Jan 24 20:23:06.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 --namespace=crd-publish-openapi-9102 apply -f -'
    Jan 24 20:23:08.230: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 01/24/23 20:23:08.231
    Jan 24 20:23:08.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 explain e2e-test-crd-publish-openapi-6790-crds'
    Jan 24 20:23:10.008: INFO: stderr: ""
    Jan 24 20:23:10.008: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6790-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 01/24/23 20:23:10.009
    Jan 24 20:23:10.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 explain e2e-test-crd-publish-openapi-6790-crds.metadata'
    Jan 24 20:23:11.846: INFO: stderr: ""
    Jan 24 20:23:11.846: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6790-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Jan 24 20:23:11.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 explain e2e-test-crd-publish-openapi-6790-crds.spec'
    Jan 24 20:23:13.142: INFO: stderr: ""
    Jan 24 20:23:13.142: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6790-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Jan 24 20:23:13.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 explain e2e-test-crd-publish-openapi-6790-crds.spec.bars'
    Jan 24 20:23:14.413: INFO: stderr: ""
    Jan 24 20:23:14.413: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6790-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 01/24/23 20:23:14.414
    Jan 24 20:23:14.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-9102 explain e2e-test-crd-publish-openapi-6790-crds.spec.bars2'
    Jan 24 20:23:16.413: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:23:33.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9102" for this suite. 01/24/23 20:23:33.664
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:23:33.708
Jan 24 20:23:33.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 20:23:33.711
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:23:33.775
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:23:33.802
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 01/24/23 20:23:33.821
Jan 24 20:23:33.875: INFO: Waiting up to 5m0s for pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4" in namespace "emptydir-7761" to be "Succeeded or Failed"
Jan 24 20:23:33.910: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4": Phase="Pending", Reason="", readiness=false. Elapsed: 34.547708ms
Jan 24 20:23:35.933: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0582043s
Jan 24 20:23:37.925: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4": Phase="Running", Reason="", readiness=false. Elapsed: 4.049719037s
Jan 24 20:23:39.963: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4": Phase="Running", Reason="", readiness=false. Elapsed: 6.088120064s
Jan 24 20:23:41.920: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.044629084s
STEP: Saw pod success 01/24/23 20:23:41.92
Jan 24 20:23:41.921: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4" satisfied condition "Succeeded or Failed"
Jan 24 20:23:41.933: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-179c0f27-0584-4298-8abb-2dc151e465f4 container test-container: <nil>
STEP: delete the pod 01/24/23 20:23:41.964
Jan 24 20:23:42.027: INFO: Waiting for pod pod-179c0f27-0584-4298-8abb-2dc151e465f4 to disappear
Jan 24 20:23:42.036: INFO: Pod pod-179c0f27-0584-4298-8abb-2dc151e465f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 20:23:42.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7761" for this suite. 01/24/23 20:23:42.069
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":317,"skipped":5716,"failed":0}
------------------------------
• [SLOW TEST] [8.404 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:23:33.708
    Jan 24 20:23:33.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 20:23:33.711
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:23:33.775
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:23:33.802
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 01/24/23 20:23:33.821
    Jan 24 20:23:33.875: INFO: Waiting up to 5m0s for pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4" in namespace "emptydir-7761" to be "Succeeded or Failed"
    Jan 24 20:23:33.910: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4": Phase="Pending", Reason="", readiness=false. Elapsed: 34.547708ms
    Jan 24 20:23:35.933: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0582043s
    Jan 24 20:23:37.925: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4": Phase="Running", Reason="", readiness=false. Elapsed: 4.049719037s
    Jan 24 20:23:39.963: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4": Phase="Running", Reason="", readiness=false. Elapsed: 6.088120064s
    Jan 24 20:23:41.920: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.044629084s
    STEP: Saw pod success 01/24/23 20:23:41.92
    Jan 24 20:23:41.921: INFO: Pod "pod-179c0f27-0584-4298-8abb-2dc151e465f4" satisfied condition "Succeeded or Failed"
    Jan 24 20:23:41.933: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-179c0f27-0584-4298-8abb-2dc151e465f4 container test-container: <nil>
    STEP: delete the pod 01/24/23 20:23:41.964
    Jan 24 20:23:42.027: INFO: Waiting for pod pod-179c0f27-0584-4298-8abb-2dc151e465f4 to disappear
    Jan 24 20:23:42.036: INFO: Pod pod-179c0f27-0584-4298-8abb-2dc151e465f4 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 20:23:42.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7761" for this suite. 01/24/23 20:23:42.069
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:23:42.135
Jan 24 20:23:42.135: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-runtime 01/24/23 20:23:42.139
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:23:42.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:23:42.241
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 01/24/23 20:23:42.322
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 01/24/23 20:24:03.013
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 01/24/23 20:24:03.037
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 01/24/23 20:24:03.08
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 01/24/23 20:24:03.081
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 01/24/23 20:24:03.197
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 01/24/23 20:24:07.443
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 01/24/23 20:24:10.507
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 01/24/23 20:24:10.584
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 01/24/23 20:24:10.585
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 01/24/23 20:24:10.8
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 01/24/23 20:24:11.944
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 01/24/23 20:24:18.26
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 01/24/23 20:24:18.297
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 01/24/23 20:24:18.299
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Jan 24 20:24:18.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7340" for this suite. 01/24/23 20:24:18.502
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":318,"skipped":5745,"failed":0}
------------------------------
• [SLOW TEST] [36.440 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:23:42.135
    Jan 24 20:23:42.135: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-runtime 01/24/23 20:23:42.139
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:23:42.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:23:42.241
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 01/24/23 20:23:42.322
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 01/24/23 20:24:03.013
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 01/24/23 20:24:03.037
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 01/24/23 20:24:03.08
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 01/24/23 20:24:03.081
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 01/24/23 20:24:03.197
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 01/24/23 20:24:07.443
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 01/24/23 20:24:10.507
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 01/24/23 20:24:10.584
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 01/24/23 20:24:10.585
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 01/24/23 20:24:10.8
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 01/24/23 20:24:11.944
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 01/24/23 20:24:18.26
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 01/24/23 20:24:18.297
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 01/24/23 20:24:18.299
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Jan 24 20:24:18.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7340" for this suite. 01/24/23 20:24:18.502
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:24:18.594
Jan 24 20:24:18.595: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 20:24:18.606
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:24:18.829
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:24:18.903
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 01/24/23 20:24:18.982
Jan 24 20:24:19.035: INFO: Waiting up to 5m0s for pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114" in namespace "emptydir-261" to be "Succeeded or Failed"
Jan 24 20:24:19.080: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Pending", Reason="", readiness=false. Elapsed: 40.699458ms
Jan 24 20:24:21.263: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Pending", Reason="", readiness=false. Elapsed: 2.223563045s
Jan 24 20:24:23.193: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Pending", Reason="", readiness=false. Elapsed: 4.153339258s
Jan 24 20:24:25.174: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Pending", Reason="", readiness=false. Elapsed: 6.134703178s
Jan 24 20:24:27.113: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Pending", Reason="", readiness=false. Elapsed: 8.073224153s
Jan 24 20:24:29.093: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.053827058s
STEP: Saw pod success 01/24/23 20:24:29.094
Jan 24 20:24:29.095: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114" satisfied condition "Succeeded or Failed"
Jan 24 20:24:29.121: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114 container test-container: <nil>
STEP: delete the pod 01/24/23 20:24:29.137
Jan 24 20:24:29.182: INFO: Waiting for pod pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114 to disappear
Jan 24 20:24:29.204: INFO: Pod pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 20:24:29.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-261" for this suite. 01/24/23 20:24:29.227
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":319,"skipped":5779,"failed":0}
------------------------------
• [SLOW TEST] [10.657 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:24:18.594
    Jan 24 20:24:18.595: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 20:24:18.606
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:24:18.829
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:24:18.903
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 01/24/23 20:24:18.982
    Jan 24 20:24:19.035: INFO: Waiting up to 5m0s for pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114" in namespace "emptydir-261" to be "Succeeded or Failed"
    Jan 24 20:24:19.080: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Pending", Reason="", readiness=false. Elapsed: 40.699458ms
    Jan 24 20:24:21.263: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Pending", Reason="", readiness=false. Elapsed: 2.223563045s
    Jan 24 20:24:23.193: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Pending", Reason="", readiness=false. Elapsed: 4.153339258s
    Jan 24 20:24:25.174: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Pending", Reason="", readiness=false. Elapsed: 6.134703178s
    Jan 24 20:24:27.113: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Pending", Reason="", readiness=false. Elapsed: 8.073224153s
    Jan 24 20:24:29.093: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.053827058s
    STEP: Saw pod success 01/24/23 20:24:29.094
    Jan 24 20:24:29.095: INFO: Pod "pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114" satisfied condition "Succeeded or Failed"
    Jan 24 20:24:29.121: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114 container test-container: <nil>
    STEP: delete the pod 01/24/23 20:24:29.137
    Jan 24 20:24:29.182: INFO: Waiting for pod pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114 to disappear
    Jan 24 20:24:29.204: INFO: Pod pod-7cd1bbda-5963-45a4-a314-84f9fc3d8114 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 20:24:29.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-261" for this suite. 01/24/23 20:24:29.227
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:24:29.321
Jan 24 20:24:29.322: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename podtemplate 01/24/23 20:24:29.326
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:24:29.39
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:24:29.444
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 01/24/23 20:24:29.468
Jan 24 20:24:29.495: INFO: created test-podtemplate-1
Jan 24 20:24:29.537: INFO: created test-podtemplate-2
Jan 24 20:24:29.552: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 01/24/23 20:24:29.553
STEP: delete collection of pod templates 01/24/23 20:24:29.565
Jan 24 20:24:29.573: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 01/24/23 20:24:29.682
Jan 24 20:24:29.683: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Jan 24 20:24:29.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6382" for this suite. 01/24/23 20:24:29.784
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":320,"skipped":5816,"failed":0}
------------------------------
• [0.494 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:24:29.321
    Jan 24 20:24:29.322: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename podtemplate 01/24/23 20:24:29.326
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:24:29.39
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:24:29.444
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 01/24/23 20:24:29.468
    Jan 24 20:24:29.495: INFO: created test-podtemplate-1
    Jan 24 20:24:29.537: INFO: created test-podtemplate-2
    Jan 24 20:24:29.552: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 01/24/23 20:24:29.553
    STEP: delete collection of pod templates 01/24/23 20:24:29.565
    Jan 24 20:24:29.573: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 01/24/23 20:24:29.682
    Jan 24 20:24:29.683: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Jan 24 20:24:29.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-6382" for this suite. 01/24/23 20:24:29.784
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:24:29.846
Jan 24 20:24:29.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-lifecycle-hook 01/24/23 20:24:29.852
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:24:29.956
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:24:29.972
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 01/24/23 20:24:30.001
Jan 24 20:24:30.050: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9781" to be "running and ready"
Jan 24 20:24:30.087: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 36.302093ms
Jan 24 20:24:30.095: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:24:32.160: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.109733926s
Jan 24 20:24:32.162: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:24:34.125: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.074696654s
Jan 24 20:24:34.126: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jan 24 20:24:34.126: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 01/24/23 20:24:34.142
Jan 24 20:24:34.185: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-9781" to be "running and ready"
Jan 24 20:24:34.223: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 38.166162ms
Jan 24 20:24:34.223: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:24:36.262: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077027618s
Jan 24 20:24:36.262: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:24:38.236: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.051091816s
Jan 24 20:24:38.236: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Jan 24 20:24:38.236: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 01/24/23 20:24:38.252
Jan 24 20:24:38.283: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 24 20:24:38.299: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 24 20:24:40.312: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 24 20:24:40.325: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 24 20:24:42.299: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 24 20:24:42.319: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 01/24/23 20:24:42.321
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jan 24 20:24:42.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9781" for this suite. 01/24/23 20:24:42.363
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":321,"skipped":5868,"failed":0}
------------------------------
• [SLOW TEST] [12.542 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:24:29.846
    Jan 24 20:24:29.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-lifecycle-hook 01/24/23 20:24:29.852
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:24:29.956
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:24:29.972
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 01/24/23 20:24:30.001
    Jan 24 20:24:30.050: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9781" to be "running and ready"
    Jan 24 20:24:30.087: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 36.302093ms
    Jan 24 20:24:30.095: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:24:32.160: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.109733926s
    Jan 24 20:24:32.162: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:24:34.125: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.074696654s
    Jan 24 20:24:34.126: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jan 24 20:24:34.126: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 01/24/23 20:24:34.142
    Jan 24 20:24:34.185: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-9781" to be "running and ready"
    Jan 24 20:24:34.223: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 38.166162ms
    Jan 24 20:24:34.223: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:24:36.262: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077027618s
    Jan 24 20:24:36.262: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:24:38.236: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.051091816s
    Jan 24 20:24:38.236: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Jan 24 20:24:38.236: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 01/24/23 20:24:38.252
    Jan 24 20:24:38.283: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Jan 24 20:24:38.299: INFO: Pod pod-with-prestop-exec-hook still exists
    Jan 24 20:24:40.312: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Jan 24 20:24:40.325: INFO: Pod pod-with-prestop-exec-hook still exists
    Jan 24 20:24:42.299: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Jan 24 20:24:42.319: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 01/24/23 20:24:42.321
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jan 24 20:24:42.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9781" for this suite. 01/24/23 20:24:42.363
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:24:42.389
Jan 24 20:24:42.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename container-lifecycle-hook 01/24/23 20:24:42.394
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:24:42.497
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:24:42.526
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 01/24/23 20:24:42.552
Jan 24 20:24:42.582: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2145" to be "running and ready"
Jan 24 20:24:42.609: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 27.334114ms
Jan 24 20:24:42.616: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:24:44.624: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04249138s
Jan 24 20:24:44.625: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:24:46.643: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.061408382s
Jan 24 20:24:46.645: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Jan 24 20:24:46.646: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 01/24/23 20:24:46.66
Jan 24 20:24:46.687: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-2145" to be "running and ready"
Jan 24 20:24:46.719: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 28.426486ms
Jan 24 20:24:46.720: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:24:48.740: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050016805s
Jan 24 20:24:48.740: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:24:50.740: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.04971801s
Jan 24 20:24:50.742: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Jan 24 20:24:50.742: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 01/24/23 20:24:50.753
STEP: delete the pod with lifecycle hook 01/24/23 20:24:50.772
Jan 24 20:24:50.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 24 20:24:50.803: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 24 20:24:52.804: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 24 20:24:52.814: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 24 20:24:54.823: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 24 20:24:54.894: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Jan 24 20:24:54.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2145" for this suite. 01/24/23 20:24:54.983
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":322,"skipped":5873,"failed":0}
------------------------------
• [SLOW TEST] [12.690 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:24:42.389
    Jan 24 20:24:42.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename container-lifecycle-hook 01/24/23 20:24:42.394
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:24:42.497
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:24:42.526
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 01/24/23 20:24:42.552
    Jan 24 20:24:42.582: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2145" to be "running and ready"
    Jan 24 20:24:42.609: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 27.334114ms
    Jan 24 20:24:42.616: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:24:44.624: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04249138s
    Jan 24 20:24:44.625: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:24:46.643: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.061408382s
    Jan 24 20:24:46.645: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Jan 24 20:24:46.646: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 01/24/23 20:24:46.66
    Jan 24 20:24:46.687: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-2145" to be "running and ready"
    Jan 24 20:24:46.719: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 28.426486ms
    Jan 24 20:24:46.720: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:24:48.740: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050016805s
    Jan 24 20:24:48.740: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:24:50.740: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.04971801s
    Jan 24 20:24:50.742: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Jan 24 20:24:50.742: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 01/24/23 20:24:50.753
    STEP: delete the pod with lifecycle hook 01/24/23 20:24:50.772
    Jan 24 20:24:50.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Jan 24 20:24:50.803: INFO: Pod pod-with-poststart-exec-hook still exists
    Jan 24 20:24:52.804: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Jan 24 20:24:52.814: INFO: Pod pod-with-poststart-exec-hook still exists
    Jan 24 20:24:54.823: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Jan 24 20:24:54.894: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Jan 24 20:24:54.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-2145" for this suite. 01/24/23 20:24:54.983
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:24:55.106
Jan 24 20:24:55.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename subpath 01/24/23 20:24:55.135
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:24:55.528
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:24:55.556
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 01/24/23 20:24:55.791
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-xpkz 01/24/23 20:24:55.896
STEP: Creating a pod to test atomic-volume-subpath 01/24/23 20:24:55.898
Jan 24 20:24:55.961: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xpkz" in namespace "subpath-2273" to be "Succeeded or Failed"
Jan 24 20:24:56.058: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Pending", Reason="", readiness=false. Elapsed: 96.647402ms
Jan 24 20:24:58.075: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.113633688s
Jan 24 20:25:00.093: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 4.131351774s
Jan 24 20:25:02.077: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 6.115336134s
Jan 24 20:25:04.079: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 8.1177898s
Jan 24 20:25:06.076: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 10.114810878s
Jan 24 20:25:08.075: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 12.113408323s
Jan 24 20:25:10.090: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 14.128233006s
Jan 24 20:25:12.088: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 16.126226514s
Jan 24 20:25:14.081: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 18.119245646s
Jan 24 20:25:16.085: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 20.123641206s
Jan 24 20:25:18.068: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 22.106027179s
Jan 24 20:25:20.072: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=false. Elapsed: 24.110398656s
Jan 24 20:25:22.066: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.104814643s
STEP: Saw pod success 01/24/23 20:25:22.066
Jan 24 20:25:22.067: INFO: Pod "pod-subpath-test-configmap-xpkz" satisfied condition "Succeeded or Failed"
Jan 24 20:25:22.073: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-subpath-test-configmap-xpkz container test-container-subpath-configmap-xpkz: <nil>
STEP: delete the pod 01/24/23 20:25:22.085
Jan 24 20:25:22.104: INFO: Waiting for pod pod-subpath-test-configmap-xpkz to disappear
Jan 24 20:25:22.112: INFO: Pod pod-subpath-test-configmap-xpkz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xpkz 01/24/23 20:25:22.113
Jan 24 20:25:22.113: INFO: Deleting pod "pod-subpath-test-configmap-xpkz" in namespace "subpath-2273"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Jan 24 20:25:22.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2273" for this suite. 01/24/23 20:25:22.128
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":323,"skipped":5895,"failed":0}
------------------------------
• [SLOW TEST] [27.042 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:24:55.106
    Jan 24 20:24:55.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename subpath 01/24/23 20:24:55.135
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:24:55.528
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:24:55.556
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 01/24/23 20:24:55.791
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-xpkz 01/24/23 20:24:55.896
    STEP: Creating a pod to test atomic-volume-subpath 01/24/23 20:24:55.898
    Jan 24 20:24:55.961: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xpkz" in namespace "subpath-2273" to be "Succeeded or Failed"
    Jan 24 20:24:56.058: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Pending", Reason="", readiness=false. Elapsed: 96.647402ms
    Jan 24 20:24:58.075: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.113633688s
    Jan 24 20:25:00.093: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 4.131351774s
    Jan 24 20:25:02.077: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 6.115336134s
    Jan 24 20:25:04.079: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 8.1177898s
    Jan 24 20:25:06.076: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 10.114810878s
    Jan 24 20:25:08.075: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 12.113408323s
    Jan 24 20:25:10.090: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 14.128233006s
    Jan 24 20:25:12.088: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 16.126226514s
    Jan 24 20:25:14.081: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 18.119245646s
    Jan 24 20:25:16.085: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 20.123641206s
    Jan 24 20:25:18.068: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=true. Elapsed: 22.106027179s
    Jan 24 20:25:20.072: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Running", Reason="", readiness=false. Elapsed: 24.110398656s
    Jan 24 20:25:22.066: INFO: Pod "pod-subpath-test-configmap-xpkz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.104814643s
    STEP: Saw pod success 01/24/23 20:25:22.066
    Jan 24 20:25:22.067: INFO: Pod "pod-subpath-test-configmap-xpkz" satisfied condition "Succeeded or Failed"
    Jan 24 20:25:22.073: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-subpath-test-configmap-xpkz container test-container-subpath-configmap-xpkz: <nil>
    STEP: delete the pod 01/24/23 20:25:22.085
    Jan 24 20:25:22.104: INFO: Waiting for pod pod-subpath-test-configmap-xpkz to disappear
    Jan 24 20:25:22.112: INFO: Pod pod-subpath-test-configmap-xpkz no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-xpkz 01/24/23 20:25:22.113
    Jan 24 20:25:22.113: INFO: Deleting pod "pod-subpath-test-configmap-xpkz" in namespace "subpath-2273"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Jan 24 20:25:22.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2273" for this suite. 01/24/23 20:25:22.128
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:25:22.156
Jan 24 20:25:22.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename dns 01/24/23 20:25:22.16
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:25:22.192
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:25:22.206
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8446.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8446.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 01/24/23 20:25:22.219
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8446.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8446.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 01/24/23 20:25:22.219
STEP: creating a pod to probe /etc/hosts 01/24/23 20:25:22.219
STEP: submitting the pod to kubernetes 01/24/23 20:25:22.22
Jan 24 20:25:22.239: INFO: Waiting up to 15m0s for pod "dns-test-aac09b4d-660f-40ed-9d05-cec88e5741d8" in namespace "dns-8446" to be "running"
Jan 24 20:25:22.265: INFO: Pod "dns-test-aac09b4d-660f-40ed-9d05-cec88e5741d8": Phase="Pending", Reason="", readiness=false. Elapsed: 25.32945ms
Jan 24 20:25:24.309: INFO: Pod "dns-test-aac09b4d-660f-40ed-9d05-cec88e5741d8": Phase="Running", Reason="", readiness=true. Elapsed: 2.068986198s
Jan 24 20:25:24.309: INFO: Pod "dns-test-aac09b4d-660f-40ed-9d05-cec88e5741d8" satisfied condition "running"
STEP: retrieving the pod 01/24/23 20:25:24.309
STEP: looking for the results for each expected name from probers 01/24/23 20:25:24.327
Jan 24 20:25:24.407: INFO: DNS probes using dns-8446/dns-test-aac09b4d-660f-40ed-9d05-cec88e5741d8 succeeded

STEP: deleting the pod 01/24/23 20:25:24.407
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 24 20:25:24.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8446" for this suite. 01/24/23 20:25:24.509
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":324,"skipped":5901,"failed":0}
------------------------------
• [2.387 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:25:22.156
    Jan 24 20:25:22.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename dns 01/24/23 20:25:22.16
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:25:22.192
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:25:22.206
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8446.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8446.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     01/24/23 20:25:22.219
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8446.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8446.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     01/24/23 20:25:22.219
    STEP: creating a pod to probe /etc/hosts 01/24/23 20:25:22.219
    STEP: submitting the pod to kubernetes 01/24/23 20:25:22.22
    Jan 24 20:25:22.239: INFO: Waiting up to 15m0s for pod "dns-test-aac09b4d-660f-40ed-9d05-cec88e5741d8" in namespace "dns-8446" to be "running"
    Jan 24 20:25:22.265: INFO: Pod "dns-test-aac09b4d-660f-40ed-9d05-cec88e5741d8": Phase="Pending", Reason="", readiness=false. Elapsed: 25.32945ms
    Jan 24 20:25:24.309: INFO: Pod "dns-test-aac09b4d-660f-40ed-9d05-cec88e5741d8": Phase="Running", Reason="", readiness=true. Elapsed: 2.068986198s
    Jan 24 20:25:24.309: INFO: Pod "dns-test-aac09b4d-660f-40ed-9d05-cec88e5741d8" satisfied condition "running"
    STEP: retrieving the pod 01/24/23 20:25:24.309
    STEP: looking for the results for each expected name from probers 01/24/23 20:25:24.327
    Jan 24 20:25:24.407: INFO: DNS probes using dns-8446/dns-test-aac09b4d-660f-40ed-9d05-cec88e5741d8 succeeded

    STEP: deleting the pod 01/24/23 20:25:24.407
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 24 20:25:24.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8446" for this suite. 01/24/23 20:25:24.509
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:25:24.555
Jan 24 20:25:24.556: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename svcaccounts 01/24/23 20:25:24.559
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:25:24.634
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:25:24.64
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Jan 24 20:25:24.666: INFO: Got root ca configmap in namespace "svcaccounts-2143"
Jan 24 20:25:24.692: INFO: Deleted root ca configmap in namespace "svcaccounts-2143"
STEP: waiting for a new root ca configmap created 01/24/23 20:25:25.194
Jan 24 20:25:25.203: INFO: Recreated root ca configmap in namespace "svcaccounts-2143"
Jan 24 20:25:25.225: INFO: Updated root ca configmap in namespace "svcaccounts-2143"
STEP: waiting for the root ca configmap reconciled 01/24/23 20:25:25.727
Jan 24 20:25:25.742: INFO: Reconciled root ca configmap in namespace "svcaccounts-2143"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 24 20:25:25.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2143" for this suite. 01/24/23 20:25:25.759
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":325,"skipped":5933,"failed":0}
------------------------------
• [1.249 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:25:24.555
    Jan 24 20:25:24.556: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename svcaccounts 01/24/23 20:25:24.559
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:25:24.634
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:25:24.64
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Jan 24 20:25:24.666: INFO: Got root ca configmap in namespace "svcaccounts-2143"
    Jan 24 20:25:24.692: INFO: Deleted root ca configmap in namespace "svcaccounts-2143"
    STEP: waiting for a new root ca configmap created 01/24/23 20:25:25.194
    Jan 24 20:25:25.203: INFO: Recreated root ca configmap in namespace "svcaccounts-2143"
    Jan 24 20:25:25.225: INFO: Updated root ca configmap in namespace "svcaccounts-2143"
    STEP: waiting for the root ca configmap reconciled 01/24/23 20:25:25.727
    Jan 24 20:25:25.742: INFO: Reconciled root ca configmap in namespace "svcaccounts-2143"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 24 20:25:25.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2143" for this suite. 01/24/23 20:25:25.759
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:25:25.815
Jan 24 20:25:25.816: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename dns 01/24/23 20:25:25.822
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:25:25.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:25:25.873
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 01/24/23 20:25:25.883
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7944 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7944;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7944 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7944;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7944.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7944.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7944.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7944.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7944.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7944.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7944.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7944.svc;check="$$(dig +notcp +noall +answer +search 185.50.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.50.185_udp@PTR;check="$$(dig +tcp +noall +answer +search 185.50.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.50.185_tcp@PTR;sleep 1; done
 01/24/23 20:25:25.932
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7944 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7944;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7944 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7944;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7944.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7944.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7944.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7944.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7944.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7944.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7944.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7944.svc;check="$$(dig +notcp +noall +answer +search 185.50.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.50.185_udp@PTR;check="$$(dig +tcp +noall +answer +search 185.50.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.50.185_tcp@PTR;sleep 1; done
 01/24/23 20:25:25.933
STEP: creating a pod to probe DNS 01/24/23 20:25:25.934
STEP: submitting the pod to kubernetes 01/24/23 20:25:25.936
Jan 24 20:25:25.986: INFO: Waiting up to 15m0s for pod "dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113" in namespace "dns-7944" to be "running"
Jan 24 20:25:25.995: INFO: Pod "dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113": Phase="Pending", Reason="", readiness=false. Elapsed: 9.326792ms
Jan 24 20:25:28.007: INFO: Pod "dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021251813s
Jan 24 20:25:30.029: INFO: Pod "dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113": Phase="Running", Reason="", readiness=true. Elapsed: 4.043370149s
Jan 24 20:25:30.029: INFO: Pod "dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113" satisfied condition "running"
STEP: retrieving the pod 01/24/23 20:25:30.03
STEP: looking for the results for each expected name from probers 01/24/23 20:25:30.049
Jan 24 20:25:30.096: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.149: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.263: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.314: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.362: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.403: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.430: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.459: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.631: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.695: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.856: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:30.960: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:31.075: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:31.099: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:31.233: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:31.316: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc wheezy_udp@_http._tcp.dns-test-service.dns-7944.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc jessie_tcp@_http._tcp.dns-test-service.dns-7944.svc]

Jan 24 20:25:36.327: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.335: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.342: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.350: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.359: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.371: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.431: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.439: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.447: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.455: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.464: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.475: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:36.526: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc]

Jan 24 20:25:41.331: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.351: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.365: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.376: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.389: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.410: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.514: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.526: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.537: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.553: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.567: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.582: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:41.715: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc]

Jan 24 20:25:46.329: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.340: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.351: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.364: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.373: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.384: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.447: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.454: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.461: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.466: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.471: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.478: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:46.518: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc]

Jan 24 20:25:51.328: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.337: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.346: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.356: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.364: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.370: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.432: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.445: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.460: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.472: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.479: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.484: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:51.544: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc]

Jan 24 20:25:56.330: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.340: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.353: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.367: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.376: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.384: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.449: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.458: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.467: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.476: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.486: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.495: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
Jan 24 20:25:56.552: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc]

Jan 24 20:26:01.666: INFO: DNS probes using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 succeeded

STEP: deleting the pod 01/24/23 20:26:01.666
STEP: deleting the test service 01/24/23 20:26:01.758
STEP: deleting the test headless service 01/24/23 20:26:01.897
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Jan 24 20:26:01.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7944" for this suite. 01/24/23 20:26:02.029
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":326,"skipped":5934,"failed":0}
------------------------------
• [SLOW TEST] [36.235 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:25:25.815
    Jan 24 20:25:25.816: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename dns 01/24/23 20:25:25.822
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:25:25.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:25:25.873
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 01/24/23 20:25:25.883
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7944 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7944;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7944 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7944;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7944.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7944.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7944.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7944.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7944.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7944.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7944.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7944.svc;check="$$(dig +notcp +noall +answer +search 185.50.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.50.185_udp@PTR;check="$$(dig +tcp +noall +answer +search 185.50.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.50.185_tcp@PTR;sleep 1; done
     01/24/23 20:25:25.932
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7944 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7944;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7944 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7944;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7944.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7944.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7944.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7944.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7944.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7944.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7944.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7944.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7944.svc;check="$$(dig +notcp +noall +answer +search 185.50.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.50.185_udp@PTR;check="$$(dig +tcp +noall +answer +search 185.50.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.50.185_tcp@PTR;sleep 1; done
     01/24/23 20:25:25.933
    STEP: creating a pod to probe DNS 01/24/23 20:25:25.934
    STEP: submitting the pod to kubernetes 01/24/23 20:25:25.936
    Jan 24 20:25:25.986: INFO: Waiting up to 15m0s for pod "dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113" in namespace "dns-7944" to be "running"
    Jan 24 20:25:25.995: INFO: Pod "dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113": Phase="Pending", Reason="", readiness=false. Elapsed: 9.326792ms
    Jan 24 20:25:28.007: INFO: Pod "dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021251813s
    Jan 24 20:25:30.029: INFO: Pod "dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113": Phase="Running", Reason="", readiness=true. Elapsed: 4.043370149s
    Jan 24 20:25:30.029: INFO: Pod "dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113" satisfied condition "running"
    STEP: retrieving the pod 01/24/23 20:25:30.03
    STEP: looking for the results for each expected name from probers 01/24/23 20:25:30.049
    Jan 24 20:25:30.096: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.149: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.263: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.314: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.362: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.403: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.430: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.459: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.631: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.695: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.856: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:30.960: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:31.075: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:31.099: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:31.233: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:31.316: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc wheezy_udp@_http._tcp.dns-test-service.dns-7944.svc wheezy_tcp@_http._tcp.dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc jessie_tcp@_http._tcp.dns-test-service.dns-7944.svc]

    Jan 24 20:25:36.327: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.335: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.342: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.350: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.359: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.371: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.431: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.439: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.447: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.455: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.464: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.475: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:36.526: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc]

    Jan 24 20:25:41.331: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.351: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.365: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.376: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.389: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.410: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.514: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.526: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.537: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.553: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.567: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.582: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:41.715: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc]

    Jan 24 20:25:46.329: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.340: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.351: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.364: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.373: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.384: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.447: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.454: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.461: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.466: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.471: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.478: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:46.518: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc]

    Jan 24 20:25:51.328: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.337: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.346: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.356: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.364: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.370: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.432: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.445: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.460: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.472: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.479: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.484: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:51.544: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc]

    Jan 24 20:25:56.330: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.340: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.353: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.367: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.376: INFO: Unable to read wheezy_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.384: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.449: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.458: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.467: INFO: Unable to read jessie_udp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.476: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944 from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.486: INFO: Unable to read jessie_udp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.495: INFO: Unable to read jessie_tcp@dns-test-service.dns-7944.svc from pod dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113: the server could not find the requested resource (get pods dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113)
    Jan 24 20:25:56.552: INFO: Lookups using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7944 wheezy_tcp@dns-test-service.dns-7944 wheezy_udp@dns-test-service.dns-7944.svc wheezy_tcp@dns-test-service.dns-7944.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7944 jessie_tcp@dns-test-service.dns-7944 jessie_udp@dns-test-service.dns-7944.svc jessie_tcp@dns-test-service.dns-7944.svc]

    Jan 24 20:26:01.666: INFO: DNS probes using dns-7944/dns-test-1e58ef9d-06c3-422b-bbd4-ac399df1d113 succeeded

    STEP: deleting the pod 01/24/23 20:26:01.666
    STEP: deleting the test service 01/24/23 20:26:01.758
    STEP: deleting the test headless service 01/24/23 20:26:01.897
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Jan 24 20:26:01.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7944" for this suite. 01/24/23 20:26:02.029
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:26:02.055
Jan 24 20:26:02.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:26:02.081
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:02.162
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:02.2
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:26:02.269
Jan 24 20:26:02.319: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6" in namespace "projected-3975" to be "Succeeded or Failed"
Jan 24 20:26:02.366: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6": Phase="Pending", Reason="", readiness=false. Elapsed: 44.642394ms
Jan 24 20:26:04.377: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054910207s
Jan 24 20:26:06.392: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6": Phase="Running", Reason="", readiness=true. Elapsed: 4.070508668s
Jan 24 20:26:08.375: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6": Phase="Running", Reason="", readiness=false. Elapsed: 6.053571849s
Jan 24 20:26:10.387: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.065695915s
STEP: Saw pod success 01/24/23 20:26:10.389
Jan 24 20:26:10.390: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6" satisfied condition "Succeeded or Failed"
Jan 24 20:26:10.414: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6 container client-container: <nil>
STEP: delete the pod 01/24/23 20:26:10.433
Jan 24 20:26:10.461: INFO: Waiting for pod downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6 to disappear
Jan 24 20:26:10.495: INFO: Pod downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Jan 24 20:26:10.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3975" for this suite. 01/24/23 20:26:10.508
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":327,"skipped":5945,"failed":0}
------------------------------
• [SLOW TEST] [8.478 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:26:02.055
    Jan 24 20:26:02.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:26:02.081
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:02.162
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:02.2
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:26:02.269
    Jan 24 20:26:02.319: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6" in namespace "projected-3975" to be "Succeeded or Failed"
    Jan 24 20:26:02.366: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6": Phase="Pending", Reason="", readiness=false. Elapsed: 44.642394ms
    Jan 24 20:26:04.377: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054910207s
    Jan 24 20:26:06.392: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6": Phase="Running", Reason="", readiness=true. Elapsed: 4.070508668s
    Jan 24 20:26:08.375: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6": Phase="Running", Reason="", readiness=false. Elapsed: 6.053571849s
    Jan 24 20:26:10.387: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.065695915s
    STEP: Saw pod success 01/24/23 20:26:10.389
    Jan 24 20:26:10.390: INFO: Pod "downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6" satisfied condition "Succeeded or Failed"
    Jan 24 20:26:10.414: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6 container client-container: <nil>
    STEP: delete the pod 01/24/23 20:26:10.433
    Jan 24 20:26:10.461: INFO: Waiting for pod downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6 to disappear
    Jan 24 20:26:10.495: INFO: Pod downwardapi-volume-1b0986ac-596d-4bf8-ba28-757ddd4915f6 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Jan 24 20:26:10.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3975" for this suite. 01/24/23 20:26:10.508
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:26:10.539
Jan 24 20:26:10.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replication-controller 01/24/23 20:26:10.576
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:10.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:10.664
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 01/24/23 20:26:10.695
STEP: When the matched label of one of its pods change 01/24/23 20:26:10.719
Jan 24 20:26:10.732: INFO: Pod name pod-release: Found 0 pods out of 1
Jan 24 20:26:15.748: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 01/24/23 20:26:15.782
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jan 24 20:26:16.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4331" for this suite. 01/24/23 20:26:16.842
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":328,"skipped":5964,"failed":0}
------------------------------
• [SLOW TEST] [6.370 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:26:10.539
    Jan 24 20:26:10.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replication-controller 01/24/23 20:26:10.576
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:10.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:10.664
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 01/24/23 20:26:10.695
    STEP: When the matched label of one of its pods change 01/24/23 20:26:10.719
    Jan 24 20:26:10.732: INFO: Pod name pod-release: Found 0 pods out of 1
    Jan 24 20:26:15.748: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 01/24/23 20:26:15.782
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jan 24 20:26:16.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-4331" for this suite. 01/24/23 20:26:16.842
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:26:16.926
Jan 24 20:26:16.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replicaset 01/24/23 20:26:16.935
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:17.093
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:17.142
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 01/24/23 20:26:17.233
STEP: Verify that the required pods have come up. 01/24/23 20:26:17.313
Jan 24 20:26:17.369: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 24 20:26:22.427: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 01/24/23 20:26:22.427
STEP: Getting /status 01/24/23 20:26:22.428
Jan 24 20:26:22.471: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 01/24/23 20:26:22.471
Jan 24 20:26:22.530: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 01/24/23 20:26:22.53
Jan 24 20:26:22.584: INFO: Observed &ReplicaSet event: ADDED
Jan 24 20:26:22.585: INFO: Observed &ReplicaSet event: MODIFIED
Jan 24 20:26:22.585: INFO: Observed &ReplicaSet event: MODIFIED
Jan 24 20:26:22.586: INFO: Observed &ReplicaSet event: MODIFIED
Jan 24 20:26:22.586: INFO: Found replicaset test-rs in namespace replicaset-9692 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jan 24 20:26:22.586: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 01/24/23 20:26:22.586
Jan 24 20:26:22.587: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jan 24 20:26:22.672: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 01/24/23 20:26:22.672
Jan 24 20:26:22.685: INFO: Observed &ReplicaSet event: ADDED
Jan 24 20:26:22.686: INFO: Observed &ReplicaSet event: MODIFIED
Jan 24 20:26:22.686: INFO: Observed &ReplicaSet event: MODIFIED
Jan 24 20:26:22.724: INFO: Observed &ReplicaSet event: MODIFIED
Jan 24 20:26:22.724: INFO: Observed replicaset test-rs in namespace replicaset-9692 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jan 24 20:26:22.733: INFO: Observed &ReplicaSet event: MODIFIED
Jan 24 20:26:22.747: INFO: Found replicaset test-rs in namespace replicaset-9692 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Jan 24 20:26:22.747: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Jan 24 20:26:22.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9692" for this suite. 01/24/23 20:26:22.793
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":329,"skipped":5999,"failed":0}
------------------------------
• [SLOW TEST] [5.931 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:26:16.926
    Jan 24 20:26:16.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replicaset 01/24/23 20:26:16.935
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:17.093
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:17.142
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 01/24/23 20:26:17.233
    STEP: Verify that the required pods have come up. 01/24/23 20:26:17.313
    Jan 24 20:26:17.369: INFO: Pod name sample-pod: Found 0 pods out of 1
    Jan 24 20:26:22.427: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 01/24/23 20:26:22.427
    STEP: Getting /status 01/24/23 20:26:22.428
    Jan 24 20:26:22.471: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 01/24/23 20:26:22.471
    Jan 24 20:26:22.530: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 01/24/23 20:26:22.53
    Jan 24 20:26:22.584: INFO: Observed &ReplicaSet event: ADDED
    Jan 24 20:26:22.585: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 24 20:26:22.585: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 24 20:26:22.586: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 24 20:26:22.586: INFO: Found replicaset test-rs in namespace replicaset-9692 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Jan 24 20:26:22.586: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 01/24/23 20:26:22.586
    Jan 24 20:26:22.587: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Jan 24 20:26:22.672: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 01/24/23 20:26:22.672
    Jan 24 20:26:22.685: INFO: Observed &ReplicaSet event: ADDED
    Jan 24 20:26:22.686: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 24 20:26:22.686: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 24 20:26:22.724: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 24 20:26:22.724: INFO: Observed replicaset test-rs in namespace replicaset-9692 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Jan 24 20:26:22.733: INFO: Observed &ReplicaSet event: MODIFIED
    Jan 24 20:26:22.747: INFO: Found replicaset test-rs in namespace replicaset-9692 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Jan 24 20:26:22.747: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Jan 24 20:26:22.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9692" for this suite. 01/24/23 20:26:22.793
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:26:22.858
Jan 24 20:26:22.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename certificates 01/24/23 20:26:22.905
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:22.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:22.987
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 01/24/23 20:26:25.119
STEP: getting /apis/certificates.k8s.io 01/24/23 20:26:25.13
STEP: getting /apis/certificates.k8s.io/v1 01/24/23 20:26:25.135
STEP: creating 01/24/23 20:26:25.141
STEP: getting 01/24/23 20:26:25.198
STEP: listing 01/24/23 20:26:25.209
STEP: watching 01/24/23 20:26:25.219
Jan 24 20:26:25.223: INFO: starting watch
STEP: patching 01/24/23 20:26:25.235
STEP: updating 01/24/23 20:26:25.25
Jan 24 20:26:25.268: INFO: waiting for watch events with expected annotations
Jan 24 20:26:25.268: INFO: saw patched and updated annotations
STEP: getting /approval 01/24/23 20:26:25.269
STEP: patching /approval 01/24/23 20:26:25.279
STEP: updating /approval 01/24/23 20:26:25.295
STEP: getting /status 01/24/23 20:26:25.317
STEP: patching /status 01/24/23 20:26:25.327
STEP: updating /status 01/24/23 20:26:25.345
STEP: deleting 01/24/23 20:26:25.364
STEP: deleting a collection 01/24/23 20:26:25.384
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:26:25.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-3609" for this suite. 01/24/23 20:26:25.415
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":330,"skipped":6000,"failed":0}
------------------------------
• [2.575 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:26:22.858
    Jan 24 20:26:22.858: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename certificates 01/24/23 20:26:22.905
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:22.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:22.987
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 01/24/23 20:26:25.119
    STEP: getting /apis/certificates.k8s.io 01/24/23 20:26:25.13
    STEP: getting /apis/certificates.k8s.io/v1 01/24/23 20:26:25.135
    STEP: creating 01/24/23 20:26:25.141
    STEP: getting 01/24/23 20:26:25.198
    STEP: listing 01/24/23 20:26:25.209
    STEP: watching 01/24/23 20:26:25.219
    Jan 24 20:26:25.223: INFO: starting watch
    STEP: patching 01/24/23 20:26:25.235
    STEP: updating 01/24/23 20:26:25.25
    Jan 24 20:26:25.268: INFO: waiting for watch events with expected annotations
    Jan 24 20:26:25.268: INFO: saw patched and updated annotations
    STEP: getting /approval 01/24/23 20:26:25.269
    STEP: patching /approval 01/24/23 20:26:25.279
    STEP: updating /approval 01/24/23 20:26:25.295
    STEP: getting /status 01/24/23 20:26:25.317
    STEP: patching /status 01/24/23 20:26:25.327
    STEP: updating /status 01/24/23 20:26:25.345
    STEP: deleting 01/24/23 20:26:25.364
    STEP: deleting a collection 01/24/23 20:26:25.384
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:26:25.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-3609" for this suite. 01/24/23 20:26:25.415
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:26:25.46
Jan 24 20:26:25.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 20:26:25.464
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:25.508
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:25.522
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-2eb93294-dfda-4dd1-9b46-1d3a2081e33d 01/24/23 20:26:25.53
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jan 24 20:26:25.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1793" for this suite. 01/24/23 20:26:25.541
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":331,"skipped":6049,"failed":0}
------------------------------
• [0.093 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:26:25.46
    Jan 24 20:26:25.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 20:26:25.464
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:25.508
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:25.522
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-2eb93294-dfda-4dd1-9b46-1d3a2081e33d 01/24/23 20:26:25.53
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 20:26:25.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1793" for this suite. 01/24/23 20:26:25.541
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:26:25.557
Jan 24 20:26:25.557: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 20:26:25.56
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:25.598
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:25.604
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:26:25.611
Jan 24 20:26:25.630: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f" in namespace "downward-api-5010" to be "Succeeded or Failed"
Jan 24 20:26:25.642: INFO: Pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.429486ms
Jan 24 20:26:27.657: INFO: Pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026409226s
Jan 24 20:26:29.679: INFO: Pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04847594s
Jan 24 20:26:31.662: INFO: Pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032159374s
STEP: Saw pod success 01/24/23 20:26:31.663
Jan 24 20:26:31.663: INFO: Pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f" satisfied condition "Succeeded or Failed"
Jan 24 20:26:31.687: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f container client-container: <nil>
STEP: delete the pod 01/24/23 20:26:31.709
Jan 24 20:26:31.753: INFO: Waiting for pod downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f to disappear
Jan 24 20:26:31.763: INFO: Pod downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 20:26:31.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5010" for this suite. 01/24/23 20:26:31.776
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":332,"skipped":6082,"failed":0}
------------------------------
• [SLOW TEST] [6.236 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:26:25.557
    Jan 24 20:26:25.557: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 20:26:25.56
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:25.598
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:25.604
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:26:25.611
    Jan 24 20:26:25.630: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f" in namespace "downward-api-5010" to be "Succeeded or Failed"
    Jan 24 20:26:25.642: INFO: Pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.429486ms
    Jan 24 20:26:27.657: INFO: Pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026409226s
    Jan 24 20:26:29.679: INFO: Pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04847594s
    Jan 24 20:26:31.662: INFO: Pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032159374s
    STEP: Saw pod success 01/24/23 20:26:31.663
    Jan 24 20:26:31.663: INFO: Pod "downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f" satisfied condition "Succeeded or Failed"
    Jan 24 20:26:31.687: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f container client-container: <nil>
    STEP: delete the pod 01/24/23 20:26:31.709
    Jan 24 20:26:31.753: INFO: Waiting for pod downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f to disappear
    Jan 24 20:26:31.763: INFO: Pod downwardapi-volume-e6aa39da-c173-4cfb-8b95-d348d5fcd85f no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 20:26:31.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5010" for this suite. 01/24/23 20:26:31.776
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:26:31.82
Jan 24 20:26:31.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename cronjob 01/24/23 20:26:31.83
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:31.897
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:31.92
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 01/24/23 20:26:31.939
STEP: Ensuring a job is scheduled 01/24/23 20:26:31.956
STEP: Ensuring exactly one is scheduled 01/24/23 20:27:01.994
STEP: Ensuring exactly one running job exists by listing jobs explicitly 01/24/23 20:27:02.01
STEP: Ensuring no more jobs are scheduled 01/24/23 20:27:02.02
STEP: Removing cronjob 01/24/23 20:32:02.036
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Jan 24 20:32:02.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-3321" for this suite. 01/24/23 20:32:02.085
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":333,"skipped":6119,"failed":0}
------------------------------
• [SLOW TEST] [330.289 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:26:31.82
    Jan 24 20:26:31.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename cronjob 01/24/23 20:26:31.83
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:26:31.897
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:26:31.92
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 01/24/23 20:26:31.939
    STEP: Ensuring a job is scheduled 01/24/23 20:26:31.956
    STEP: Ensuring exactly one is scheduled 01/24/23 20:27:01.994
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 01/24/23 20:27:02.01
    STEP: Ensuring no more jobs are scheduled 01/24/23 20:27:02.02
    STEP: Removing cronjob 01/24/23 20:32:02.036
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Jan 24 20:32:02.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-3321" for this suite. 01/24/23 20:32:02.085
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:32:02.123
Jan 24 20:32:02.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 20:32:02.194
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:32:02.295
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:32:02.37
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 01/24/23 20:32:02.42
Jan 24 20:32:02.472: INFO: Waiting up to 5m0s for pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04" in namespace "emptydir-277" to be "Succeeded or Failed"
Jan 24 20:32:02.490: INFO: Pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04": Phase="Pending", Reason="", readiness=false. Elapsed: 15.515314ms
Jan 24 20:32:04.584: INFO: Pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.109836523s
Jan 24 20:32:06.503: INFO: Pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028163617s
Jan 24 20:32:08.521: INFO: Pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.046126066s
STEP: Saw pod success 01/24/23 20:32:08.521
Jan 24 20:32:08.522: INFO: Pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04" satisfied condition "Succeeded or Failed"
Jan 24 20:32:08.536: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04 container test-container: <nil>
STEP: delete the pod 01/24/23 20:32:08.612
Jan 24 20:32:08.661: INFO: Waiting for pod pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04 to disappear
Jan 24 20:32:08.686: INFO: Pod pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 20:32:08.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-277" for this suite. 01/24/23 20:32:08.706
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":334,"skipped":6119,"failed":0}
------------------------------
• [SLOW TEST] [6.622 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:32:02.123
    Jan 24 20:32:02.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 20:32:02.194
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:32:02.295
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:32:02.37
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 01/24/23 20:32:02.42
    Jan 24 20:32:02.472: INFO: Waiting up to 5m0s for pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04" in namespace "emptydir-277" to be "Succeeded or Failed"
    Jan 24 20:32:02.490: INFO: Pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04": Phase="Pending", Reason="", readiness=false. Elapsed: 15.515314ms
    Jan 24 20:32:04.584: INFO: Pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.109836523s
    Jan 24 20:32:06.503: INFO: Pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028163617s
    Jan 24 20:32:08.521: INFO: Pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.046126066s
    STEP: Saw pod success 01/24/23 20:32:08.521
    Jan 24 20:32:08.522: INFO: Pod "pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04" satisfied condition "Succeeded or Failed"
    Jan 24 20:32:08.536: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04 container test-container: <nil>
    STEP: delete the pod 01/24/23 20:32:08.612
    Jan 24 20:32:08.661: INFO: Waiting for pod pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04 to disappear
    Jan 24 20:32:08.686: INFO: Pod pod-05fd9ce3-bc83-4b9e-b435-8e63e0ab5d04 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 20:32:08.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-277" for this suite. 01/24/23 20:32:08.706
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:32:08.745
Jan 24 20:32:08.746: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 20:32:08.772
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:32:08.871
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:32:08.881
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Jan 24 20:32:08.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/24/23 20:32:27.563
Jan 24 20:32:27.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-2283 --namespace=crd-publish-openapi-2283 create -f -'
Jan 24 20:32:34.070: INFO: stderr: ""
Jan 24 20:32:34.070: INFO: stdout: "e2e-test-crd-publish-openapi-6522-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jan 24 20:32:34.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-2283 --namespace=crd-publish-openapi-2283 delete e2e-test-crd-publish-openapi-6522-crds test-cr'
Jan 24 20:32:34.503: INFO: stderr: ""
Jan 24 20:32:34.503: INFO: stdout: "e2e-test-crd-publish-openapi-6522-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Jan 24 20:32:34.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-2283 --namespace=crd-publish-openapi-2283 apply -f -'
Jan 24 20:32:35.663: INFO: stderr: ""
Jan 24 20:32:35.663: INFO: stdout: "e2e-test-crd-publish-openapi-6522-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jan 24 20:32:35.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-2283 --namespace=crd-publish-openapi-2283 delete e2e-test-crd-publish-openapi-6522-crds test-cr'
Jan 24 20:32:36.027: INFO: stderr: ""
Jan 24 20:32:36.028: INFO: stdout: "e2e-test-crd-publish-openapi-6522-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 01/24/23 20:32:36.028
Jan 24 20:32:36.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-2283 explain e2e-test-crd-publish-openapi-6522-crds'
Jan 24 20:32:37.274: INFO: stderr: ""
Jan 24 20:32:37.275: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6522-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:32:56.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2283" for this suite. 01/24/23 20:32:56.162
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":335,"skipped":6119,"failed":0}
------------------------------
• [SLOW TEST] [47.447 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:32:08.745
    Jan 24 20:32:08.746: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 20:32:08.772
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:32:08.871
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:32:08.881
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Jan 24 20:32:08.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 01/24/23 20:32:27.563
    Jan 24 20:32:27.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-2283 --namespace=crd-publish-openapi-2283 create -f -'
    Jan 24 20:32:34.070: INFO: stderr: ""
    Jan 24 20:32:34.070: INFO: stdout: "e2e-test-crd-publish-openapi-6522-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Jan 24 20:32:34.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-2283 --namespace=crd-publish-openapi-2283 delete e2e-test-crd-publish-openapi-6522-crds test-cr'
    Jan 24 20:32:34.503: INFO: stderr: ""
    Jan 24 20:32:34.503: INFO: stdout: "e2e-test-crd-publish-openapi-6522-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Jan 24 20:32:34.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-2283 --namespace=crd-publish-openapi-2283 apply -f -'
    Jan 24 20:32:35.663: INFO: stderr: ""
    Jan 24 20:32:35.663: INFO: stdout: "e2e-test-crd-publish-openapi-6522-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Jan 24 20:32:35.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-2283 --namespace=crd-publish-openapi-2283 delete e2e-test-crd-publish-openapi-6522-crds test-cr'
    Jan 24 20:32:36.027: INFO: stderr: ""
    Jan 24 20:32:36.028: INFO: stdout: "e2e-test-crd-publish-openapi-6522-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 01/24/23 20:32:36.028
    Jan 24 20:32:36.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=crd-publish-openapi-2283 explain e2e-test-crd-publish-openapi-6522-crds'
    Jan 24 20:32:37.274: INFO: stderr: ""
    Jan 24 20:32:37.275: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6522-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:32:56.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2283" for this suite. 01/24/23 20:32:56.162
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:32:56.203
Jan 24 20:32:56.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename var-expansion 01/24/23 20:32:56.211
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:32:56.33
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:32:56.348
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Jan 24 20:32:56.485: INFO: Waiting up to 2m0s for pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2" in namespace "var-expansion-9741" to be "container 0 failed with reason CreateContainerConfigError"
Jan 24 20:32:56.516: INFO: Pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2": Phase="Pending", Reason="", readiness=false. Elapsed: 29.866244ms
Jan 24 20:32:58.564: INFO: Pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077428347s
Jan 24 20:33:00.534: INFO: Pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048180035s
Jan 24 20:33:00.535: INFO: Pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Jan 24 20:33:00.535: INFO: Deleting pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2" in namespace "var-expansion-9741"
Jan 24 20:33:00.594: INFO: Wait up to 5m0s for pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 24 20:33:04.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9741" for this suite. 01/24/23 20:33:04.699
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":336,"skipped":6135,"failed":0}
------------------------------
• [SLOW TEST] [8.551 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:32:56.203
    Jan 24 20:32:56.204: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename var-expansion 01/24/23 20:32:56.211
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:32:56.33
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:32:56.348
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Jan 24 20:32:56.485: INFO: Waiting up to 2m0s for pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2" in namespace "var-expansion-9741" to be "container 0 failed with reason CreateContainerConfigError"
    Jan 24 20:32:56.516: INFO: Pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2": Phase="Pending", Reason="", readiness=false. Elapsed: 29.866244ms
    Jan 24 20:32:58.564: INFO: Pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077428347s
    Jan 24 20:33:00.534: INFO: Pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048180035s
    Jan 24 20:33:00.535: INFO: Pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Jan 24 20:33:00.535: INFO: Deleting pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2" in namespace "var-expansion-9741"
    Jan 24 20:33:00.594: INFO: Wait up to 5m0s for pod "var-expansion-182a1f59-e98c-46e5-afb5-27de4308cdd2" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 24 20:33:04.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-9741" for this suite. 01/24/23 20:33:04.699
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:33:04.821
Jan 24 20:33:04.829: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename svcaccounts 01/24/23 20:33:04.842
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:33:04.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:33:04.922
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Jan 24 20:33:05.004: INFO: created pod pod-service-account-defaultsa
Jan 24 20:33:05.004: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 24 20:33:05.055: INFO: created pod pod-service-account-mountsa
Jan 24 20:33:05.059: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 24 20:33:05.094: INFO: created pod pod-service-account-nomountsa
Jan 24 20:33:05.094: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 24 20:33:05.112: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 24 20:33:05.113: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 24 20:33:05.178: INFO: created pod pod-service-account-mountsa-mountspec
Jan 24 20:33:05.179: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 24 20:33:05.273: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 24 20:33:05.273: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 24 20:33:05.297: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 24 20:33:05.298: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 24 20:33:05.387: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 24 20:33:05.388: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 24 20:33:05.615: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 24 20:33:05.616: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Jan 24 20:33:05.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9464" for this suite. 01/24/23 20:33:05.816
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":337,"skipped":6186,"failed":0}
------------------------------
• [1.578 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:33:04.821
    Jan 24 20:33:04.829: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename svcaccounts 01/24/23 20:33:04.842
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:33:04.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:33:04.922
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Jan 24 20:33:05.004: INFO: created pod pod-service-account-defaultsa
    Jan 24 20:33:05.004: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Jan 24 20:33:05.055: INFO: created pod pod-service-account-mountsa
    Jan 24 20:33:05.059: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Jan 24 20:33:05.094: INFO: created pod pod-service-account-nomountsa
    Jan 24 20:33:05.094: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Jan 24 20:33:05.112: INFO: created pod pod-service-account-defaultsa-mountspec
    Jan 24 20:33:05.113: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Jan 24 20:33:05.178: INFO: created pod pod-service-account-mountsa-mountspec
    Jan 24 20:33:05.179: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Jan 24 20:33:05.273: INFO: created pod pod-service-account-nomountsa-mountspec
    Jan 24 20:33:05.273: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Jan 24 20:33:05.297: INFO: created pod pod-service-account-defaultsa-nomountspec
    Jan 24 20:33:05.298: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Jan 24 20:33:05.387: INFO: created pod pod-service-account-mountsa-nomountspec
    Jan 24 20:33:05.388: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Jan 24 20:33:05.615: INFO: created pod pod-service-account-nomountsa-nomountspec
    Jan 24 20:33:05.616: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Jan 24 20:33:05.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9464" for this suite. 01/24/23 20:33:05.816
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:33:06.564
Jan 24 20:33:06.565: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 20:33:06.57
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:33:06.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:33:06.853
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:33:06.999
Jan 24 20:33:07.246: INFO: Waiting up to 5m0s for pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc" in namespace "downward-api-1869" to be "Succeeded or Failed"
Jan 24 20:33:07.320: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 73.75768ms
Jan 24 20:33:09.492: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.24587599s
Jan 24 20:33:11.595: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.349313827s
Jan 24 20:33:13.333: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.087186827s
Jan 24 20:33:15.349: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.102859492s
Jan 24 20:33:17.332: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.085961729s
Jan 24 20:33:19.328: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.081593889s
STEP: Saw pod success 01/24/23 20:33:19.328
Jan 24 20:33:19.328: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc" satisfied condition "Succeeded or Failed"
Jan 24 20:33:19.336: INFO: Trying to get logs from node vikash-v125latest-conf-59870 pod downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc container client-container: <nil>
STEP: delete the pod 01/24/23 20:33:19.378
Jan 24 20:33:19.417: INFO: Waiting for pod downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc to disappear
Jan 24 20:33:19.425: INFO: Pod downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 20:33:19.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1869" for this suite. 01/24/23 20:33:19.437
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":338,"skipped":6209,"failed":0}
------------------------------
• [SLOW TEST] [12.895 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:33:06.564
    Jan 24 20:33:06.565: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 20:33:06.57
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:33:06.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:33:06.853
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:33:06.999
    Jan 24 20:33:07.246: INFO: Waiting up to 5m0s for pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc" in namespace "downward-api-1869" to be "Succeeded or Failed"
    Jan 24 20:33:07.320: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 73.75768ms
    Jan 24 20:33:09.492: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.24587599s
    Jan 24 20:33:11.595: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.349313827s
    Jan 24 20:33:13.333: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.087186827s
    Jan 24 20:33:15.349: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.102859492s
    Jan 24 20:33:17.332: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.085961729s
    Jan 24 20:33:19.328: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.081593889s
    STEP: Saw pod success 01/24/23 20:33:19.328
    Jan 24 20:33:19.328: INFO: Pod "downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc" satisfied condition "Succeeded or Failed"
    Jan 24 20:33:19.336: INFO: Trying to get logs from node vikash-v125latest-conf-59870 pod downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc container client-container: <nil>
    STEP: delete the pod 01/24/23 20:33:19.378
    Jan 24 20:33:19.417: INFO: Waiting for pod downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc to disappear
    Jan 24 20:33:19.425: INFO: Pod downwardapi-volume-947730b0-f0e7-497f-af13-2f15462f6fbc no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 20:33:19.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1869" for this suite. 01/24/23 20:33:19.437
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:33:19.459
Jan 24 20:33:19.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename statefulset 01/24/23 20:33:19.461
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:33:19.494
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:33:19.5
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6427 01/24/23 20:33:19.505
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 01/24/23 20:33:19.525
Jan 24 20:33:19.568: INFO: Found 0 stateful pods, waiting for 3
Jan 24 20:33:29.591: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 20:33:29.591: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 20:33:29.591: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Jan 24 20:33:39.627: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 20:33:39.627: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 20:33:39.628: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 01/24/23 20:33:39.764
Jan 24 20:33:39.976: INFO: Updating stateful set ss2
STEP: Creating a new revision 01/24/23 20:33:39.977
STEP: Not applying an update when the partition is greater than the number of replicas 01/24/23 20:33:50.435
STEP: Performing a canary update 01/24/23 20:33:50.436
Jan 24 20:33:50.521: INFO: Updating stateful set ss2
Jan 24 20:33:50.592: INFO: Waiting for Pod statefulset-6427/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 01/24/23 20:34:00.645
Jan 24 20:34:01.862: INFO: Found 2 stateful pods, waiting for 3
Jan 24 20:34:11.877: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 20:34:11.878: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 24 20:34:11.878: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 01/24/23 20:34:11.897
Jan 24 20:34:11.932: INFO: Updating stateful set ss2
Jan 24 20:34:11.945: INFO: Waiting for Pod statefulset-6427/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Jan 24 20:34:22.008: INFO: Updating stateful set ss2
Jan 24 20:34:22.026: INFO: Waiting for StatefulSet statefulset-6427/ss2 to complete update
Jan 24 20:34:22.026: INFO: Waiting for Pod statefulset-6427/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jan 24 20:34:32.228: INFO: Deleting all statefulset in ns statefulset-6427
Jan 24 20:34:32.267: INFO: Scaling statefulset ss2 to 0
Jan 24 20:34:42.522: INFO: Waiting for statefulset status.replicas updated to 0
Jan 24 20:34:42.558: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Jan 24 20:34:42.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6427" for this suite. 01/24/23 20:34:43.051
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":339,"skipped":6247,"failed":0}
------------------------------
• [SLOW TEST] [83.699 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:33:19.459
    Jan 24 20:33:19.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename statefulset 01/24/23 20:33:19.461
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:33:19.494
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:33:19.5
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6427 01/24/23 20:33:19.505
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 01/24/23 20:33:19.525
    Jan 24 20:33:19.568: INFO: Found 0 stateful pods, waiting for 3
    Jan 24 20:33:29.591: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 20:33:29.591: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 20:33:29.591: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
    Jan 24 20:33:39.627: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 20:33:39.627: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 20:33:39.628: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 01/24/23 20:33:39.764
    Jan 24 20:33:39.976: INFO: Updating stateful set ss2
    STEP: Creating a new revision 01/24/23 20:33:39.977
    STEP: Not applying an update when the partition is greater than the number of replicas 01/24/23 20:33:50.435
    STEP: Performing a canary update 01/24/23 20:33:50.436
    Jan 24 20:33:50.521: INFO: Updating stateful set ss2
    Jan 24 20:33:50.592: INFO: Waiting for Pod statefulset-6427/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 01/24/23 20:34:00.645
    Jan 24 20:34:01.862: INFO: Found 2 stateful pods, waiting for 3
    Jan 24 20:34:11.877: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 20:34:11.878: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Jan 24 20:34:11.878: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 01/24/23 20:34:11.897
    Jan 24 20:34:11.932: INFO: Updating stateful set ss2
    Jan 24 20:34:11.945: INFO: Waiting for Pod statefulset-6427/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Jan 24 20:34:22.008: INFO: Updating stateful set ss2
    Jan 24 20:34:22.026: INFO: Waiting for StatefulSet statefulset-6427/ss2 to complete update
    Jan 24 20:34:22.026: INFO: Waiting for Pod statefulset-6427/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Jan 24 20:34:32.228: INFO: Deleting all statefulset in ns statefulset-6427
    Jan 24 20:34:32.267: INFO: Scaling statefulset ss2 to 0
    Jan 24 20:34:42.522: INFO: Waiting for statefulset status.replicas updated to 0
    Jan 24 20:34:42.558: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Jan 24 20:34:42.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6427" for this suite. 01/24/23 20:34:43.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:34:43.162
Jan 24 20:34:43.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename disruption 01/24/23 20:34:43.178
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:34:43.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:34:43.354
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:34:43.388
Jan 24 20:34:43.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename disruption-2 01/24/23 20:34:43.393
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:34:43.456
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:34:43.484
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 01/24/23 20:34:43.534
STEP: Waiting for the pdb to be processed 01/24/23 20:34:45.593
STEP: Waiting for the pdb to be processed 01/24/23 20:34:47.679
STEP: listing a collection of PDBs across all namespaces 01/24/23 20:34:49.848
STEP: listing a collection of PDBs in namespace disruption-8567 01/24/23 20:34:49.953
STEP: deleting a collection of PDBs 01/24/23 20:34:49.974
STEP: Waiting for the PDB collection to be deleted 01/24/23 20:34:50.022
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Jan 24 20:34:50.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-4575" for this suite. 01/24/23 20:34:50.115
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Jan 24 20:34:50.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8567" for this suite. 01/24/23 20:34:50.177
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":340,"skipped":6263,"failed":0}
------------------------------
• [SLOW TEST] [7.039 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:34:43.162
    Jan 24 20:34:43.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename disruption 01/24/23 20:34:43.178
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:34:43.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:34:43.354
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:34:43.388
    Jan 24 20:34:43.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename disruption-2 01/24/23 20:34:43.393
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:34:43.456
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:34:43.484
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 01/24/23 20:34:43.534
    STEP: Waiting for the pdb to be processed 01/24/23 20:34:45.593
    STEP: Waiting for the pdb to be processed 01/24/23 20:34:47.679
    STEP: listing a collection of PDBs across all namespaces 01/24/23 20:34:49.848
    STEP: listing a collection of PDBs in namespace disruption-8567 01/24/23 20:34:49.953
    STEP: deleting a collection of PDBs 01/24/23 20:34:49.974
    STEP: Waiting for the PDB collection to be deleted 01/24/23 20:34:50.022
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Jan 24 20:34:50.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-4575" for this suite. 01/24/23 20:34:50.115
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Jan 24 20:34:50.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8567" for this suite. 01/24/23 20:34:50.177
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:34:50.202
Jan 24 20:34:50.202: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename taint-multiple-pods 01/24/23 20:34:50.214
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:34:50.373
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:34:50.42
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Jan 24 20:34:50.459: INFO: Waiting up to 1m0s for all nodes to be ready
Jan 24 20:35:50.557: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Jan 24 20:35:50.566: INFO: Starting informer...
STEP: Starting pods... 01/24/23 20:35:50.566
Jan 24 20:35:50.798: INFO: Pod1 is running on vikash-v125latest-conf-71087. Tainting Node
Jan 24 20:35:50.952: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-6255" to be "running"
Jan 24 20:35:51.053: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 100.880887ms
Jan 24 20:35:53.135: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.183485792s
Jan 24 20:35:55.079: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.12724541s
Jan 24 20:35:55.079: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Jan 24 20:35:55.079: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-6255" to be "running"
Jan 24 20:35:55.099: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 20.096956ms
Jan 24 20:35:55.099: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Jan 24 20:35:55.099: INFO: Pod2 is running on vikash-v125latest-conf-71087. Tainting Node
STEP: Trying to apply a taint on the Node 01/24/23 20:35:55.099
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/24/23 20:35:55.208
STEP: Waiting for Pod1 and Pod2 to be deleted 01/24/23 20:35:55.573
Jan 24 20:36:01.515: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Jan 24 20:36:21.667: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/24/23 20:36:21.745
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Jan 24 20:36:21.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-6255" for this suite. 01/24/23 20:36:21.868
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":341,"skipped":6268,"failed":0}
------------------------------
• [SLOW TEST] [91.684 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:34:50.202
    Jan 24 20:34:50.202: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename taint-multiple-pods 01/24/23 20:34:50.214
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:34:50.373
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:34:50.42
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Jan 24 20:34:50.459: INFO: Waiting up to 1m0s for all nodes to be ready
    Jan 24 20:35:50.557: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Jan 24 20:35:50.566: INFO: Starting informer...
    STEP: Starting pods... 01/24/23 20:35:50.566
    Jan 24 20:35:50.798: INFO: Pod1 is running on vikash-v125latest-conf-71087. Tainting Node
    Jan 24 20:35:50.952: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-6255" to be "running"
    Jan 24 20:35:51.053: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 100.880887ms
    Jan 24 20:35:53.135: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.183485792s
    Jan 24 20:35:55.079: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.12724541s
    Jan 24 20:35:55.079: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Jan 24 20:35:55.079: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-6255" to be "running"
    Jan 24 20:35:55.099: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 20.096956ms
    Jan 24 20:35:55.099: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Jan 24 20:35:55.099: INFO: Pod2 is running on vikash-v125latest-conf-71087. Tainting Node
    STEP: Trying to apply a taint on the Node 01/24/23 20:35:55.099
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/24/23 20:35:55.208
    STEP: Waiting for Pod1 and Pod2 to be deleted 01/24/23 20:35:55.573
    Jan 24 20:36:01.515: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Jan 24 20:36:21.667: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 01/24/23 20:36:21.745
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 20:36:21.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-6255" for this suite. 01/24/23 20:36:21.868
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:36:21.9
Jan 24 20:36:21.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 20:36:21.912
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:36:21.976
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:36:21.991
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 20:36:22.051
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 20:36:23.701
STEP: Deploying the webhook pod 01/24/23 20:36:23.717
STEP: Wait for the deployment to be ready 01/24/23 20:36:23.806
Jan 24 20:36:24.095: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 24 20:36:26.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 36, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 36, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 36, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 36, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 20:36:28.228
STEP: Verifying the service has paired with the endpoint 01/24/23 20:36:28.291
Jan 24 20:36:29.292: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Jan 24 20:36:29.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4148-crds.webhook.example.com via the AdmissionRegistration API 01/24/23 20:36:29.952
STEP: Creating a custom resource that should be mutated by the webhook 01/24/23 20:36:30.05
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:36:32.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3083" for this suite. 01/24/23 20:36:32.998
STEP: Destroying namespace "webhook-3083-markers" for this suite. 01/24/23 20:36:33.038
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":342,"skipped":6275,"failed":0}
------------------------------
• [SLOW TEST] [11.508 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:36:21.9
    Jan 24 20:36:21.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 20:36:21.912
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:36:21.976
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:36:21.991
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 20:36:22.051
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 20:36:23.701
    STEP: Deploying the webhook pod 01/24/23 20:36:23.717
    STEP: Wait for the deployment to be ready 01/24/23 20:36:23.806
    Jan 24 20:36:24.095: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 24 20:36:26.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 36, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 36, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 36, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 36, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 20:36:28.228
    STEP: Verifying the service has paired with the endpoint 01/24/23 20:36:28.291
    Jan 24 20:36:29.292: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Jan 24 20:36:29.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4148-crds.webhook.example.com via the AdmissionRegistration API 01/24/23 20:36:29.952
    STEP: Creating a custom resource that should be mutated by the webhook 01/24/23 20:36:30.05
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:36:32.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3083" for this suite. 01/24/23 20:36:32.998
    STEP: Destroying namespace "webhook-3083-markers" for this suite. 01/24/23 20:36:33.038
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:36:33.409
Jan 24 20:36:33.409: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename projected 01/24/23 20:36:33.413
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:36:33.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:36:33.526
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-fe2ebda8-8977-4bde-814d-29bf307bcc63 01/24/23 20:36:33.542
STEP: Creating configMap with name cm-test-opt-upd-6cbfd6ff-52fe-4c69-92cc-29db8de32c80 01/24/23 20:36:33.554
STEP: Creating the pod 01/24/23 20:36:33.572
Jan 24 20:36:33.602: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5" in namespace "projected-8733" to be "running and ready"
Jan 24 20:36:33.620: INFO: Pod "pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5": Phase="Pending", Reason="", readiness=false. Elapsed: 17.925827ms
Jan 24 20:36:33.620: INFO: The phase of Pod pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:36:35.635: INFO: Pod "pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033015672s
Jan 24 20:36:35.635: INFO: The phase of Pod pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:36:37.634: INFO: Pod "pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5": Phase="Running", Reason="", readiness=true. Elapsed: 4.031970544s
Jan 24 20:36:37.635: INFO: The phase of Pod pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5 is Running (Ready = true)
Jan 24 20:36:37.635: INFO: Pod "pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-fe2ebda8-8977-4bde-814d-29bf307bcc63 01/24/23 20:36:37.72
STEP: Updating configmap cm-test-opt-upd-6cbfd6ff-52fe-4c69-92cc-29db8de32c80 01/24/23 20:36:37.739
STEP: Creating configMap with name cm-test-opt-create-16d1eee6-e07c-46b9-a2df-b905772ab8bc 01/24/23 20:36:37.761
STEP: waiting to observe update in volume 01/24/23 20:36:37.795
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Jan 24 20:38:01.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8733" for this suite. 01/24/23 20:38:01.87
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":343,"skipped":6277,"failed":0}
------------------------------
• [SLOW TEST] [88.496 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:36:33.409
    Jan 24 20:36:33.409: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename projected 01/24/23 20:36:33.413
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:36:33.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:36:33.526
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-fe2ebda8-8977-4bde-814d-29bf307bcc63 01/24/23 20:36:33.542
    STEP: Creating configMap with name cm-test-opt-upd-6cbfd6ff-52fe-4c69-92cc-29db8de32c80 01/24/23 20:36:33.554
    STEP: Creating the pod 01/24/23 20:36:33.572
    Jan 24 20:36:33.602: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5" in namespace "projected-8733" to be "running and ready"
    Jan 24 20:36:33.620: INFO: Pod "pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5": Phase="Pending", Reason="", readiness=false. Elapsed: 17.925827ms
    Jan 24 20:36:33.620: INFO: The phase of Pod pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:36:35.635: INFO: Pod "pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033015672s
    Jan 24 20:36:35.635: INFO: The phase of Pod pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:36:37.634: INFO: Pod "pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5": Phase="Running", Reason="", readiness=true. Elapsed: 4.031970544s
    Jan 24 20:36:37.635: INFO: The phase of Pod pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5 is Running (Ready = true)
    Jan 24 20:36:37.635: INFO: Pod "pod-projected-configmaps-23c8d99f-a39e-4ac6-a9bc-7b8669cfe3c5" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-fe2ebda8-8977-4bde-814d-29bf307bcc63 01/24/23 20:36:37.72
    STEP: Updating configmap cm-test-opt-upd-6cbfd6ff-52fe-4c69-92cc-29db8de32c80 01/24/23 20:36:37.739
    STEP: Creating configMap with name cm-test-opt-create-16d1eee6-e07c-46b9-a2df-b905772ab8bc 01/24/23 20:36:37.761
    STEP: waiting to observe update in volume 01/24/23 20:36:37.795
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Jan 24 20:38:01.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8733" for this suite. 01/24/23 20:38:01.87
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:38:01.909
Jan 24 20:38:01.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename daemonsets 01/24/23 20:38:01.939
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:38:02.022
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:38:02.039
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 01/24/23 20:38:02.146
STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 20:38:02.23
Jan 24 20:38:02.311: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 20:38:02.311: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:38:03.373: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 20:38:03.374: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:38:04.400: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 20:38:04.400: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:38:05.464: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jan 24 20:38:05.464: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:38:06.591: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 20:38:06.591: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:38:07.488: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 20:38:07.488: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:38:08.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 20:38:08.426: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:38:09.332: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jan 24 20:38:09.332: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
Jan 24 20:38:10.337: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jan 24 20:38:10.337: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
STEP: listing all DeamonSets 01/24/23 20:38:10.368
STEP: DeleteCollection of the DaemonSets 01/24/23 20:38:10.379
STEP: Verify that ReplicaSets have been deleted 01/24/23 20:38:10.404
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Jan 24 20:38:10.517: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"44282"},"items":null}

Jan 24 20:38:10.531: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"44283"},"items":[{"metadata":{"name":"daemon-set-nnznt","generateName":"daemon-set-","namespace":"daemonsets-565","uid":"471c949b-bb81-49e2-934b-e9bc0ddfa379","resourceVersion":"44282","creationTimestamp":"2023-01-24T20:38:02Z","deletionTimestamp":"2023-01-24T20:38:40Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"330dd7a16e0fc9b54cdf5bcf019aa10f82dc2ae6e86c5fdb27ad06984e5072f0","cni.projectcalico.org/podIP":"10.244.47.100/32","cni.projectcalico.org/podIPs":"10.244.47.100/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"ff856e1a-7251-481d-b74b-697c346c9086","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:02Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ff856e1a-7251-481d-b74b-697c346c9086\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:09Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.100\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-58m6m","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-58m6m","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"vikash-v125latest-conf-59870","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["vikash-v125latest-conf-59870"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:02Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:09Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:09Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:02Z"}],"hostIP":"10.10.1.213","podIP":"10.244.47.100","podIPs":[{"ip":"10.244.47.100"}],"startTime":"2023-01-24T20:38:02Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-01-24T20:38:08Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://57d87f23a500f744293633c6e41cc26e00a3142aad04c48704cdfb49c61caaf3","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-z8k24","generateName":"daemon-set-","namespace":"daemonsets-565","uid":"c8c5c0db-82df-4a8b-93e9-f3edd21d9f03","resourceVersion":"44281","creationTimestamp":"2023-01-24T20:38:02Z","deletionTimestamp":"2023-01-24T20:38:40Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f5062b8fb32de25e05e0409d2a9b958fd0e9593d06709beb0238d22122574247","cni.projectcalico.org/podIP":"10.244.71.199/32","cni.projectcalico.org/podIPs":"10.244.71.199/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"ff856e1a-7251-481d-b74b-697c346c9086","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:02Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ff856e1a-7251-481d-b74b-697c346c9086\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.199\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6pcpr","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6pcpr","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"vikash-v125latest-conf-71087","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["vikash-v125latest-conf-71087"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:02Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:06Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:06Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:02Z"}],"hostIP":"10.10.1.127","podIP":"10.244.71.199","podIPs":[{"ip":"10.244.71.199"}],"startTime":"2023-01-24T20:38:02Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-01-24T20:38:05Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://8516a2ea261e2cf1c1a91acee7c110693231c98bc7ad652417a1750a3f5d2a60","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Jan 24 20:38:10.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-565" for this suite. 01/24/23 20:38:10.602
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":344,"skipped":6292,"failed":0}
------------------------------
• [SLOW TEST] [8.709 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:38:01.909
    Jan 24 20:38:01.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename daemonsets 01/24/23 20:38:01.939
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:38:02.022
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:38:02.039
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 01/24/23 20:38:02.146
    STEP: Check that daemon pods launch on every node of the cluster. 01/24/23 20:38:02.23
    Jan 24 20:38:02.311: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 20:38:02.311: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:38:03.373: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 20:38:03.374: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:38:04.400: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 20:38:04.400: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:38:05.464: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Jan 24 20:38:05.464: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:38:06.591: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 20:38:06.591: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:38:07.488: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 20:38:07.488: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:38:08.426: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 20:38:08.426: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:38:09.332: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Jan 24 20:38:09.332: INFO: Node vikash-v125latest-conf-59870 is running 0 daemon pod, expected 1
    Jan 24 20:38:10.337: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Jan 24 20:38:10.337: INFO: Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
    STEP: listing all DeamonSets 01/24/23 20:38:10.368
    STEP: DeleteCollection of the DaemonSets 01/24/23 20:38:10.379
    STEP: Verify that ReplicaSets have been deleted 01/24/23 20:38:10.404
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Jan 24 20:38:10.517: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"44282"},"items":null}

    Jan 24 20:38:10.531: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"44283"},"items":[{"metadata":{"name":"daemon-set-nnznt","generateName":"daemon-set-","namespace":"daemonsets-565","uid":"471c949b-bb81-49e2-934b-e9bc0ddfa379","resourceVersion":"44282","creationTimestamp":"2023-01-24T20:38:02Z","deletionTimestamp":"2023-01-24T20:38:40Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"330dd7a16e0fc9b54cdf5bcf019aa10f82dc2ae6e86c5fdb27ad06984e5072f0","cni.projectcalico.org/podIP":"10.244.47.100/32","cni.projectcalico.org/podIPs":"10.244.47.100/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"ff856e1a-7251-481d-b74b-697c346c9086","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:02Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ff856e1a-7251-481d-b74b-697c346c9086\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:09Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.47.100\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-58m6m","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-58m6m","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"vikash-v125latest-conf-59870","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["vikash-v125latest-conf-59870"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:02Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:09Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:09Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:02Z"}],"hostIP":"10.10.1.213","podIP":"10.244.47.100","podIPs":[{"ip":"10.244.47.100"}],"startTime":"2023-01-24T20:38:02Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-01-24T20:38:08Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://57d87f23a500f744293633c6e41cc26e00a3142aad04c48704cdfb49c61caaf3","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-z8k24","generateName":"daemon-set-","namespace":"daemonsets-565","uid":"c8c5c0db-82df-4a8b-93e9-f3edd21d9f03","resourceVersion":"44281","creationTimestamp":"2023-01-24T20:38:02Z","deletionTimestamp":"2023-01-24T20:38:40Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f5062b8fb32de25e05e0409d2a9b958fd0e9593d06709beb0238d22122574247","cni.projectcalico.org/podIP":"10.244.71.199/32","cni.projectcalico.org/podIPs":"10.244.71.199/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"ff856e1a-7251-481d-b74b-697c346c9086","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:02Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ff856e1a-7251-481d-b74b-697c346c9086\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-01-24T20:38:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.244.71.199\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6pcpr","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6pcpr","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"vikash-v125latest-conf-71087","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["vikash-v125latest-conf-71087"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:02Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:06Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:06Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-01-24T20:38:02Z"}],"hostIP":"10.10.1.127","podIP":"10.244.71.199","podIPs":[{"ip":"10.244.71.199"}],"startTime":"2023-01-24T20:38:02Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-01-24T20:38:05Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://8516a2ea261e2cf1c1a91acee7c110693231c98bc7ad652417a1750a3f5d2a60","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 20:38:10.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-565" for this suite. 01/24/23 20:38:10.602
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:38:10.627
Jan 24 20:38:10.627: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename kubectl 01/24/23 20:38:10.635
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:38:10.687
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:38:10.718
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 01/24/23 20:38:10.737
Jan 24 20:38:10.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 create -f -'
Jan 24 20:38:15.328: INFO: stderr: ""
Jan 24 20:38:15.328: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 01/24/23 20:38:15.328
Jan 24 20:38:15.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:38:16.130: INFO: stderr: ""
Jan 24 20:38:16.130: INFO: stdout: "update-demo-nautilus-8mql4 update-demo-nautilus-vvgqw "
Jan 24 20:38:16.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods update-demo-nautilus-8mql4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:38:16.456: INFO: stderr: ""
Jan 24 20:38:16.456: INFO: stdout: ""
Jan 24 20:38:16.456: INFO: update-demo-nautilus-8mql4 is created but not running
Jan 24 20:38:21.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jan 24 20:38:21.766: INFO: stderr: ""
Jan 24 20:38:21.766: INFO: stdout: "update-demo-nautilus-8mql4 update-demo-nautilus-vvgqw "
Jan 24 20:38:21.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods update-demo-nautilus-8mql4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:38:22.090: INFO: stderr: ""
Jan 24 20:38:22.090: INFO: stdout: "true"
Jan 24 20:38:22.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods update-demo-nautilus-8mql4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 24 20:38:23.215: INFO: stderr: ""
Jan 24 20:38:23.215: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 24 20:38:23.215: INFO: validating pod update-demo-nautilus-8mql4
Jan 24 20:38:23.242: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 24 20:38:23.242: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 24 20:38:23.242: INFO: update-demo-nautilus-8mql4 is verified up and running
Jan 24 20:38:23.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods update-demo-nautilus-vvgqw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jan 24 20:38:23.665: INFO: stderr: ""
Jan 24 20:38:23.665: INFO: stdout: "true"
Jan 24 20:38:23.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods update-demo-nautilus-vvgqw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jan 24 20:38:24.882: INFO: stderr: ""
Jan 24 20:38:24.882: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Jan 24 20:38:24.882: INFO: validating pod update-demo-nautilus-vvgqw
Jan 24 20:38:24.952: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 24 20:38:24.953: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 24 20:38:24.953: INFO: update-demo-nautilus-vvgqw is verified up and running
STEP: using delete to clean up resources 01/24/23 20:38:24.953
Jan 24 20:38:24.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 delete --grace-period=0 --force -f -'
Jan 24 20:38:25.744: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 24 20:38:25.744: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 24 20:38:25.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get rc,svc -l name=update-demo --no-headers'
Jan 24 20:38:26.346: INFO: stderr: "No resources found in kubectl-4027 namespace.\n"
Jan 24 20:38:26.346: INFO: stdout: ""
Jan 24 20:38:26.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 24 20:38:27.154: INFO: stderr: ""
Jan 24 20:38:27.154: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Jan 24 20:38:27.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4027" for this suite. 01/24/23 20:38:27.226
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":345,"skipped":6341,"failed":0}
------------------------------
• [SLOW TEST] [16.622 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:38:10.627
    Jan 24 20:38:10.627: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename kubectl 01/24/23 20:38:10.635
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:38:10.687
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:38:10.718
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 01/24/23 20:38:10.737
    Jan 24 20:38:10.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 create -f -'
    Jan 24 20:38:15.328: INFO: stderr: ""
    Jan 24 20:38:15.328: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 01/24/23 20:38:15.328
    Jan 24 20:38:15.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:38:16.130: INFO: stderr: ""
    Jan 24 20:38:16.130: INFO: stdout: "update-demo-nautilus-8mql4 update-demo-nautilus-vvgqw "
    Jan 24 20:38:16.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods update-demo-nautilus-8mql4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:38:16.456: INFO: stderr: ""
    Jan 24 20:38:16.456: INFO: stdout: ""
    Jan 24 20:38:16.456: INFO: update-demo-nautilus-8mql4 is created but not running
    Jan 24 20:38:21.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Jan 24 20:38:21.766: INFO: stderr: ""
    Jan 24 20:38:21.766: INFO: stdout: "update-demo-nautilus-8mql4 update-demo-nautilus-vvgqw "
    Jan 24 20:38:21.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods update-demo-nautilus-8mql4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:38:22.090: INFO: stderr: ""
    Jan 24 20:38:22.090: INFO: stdout: "true"
    Jan 24 20:38:22.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods update-demo-nautilus-8mql4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 24 20:38:23.215: INFO: stderr: ""
    Jan 24 20:38:23.215: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 24 20:38:23.215: INFO: validating pod update-demo-nautilus-8mql4
    Jan 24 20:38:23.242: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 24 20:38:23.242: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 24 20:38:23.242: INFO: update-demo-nautilus-8mql4 is verified up and running
    Jan 24 20:38:23.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods update-demo-nautilus-vvgqw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Jan 24 20:38:23.665: INFO: stderr: ""
    Jan 24 20:38:23.665: INFO: stdout: "true"
    Jan 24 20:38:23.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods update-demo-nautilus-vvgqw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Jan 24 20:38:24.882: INFO: stderr: ""
    Jan 24 20:38:24.882: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Jan 24 20:38:24.882: INFO: validating pod update-demo-nautilus-vvgqw
    Jan 24 20:38:24.952: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Jan 24 20:38:24.953: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Jan 24 20:38:24.953: INFO: update-demo-nautilus-vvgqw is verified up and running
    STEP: using delete to clean up resources 01/24/23 20:38:24.953
    Jan 24 20:38:24.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 delete --grace-period=0 --force -f -'
    Jan 24 20:38:25.744: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Jan 24 20:38:25.744: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Jan 24 20:38:25.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get rc,svc -l name=update-demo --no-headers'
    Jan 24 20:38:26.346: INFO: stderr: "No resources found in kubectl-4027 namespace.\n"
    Jan 24 20:38:26.346: INFO: stdout: ""
    Jan 24 20:38:26.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=kubectl-4027 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Jan 24 20:38:27.154: INFO: stderr: ""
    Jan 24 20:38:27.154: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Jan 24 20:38:27.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4027" for this suite. 01/24/23 20:38:27.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:38:27.46
Jan 24 20:38:27.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename downward-api 01/24/23 20:38:27.48
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:38:27.643
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:38:27.666
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 01/24/23 20:38:27.699
Jan 24 20:38:27.965: INFO: Waiting up to 5m0s for pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3" in namespace "downward-api-5811" to be "Succeeded or Failed"
Jan 24 20:38:28.058: INFO: Pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3": Phase="Pending", Reason="", readiness=false. Elapsed: 34.069794ms
Jan 24 20:38:30.138: INFO: Pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114358355s
Jan 24 20:38:32.086: INFO: Pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062151366s
Jan 24 20:38:34.078: INFO: Pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0541455s
STEP: Saw pod success 01/24/23 20:38:34.078
Jan 24 20:38:34.079: INFO: Pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3" satisfied condition "Succeeded or Failed"
Jan 24 20:38:34.092: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3 container client-container: <nil>
STEP: delete the pod 01/24/23 20:38:34.135
Jan 24 20:38:34.193: INFO: Waiting for pod downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3 to disappear
Jan 24 20:38:34.208: INFO: Pod downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Jan 24 20:38:34.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5811" for this suite. 01/24/23 20:38:34.253
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":346,"skipped":6381,"failed":0}
------------------------------
• [SLOW TEST] [6.836 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:38:27.46
    Jan 24 20:38:27.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename downward-api 01/24/23 20:38:27.48
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:38:27.643
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:38:27.666
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 01/24/23 20:38:27.699
    Jan 24 20:38:27.965: INFO: Waiting up to 5m0s for pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3" in namespace "downward-api-5811" to be "Succeeded or Failed"
    Jan 24 20:38:28.058: INFO: Pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3": Phase="Pending", Reason="", readiness=false. Elapsed: 34.069794ms
    Jan 24 20:38:30.138: INFO: Pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114358355s
    Jan 24 20:38:32.086: INFO: Pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062151366s
    Jan 24 20:38:34.078: INFO: Pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0541455s
    STEP: Saw pod success 01/24/23 20:38:34.078
    Jan 24 20:38:34.079: INFO: Pod "downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3" satisfied condition "Succeeded or Failed"
    Jan 24 20:38:34.092: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3 container client-container: <nil>
    STEP: delete the pod 01/24/23 20:38:34.135
    Jan 24 20:38:34.193: INFO: Waiting for pod downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3 to disappear
    Jan 24 20:38:34.208: INFO: Pod downwardapi-volume-38495980-3989-4270-9442-f9e65ec805c3 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Jan 24 20:38:34.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5811" for this suite. 01/24/23 20:38:34.253
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:38:34.301
Jan 24 20:38:34.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 20:38:34.308
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:38:34.45
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:38:34.469
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-4623 01/24/23 20:38:34.487
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4623 to expose endpoints map[] 01/24/23 20:38:34.532
Jan 24 20:38:34.570: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Jan 24 20:38:35.616: INFO: successfully validated that service endpoint-test2 in namespace services-4623 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4623 01/24/23 20:38:35.617
Jan 24 20:38:35.670: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4623" to be "running and ready"
Jan 24 20:38:35.696: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.368689ms
Jan 24 20:38:35.697: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:38:37.733: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.062966814s
Jan 24 20:38:37.733: INFO: The phase of Pod pod1 is Running (Ready = true)
Jan 24 20:38:37.733: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4623 to expose endpoints map[pod1:[80]] 01/24/23 20:38:37.749
Jan 24 20:38:37.829: INFO: successfully validated that service endpoint-test2 in namespace services-4623 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 01/24/23 20:38:37.83
Jan 24 20:38:37.833: INFO: Creating new exec pod
Jan 24 20:38:37.861: INFO: Waiting up to 5m0s for pod "execpodpr44s" in namespace "services-4623" to be "running"
Jan 24 20:38:37.880: INFO: Pod "execpodpr44s": Phase="Pending", Reason="", readiness=false. Elapsed: 19.02794ms
Jan 24 20:38:39.897: INFO: Pod "execpodpr44s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035841364s
Jan 24 20:38:41.890: INFO: Pod "execpodpr44s": Phase="Running", Reason="", readiness=true. Elapsed: 4.029404588s
Jan 24 20:38:41.890: INFO: Pod "execpodpr44s" satisfied condition "running"
Jan 24 20:38:42.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jan 24 20:38:43.556: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jan 24 20:38:43.557: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 20:38:43.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.226.95 80'
Jan 24 20:38:44.575: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.226.95 80\nConnection to 10.10.226.95 80 port [tcp/http] succeeded!\n"
Jan 24 20:38:44.575: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-4623 01/24/23 20:38:44.575
Jan 24 20:38:44.652: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4623" to be "running and ready"
Jan 24 20:38:44.769: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 116.016196ms
Jan 24 20:38:44.769: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:38:46.796: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.143773469s
Jan 24 20:38:46.797: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jan 24 20:38:48.808: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.155164058s
Jan 24 20:38:48.809: INFO: The phase of Pod pod2 is Running (Ready = true)
Jan 24 20:38:48.810: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4623 to expose endpoints map[pod1:[80] pod2:[80]] 01/24/23 20:38:48.829
Jan 24 20:38:48.952: INFO: successfully validated that service endpoint-test2 in namespace services-4623 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 01/24/23 20:38:48.955
Jan 24 20:38:49.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jan 24 20:38:50.957: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jan 24 20:38:50.957: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 20:38:50.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.226.95 80'
Jan 24 20:38:52.013: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.226.95 80\nConnection to 10.10.226.95 80 port [tcp/http] succeeded!\n"
Jan 24 20:38:52.013: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-4623 01/24/23 20:38:52.013
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4623 to expose endpoints map[pod2:[80]] 01/24/23 20:38:52.083
Jan 24 20:38:53.204: INFO: successfully validated that service endpoint-test2 in namespace services-4623 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 01/24/23 20:38:53.204
Jan 24 20:38:54.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jan 24 20:38:55.171: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jan 24 20:38:55.171: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jan 24 20:38:55.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.226.95 80'
Jan 24 20:38:55.935: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.226.95 80\nConnection to 10.10.226.95 80 port [tcp/http] succeeded!\n"
Jan 24 20:38:55.935: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-4623 01/24/23 20:38:55.935
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4623 to expose endpoints map[] 01/24/23 20:38:56.017
Jan 24 20:38:56.278: INFO: successfully validated that service endpoint-test2 in namespace services-4623 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 20:38:56.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4623" for this suite. 01/24/23 20:38:56.427
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":347,"skipped":6396,"failed":0}
------------------------------
• [SLOW TEST] [22.155 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:38:34.301
    Jan 24 20:38:34.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 20:38:34.308
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:38:34.45
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:38:34.469
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-4623 01/24/23 20:38:34.487
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4623 to expose endpoints map[] 01/24/23 20:38:34.532
    Jan 24 20:38:34.570: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
    Jan 24 20:38:35.616: INFO: successfully validated that service endpoint-test2 in namespace services-4623 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-4623 01/24/23 20:38:35.617
    Jan 24 20:38:35.670: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4623" to be "running and ready"
    Jan 24 20:38:35.696: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.368689ms
    Jan 24 20:38:35.697: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:38:37.733: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.062966814s
    Jan 24 20:38:37.733: INFO: The phase of Pod pod1 is Running (Ready = true)
    Jan 24 20:38:37.733: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4623 to expose endpoints map[pod1:[80]] 01/24/23 20:38:37.749
    Jan 24 20:38:37.829: INFO: successfully validated that service endpoint-test2 in namespace services-4623 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 01/24/23 20:38:37.83
    Jan 24 20:38:37.833: INFO: Creating new exec pod
    Jan 24 20:38:37.861: INFO: Waiting up to 5m0s for pod "execpodpr44s" in namespace "services-4623" to be "running"
    Jan 24 20:38:37.880: INFO: Pod "execpodpr44s": Phase="Pending", Reason="", readiness=false. Elapsed: 19.02794ms
    Jan 24 20:38:39.897: INFO: Pod "execpodpr44s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035841364s
    Jan 24 20:38:41.890: INFO: Pod "execpodpr44s": Phase="Running", Reason="", readiness=true. Elapsed: 4.029404588s
    Jan 24 20:38:41.890: INFO: Pod "execpodpr44s" satisfied condition "running"
    Jan 24 20:38:42.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Jan 24 20:38:43.556: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Jan 24 20:38:43.557: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 20:38:43.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.226.95 80'
    Jan 24 20:38:44.575: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.226.95 80\nConnection to 10.10.226.95 80 port [tcp/http] succeeded!\n"
    Jan 24 20:38:44.575: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-4623 01/24/23 20:38:44.575
    Jan 24 20:38:44.652: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4623" to be "running and ready"
    Jan 24 20:38:44.769: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 116.016196ms
    Jan 24 20:38:44.769: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:38:46.796: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.143773469s
    Jan 24 20:38:46.797: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Jan 24 20:38:48.808: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.155164058s
    Jan 24 20:38:48.809: INFO: The phase of Pod pod2 is Running (Ready = true)
    Jan 24 20:38:48.810: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4623 to expose endpoints map[pod1:[80] pod2:[80]] 01/24/23 20:38:48.829
    Jan 24 20:38:48.952: INFO: successfully validated that service endpoint-test2 in namespace services-4623 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 01/24/23 20:38:48.955
    Jan 24 20:38:49.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Jan 24 20:38:50.957: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Jan 24 20:38:50.957: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 20:38:50.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.226.95 80'
    Jan 24 20:38:52.013: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.226.95 80\nConnection to 10.10.226.95 80 port [tcp/http] succeeded!\n"
    Jan 24 20:38:52.013: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-4623 01/24/23 20:38:52.013
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4623 to expose endpoints map[pod2:[80]] 01/24/23 20:38:52.083
    Jan 24 20:38:53.204: INFO: successfully validated that service endpoint-test2 in namespace services-4623 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 01/24/23 20:38:53.204
    Jan 24 20:38:54.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Jan 24 20:38:55.171: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Jan 24 20:38:55.171: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Jan 24 20:38:55.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-4623 exec execpodpr44s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.226.95 80'
    Jan 24 20:38:55.935: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.226.95 80\nConnection to 10.10.226.95 80 port [tcp/http] succeeded!\n"
    Jan 24 20:38:55.935: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-4623 01/24/23 20:38:55.935
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4623 to expose endpoints map[] 01/24/23 20:38:56.017
    Jan 24 20:38:56.278: INFO: successfully validated that service endpoint-test2 in namespace services-4623 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 20:38:56.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4623" for this suite. 01/24/23 20:38:56.427
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:38:56.465
Jan 24 20:38:56.465: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 20:38:56.468
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:38:56.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:38:56.543
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-9dbc6e6c-e0ea-4ea4-a86d-a65d8fe653d5 01/24/23 20:38:56.556
STEP: Creating a pod to test consume configMaps 01/24/23 20:38:56.575
Jan 24 20:38:56.631: INFO: Waiting up to 5m0s for pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285" in namespace "configmap-244" to be "Succeeded or Failed"
Jan 24 20:38:56.742: INFO: Pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285": Phase="Pending", Reason="", readiness=false. Elapsed: 109.953932ms
Jan 24 20:38:58.858: INFO: Pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285": Phase="Pending", Reason="", readiness=false. Elapsed: 2.225792377s
Jan 24 20:39:00.883: INFO: Pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251009336s
Jan 24 20:39:02.838: INFO: Pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.205901s
STEP: Saw pod success 01/24/23 20:39:02.838
Jan 24 20:39:02.838: INFO: Pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285" satisfied condition "Succeeded or Failed"
Jan 24 20:39:02.875: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285 container agnhost-container: <nil>
STEP: delete the pod 01/24/23 20:39:02.981
Jan 24 20:39:03.095: INFO: Waiting for pod pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285 to disappear
Jan 24 20:39:03.156: INFO: Pod pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 20:39:03.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-244" for this suite. 01/24/23 20:39:03.207
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":348,"skipped":6451,"failed":0}
------------------------------
• [SLOW TEST] [6.820 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:38:56.465
    Jan 24 20:38:56.465: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 20:38:56.468
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:38:56.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:38:56.543
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-9dbc6e6c-e0ea-4ea4-a86d-a65d8fe653d5 01/24/23 20:38:56.556
    STEP: Creating a pod to test consume configMaps 01/24/23 20:38:56.575
    Jan 24 20:38:56.631: INFO: Waiting up to 5m0s for pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285" in namespace "configmap-244" to be "Succeeded or Failed"
    Jan 24 20:38:56.742: INFO: Pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285": Phase="Pending", Reason="", readiness=false. Elapsed: 109.953932ms
    Jan 24 20:38:58.858: INFO: Pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285": Phase="Pending", Reason="", readiness=false. Elapsed: 2.225792377s
    Jan 24 20:39:00.883: INFO: Pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251009336s
    Jan 24 20:39:02.838: INFO: Pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.205901s
    STEP: Saw pod success 01/24/23 20:39:02.838
    Jan 24 20:39:02.838: INFO: Pod "pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285" satisfied condition "Succeeded or Failed"
    Jan 24 20:39:02.875: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285 container agnhost-container: <nil>
    STEP: delete the pod 01/24/23 20:39:02.981
    Jan 24 20:39:03.095: INFO: Waiting for pod pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285 to disappear
    Jan 24 20:39:03.156: INFO: Pod pod-configmaps-e971a6ce-3c4c-4ae2-b7ba-b82843853285 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 20:39:03.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-244" for this suite. 01/24/23 20:39:03.207
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:39:03.448
Jan 24 20:39:03.449: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename namespaces 01/24/23 20:39:03.457
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:39:03.551
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:39:03.597
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 01/24/23 20:39:03.656
STEP: patching the Namespace 01/24/23 20:39:03.854
STEP: get the Namespace and ensuring it has the label 01/24/23 20:39:03.934
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Jan 24 20:39:03.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2383" for this suite. 01/24/23 20:39:03.979
STEP: Destroying namespace "nspatchtest-63591b6b-c25b-4bc0-95ef-a552610437b3-7975" for this suite. 01/24/23 20:39:04.017
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":349,"skipped":6470,"failed":0}
------------------------------
• [0.614 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:39:03.448
    Jan 24 20:39:03.449: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename namespaces 01/24/23 20:39:03.457
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:39:03.551
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:39:03.597
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 01/24/23 20:39:03.656
    STEP: patching the Namespace 01/24/23 20:39:03.854
    STEP: get the Namespace and ensuring it has the label 01/24/23 20:39:03.934
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Jan 24 20:39:03.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-2383" for this suite. 01/24/23 20:39:03.979
    STEP: Destroying namespace "nspatchtest-63591b6b-c25b-4bc0-95ef-a552610437b3-7975" for this suite. 01/24/23 20:39:04.017
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:39:04.163
Jan 24 20:39:04.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename configmap 01/24/23 20:39:04.177
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:39:04.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:39:04.425
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-04249a54-46be-4490-b84a-e62637f51a20 01/24/23 20:39:04.552
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Jan 24 20:39:04.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8378" for this suite. 01/24/23 20:39:04.664
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":350,"skipped":6484,"failed":0}
------------------------------
• [0.636 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:39:04.163
    Jan 24 20:39:04.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename configmap 01/24/23 20:39:04.177
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:39:04.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:39:04.425
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-04249a54-46be-4490-b84a-e62637f51a20 01/24/23 20:39:04.552
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Jan 24 20:39:04.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8378" for this suite. 01/24/23 20:39:04.664
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:39:04.95
Jan 24 20:39:04.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 20:39:04.977
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:39:05.384
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:39:05.559
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 01/24/23 20:39:05.675
Jan 24 20:39:05.681: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: rename a version 01/24/23 20:39:18.84
STEP: check the new version name is served 01/24/23 20:39:18.888
STEP: check the old version name is removed 01/24/23 20:39:26.117
STEP: check the other version is not changed 01/24/23 20:39:30.447
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:39:52.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7917" for this suite. 01/24/23 20:39:52.247
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":351,"skipped":6499,"failed":0}
------------------------------
• [SLOW TEST] [47.331 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:39:04.95
    Jan 24 20:39:04.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename crd-publish-openapi 01/24/23 20:39:04.977
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:39:05.384
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:39:05.559
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 01/24/23 20:39:05.675
    Jan 24 20:39:05.681: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: rename a version 01/24/23 20:39:18.84
    STEP: check the new version name is served 01/24/23 20:39:18.888
    STEP: check the old version name is removed 01/24/23 20:39:26.117
    STEP: check the other version is not changed 01/24/23 20:39:30.447
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:39:52.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7917" for this suite. 01/24/23 20:39:52.247
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:39:52.292
Jan 24 20:39:52.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename conformance-tests 01/24/23 20:39:52.303
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:39:52.421
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:39:52.44
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 01/24/23 20:39:52.471
Jan 24 20:39:52.472: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Jan 24 20:39:52.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-3775" for this suite. 01/24/23 20:39:52.537
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":352,"skipped":6540,"failed":0}
------------------------------
• [0.282 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:39:52.292
    Jan 24 20:39:52.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename conformance-tests 01/24/23 20:39:52.303
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:39:52.421
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:39:52.44
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 01/24/23 20:39:52.471
    Jan 24 20:39:52.472: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Jan 24 20:39:52.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-3775" for this suite. 01/24/23 20:39:52.537
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:39:52.579
Jan 24 20:39:52.580: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename services 01/24/23 20:39:52.591
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:39:52.727
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:39:52.752
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1956 01/24/23 20:39:52.766
STEP: changing the ExternalName service to type=NodePort 01/24/23 20:39:52.791
STEP: creating replication controller externalname-service in namespace services-1956 01/24/23 20:39:52.925
I0124 20:39:52.955634      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1956, replica count: 2
I0124 20:39:56.060597      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0124 20:39:59.062961      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 24 20:39:59.063: INFO: Creating new exec pod
Jan 24 20:39:59.115: INFO: Waiting up to 5m0s for pod "execpodskl8h" in namespace "services-1956" to be "running"
Jan 24 20:39:59.132: INFO: Pod "execpodskl8h": Phase="Pending", Reason="", readiness=false. Elapsed: 17.42928ms
Jan 24 20:40:01.143: INFO: Pod "execpodskl8h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028599279s
Jan 24 20:40:03.146: INFO: Pod "execpodskl8h": Phase="Running", Reason="", readiness=true. Elapsed: 4.03139485s
Jan 24 20:40:03.147: INFO: Pod "execpodskl8h" satisfied condition "running"
Jan 24 20:40:04.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-1956 exec execpodskl8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jan 24 20:40:04.975: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jan 24 20:40:04.975: INFO: stdout: ""
Jan 24 20:40:05.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-1956 exec execpodskl8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jan 24 20:40:06.667: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jan 24 20:40:06.668: INFO: stdout: "externalname-service-lw777"
Jan 24 20:40:06.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-1956 exec execpodskl8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.35.224 80'
Jan 24 20:40:07.639: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.35.224 80\nConnection to 10.10.35.224 80 port [tcp/http] succeeded!\n"
Jan 24 20:40:07.640: INFO: stdout: "externalname-service-jxmn5"
Jan 24 20:40:07.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-1956 exec execpodskl8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 32101'
Jan 24 20:40:08.779: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 32101\nConnection to 10.10.1.213 32101 port [tcp/*] succeeded!\n"
Jan 24 20:40:08.779: INFO: stdout: "externalname-service-lw777"
Jan 24 20:40:08.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-1956 exec execpodskl8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.127 32101'
Jan 24 20:40:11.733: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.127 32101\nConnection to 10.10.1.127 32101 port [tcp/*] succeeded!\n"
Jan 24 20:40:11.733: INFO: stdout: "externalname-service-lw777"
Jan 24 20:40:11.733: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Jan 24 20:40:11.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1956" for this suite. 01/24/23 20:40:11.795
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":353,"skipped":6542,"failed":0}
------------------------------
• [SLOW TEST] [19.234 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:39:52.579
    Jan 24 20:39:52.580: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename services 01/24/23 20:39:52.591
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:39:52.727
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:39:52.752
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-1956 01/24/23 20:39:52.766
    STEP: changing the ExternalName service to type=NodePort 01/24/23 20:39:52.791
    STEP: creating replication controller externalname-service in namespace services-1956 01/24/23 20:39:52.925
    I0124 20:39:52.955634      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-1956, replica count: 2
    I0124 20:39:56.060597      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0124 20:39:59.062961      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Jan 24 20:39:59.063: INFO: Creating new exec pod
    Jan 24 20:39:59.115: INFO: Waiting up to 5m0s for pod "execpodskl8h" in namespace "services-1956" to be "running"
    Jan 24 20:39:59.132: INFO: Pod "execpodskl8h": Phase="Pending", Reason="", readiness=false. Elapsed: 17.42928ms
    Jan 24 20:40:01.143: INFO: Pod "execpodskl8h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028599279s
    Jan 24 20:40:03.146: INFO: Pod "execpodskl8h": Phase="Running", Reason="", readiness=true. Elapsed: 4.03139485s
    Jan 24 20:40:03.147: INFO: Pod "execpodskl8h" satisfied condition "running"
    Jan 24 20:40:04.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-1956 exec execpodskl8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Jan 24 20:40:04.975: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Jan 24 20:40:04.975: INFO: stdout: ""
    Jan 24 20:40:05.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-1956 exec execpodskl8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Jan 24 20:40:06.667: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Jan 24 20:40:06.668: INFO: stdout: "externalname-service-lw777"
    Jan 24 20:40:06.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-1956 exec execpodskl8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.35.224 80'
    Jan 24 20:40:07.639: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.35.224 80\nConnection to 10.10.35.224 80 port [tcp/http] succeeded!\n"
    Jan 24 20:40:07.640: INFO: stdout: "externalname-service-jxmn5"
    Jan 24 20:40:07.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-1956 exec execpodskl8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.213 32101'
    Jan 24 20:40:08.779: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.213 32101\nConnection to 10.10.1.213 32101 port [tcp/*] succeeded!\n"
    Jan 24 20:40:08.779: INFO: stdout: "externalname-service-lw777"
    Jan 24 20:40:08.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2021580216 --namespace=services-1956 exec execpodskl8h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.10.1.127 32101'
    Jan 24 20:40:11.733: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.10.1.127 32101\nConnection to 10.10.1.127 32101 port [tcp/*] succeeded!\n"
    Jan 24 20:40:11.733: INFO: stdout: "externalname-service-lw777"
    Jan 24 20:40:11.733: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Jan 24 20:40:11.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1956" for this suite. 01/24/23 20:40:11.795
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:40:11.813
Jan 24 20:40:11.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename var-expansion 01/24/23 20:40:11.816
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:40:11.852
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:40:11.858
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 01/24/23 20:40:11.866
Jan 24 20:40:11.883: INFO: Waiting up to 5m0s for pod "var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e" in namespace "var-expansion-7398" to be "Succeeded or Failed"
Jan 24 20:40:11.890: INFO: Pod "var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.105467ms
Jan 24 20:40:13.904: INFO: Pod "var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020352027s
Jan 24 20:40:15.896: INFO: Pod "var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012857983s
STEP: Saw pod success 01/24/23 20:40:15.897
Jan 24 20:40:15.897: INFO: Pod "var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e" satisfied condition "Succeeded or Failed"
Jan 24 20:40:15.902: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e container dapi-container: <nil>
STEP: delete the pod 01/24/23 20:40:15.912
Jan 24 20:40:15.927: INFO: Waiting for pod var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e to disappear
Jan 24 20:40:15.939: INFO: Pod var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 24 20:40:15.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7398" for this suite. 01/24/23 20:40:15.948
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":354,"skipped":6542,"failed":0}
------------------------------
• [4.153 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:40:11.813
    Jan 24 20:40:11.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename var-expansion 01/24/23 20:40:11.816
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:40:11.852
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:40:11.858
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 01/24/23 20:40:11.866
    Jan 24 20:40:11.883: INFO: Waiting up to 5m0s for pod "var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e" in namespace "var-expansion-7398" to be "Succeeded or Failed"
    Jan 24 20:40:11.890: INFO: Pod "var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.105467ms
    Jan 24 20:40:13.904: INFO: Pod "var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020352027s
    Jan 24 20:40:15.896: INFO: Pod "var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012857983s
    STEP: Saw pod success 01/24/23 20:40:15.897
    Jan 24 20:40:15.897: INFO: Pod "var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e" satisfied condition "Succeeded or Failed"
    Jan 24 20:40:15.902: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e container dapi-container: <nil>
    STEP: delete the pod 01/24/23 20:40:15.912
    Jan 24 20:40:15.927: INFO: Waiting for pod var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e to disappear
    Jan 24 20:40:15.939: INFO: Pod var-expansion-45d9ec8e-af25-4eca-92ed-61d549c8478e no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 24 20:40:15.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7398" for this suite. 01/24/23 20:40:15.948
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:40:15.967
Jan 24 20:40:15.968: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename var-expansion 01/24/23 20:40:15.969
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:40:15.993
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:40:16.001
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 01/24/23 20:40:16.006
STEP: waiting for pod running 01/24/23 20:40:16.024
Jan 24 20:40:16.024: INFO: Waiting up to 2m0s for pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" in namespace "var-expansion-8673" to be "running"
Jan 24 20:40:16.028: INFO: Pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.628019ms
Jan 24 20:40:18.065: INFO: Pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.04152103s
Jan 24 20:40:18.065: INFO: Pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" satisfied condition "running"
STEP: creating a file in subpath 01/24/23 20:40:18.065
Jan 24 20:40:18.078: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-8673 PodName:var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 20:40:18.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 20:40:18.080: INFO: ExecWithOptions: Clientset creation
Jan 24 20:40:18.080: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/var-expansion-8673/pods/var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 01/24/23 20:40:18.285
Jan 24 20:40:18.295: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-8673 PodName:var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jan 24 20:40:18.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
Jan 24 20:40:18.298: INFO: ExecWithOptions: Clientset creation
Jan 24 20:40:18.299: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/var-expansion-8673/pods/var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 01/24/23 20:40:18.561
Jan 24 20:40:19.110: INFO: Successfully updated pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1"
STEP: waiting for annotated pod running 01/24/23 20:40:19.11
Jan 24 20:40:19.111: INFO: Waiting up to 2m0s for pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" in namespace "var-expansion-8673" to be "running"
Jan 24 20:40:19.126: INFO: Pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1": Phase="Running", Reason="", readiness=true. Elapsed: 15.152716ms
Jan 24 20:40:19.126: INFO: Pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" satisfied condition "running"
STEP: deleting the pod gracefully 01/24/23 20:40:19.126
Jan 24 20:40:19.126: INFO: Deleting pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" in namespace "var-expansion-8673"
Jan 24 20:40:19.145: INFO: Wait up to 5m0s for pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Jan 24 20:40:53.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8673" for this suite. 01/24/23 20:40:53.196
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":355,"skipped":6570,"failed":0}
------------------------------
• [SLOW TEST] [37.261 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:40:15.967
    Jan 24 20:40:15.968: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename var-expansion 01/24/23 20:40:15.969
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:40:15.993
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:40:16.001
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 01/24/23 20:40:16.006
    STEP: waiting for pod running 01/24/23 20:40:16.024
    Jan 24 20:40:16.024: INFO: Waiting up to 2m0s for pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" in namespace "var-expansion-8673" to be "running"
    Jan 24 20:40:16.028: INFO: Pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.628019ms
    Jan 24 20:40:18.065: INFO: Pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.04152103s
    Jan 24 20:40:18.065: INFO: Pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" satisfied condition "running"
    STEP: creating a file in subpath 01/24/23 20:40:18.065
    Jan 24 20:40:18.078: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-8673 PodName:var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 20:40:18.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 20:40:18.080: INFO: ExecWithOptions: Clientset creation
    Jan 24 20:40:18.080: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/var-expansion-8673/pods/var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 01/24/23 20:40:18.285
    Jan 24 20:40:18.295: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-8673 PodName:var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Jan 24 20:40:18.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    Jan 24 20:40:18.298: INFO: ExecWithOptions: Clientset creation
    Jan 24 20:40:18.299: INFO: ExecWithOptions: execute(POST https://10.10.0.1:443/api/v1/namespaces/var-expansion-8673/pods/var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 01/24/23 20:40:18.561
    Jan 24 20:40:19.110: INFO: Successfully updated pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1"
    STEP: waiting for annotated pod running 01/24/23 20:40:19.11
    Jan 24 20:40:19.111: INFO: Waiting up to 2m0s for pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" in namespace "var-expansion-8673" to be "running"
    Jan 24 20:40:19.126: INFO: Pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1": Phase="Running", Reason="", readiness=true. Elapsed: 15.152716ms
    Jan 24 20:40:19.126: INFO: Pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" satisfied condition "running"
    STEP: deleting the pod gracefully 01/24/23 20:40:19.126
    Jan 24 20:40:19.126: INFO: Deleting pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" in namespace "var-expansion-8673"
    Jan 24 20:40:19.145: INFO: Wait up to 5m0s for pod "var-expansion-bedd1303-d5f2-4303-ae6a-be47a45079b1" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Jan 24 20:40:53.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8673" for this suite. 01/24/23 20:40:53.196
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:40:53.244
Jan 24 20:40:53.246: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename emptydir 01/24/23 20:40:53.259
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:40:53.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:40:53.331
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 01/24/23 20:40:53.394
Jan 24 20:40:53.424: INFO: Waiting up to 5m0s for pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7" in namespace "emptydir-8287" to be "Succeeded or Failed"
Jan 24 20:40:53.462: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7": Phase="Pending", Reason="", readiness=false. Elapsed: 21.862631ms
Jan 24 20:40:55.485: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045273721s
Jan 24 20:40:57.472: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032460058s
Jan 24 20:40:59.538: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.098716547s
Jan 24 20:41:01.584: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.144538495s
STEP: Saw pod success 01/24/23 20:41:01.615
Jan 24 20:41:01.629: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7" satisfied condition "Succeeded or Failed"
Jan 24 20:41:01.655: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-f4373191-6ffa-4d62-9866-95f57f8c62c7 container test-container: <nil>
STEP: delete the pod 01/24/23 20:41:01.682
Jan 24 20:41:01.747: INFO: Waiting for pod pod-f4373191-6ffa-4d62-9866-95f57f8c62c7 to disappear
Jan 24 20:41:01.771: INFO: Pod pod-f4373191-6ffa-4d62-9866-95f57f8c62c7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Jan 24 20:41:01.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8287" for this suite. 01/24/23 20:41:01.81
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":356,"skipped":6598,"failed":0}
------------------------------
• [SLOW TEST] [8.578 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:40:53.244
    Jan 24 20:40:53.246: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename emptydir 01/24/23 20:40:53.259
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:40:53.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:40:53.331
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 01/24/23 20:40:53.394
    Jan 24 20:40:53.424: INFO: Waiting up to 5m0s for pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7" in namespace "emptydir-8287" to be "Succeeded or Failed"
    Jan 24 20:40:53.462: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7": Phase="Pending", Reason="", readiness=false. Elapsed: 21.862631ms
    Jan 24 20:40:55.485: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045273721s
    Jan 24 20:40:57.472: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032460058s
    Jan 24 20:40:59.538: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.098716547s
    Jan 24 20:41:01.584: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.144538495s
    STEP: Saw pod success 01/24/23 20:41:01.615
    Jan 24 20:41:01.629: INFO: Pod "pod-f4373191-6ffa-4d62-9866-95f57f8c62c7" satisfied condition "Succeeded or Failed"
    Jan 24 20:41:01.655: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-f4373191-6ffa-4d62-9866-95f57f8c62c7 container test-container: <nil>
    STEP: delete the pod 01/24/23 20:41:01.682
    Jan 24 20:41:01.747: INFO: Waiting for pod pod-f4373191-6ffa-4d62-9866-95f57f8c62c7 to disappear
    Jan 24 20:41:01.771: INFO: Pod pod-f4373191-6ffa-4d62-9866-95f57f8c62c7 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Jan 24 20:41:01.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8287" for this suite. 01/24/23 20:41:01.81
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:41:01.837
Jan 24 20:41:01.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename secrets 01/24/23 20:41:01.839
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:01.871
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:01.878
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-11749b77-7126-447e-bcfe-2fd7341577d2 01/24/23 20:41:01.882
STEP: Creating a pod to test consume secrets 01/24/23 20:41:01.892
Jan 24 20:41:01.973: INFO: Waiting up to 5m0s for pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582" in namespace "secrets-5222" to be "Succeeded or Failed"
Jan 24 20:41:01.994: INFO: Pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582": Phase="Pending", Reason="", readiness=false. Elapsed: 20.474253ms
Jan 24 20:41:04.000: INFO: Pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026450737s
Jan 24 20:41:06.002: INFO: Pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02880028s
Jan 24 20:41:08.006: INFO: Pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032300665s
STEP: Saw pod success 01/24/23 20:41:08.006
Jan 24 20:41:08.006: INFO: Pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582" satisfied condition "Succeeded or Failed"
Jan 24 20:41:08.016: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582 container secret-env-test: <nil>
STEP: delete the pod 01/24/23 20:41:08.03
Jan 24 20:41:08.050: INFO: Waiting for pod pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582 to disappear
Jan 24 20:41:08.056: INFO: Pod pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Jan 24 20:41:08.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5222" for this suite. 01/24/23 20:41:08.061
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":357,"skipped":6607,"failed":0}
------------------------------
• [SLOW TEST] [6.241 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:41:01.837
    Jan 24 20:41:01.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename secrets 01/24/23 20:41:01.839
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:01.871
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:01.878
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-11749b77-7126-447e-bcfe-2fd7341577d2 01/24/23 20:41:01.882
    STEP: Creating a pod to test consume secrets 01/24/23 20:41:01.892
    Jan 24 20:41:01.973: INFO: Waiting up to 5m0s for pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582" in namespace "secrets-5222" to be "Succeeded or Failed"
    Jan 24 20:41:01.994: INFO: Pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582": Phase="Pending", Reason="", readiness=false. Elapsed: 20.474253ms
    Jan 24 20:41:04.000: INFO: Pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026450737s
    Jan 24 20:41:06.002: INFO: Pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02880028s
    Jan 24 20:41:08.006: INFO: Pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.032300665s
    STEP: Saw pod success 01/24/23 20:41:08.006
    Jan 24 20:41:08.006: INFO: Pod "pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582" satisfied condition "Succeeded or Failed"
    Jan 24 20:41:08.016: INFO: Trying to get logs from node vikash-v125latest-conf-71087 pod pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582 container secret-env-test: <nil>
    STEP: delete the pod 01/24/23 20:41:08.03
    Jan 24 20:41:08.050: INFO: Waiting for pod pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582 to disappear
    Jan 24 20:41:08.056: INFO: Pod pod-secrets-b3a4c48a-ea5f-418c-a9af-d10e93010582 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Jan 24 20:41:08.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5222" for this suite. 01/24/23 20:41:08.061
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:41:08.096
Jan 24 20:41:08.096: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename security-context-test 01/24/23 20:41:08.098
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:08.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:08.143
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Jan 24 20:41:08.205: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-6197511d-0a4e-40ec-a2b4-5964cea0a01c" in namespace "security-context-test-8961" to be "Succeeded or Failed"
Jan 24 20:41:08.216: INFO: Pod "busybox-readonly-false-6197511d-0a4e-40ec-a2b4-5964cea0a01c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.911792ms
Jan 24 20:41:10.225: INFO: Pod "busybox-readonly-false-6197511d-0a4e-40ec-a2b4-5964cea0a01c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019287655s
Jan 24 20:41:12.234: INFO: Pod "busybox-readonly-false-6197511d-0a4e-40ec-a2b4-5964cea0a01c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028742156s
Jan 24 20:41:12.239: INFO: Pod "busybox-readonly-false-6197511d-0a4e-40ec-a2b4-5964cea0a01c" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Jan 24 20:41:12.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8961" for this suite. 01/24/23 20:41:12.252
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":358,"skipped":6643,"failed":0}
------------------------------
• [4.186 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:41:08.096
    Jan 24 20:41:08.096: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename security-context-test 01/24/23 20:41:08.098
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:08.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:08.143
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Jan 24 20:41:08.205: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-6197511d-0a4e-40ec-a2b4-5964cea0a01c" in namespace "security-context-test-8961" to be "Succeeded or Failed"
    Jan 24 20:41:08.216: INFO: Pod "busybox-readonly-false-6197511d-0a4e-40ec-a2b4-5964cea0a01c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.911792ms
    Jan 24 20:41:10.225: INFO: Pod "busybox-readonly-false-6197511d-0a4e-40ec-a2b4-5964cea0a01c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019287655s
    Jan 24 20:41:12.234: INFO: Pod "busybox-readonly-false-6197511d-0a4e-40ec-a2b4-5964cea0a01c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028742156s
    Jan 24 20:41:12.239: INFO: Pod "busybox-readonly-false-6197511d-0a4e-40ec-a2b4-5964cea0a01c" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Jan 24 20:41:12.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-8961" for this suite. 01/24/23 20:41:12.252
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:41:12.298
Jan 24 20:41:12.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 20:41:12.303
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:12.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:12.366
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 01/24/23 20:41:12.373
STEP: Creating a ResourceQuota 01/24/23 20:41:17.483
STEP: Ensuring resource quota status is calculated 01/24/23 20:41:17.759
STEP: Creating a ReplicaSet 01/24/23 20:41:19.821
STEP: Ensuring resource quota status captures replicaset creation 01/24/23 20:41:19.89
STEP: Deleting a ReplicaSet 01/24/23 20:41:21.9
STEP: Ensuring resource quota status released usage 01/24/23 20:41:21.918
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 20:41:23.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-197" for this suite. 01/24/23 20:41:23.971
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":359,"skipped":6646,"failed":0}
------------------------------
• [SLOW TEST] [11.697 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:41:12.298
    Jan 24 20:41:12.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 20:41:12.303
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:12.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:12.366
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 01/24/23 20:41:12.373
    STEP: Creating a ResourceQuota 01/24/23 20:41:17.483
    STEP: Ensuring resource quota status is calculated 01/24/23 20:41:17.759
    STEP: Creating a ReplicaSet 01/24/23 20:41:19.821
    STEP: Ensuring resource quota status captures replicaset creation 01/24/23 20:41:19.89
    STEP: Deleting a ReplicaSet 01/24/23 20:41:21.9
    STEP: Ensuring resource quota status released usage 01/24/23 20:41:21.918
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 20:41:23.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-197" for this suite. 01/24/23 20:41:23.971
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:41:23.998
Jan 24 20:41:23.998: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename resourcequota 01/24/23 20:41:24.005
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:24.085
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:24.111
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 01/24/23 20:41:24.152
STEP: Ensuring ResourceQuota status is calculated 01/24/23 20:41:24.189
STEP: Creating a ResourceQuota with not terminating scope 01/24/23 20:41:26.199
STEP: Ensuring ResourceQuota status is calculated 01/24/23 20:41:26.211
STEP: Creating a long running pod 01/24/23 20:41:28.239
STEP: Ensuring resource quota with not terminating scope captures the pod usage 01/24/23 20:41:28.318
STEP: Ensuring resource quota with terminating scope ignored the pod usage 01/24/23 20:41:30.633
STEP: Deleting the pod 01/24/23 20:41:32.672
STEP: Ensuring resource quota status released the pod usage 01/24/23 20:41:32.782
STEP: Creating a terminating pod 01/24/23 20:41:34.803
STEP: Ensuring resource quota with terminating scope captures the pod usage 01/24/23 20:41:34.878
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 01/24/23 20:41:36.959
STEP: Deleting the pod 01/24/23 20:41:39.012
STEP: Ensuring resource quota status released the pod usage 01/24/23 20:41:39.182
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Jan 24 20:41:41.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3881" for this suite. 01/24/23 20:41:41.233
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":360,"skipped":6654,"failed":0}
------------------------------
• [SLOW TEST] [17.267 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:41:23.998
    Jan 24 20:41:23.998: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename resourcequota 01/24/23 20:41:24.005
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:24.085
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:24.111
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 01/24/23 20:41:24.152
    STEP: Ensuring ResourceQuota status is calculated 01/24/23 20:41:24.189
    STEP: Creating a ResourceQuota with not terminating scope 01/24/23 20:41:26.199
    STEP: Ensuring ResourceQuota status is calculated 01/24/23 20:41:26.211
    STEP: Creating a long running pod 01/24/23 20:41:28.239
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 01/24/23 20:41:28.318
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 01/24/23 20:41:30.633
    STEP: Deleting the pod 01/24/23 20:41:32.672
    STEP: Ensuring resource quota status released the pod usage 01/24/23 20:41:32.782
    STEP: Creating a terminating pod 01/24/23 20:41:34.803
    STEP: Ensuring resource quota with terminating scope captures the pod usage 01/24/23 20:41:34.878
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 01/24/23 20:41:36.959
    STEP: Deleting the pod 01/24/23 20:41:39.012
    STEP: Ensuring resource quota status released the pod usage 01/24/23 20:41:39.182
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Jan 24 20:41:41.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3881" for this suite. 01/24/23 20:41:41.233
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:41:41.28
Jan 24 20:41:41.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename webhook 01/24/23 20:41:41.285
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:41.359
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:41.376
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 01/24/23 20:41:41.458
STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 20:41:44.585
STEP: Deploying the webhook pod 01/24/23 20:41:44.629
STEP: Wait for the deployment to be ready 01/24/23 20:41:44.861
Jan 24 20:41:44.972: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jan 24 20:41:47.118: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 41, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 41, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 41, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 41, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 01/24/23 20:41:49.134
STEP: Verifying the service has paired with the endpoint 01/24/23 20:41:49.176
Jan 24 20:41:50.177: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 01/24/23 20:41:50.243
STEP: Creating a custom resource definition that should be denied by the webhook 01/24/23 20:41:50.378
Jan 24 20:41:50.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Jan 24 20:41:50.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7562" for this suite. 01/24/23 20:41:50.536
STEP: Destroying namespace "webhook-7562-markers" for this suite. 01/24/23 20:41:50.575
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":361,"skipped":6661,"failed":0}
------------------------------
• [SLOW TEST] [9.731 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:41:41.28
    Jan 24 20:41:41.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename webhook 01/24/23 20:41:41.285
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:41.359
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:41.376
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 01/24/23 20:41:41.458
    STEP: Create role binding to let webhook read extension-apiserver-authentication 01/24/23 20:41:44.585
    STEP: Deploying the webhook pod 01/24/23 20:41:44.629
    STEP: Wait for the deployment to be ready 01/24/23 20:41:44.861
    Jan 24 20:41:44.972: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Jan 24 20:41:47.118: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.January, 24, 20, 41, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 41, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.January, 24, 20, 41, 45, 0, time.Local), LastTransitionTime:time.Date(2023, time.January, 24, 20, 41, 44, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 01/24/23 20:41:49.134
    STEP: Verifying the service has paired with the endpoint 01/24/23 20:41:49.176
    Jan 24 20:41:50.177: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 01/24/23 20:41:50.243
    STEP: Creating a custom resource definition that should be denied by the webhook 01/24/23 20:41:50.378
    Jan 24 20:41:50.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Jan 24 20:41:50.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7562" for this suite. 01/24/23 20:41:50.536
    STEP: Destroying namespace "webhook-7562-markers" for this suite. 01/24/23 20:41:50.575
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 01/24/23 20:41:51.151
Jan 24 20:41:51.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
STEP: Building a namespace api object, basename replication-controller 01/24/23 20:41:51.184
STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:51.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:51.657
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Jan 24 20:41:51.763: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 01/24/23 20:41:52.92
STEP: Checking rc "condition-test" has the desired failure condition set 01/24/23 20:41:53.029
STEP: Scaling down rc "condition-test" to satisfy pod quota 01/24/23 20:41:54.147
Jan 24 20:41:54.235: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 01/24/23 20:41:54.235
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Jan 24 20:41:54.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8454" for this suite. 01/24/23 20:41:54.522
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":362,"skipped":6684,"failed":0}
------------------------------
• [3.590 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 01/24/23 20:41:51.151
    Jan 24 20:41:51.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2021580216
    STEP: Building a namespace api object, basename replication-controller 01/24/23 20:41:51.184
    STEP: Waiting for a default service account to be provisioned in namespace 01/24/23 20:41:51.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 01/24/23 20:41:51.657
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Jan 24 20:41:51.763: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 01/24/23 20:41:52.92
    STEP: Checking rc "condition-test" has the desired failure condition set 01/24/23 20:41:53.029
    STEP: Scaling down rc "condition-test" to satisfy pod quota 01/24/23 20:41:54.147
    Jan 24 20:41:54.235: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 01/24/23 20:41:54.235
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Jan 24 20:41:54.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-8454" for this suite. 01/24/23 20:41:54.522
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6704,"failed":0}
Jan 24 20:41:54.808: INFO: Running AfterSuite actions on all nodes
Jan 24 20:41:54.808: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Jan 24 20:41:54.808: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Jan 24 20:41:54.808: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Jan 24 20:41:54.808: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Jan 24 20:41:54.808: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Jan 24 20:41:54.809: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Jan 24 20:41:54.809: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Jan 24 20:41:54.809: INFO: Running AfterSuite actions on node 1
Jan 24 20:41:54.809: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.013 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Jan 24 20:41:54.808: INFO: Running AfterSuite actions on all nodes
    Jan 24 20:41:54.808: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Jan 24 20:41:54.808: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Jan 24 20:41:54.808: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Jan 24 20:41:54.808: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Jan 24 20:41:54.808: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Jan 24 20:41:54.809: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Jan 24 20:41:54.809: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Jan 24 20:41:54.809: INFO: Running AfterSuite actions on node 1
    Jan 24 20:41:54.809: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [1.436 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7066 Specs in 7732.876 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6704 Skipped
PASS

Ginkgo ran 1 suite in 2h8m56.93949093s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

