I0418 04:01:25.856677      22 e2e.go:116] Starting e2e run "899f438d-034f-4171-9b0e-85efb09fb82d" on Ginkgo node 1
Apr 18 04:01:25.873: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1681790485 - will randomize all specs

Will run 362 of 7066 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Apr 18 04:01:25.968: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
E0418 04:01:25.969321      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
E0418 04:01:25.969321      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
Apr 18 04:01:25.969: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 18 04:01:26.256: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 18 04:01:26.318: INFO: 24 / 24 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 18 04:01:26.318: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Apr 18 04:01:26.318: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 18 04:01:26.324: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 18 04:01:26.324: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-nfs-node' (0 seconds elapsed)
Apr 18 04:01:26.324: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Apr 18 04:01:26.324: INFO: e2e test version: v1.25.6
Apr 18 04:01:26.325: INFO: kube-apiserver version: v1.25.6
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Apr 18 04:01:26.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:01:26.329: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.362 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Apr 18 04:01:25.968: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    E0418 04:01:25.969321      22 progress.go:80] Failed to post progress update to http://localhost:8099/progress: Post "http://localhost:8099/progress": dial tcp [::1]:8099: connect: connection refused
    Apr 18 04:01:25.969: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Apr 18 04:01:26.256: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Apr 18 04:01:26.318: INFO: 24 / 24 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Apr 18 04:01:26.318: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
    Apr 18 04:01:26.318: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Apr 18 04:01:26.324: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Apr 18 04:01:26.324: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-nfs-node' (0 seconds elapsed)
    Apr 18 04:01:26.324: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
    Apr 18 04:01:26.324: INFO: e2e test version: v1.25.6
    Apr 18 04:01:26.325: INFO: kube-apiserver version: v1.25.6
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Apr 18 04:01:26.325: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:01:26.329: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:01:26.358
Apr 18 04:01:26.358: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename security-context 04/18/23 04:01:26.359
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:01:26.571
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:01:26.574
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/18/23 04:01:26.577
Apr 18 04:01:26.713: INFO: Waiting up to 5m0s for pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad" in namespace "security-context-4464" to be "Succeeded or Failed"
Apr 18 04:01:26.809: INFO: Pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad": Phase="Pending", Reason="", readiness=false. Elapsed: 96.374274ms
Apr 18 04:01:28.813: INFO: Pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100613081s
Apr 18 04:01:30.814: INFO: Pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad": Phase="Pending", Reason="", readiness=false. Elapsed: 4.101278944s
Apr 18 04:01:32.822: INFO: Pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.109049709s
STEP: Saw pod success 04/18/23 04:01:32.822
Apr 18 04:01:32.822: INFO: Pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad" satisfied condition "Succeeded or Failed"
Apr 18 04:01:32.825: INFO: Trying to get logs from node apps-208 pod security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad container test-container: <nil>
STEP: delete the pod 04/18/23 04:01:32.839
Apr 18 04:01:33.010: INFO: Waiting for pod security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad to disappear
Apr 18 04:01:33.012: INFO: Pod security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 04:01:33.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-4464" for this suite. 04/18/23 04:01:33.017
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":1,"skipped":22,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.705 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:01:26.358
    Apr 18 04:01:26.358: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename security-context 04/18/23 04:01:26.359
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:01:26.571
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:01:26.574
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/18/23 04:01:26.577
    Apr 18 04:01:26.713: INFO: Waiting up to 5m0s for pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad" in namespace "security-context-4464" to be "Succeeded or Failed"
    Apr 18 04:01:26.809: INFO: Pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad": Phase="Pending", Reason="", readiness=false. Elapsed: 96.374274ms
    Apr 18 04:01:28.813: INFO: Pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100613081s
    Apr 18 04:01:30.814: INFO: Pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad": Phase="Pending", Reason="", readiness=false. Elapsed: 4.101278944s
    Apr 18 04:01:32.822: INFO: Pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.109049709s
    STEP: Saw pod success 04/18/23 04:01:32.822
    Apr 18 04:01:32.822: INFO: Pod "security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad" satisfied condition "Succeeded or Failed"
    Apr 18 04:01:32.825: INFO: Trying to get logs from node apps-208 pod security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad container test-container: <nil>
    STEP: delete the pod 04/18/23 04:01:32.839
    Apr 18 04:01:33.010: INFO: Waiting for pod security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad to disappear
    Apr 18 04:01:33.012: INFO: Pod security-context-f3e00acb-2921-4e64-88ec-3255a7ee41ad no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 04:01:33.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-4464" for this suite. 04/18/23 04:01:33.017
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:01:33.064
Apr 18 04:01:33.065: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename hostport 04/18/23 04:01:33.066
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:01:33.246
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:01:33.249
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/18/23 04:01:33.264
Apr 18 04:01:33.386: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-917" to be "running and ready"
Apr 18 04:01:33.413: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.874767ms
Apr 18 04:01:33.413: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:01:35.471: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084551213s
Apr 18 04:01:35.471: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:01:37.418: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.032155303s
Apr 18 04:01:37.418: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 18 04:01:37.418: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.2.107 on the node which pod1 resides and expect scheduled 04/18/23 04:01:37.418
Apr 18 04:01:37.462: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-917" to be "running and ready"
Apr 18 04:01:37.465: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.969968ms
Apr 18 04:01:37.465: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:01:39.564: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101736372s
Apr 18 04:01:39.564: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:01:41.468: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.006723564s
Apr 18 04:01:41.469: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 18 04:01:41.469: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.2.107 but use UDP protocol on the node which pod2 resides 04/18/23 04:01:41.469
Apr 18 04:01:41.496: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-917" to be "running and ready"
Apr 18 04:01:41.499: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.204094ms
Apr 18 04:01:41.499: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:01:43.538: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042148017s
Apr 18 04:01:43.538: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:01:45.536: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.040482145s
Apr 18 04:01:45.536: INFO: The phase of Pod pod3 is Running (Ready = true)
Apr 18 04:01:45.536: INFO: Pod "pod3" satisfied condition "running and ready"
Apr 18 04:01:45.644: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-917" to be "running and ready"
Apr 18 04:01:45.646: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.834867ms
Apr 18 04:01:45.646: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:01:47.654: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010689841s
Apr 18 04:01:47.654: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:01:49.651: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 4.007105651s
Apr 18 04:01:49.651: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Apr 18 04:01:49.651: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/18/23 04:01:49.654
Apr 18 04:01:49.654: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.2.107 http://127.0.0.1:54323/hostname] Namespace:hostport-917 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:01:49.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:01:49.655: INFO: ExecWithOptions: Clientset creation
Apr 18 04:01:49.655: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-917/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.2.107+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.2.107, port: 54323 04/18/23 04:01:49.993
Apr 18 04:01:49.993: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.2.107:54323/hostname] Namespace:hostport-917 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:01:49.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:01:49.994: INFO: ExecWithOptions: Clientset creation
Apr 18 04:01:49.994: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-917/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.2.107%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.2.107, port: 54323 UDP 04/18/23 04:01:50.078
Apr 18 04:01:50.078: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.2.107 54323] Namespace:hostport-917 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:01:50.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:01:50.079: INFO: ExecWithOptions: Clientset creation
Apr 18 04:01:50.079: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-917/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.2.107+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Apr 18 04:01:55.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-917" for this suite. 04/18/23 04:01:55.196
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":2,"skipped":34,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.157 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:01:33.064
    Apr 18 04:01:33.065: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename hostport 04/18/23 04:01:33.066
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:01:33.246
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:01:33.249
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/18/23 04:01:33.264
    Apr 18 04:01:33.386: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-917" to be "running and ready"
    Apr 18 04:01:33.413: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.874767ms
    Apr 18 04:01:33.413: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:01:35.471: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084551213s
    Apr 18 04:01:35.471: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:01:37.418: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.032155303s
    Apr 18 04:01:37.418: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 18 04:01:37.418: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.2.107 on the node which pod1 resides and expect scheduled 04/18/23 04:01:37.418
    Apr 18 04:01:37.462: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-917" to be "running and ready"
    Apr 18 04:01:37.465: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.969968ms
    Apr 18 04:01:37.465: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:01:39.564: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101736372s
    Apr 18 04:01:39.564: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:01:41.468: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.006723564s
    Apr 18 04:01:41.469: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 18 04:01:41.469: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.2.107 but use UDP protocol on the node which pod2 resides 04/18/23 04:01:41.469
    Apr 18 04:01:41.496: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-917" to be "running and ready"
    Apr 18 04:01:41.499: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.204094ms
    Apr 18 04:01:41.499: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:01:43.538: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042148017s
    Apr 18 04:01:43.538: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:01:45.536: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.040482145s
    Apr 18 04:01:45.536: INFO: The phase of Pod pod3 is Running (Ready = true)
    Apr 18 04:01:45.536: INFO: Pod "pod3" satisfied condition "running and ready"
    Apr 18 04:01:45.644: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-917" to be "running and ready"
    Apr 18 04:01:45.646: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.834867ms
    Apr 18 04:01:45.646: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:01:47.654: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010689841s
    Apr 18 04:01:47.654: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:01:49.651: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 4.007105651s
    Apr 18 04:01:49.651: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Apr 18 04:01:49.651: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/18/23 04:01:49.654
    Apr 18 04:01:49.654: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.2.107 http://127.0.0.1:54323/hostname] Namespace:hostport-917 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:01:49.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:01:49.655: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:01:49.655: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-917/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.2.107+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.2.107, port: 54323 04/18/23 04:01:49.993
    Apr 18 04:01:49.993: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.2.107:54323/hostname] Namespace:hostport-917 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:01:49.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:01:49.994: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:01:49.994: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-917/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.2.107%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.2.107, port: 54323 UDP 04/18/23 04:01:50.078
    Apr 18 04:01:50.078: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.2.107 54323] Namespace:hostport-917 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:01:50.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:01:50.079: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:01:50.079: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/hostport-917/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.2.107+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Apr 18 04:01:55.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-917" for this suite. 04/18/23 04:01:55.196
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:01:55.224
Apr 18 04:01:55.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 04:01:55.225
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:01:55.406
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:01:55.408
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 04/18/23 04:01:55.488
Apr 18 04:01:55.584: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678" in namespace "downward-api-2736" to be "Succeeded or Failed"
Apr 18 04:01:55.654: INFO: Pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678": Phase="Pending", Reason="", readiness=false. Elapsed: 70.449719ms
Apr 18 04:01:57.659: INFO: Pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075563727s
Apr 18 04:01:59.660: INFO: Pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678": Phase="Running", Reason="", readiness=false. Elapsed: 4.07586383s
Apr 18 04:02:01.660: INFO: Pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.076206121s
STEP: Saw pod success 04/18/23 04:02:01.66
Apr 18 04:02:01.660: INFO: Pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678" satisfied condition "Succeeded or Failed"
Apr 18 04:02:01.706: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678 container client-container: <nil>
STEP: delete the pod 04/18/23 04:02:02.119
Apr 18 04:02:02.297: INFO: Waiting for pod downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678 to disappear
Apr 18 04:02:02.300: INFO: Pod downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 04:02:02.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2736" for this suite. 04/18/23 04:02:02.33
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":3,"skipped":82,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.179 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:01:55.224
    Apr 18 04:01:55.224: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 04:01:55.225
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:01:55.406
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:01:55.408
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 04/18/23 04:01:55.488
    Apr 18 04:01:55.584: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678" in namespace "downward-api-2736" to be "Succeeded or Failed"
    Apr 18 04:01:55.654: INFO: Pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678": Phase="Pending", Reason="", readiness=false. Elapsed: 70.449719ms
    Apr 18 04:01:57.659: INFO: Pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075563727s
    Apr 18 04:01:59.660: INFO: Pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678": Phase="Running", Reason="", readiness=false. Elapsed: 4.07586383s
    Apr 18 04:02:01.660: INFO: Pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.076206121s
    STEP: Saw pod success 04/18/23 04:02:01.66
    Apr 18 04:02:01.660: INFO: Pod "downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678" satisfied condition "Succeeded or Failed"
    Apr 18 04:02:01.706: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678 container client-container: <nil>
    STEP: delete the pod 04/18/23 04:02:02.119
    Apr 18 04:02:02.297: INFO: Waiting for pod downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678 to disappear
    Apr 18 04:02:02.300: INFO: Pod downwardapi-volume-2645069c-6e08-4a9e-af06-6ae6e239f678 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 04:02:02.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2736" for this suite. 04/18/23 04:02:02.33
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:02:02.403
Apr 18 04:02:02.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:02:02.404
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:02.802
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:02.805
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 04/18/23 04:02:02.807
Apr 18 04:02:02.863: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4" in namespace "projected-603" to be "Succeeded or Failed"
Apr 18 04:02:02.866: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.878001ms
Apr 18 04:02:04.927: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064000393s
Apr 18 04:02:06.870: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4": Phase="Running", Reason="", readiness=true. Elapsed: 4.00747074s
Apr 18 04:02:08.870: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4": Phase="Running", Reason="", readiness=false. Elapsed: 6.007603115s
Apr 18 04:02:10.871: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.007819755s
STEP: Saw pod success 04/18/23 04:02:10.871
Apr 18 04:02:10.871: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4" satisfied condition "Succeeded or Failed"
Apr 18 04:02:10.874: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4 container client-container: <nil>
STEP: delete the pod 04/18/23 04:02:10.881
Apr 18 04:02:10.966: INFO: Waiting for pod downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4 to disappear
Apr 18 04:02:10.969: INFO: Pod downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 04:02:10.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-603" for this suite. 04/18/23 04:02:10.974
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":4,"skipped":84,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.633 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:02:02.403
    Apr 18 04:02:02.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:02:02.404
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:02.802
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:02.805
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 04/18/23 04:02:02.807
    Apr 18 04:02:02.863: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4" in namespace "projected-603" to be "Succeeded or Failed"
    Apr 18 04:02:02.866: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.878001ms
    Apr 18 04:02:04.927: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064000393s
    Apr 18 04:02:06.870: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4": Phase="Running", Reason="", readiness=true. Elapsed: 4.00747074s
    Apr 18 04:02:08.870: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4": Phase="Running", Reason="", readiness=false. Elapsed: 6.007603115s
    Apr 18 04:02:10.871: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.007819755s
    STEP: Saw pod success 04/18/23 04:02:10.871
    Apr 18 04:02:10.871: INFO: Pod "downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4" satisfied condition "Succeeded or Failed"
    Apr 18 04:02:10.874: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4 container client-container: <nil>
    STEP: delete the pod 04/18/23 04:02:10.881
    Apr 18 04:02:10.966: INFO: Waiting for pod downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4 to disappear
    Apr 18 04:02:10.969: INFO: Pod downwardapi-volume-e6eaaecd-d577-4999-8744-8b81e5dd35e4 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 04:02:10.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-603" for this suite. 04/18/23 04:02:10.974
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:02:11.037
Apr 18 04:02:11.037: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-webhook 04/18/23 04:02:11.038
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:11.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:11.122
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/18/23 04:02:11.124
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/18/23 04:02:11.987
STEP: Deploying the custom resource conversion webhook pod 04/18/23 04:02:12.015
STEP: Wait for the deployment to be ready 04/18/23 04:02:12.12
Apr 18 04:02:12.303: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Apr 18 04:02:14.405: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 2, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 2, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 2, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 2, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 04:02:16.414
STEP: Verifying the service has paired with the endpoint 04/18/23 04:02:16.547
Apr 18 04:02:17.547: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Apr 18 04:02:17.566: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Creating a v1 custom resource 04/18/23 04:02:25.298
STEP: Create a v2 custom resource 04/18/23 04:02:25.381
STEP: List CRs in v1 04/18/23 04:02:25.4
STEP: List CRs in v2 04/18/23 04:02:25.461
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:02:26.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6368" for this suite. 04/18/23 04:02:26.016
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":5,"skipped":94,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.364 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:02:11.037
    Apr 18 04:02:11.037: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-webhook 04/18/23 04:02:11.038
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:11.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:11.122
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/18/23 04:02:11.124
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/18/23 04:02:11.987
    STEP: Deploying the custom resource conversion webhook pod 04/18/23 04:02:12.015
    STEP: Wait for the deployment to be ready 04/18/23 04:02:12.12
    Apr 18 04:02:12.303: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
    Apr 18 04:02:14.405: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 2, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 2, 12, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 2, 12, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 2, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 04:02:16.414
    STEP: Verifying the service has paired with the endpoint 04/18/23 04:02:16.547
    Apr 18 04:02:17.547: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Apr 18 04:02:17.566: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Creating a v1 custom resource 04/18/23 04:02:25.298
    STEP: Create a v2 custom resource 04/18/23 04:02:25.381
    STEP: List CRs in v1 04/18/23 04:02:25.4
    STEP: List CRs in v2 04/18/23 04:02:25.461
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:02:26.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-6368" for this suite. 04/18/23 04:02:26.016
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:02:26.402
Apr 18 04:02:26.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename controllerrevisions 04/18/23 04:02:26.404
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:26.525
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:26.528
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-5nx5d-daemon-set" 04/18/23 04:02:27
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 04:02:27.088
Apr 18 04:02:27.223: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 0
Apr 18 04:02:27.223: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:02:28.232: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 0
Apr 18 04:02:28.232: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:02:29.268: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 0
Apr 18 04:02:29.269: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:02:30.574: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 2
Apr 18 04:02:30.574: INFO: Node apps-209 is running 0 daemon pod, expected 1
Apr 18 04:02:31.377: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 3
Apr 18 04:02:31.377: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-5nx5d-daemon-set
STEP: Confirm DaemonSet "e2e-5nx5d-daemon-set" successfully created with "daemonset-name=e2e-5nx5d-daemon-set" label 04/18/23 04:02:31.38
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-5nx5d-daemon-set" 04/18/23 04:02:31.386
Apr 18 04:02:31.391: INFO: Located ControllerRevision: "e2e-5nx5d-daemon-set-5845695899"
STEP: Patching ControllerRevision "e2e-5nx5d-daemon-set-5845695899" 04/18/23 04:02:31.393
Apr 18 04:02:31.425: INFO: e2e-5nx5d-daemon-set-5845695899 has been patched
STEP: Create a new ControllerRevision 04/18/23 04:02:31.425
Apr 18 04:02:31.508: INFO: Created ControllerRevision: e2e-5nx5d-daemon-set-67c7d4dc87
STEP: Confirm that there are two ControllerRevisions 04/18/23 04:02:31.508
Apr 18 04:02:31.508: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 18 04:02:31.512: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-5nx5d-daemon-set-5845695899" 04/18/23 04:02:31.512
STEP: Confirm that there is only one ControllerRevision 04/18/23 04:02:31.527
Apr 18 04:02:31.527: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 18 04:02:31.542: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-5nx5d-daemon-set-67c7d4dc87" 04/18/23 04:02:31.545
Apr 18 04:02:31.567: INFO: e2e-5nx5d-daemon-set-67c7d4dc87 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 04/18/23 04:02:31.567
W0418 04:02:31.653431      22 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 04/18/23 04:02:31.653
Apr 18 04:02:31.653: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 18 04:02:32.657: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 18 04:02:32.702: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-5nx5d-daemon-set-67c7d4dc87=updated" 04/18/23 04:02:32.702
STEP: Confirm that there is only one ControllerRevision 04/18/23 04:02:32.722
Apr 18 04:02:32.722: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 18 04:02:32.734: INFO: Found 1 ControllerRevisions
Apr 18 04:02:32.768: INFO: ControllerRevision "e2e-5nx5d-daemon-set-d6bb88cc8" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-5nx5d-daemon-set" 04/18/23 04:02:32.793
STEP: deleting DaemonSet.extensions e2e-5nx5d-daemon-set in namespace controllerrevisions-30, will wait for the garbage collector to delete the pods 04/18/23 04:02:32.793
Apr 18 04:02:32.877: INFO: Deleting DaemonSet.extensions e2e-5nx5d-daemon-set took: 30.483164ms
Apr 18 04:02:33.077: INFO: Terminating DaemonSet.extensions e2e-5nx5d-daemon-set pods took: 200.273322ms
Apr 18 04:02:35.809: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 0
Apr 18 04:02:35.809: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-5nx5d-daemon-set
Apr 18 04:02:35.814: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4078722"},"items":null}

Apr 18 04:02:35.816: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4078722"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Apr 18 04:02:35.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-30" for this suite. 04/18/23 04:02:35.834
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":6,"skipped":105,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.489 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:02:26.402
    Apr 18 04:02:26.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename controllerrevisions 04/18/23 04:02:26.404
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:26.525
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:26.528
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-5nx5d-daemon-set" 04/18/23 04:02:27
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 04:02:27.088
    Apr 18 04:02:27.223: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 0
    Apr 18 04:02:27.223: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:02:28.232: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 0
    Apr 18 04:02:28.232: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:02:29.268: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 0
    Apr 18 04:02:29.269: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:02:30.574: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 2
    Apr 18 04:02:30.574: INFO: Node apps-209 is running 0 daemon pod, expected 1
    Apr 18 04:02:31.377: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 3
    Apr 18 04:02:31.377: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-5nx5d-daemon-set
    STEP: Confirm DaemonSet "e2e-5nx5d-daemon-set" successfully created with "daemonset-name=e2e-5nx5d-daemon-set" label 04/18/23 04:02:31.38
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-5nx5d-daemon-set" 04/18/23 04:02:31.386
    Apr 18 04:02:31.391: INFO: Located ControllerRevision: "e2e-5nx5d-daemon-set-5845695899"
    STEP: Patching ControllerRevision "e2e-5nx5d-daemon-set-5845695899" 04/18/23 04:02:31.393
    Apr 18 04:02:31.425: INFO: e2e-5nx5d-daemon-set-5845695899 has been patched
    STEP: Create a new ControllerRevision 04/18/23 04:02:31.425
    Apr 18 04:02:31.508: INFO: Created ControllerRevision: e2e-5nx5d-daemon-set-67c7d4dc87
    STEP: Confirm that there are two ControllerRevisions 04/18/23 04:02:31.508
    Apr 18 04:02:31.508: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 18 04:02:31.512: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-5nx5d-daemon-set-5845695899" 04/18/23 04:02:31.512
    STEP: Confirm that there is only one ControllerRevision 04/18/23 04:02:31.527
    Apr 18 04:02:31.527: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 18 04:02:31.542: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-5nx5d-daemon-set-67c7d4dc87" 04/18/23 04:02:31.545
    Apr 18 04:02:31.567: INFO: e2e-5nx5d-daemon-set-67c7d4dc87 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 04/18/23 04:02:31.567
    W0418 04:02:31.653431      22 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 04/18/23 04:02:31.653
    Apr 18 04:02:31.653: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 18 04:02:32.657: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 18 04:02:32.702: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-5nx5d-daemon-set-67c7d4dc87=updated" 04/18/23 04:02:32.702
    STEP: Confirm that there is only one ControllerRevision 04/18/23 04:02:32.722
    Apr 18 04:02:32.722: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 18 04:02:32.734: INFO: Found 1 ControllerRevisions
    Apr 18 04:02:32.768: INFO: ControllerRevision "e2e-5nx5d-daemon-set-d6bb88cc8" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-5nx5d-daemon-set" 04/18/23 04:02:32.793
    STEP: deleting DaemonSet.extensions e2e-5nx5d-daemon-set in namespace controllerrevisions-30, will wait for the garbage collector to delete the pods 04/18/23 04:02:32.793
    Apr 18 04:02:32.877: INFO: Deleting DaemonSet.extensions e2e-5nx5d-daemon-set took: 30.483164ms
    Apr 18 04:02:33.077: INFO: Terminating DaemonSet.extensions e2e-5nx5d-daemon-set pods took: 200.273322ms
    Apr 18 04:02:35.809: INFO: Number of nodes with available pods controlled by daemonset e2e-5nx5d-daemon-set: 0
    Apr 18 04:02:35.809: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-5nx5d-daemon-set
    Apr 18 04:02:35.814: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4078722"},"items":null}

    Apr 18 04:02:35.816: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4078722"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 04:02:35.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-30" for this suite. 04/18/23 04:02:35.834
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:02:35.893
Apr 18 04:02:35.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:02:35.894
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:35.933
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:35.935
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-7552cdb6-1834-4f5f-b5ea-0f8a0fd03877 04/18/23 04:02:35.938
STEP: Creating a pod to test consume configMaps 04/18/23 04:02:36.003
Apr 18 04:02:36.067: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338" in namespace "projected-3695" to be "Succeeded or Failed"
Apr 18 04:02:36.079: INFO: Pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338": Phase="Pending", Reason="", readiness=false. Elapsed: 11.74436ms
Apr 18 04:02:38.119: INFO: Pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05242534s
Apr 18 04:02:40.110: INFO: Pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338": Phase="Running", Reason="", readiness=false. Elapsed: 4.042951055s
Apr 18 04:02:42.083: INFO: Pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015982223s
STEP: Saw pod success 04/18/23 04:02:42.083
Apr 18 04:02:42.083: INFO: Pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338" satisfied condition "Succeeded or Failed"
Apr 18 04:02:42.111: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338 container projected-configmap-volume-test: <nil>
STEP: delete the pod 04/18/23 04:02:42.117
Apr 18 04:02:42.221: INFO: Waiting for pod pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338 to disappear
Apr 18 04:02:42.244: INFO: Pod pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 04:02:42.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3695" for this suite. 04/18/23 04:02:42.25
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":7,"skipped":126,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.386 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:02:35.893
    Apr 18 04:02:35.893: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:02:35.894
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:35.933
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:35.935
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-7552cdb6-1834-4f5f-b5ea-0f8a0fd03877 04/18/23 04:02:35.938
    STEP: Creating a pod to test consume configMaps 04/18/23 04:02:36.003
    Apr 18 04:02:36.067: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338" in namespace "projected-3695" to be "Succeeded or Failed"
    Apr 18 04:02:36.079: INFO: Pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338": Phase="Pending", Reason="", readiness=false. Elapsed: 11.74436ms
    Apr 18 04:02:38.119: INFO: Pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05242534s
    Apr 18 04:02:40.110: INFO: Pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338": Phase="Running", Reason="", readiness=false. Elapsed: 4.042951055s
    Apr 18 04:02:42.083: INFO: Pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015982223s
    STEP: Saw pod success 04/18/23 04:02:42.083
    Apr 18 04:02:42.083: INFO: Pod "pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338" satisfied condition "Succeeded or Failed"
    Apr 18 04:02:42.111: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 04/18/23 04:02:42.117
    Apr 18 04:02:42.221: INFO: Waiting for pod pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338 to disappear
    Apr 18 04:02:42.244: INFO: Pod pod-projected-configmaps-062affa0-20b7-471e-9557-1f68d340c338 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 04:02:42.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3695" for this suite. 04/18/23 04:02:42.25
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:02:42.282
Apr 18 04:02:42.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 04:02:42.283
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:42.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:42.348
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 04/18/23 04:02:42.35
Apr 18 04:02:42.469: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8" in namespace "emptydir-3888" to be "running"
Apr 18 04:02:42.486: INFO: Pod "pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.923505ms
Apr 18 04:02:44.490: INFO: Pod "pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021544394s
Apr 18 04:02:46.490: INFO: Pod "pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8": Phase="Running", Reason="", readiness=true. Elapsed: 4.02139059s
Apr 18 04:02:46.490: INFO: Pod "pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8" satisfied condition "running"
STEP: Reading file content from the nginx-container 04/18/23 04:02:46.49
Apr 18 04:02:46.490: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3888 PodName:pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:02:46.490: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:02:46.491: INFO: ExecWithOptions: Clientset creation
Apr 18 04:02:46.491: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-3888/pods/pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Apr 18 04:02:46.571: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 04:02:46.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3888" for this suite. 04/18/23 04:02:46.576
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":8,"skipped":212,"failed":0}
------------------------------
â€¢ [4.330 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:02:42.282
    Apr 18 04:02:42.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 04:02:42.283
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:42.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:42.348
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 04/18/23 04:02:42.35
    Apr 18 04:02:42.469: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8" in namespace "emptydir-3888" to be "running"
    Apr 18 04:02:42.486: INFO: Pod "pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.923505ms
    Apr 18 04:02:44.490: INFO: Pod "pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021544394s
    Apr 18 04:02:46.490: INFO: Pod "pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8": Phase="Running", Reason="", readiness=true. Elapsed: 4.02139059s
    Apr 18 04:02:46.490: INFO: Pod "pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8" satisfied condition "running"
    STEP: Reading file content from the nginx-container 04/18/23 04:02:46.49
    Apr 18 04:02:46.490: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3888 PodName:pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:02:46.490: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:02:46.491: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:02:46.491: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/emptydir-3888/pods/pod-sharedvolume-dd1ee540-4931-45ef-8601-8f6ea0b8c8c8/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Apr 18 04:02:46.571: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 04:02:46.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3888" for this suite. 04/18/23 04:02:46.576
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:02:46.614
Apr 18 04:02:46.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 04:02:46.615
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:46.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:46.77
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Apr 18 04:02:46.836: INFO: Waiting up to 5m0s for pod "server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0" in namespace "pods-4642" to be "running and ready"
Apr 18 04:02:46.839: INFO: Pod "server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.981177ms
Apr 18 04:02:46.839: INFO: The phase of Pod server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:02:48.842: INFO: Pod "server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006058781s
Apr 18 04:02:48.842: INFO: The phase of Pod server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:02:50.844: INFO: Pod "server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0": Phase="Running", Reason="", readiness=true. Elapsed: 4.007970893s
Apr 18 04:02:50.844: INFO: The phase of Pod server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0 is Running (Ready = true)
Apr 18 04:02:50.844: INFO: Pod "server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0" satisfied condition "running and ready"
Apr 18 04:02:50.994: INFO: Waiting up to 5m0s for pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f" in namespace "pods-4642" to be "Succeeded or Failed"
Apr 18 04:02:51.148: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f": Phase="Pending", Reason="", readiness=false. Elapsed: 154.244991ms
Apr 18 04:02:53.205: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.21161144s
Apr 18 04:02:55.162: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f": Phase="Running", Reason="", readiness=false. Elapsed: 4.168313404s
Apr 18 04:02:57.178: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f": Phase="Running", Reason="", readiness=false. Elapsed: 6.184454074s
Apr 18 04:02:59.153: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.159095593s
STEP: Saw pod success 04/18/23 04:02:59.153
Apr 18 04:02:59.153: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f" satisfied condition "Succeeded or Failed"
Apr 18 04:02:59.156: INFO: Trying to get logs from node apps-208 pod client-envvars-9a196a40-29ad-483b-9142-743585b9921f container env3cont: <nil>
STEP: delete the pod 04/18/23 04:02:59.163
Apr 18 04:02:59.268: INFO: Waiting for pod client-envvars-9a196a40-29ad-483b-9142-743585b9921f to disappear
Apr 18 04:02:59.310: INFO: Pod client-envvars-9a196a40-29ad-483b-9142-743585b9921f no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 04:02:59.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4642" for this suite. 04/18/23 04:02:59.315
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":9,"skipped":240,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.726 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:02:46.614
    Apr 18 04:02:46.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 04:02:46.615
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:46.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:46.77
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Apr 18 04:02:46.836: INFO: Waiting up to 5m0s for pod "server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0" in namespace "pods-4642" to be "running and ready"
    Apr 18 04:02:46.839: INFO: Pod "server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.981177ms
    Apr 18 04:02:46.839: INFO: The phase of Pod server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:02:48.842: INFO: Pod "server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006058781s
    Apr 18 04:02:48.842: INFO: The phase of Pod server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:02:50.844: INFO: Pod "server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0": Phase="Running", Reason="", readiness=true. Elapsed: 4.007970893s
    Apr 18 04:02:50.844: INFO: The phase of Pod server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0 is Running (Ready = true)
    Apr 18 04:02:50.844: INFO: Pod "server-envvars-d496f62f-81f4-418c-9541-d6513c79b7e0" satisfied condition "running and ready"
    Apr 18 04:02:50.994: INFO: Waiting up to 5m0s for pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f" in namespace "pods-4642" to be "Succeeded or Failed"
    Apr 18 04:02:51.148: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f": Phase="Pending", Reason="", readiness=false. Elapsed: 154.244991ms
    Apr 18 04:02:53.205: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.21161144s
    Apr 18 04:02:55.162: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f": Phase="Running", Reason="", readiness=false. Elapsed: 4.168313404s
    Apr 18 04:02:57.178: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f": Phase="Running", Reason="", readiness=false. Elapsed: 6.184454074s
    Apr 18 04:02:59.153: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.159095593s
    STEP: Saw pod success 04/18/23 04:02:59.153
    Apr 18 04:02:59.153: INFO: Pod "client-envvars-9a196a40-29ad-483b-9142-743585b9921f" satisfied condition "Succeeded or Failed"
    Apr 18 04:02:59.156: INFO: Trying to get logs from node apps-208 pod client-envvars-9a196a40-29ad-483b-9142-743585b9921f container env3cont: <nil>
    STEP: delete the pod 04/18/23 04:02:59.163
    Apr 18 04:02:59.268: INFO: Waiting for pod client-envvars-9a196a40-29ad-483b-9142-743585b9921f to disappear
    Apr 18 04:02:59.310: INFO: Pod client-envvars-9a196a40-29ad-483b-9142-743585b9921f no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 04:02:59.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4642" for this suite. 04/18/23 04:02:59.315
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:02:59.341
Apr 18 04:02:59.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename var-expansion 04/18/23 04:02:59.342
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:59.385
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:59.387
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 04/18/23 04:02:59.39
Apr 18 04:02:59.511: INFO: Waiting up to 5m0s for pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069" in namespace "var-expansion-4681" to be "Succeeded or Failed"
Apr 18 04:02:59.514: INFO: Pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069": Phase="Pending", Reason="", readiness=false. Elapsed: 2.907823ms
Apr 18 04:03:01.560: INFO: Pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04919242s
Apr 18 04:03:03.518: INFO: Pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007234466s
Apr 18 04:03:05.518: INFO: Pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006965343s
STEP: Saw pod success 04/18/23 04:03:05.518
Apr 18 04:03:05.518: INFO: Pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069" satisfied condition "Succeeded or Failed"
Apr 18 04:03:05.521: INFO: Trying to get logs from node apps-208 pod var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069 container dapi-container: <nil>
STEP: delete the pod 04/18/23 04:03:05.527
Apr 18 04:03:05.573: INFO: Waiting for pod var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069 to disappear
Apr 18 04:03:05.634: INFO: Pod var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 04:03:05.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4681" for this suite. 04/18/23 04:03:05.638
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":10,"skipped":257,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.333 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:02:59.341
    Apr 18 04:02:59.341: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename var-expansion 04/18/23 04:02:59.342
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:02:59.385
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:02:59.387
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 04/18/23 04:02:59.39
    Apr 18 04:02:59.511: INFO: Waiting up to 5m0s for pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069" in namespace "var-expansion-4681" to be "Succeeded or Failed"
    Apr 18 04:02:59.514: INFO: Pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069": Phase="Pending", Reason="", readiness=false. Elapsed: 2.907823ms
    Apr 18 04:03:01.560: INFO: Pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04919242s
    Apr 18 04:03:03.518: INFO: Pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007234466s
    Apr 18 04:03:05.518: INFO: Pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006965343s
    STEP: Saw pod success 04/18/23 04:03:05.518
    Apr 18 04:03:05.518: INFO: Pod "var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069" satisfied condition "Succeeded or Failed"
    Apr 18 04:03:05.521: INFO: Trying to get logs from node apps-208 pod var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 04:03:05.527
    Apr 18 04:03:05.573: INFO: Waiting for pod var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069 to disappear
    Apr 18 04:03:05.634: INFO: Pod var-expansion-9a1a898e-e3e2-4fa7-aa57-ef43201fd069 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 04:03:05.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4681" for this suite. 04/18/23 04:03:05.638
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:03:05.674
Apr 18 04:03:05.674: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename dns 04/18/23 04:03:05.675
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:03:05.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:03:05.722
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 04/18/23 04:03:05.724
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
 04/18/23 04:03:05.739
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
 04/18/23 04:03:05.74
STEP: creating a pod to probe DNS 04/18/23 04:03:05.74
STEP: submitting the pod to kubernetes 04/18/23 04:03:05.74
Apr 18 04:03:05.845: INFO: Waiting up to 15m0s for pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4" in namespace "dns-662" to be "running"
Apr 18 04:03:05.848: INFO: Pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.483292ms
Apr 18 04:03:07.851: INFO: Pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006032385s
Apr 18 04:03:09.925: INFO: Pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.079626308s
Apr 18 04:03:11.851: INFO: Pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4": Phase="Running", Reason="", readiness=true. Elapsed: 6.006163351s
Apr 18 04:03:11.851: INFO: Pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4" satisfied condition "running"
STEP: retrieving the pod 04/18/23 04:03:11.851
STEP: looking for the results for each expected name from probers 04/18/23 04:03:11.866
Apr 18 04:03:11.874: INFO: DNS probes using dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4 succeeded

STEP: deleting the pod 04/18/23 04:03:11.874
STEP: changing the externalName to bar.example.com 04/18/23 04:03:11.941
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
 04/18/23 04:03:12.035
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
 04/18/23 04:03:12.035
STEP: creating a second pod to probe DNS 04/18/23 04:03:12.035
STEP: submitting the pod to kubernetes 04/18/23 04:03:12.035
Apr 18 04:03:12.107: INFO: Waiting up to 15m0s for pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7" in namespace "dns-662" to be "running"
Apr 18 04:03:12.124: INFO: Pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.991459ms
Apr 18 04:03:14.129: INFO: Pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021889984s
Apr 18 04:03:16.202: INFO: Pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.095074568s
Apr 18 04:03:18.129: INFO: Pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7": Phase="Running", Reason="", readiness=true. Elapsed: 6.022248263s
Apr 18 04:03:18.129: INFO: Pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7" satisfied condition "running"
STEP: retrieving the pod 04/18/23 04:03:18.129
STEP: looking for the results for each expected name from probers 04/18/23 04:03:18.133
Apr 18 04:03:18.137: INFO: File wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 04:03:18.141: INFO: File jessie_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 04:03:18.141: INFO: Lookups using dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 failed for: [wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local jessie_udp@dns-test-service-3.dns-662.svc.cluster.local]

Apr 18 04:03:23.148: INFO: File wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 04:03:23.151: INFO: File jessie_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 04:03:23.151: INFO: Lookups using dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 failed for: [wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local jessie_udp@dns-test-service-3.dns-662.svc.cluster.local]

Apr 18 04:03:28.146: INFO: File wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 04:03:28.149: INFO: File jessie_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 04:03:28.149: INFO: Lookups using dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 failed for: [wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local jessie_udp@dns-test-service-3.dns-662.svc.cluster.local]

Apr 18 04:03:33.147: INFO: File wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 04:03:33.151: INFO: File jessie_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 04:03:33.151: INFO: Lookups using dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 failed for: [wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local jessie_udp@dns-test-service-3.dns-662.svc.cluster.local]

Apr 18 04:03:38.147: INFO: File wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 04:03:38.151: INFO: File jessie_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 18 04:03:38.151: INFO: Lookups using dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 failed for: [wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local jessie_udp@dns-test-service-3.dns-662.svc.cluster.local]

Apr 18 04:03:43.150: INFO: DNS probes using dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 succeeded

STEP: deleting the pod 04/18/23 04:03:43.15
STEP: changing the service to type=ClusterIP 04/18/23 04:03:43.241
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
 04/18/23 04:03:43.603
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
 04/18/23 04:03:43.603
STEP: creating a third pod to probe DNS 04/18/23 04:03:43.603
STEP: submitting the pod to kubernetes 04/18/23 04:03:43.606
Apr 18 04:03:43.632: INFO: Waiting up to 15m0s for pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6" in namespace "dns-662" to be "running"
Apr 18 04:03:43.667: INFO: Pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6": Phase="Pending", Reason="", readiness=false. Elapsed: 34.552985ms
Apr 18 04:03:45.671: INFO: Pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03912752s
Apr 18 04:03:47.718: INFO: Pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.085237105s
Apr 18 04:03:49.673: INFO: Pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6": Phase="Running", Reason="", readiness=true. Elapsed: 6.040325771s
Apr 18 04:03:49.673: INFO: Pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6" satisfied condition "running"
STEP: retrieving the pod 04/18/23 04:03:49.673
STEP: looking for the results for each expected name from probers 04/18/23 04:03:49.676
Apr 18 04:03:49.684: INFO: DNS probes using dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6 succeeded

STEP: deleting the pod 04/18/23 04:03:49.684
STEP: deleting the test externalName service 04/18/23 04:03:49.745
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 04:03:49.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-662" for this suite. 04/18/23 04:03:49.853
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":11,"skipped":266,"failed":0}
------------------------------
â€¢ [SLOW TEST] [44.221 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:03:05.674
    Apr 18 04:03:05.674: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename dns 04/18/23 04:03:05.675
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:03:05.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:03:05.722
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 04/18/23 04:03:05.724
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
     04/18/23 04:03:05.739
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
     04/18/23 04:03:05.74
    STEP: creating a pod to probe DNS 04/18/23 04:03:05.74
    STEP: submitting the pod to kubernetes 04/18/23 04:03:05.74
    Apr 18 04:03:05.845: INFO: Waiting up to 15m0s for pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4" in namespace "dns-662" to be "running"
    Apr 18 04:03:05.848: INFO: Pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.483292ms
    Apr 18 04:03:07.851: INFO: Pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006032385s
    Apr 18 04:03:09.925: INFO: Pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.079626308s
    Apr 18 04:03:11.851: INFO: Pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4": Phase="Running", Reason="", readiness=true. Elapsed: 6.006163351s
    Apr 18 04:03:11.851: INFO: Pod "dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 04:03:11.851
    STEP: looking for the results for each expected name from probers 04/18/23 04:03:11.866
    Apr 18 04:03:11.874: INFO: DNS probes using dns-test-5751ee6a-b10f-40a7-ad0d-c6f9c02238f4 succeeded

    STEP: deleting the pod 04/18/23 04:03:11.874
    STEP: changing the externalName to bar.example.com 04/18/23 04:03:11.941
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
     04/18/23 04:03:12.035
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
     04/18/23 04:03:12.035
    STEP: creating a second pod to probe DNS 04/18/23 04:03:12.035
    STEP: submitting the pod to kubernetes 04/18/23 04:03:12.035
    Apr 18 04:03:12.107: INFO: Waiting up to 15m0s for pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7" in namespace "dns-662" to be "running"
    Apr 18 04:03:12.124: INFO: Pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.991459ms
    Apr 18 04:03:14.129: INFO: Pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021889984s
    Apr 18 04:03:16.202: INFO: Pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.095074568s
    Apr 18 04:03:18.129: INFO: Pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7": Phase="Running", Reason="", readiness=true. Elapsed: 6.022248263s
    Apr 18 04:03:18.129: INFO: Pod "dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 04:03:18.129
    STEP: looking for the results for each expected name from probers 04/18/23 04:03:18.133
    Apr 18 04:03:18.137: INFO: File wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 04:03:18.141: INFO: File jessie_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 04:03:18.141: INFO: Lookups using dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 failed for: [wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local jessie_udp@dns-test-service-3.dns-662.svc.cluster.local]

    Apr 18 04:03:23.148: INFO: File wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 04:03:23.151: INFO: File jessie_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 04:03:23.151: INFO: Lookups using dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 failed for: [wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local jessie_udp@dns-test-service-3.dns-662.svc.cluster.local]

    Apr 18 04:03:28.146: INFO: File wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 04:03:28.149: INFO: File jessie_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 04:03:28.149: INFO: Lookups using dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 failed for: [wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local jessie_udp@dns-test-service-3.dns-662.svc.cluster.local]

    Apr 18 04:03:33.147: INFO: File wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 04:03:33.151: INFO: File jessie_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 04:03:33.151: INFO: Lookups using dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 failed for: [wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local jessie_udp@dns-test-service-3.dns-662.svc.cluster.local]

    Apr 18 04:03:38.147: INFO: File wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 04:03:38.151: INFO: File jessie_udp@dns-test-service-3.dns-662.svc.cluster.local from pod  dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 18 04:03:38.151: INFO: Lookups using dns-662/dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 failed for: [wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local jessie_udp@dns-test-service-3.dns-662.svc.cluster.local]

    Apr 18 04:03:43.150: INFO: DNS probes using dns-test-5c585b58-6385-47d4-b1ad-80a006cc8ea7 succeeded

    STEP: deleting the pod 04/18/23 04:03:43.15
    STEP: changing the service to type=ClusterIP 04/18/23 04:03:43.241
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
     04/18/23 04:03:43.603
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-662.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-662.svc.cluster.local; sleep 1; done
     04/18/23 04:03:43.603
    STEP: creating a third pod to probe DNS 04/18/23 04:03:43.603
    STEP: submitting the pod to kubernetes 04/18/23 04:03:43.606
    Apr 18 04:03:43.632: INFO: Waiting up to 15m0s for pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6" in namespace "dns-662" to be "running"
    Apr 18 04:03:43.667: INFO: Pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6": Phase="Pending", Reason="", readiness=false. Elapsed: 34.552985ms
    Apr 18 04:03:45.671: INFO: Pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03912752s
    Apr 18 04:03:47.718: INFO: Pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.085237105s
    Apr 18 04:03:49.673: INFO: Pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6": Phase="Running", Reason="", readiness=true. Elapsed: 6.040325771s
    Apr 18 04:03:49.673: INFO: Pod "dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 04:03:49.673
    STEP: looking for the results for each expected name from probers 04/18/23 04:03:49.676
    Apr 18 04:03:49.684: INFO: DNS probes using dns-test-24f5eb54-5f2d-4b6e-ac7c-f1857880f8d6 succeeded

    STEP: deleting the pod 04/18/23 04:03:49.684
    STEP: deleting the test externalName service 04/18/23 04:03:49.745
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 04:03:49.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-662" for this suite. 04/18/23 04:03:49.853
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:03:49.896
Apr 18 04:03:49.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 04:03:49.897
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:03:49.95
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:03:49.963
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 04/18/23 04:03:49.966
STEP: Creating a ResourceQuota 04/18/23 04:03:54.969
STEP: Ensuring resource quota status is calculated 04/18/23 04:03:55.005
STEP: Creating a Pod that fits quota 04/18/23 04:03:57.017
STEP: Ensuring ResourceQuota status captures the pod usage 04/18/23 04:03:57.155
STEP: Not allowing a pod to be created that exceeds remaining quota 04/18/23 04:03:59.159
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/18/23 04:03:59.162
STEP: Ensuring a pod cannot update its resource requirements 04/18/23 04:03:59.164
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/18/23 04:03:59.169
STEP: Deleting the pod 04/18/23 04:04:01.173
STEP: Ensuring resource quota status released the pod usage 04/18/23 04:04:01.317
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 04:04:03.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4553" for this suite. 04/18/23 04:04:03.327
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":12,"skipped":282,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.459 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:03:49.896
    Apr 18 04:03:49.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 04:03:49.897
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:03:49.95
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:03:49.963
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 04/18/23 04:03:49.966
    STEP: Creating a ResourceQuota 04/18/23 04:03:54.969
    STEP: Ensuring resource quota status is calculated 04/18/23 04:03:55.005
    STEP: Creating a Pod that fits quota 04/18/23 04:03:57.017
    STEP: Ensuring ResourceQuota status captures the pod usage 04/18/23 04:03:57.155
    STEP: Not allowing a pod to be created that exceeds remaining quota 04/18/23 04:03:59.159
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/18/23 04:03:59.162
    STEP: Ensuring a pod cannot update its resource requirements 04/18/23 04:03:59.164
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/18/23 04:03:59.169
    STEP: Deleting the pod 04/18/23 04:04:01.173
    STEP: Ensuring resource quota status released the pod usage 04/18/23 04:04:01.317
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 04:04:03.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4553" for this suite. 04/18/23 04:04:03.327
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:04:03.356
Apr 18 04:04:03.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 04:04:03.357
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:04:03.487
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:04:03.49
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Apr 18 04:04:03.507: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:05:06.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5722" for this suite. 04/18/23 04:05:06.375
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":13,"skipped":314,"failed":0}
------------------------------
â€¢ [SLOW TEST] [63.046 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:04:03.356
    Apr 18 04:04:03.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 04:04:03.357
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:04:03.487
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:04:03.49
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Apr 18 04:04:03.507: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:05:06.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-5722" for this suite. 04/18/23 04:05:06.375
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:05:06.402
Apr 18 04:05:06.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 04:05:06.403
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:06.508
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:06.511
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 04/18/23 04:05:06.513
Apr 18 04:05:06.561: INFO: Waiting up to 5m0s for pod "pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0" in namespace "pods-81" to be "running and ready"
Apr 18 04:05:06.657: INFO: Pod "pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0": Phase="Pending", Reason="", readiness=false. Elapsed: 96.252605ms
Apr 18 04:05:06.657: INFO: The phase of Pod pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:05:08.662: INFO: Pod "pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101140827s
Apr 18 04:05:08.662: INFO: The phase of Pod pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:05:10.666: INFO: Pod "pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0": Phase="Running", Reason="", readiness=true. Elapsed: 4.105400307s
Apr 18 04:05:10.666: INFO: The phase of Pod pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0 is Running (Ready = true)
Apr 18 04:05:10.666: INFO: Pod "pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0" satisfied condition "running and ready"
Apr 18 04:05:10.864: INFO: Pod pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0 has hostIP: 192.168.2.108
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 04:05:10.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-81" for this suite. 04/18/23 04:05:10.891
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":14,"skipped":324,"failed":0}
------------------------------
â€¢ [4.508 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:05:06.402
    Apr 18 04:05:06.402: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 04:05:06.403
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:06.508
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:06.511
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 04/18/23 04:05:06.513
    Apr 18 04:05:06.561: INFO: Waiting up to 5m0s for pod "pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0" in namespace "pods-81" to be "running and ready"
    Apr 18 04:05:06.657: INFO: Pod "pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0": Phase="Pending", Reason="", readiness=false. Elapsed: 96.252605ms
    Apr 18 04:05:06.657: INFO: The phase of Pod pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:05:08.662: INFO: Pod "pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101140827s
    Apr 18 04:05:08.662: INFO: The phase of Pod pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:05:10.666: INFO: Pod "pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0": Phase="Running", Reason="", readiness=true. Elapsed: 4.105400307s
    Apr 18 04:05:10.666: INFO: The phase of Pod pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0 is Running (Ready = true)
    Apr 18 04:05:10.666: INFO: Pod "pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0" satisfied condition "running and ready"
    Apr 18 04:05:10.864: INFO: Pod pod-hostip-7ffaaa97-b26b-4136-b63a-496189895ec0 has hostIP: 192.168.2.108
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 04:05:10.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-81" for this suite. 04/18/23 04:05:10.891
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:05:10.911
Apr 18 04:05:10.911: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 04:05:10.912
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:11.064
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:11.067
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-211b987a-573d-4961-a419-2b17009106cb 04/18/23 04:05:11.069
STEP: Creating a pod to test consume configMaps 04/18/23 04:05:11.085
Apr 18 04:05:11.264: INFO: Waiting up to 5m0s for pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08" in namespace "configmap-3253" to be "Succeeded or Failed"
Apr 18 04:05:11.273: INFO: Pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08": Phase="Pending", Reason="", readiness=false. Elapsed: 8.775627ms
Apr 18 04:05:13.356: INFO: Pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091167348s
Apr 18 04:05:15.278: INFO: Pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08": Phase="Running", Reason="", readiness=false. Elapsed: 4.013394621s
Apr 18 04:05:17.279: INFO: Pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014236711s
STEP: Saw pod success 04/18/23 04:05:17.279
Apr 18 04:05:17.279: INFO: Pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08" satisfied condition "Succeeded or Failed"
Apr 18 04:05:17.284: INFO: Trying to get logs from node apps-208 pod pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08 container configmap-volume-test: <nil>
STEP: delete the pod 04/18/23 04:05:17.296
Apr 18 04:05:17.390: INFO: Waiting for pod pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08 to disappear
Apr 18 04:05:17.449: INFO: Pod pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 04:05:17.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3253" for this suite. 04/18/23 04:05:17.454
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":15,"skipped":328,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.568 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:05:10.911
    Apr 18 04:05:10.911: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 04:05:10.912
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:11.064
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:11.067
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-211b987a-573d-4961-a419-2b17009106cb 04/18/23 04:05:11.069
    STEP: Creating a pod to test consume configMaps 04/18/23 04:05:11.085
    Apr 18 04:05:11.264: INFO: Waiting up to 5m0s for pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08" in namespace "configmap-3253" to be "Succeeded or Failed"
    Apr 18 04:05:11.273: INFO: Pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08": Phase="Pending", Reason="", readiness=false. Elapsed: 8.775627ms
    Apr 18 04:05:13.356: INFO: Pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091167348s
    Apr 18 04:05:15.278: INFO: Pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08": Phase="Running", Reason="", readiness=false. Elapsed: 4.013394621s
    Apr 18 04:05:17.279: INFO: Pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014236711s
    STEP: Saw pod success 04/18/23 04:05:17.279
    Apr 18 04:05:17.279: INFO: Pod "pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08" satisfied condition "Succeeded or Failed"
    Apr 18 04:05:17.284: INFO: Trying to get logs from node apps-208 pod pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08 container configmap-volume-test: <nil>
    STEP: delete the pod 04/18/23 04:05:17.296
    Apr 18 04:05:17.390: INFO: Waiting for pod pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08 to disappear
    Apr 18 04:05:17.449: INFO: Pod pod-configmaps-83ab55d8-e8bd-40ea-af3f-adab6ff19a08 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 04:05:17.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3253" for this suite. 04/18/23 04:05:17.454
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:05:17.479
Apr 18 04:05:17.479: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 04:05:17.48
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:17.543
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:17.545
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-1823/configmap-test-97aee4f9-a471-488f-9ab7-704604106fde 04/18/23 04:05:17.548
STEP: Creating a pod to test consume configMaps 04/18/23 04:05:17.72
Apr 18 04:05:17.877: INFO: Waiting up to 5m0s for pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf" in namespace "configmap-1823" to be "Succeeded or Failed"
Apr 18 04:05:17.945: INFO: Pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf": Phase="Pending", Reason="", readiness=false. Elapsed: 67.783177ms
Apr 18 04:05:19.998: INFO: Pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121217303s
Apr 18 04:05:21.953: INFO: Pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075418867s
Apr 18 04:05:23.974: INFO: Pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.096468587s
STEP: Saw pod success 04/18/23 04:05:23.974
Apr 18 04:05:23.974: INFO: Pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf" satisfied condition "Succeeded or Failed"
Apr 18 04:05:23.977: INFO: Trying to get logs from node apps-208 pod pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf container env-test: <nil>
STEP: delete the pod 04/18/23 04:05:23.988
Apr 18 04:05:24.163: INFO: Waiting for pod pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf to disappear
Apr 18 04:05:24.178: INFO: Pod pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 04:05:24.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1823" for this suite. 04/18/23 04:05:24.183
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":16,"skipped":333,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.739 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:05:17.479
    Apr 18 04:05:17.479: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 04:05:17.48
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:17.543
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:17.545
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-1823/configmap-test-97aee4f9-a471-488f-9ab7-704604106fde 04/18/23 04:05:17.548
    STEP: Creating a pod to test consume configMaps 04/18/23 04:05:17.72
    Apr 18 04:05:17.877: INFO: Waiting up to 5m0s for pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf" in namespace "configmap-1823" to be "Succeeded or Failed"
    Apr 18 04:05:17.945: INFO: Pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf": Phase="Pending", Reason="", readiness=false. Elapsed: 67.783177ms
    Apr 18 04:05:19.998: INFO: Pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121217303s
    Apr 18 04:05:21.953: INFO: Pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075418867s
    Apr 18 04:05:23.974: INFO: Pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.096468587s
    STEP: Saw pod success 04/18/23 04:05:23.974
    Apr 18 04:05:23.974: INFO: Pod "pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf" satisfied condition "Succeeded or Failed"
    Apr 18 04:05:23.977: INFO: Trying to get logs from node apps-208 pod pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf container env-test: <nil>
    STEP: delete the pod 04/18/23 04:05:23.988
    Apr 18 04:05:24.163: INFO: Waiting for pod pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf to disappear
    Apr 18 04:05:24.178: INFO: Pod pod-configmaps-e307d1d7-5151-4b0c-a124-e1e3b81f9ebf no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 04:05:24.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1823" for this suite. 04/18/23 04:05:24.183
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:05:24.218
Apr 18 04:05:24.218: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pod-network-test 04/18/23 04:05:24.219
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:24.323
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:24.326
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-2123 04/18/23 04:05:24.328
STEP: creating a selector 04/18/23 04:05:24.328
STEP: Creating the service pods in kubernetes 04/18/23 04:05:24.328
Apr 18 04:05:24.328: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 18 04:05:24.529: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2123" to be "running and ready"
Apr 18 04:05:24.598: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 69.192153ms
Apr 18 04:05:24.598: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:05:26.607: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078135983s
Apr 18 04:05:26.607: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:05:28.675: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.145627087s
Apr 18 04:05:28.675: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:05:30.625: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.095551365s
Apr 18 04:05:30.625: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:05:32.625: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.095844429s
Apr 18 04:05:32.625: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:05:34.614: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.084809625s
Apr 18 04:05:34.614: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:05:36.614: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.08461654s
Apr 18 04:05:36.614: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:05:38.623: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.093677895s
Apr 18 04:05:38.623: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:05:41.062: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.532343776s
Apr 18 04:05:41.062: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:05:42.606: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.076788572s
Apr 18 04:05:42.606: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:05:45.116: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 20.5866768s
Apr 18 04:05:45.116: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 18 04:05:45.116: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 18 04:05:45.119: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2123" to be "running and ready"
Apr 18 04:05:45.160: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 40.918753ms
Apr 18 04:05:45.160: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 18 04:05:45.160: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 18 04:05:45.198: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2123" to be "running and ready"
Apr 18 04:05:45.201: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.73125ms
Apr 18 04:05:45.201: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 18 04:05:45.201: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/18/23 04:05:45.203
Apr 18 04:05:45.256: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2123" to be "running"
Apr 18 04:05:45.264: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.935811ms
Apr 18 04:05:47.268: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012078624s
Apr 18 04:05:49.269: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.012784718s
Apr 18 04:05:49.269: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 18 04:05:49.272: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2123" to be "running"
Apr 18 04:05:49.275: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.129575ms
Apr 18 04:05:49.275: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 18 04:05:49.278: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 18 04:05:49.278: INFO: Going to poll 172.16.100.157 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 18 04:05:49.280: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.100.157 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2123 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:05:49.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:05:49.281: INFO: ExecWithOptions: Clientset creation
Apr 18 04:05:49.281: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2123/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.100.157+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 04:05:50.366: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 18 04:05:50.366: INFO: Going to poll 172.16.125.57 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 18 04:05:50.370: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.125.57 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2123 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:05:50.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:05:50.371: INFO: ExecWithOptions: Clientset creation
Apr 18 04:05:50.371: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2123/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.125.57+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 04:05:51.467: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 18 04:05:51.467: INFO: Going to poll 172.16.144.33 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Apr 18 04:05:51.471: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.144.33 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2123 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:05:51.471: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:05:51.472: INFO: ExecWithOptions: Clientset creation
Apr 18 04:05:51.472: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2123/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.144.33+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 04:05:52.567: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 18 04:05:52.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2123" for this suite. 04/18/23 04:05:52.572
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":17,"skipped":344,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.407 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:05:24.218
    Apr 18 04:05:24.218: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pod-network-test 04/18/23 04:05:24.219
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:24.323
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:24.326
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-2123 04/18/23 04:05:24.328
    STEP: creating a selector 04/18/23 04:05:24.328
    STEP: Creating the service pods in kubernetes 04/18/23 04:05:24.328
    Apr 18 04:05:24.328: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 18 04:05:24.529: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2123" to be "running and ready"
    Apr 18 04:05:24.598: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 69.192153ms
    Apr 18 04:05:24.598: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:05:26.607: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078135983s
    Apr 18 04:05:26.607: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:05:28.675: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.145627087s
    Apr 18 04:05:28.675: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:05:30.625: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.095551365s
    Apr 18 04:05:30.625: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:05:32.625: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.095844429s
    Apr 18 04:05:32.625: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:05:34.614: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.084809625s
    Apr 18 04:05:34.614: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:05:36.614: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.08461654s
    Apr 18 04:05:36.614: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:05:38.623: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.093677895s
    Apr 18 04:05:38.623: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:05:41.062: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.532343776s
    Apr 18 04:05:41.062: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:05:42.606: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.076788572s
    Apr 18 04:05:42.606: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:05:45.116: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 20.5866768s
    Apr 18 04:05:45.116: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 18 04:05:45.116: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 18 04:05:45.119: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2123" to be "running and ready"
    Apr 18 04:05:45.160: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 40.918753ms
    Apr 18 04:05:45.160: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 18 04:05:45.160: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 18 04:05:45.198: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2123" to be "running and ready"
    Apr 18 04:05:45.201: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.73125ms
    Apr 18 04:05:45.201: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 18 04:05:45.201: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/18/23 04:05:45.203
    Apr 18 04:05:45.256: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2123" to be "running"
    Apr 18 04:05:45.264: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.935811ms
    Apr 18 04:05:47.268: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012078624s
    Apr 18 04:05:49.269: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.012784718s
    Apr 18 04:05:49.269: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 18 04:05:49.272: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2123" to be "running"
    Apr 18 04:05:49.275: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.129575ms
    Apr 18 04:05:49.275: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 18 04:05:49.278: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 18 04:05:49.278: INFO: Going to poll 172.16.100.157 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 04:05:49.280: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.100.157 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2123 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:05:49.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:05:49.281: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:05:49.281: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2123/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.100.157+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 04:05:50.366: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 18 04:05:50.366: INFO: Going to poll 172.16.125.57 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 04:05:50.370: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.125.57 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2123 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:05:50.370: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:05:50.371: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:05:50.371: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2123/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.125.57+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 04:05:51.467: INFO: Found all 1 expected endpoints: [netserver-1]
    Apr 18 04:05:51.467: INFO: Going to poll 172.16.144.33 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 04:05:51.471: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.16.144.33 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2123 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:05:51.471: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:05:51.472: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:05:51.472: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-2123/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+172.16.144.33+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 04:05:52.567: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 18 04:05:52.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-2123" for this suite. 04/18/23 04:05:52.572
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:05:52.625
Apr 18 04:05:52.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:05:52.626
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:52.813
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:52.816
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 04/18/23 04:05:52.819
Apr 18 04:05:52.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd" in namespace "projected-1137" to be "Succeeded or Failed"
Apr 18 04:05:52.975: INFO: Pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd": Phase="Pending", Reason="", readiness=false. Elapsed: 45.738151ms
Apr 18 04:05:54.980: INFO: Pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050797597s
Apr 18 04:05:56.980: INFO: Pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050762625s
Apr 18 04:05:58.981: INFO: Pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051871498s
STEP: Saw pod success 04/18/23 04:05:58.981
Apr 18 04:05:58.981: INFO: Pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd" satisfied condition "Succeeded or Failed"
Apr 18 04:05:58.999: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd container client-container: <nil>
STEP: delete the pod 04/18/23 04:05:59.009
Apr 18 04:05:59.124: INFO: Waiting for pod downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd to disappear
Apr 18 04:05:59.150: INFO: Pod downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 04:05:59.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1137" for this suite. 04/18/23 04:05:59.159
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":18,"skipped":346,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.548 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:05:52.625
    Apr 18 04:05:52.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:05:52.626
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:52.813
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:52.816
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 04/18/23 04:05:52.819
    Apr 18 04:05:52.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd" in namespace "projected-1137" to be "Succeeded or Failed"
    Apr 18 04:05:52.975: INFO: Pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd": Phase="Pending", Reason="", readiness=false. Elapsed: 45.738151ms
    Apr 18 04:05:54.980: INFO: Pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050797597s
    Apr 18 04:05:56.980: INFO: Pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050762625s
    Apr 18 04:05:58.981: INFO: Pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.051871498s
    STEP: Saw pod success 04/18/23 04:05:58.981
    Apr 18 04:05:58.981: INFO: Pod "downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd" satisfied condition "Succeeded or Failed"
    Apr 18 04:05:58.999: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd container client-container: <nil>
    STEP: delete the pod 04/18/23 04:05:59.009
    Apr 18 04:05:59.124: INFO: Waiting for pod downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd to disappear
    Apr 18 04:05:59.150: INFO: Pod downwardapi-volume-560ea1f6-a3b6-44f4-a0c3-7a6dec8317dd no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 04:05:59.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1137" for this suite. 04/18/23 04:05:59.159
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:05:59.174
Apr 18 04:05:59.174: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename cronjob 04/18/23 04:05:59.175
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:59.307
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:59.31
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 04/18/23 04:05:59.315
STEP: Ensuring more than one job is running at a time 04/18/23 04:05:59.549
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/18/23 04:07:01.553
STEP: Removing cronjob 04/18/23 04:07:01.655
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 18 04:07:01.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2777" for this suite. 04/18/23 04:07:01.752
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":19,"skipped":350,"failed":0}
------------------------------
â€¢ [SLOW TEST] [62.821 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:05:59.174
    Apr 18 04:05:59.174: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename cronjob 04/18/23 04:05:59.175
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:05:59.307
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:05:59.31
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 04/18/23 04:05:59.315
    STEP: Ensuring more than one job is running at a time 04/18/23 04:05:59.549
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/18/23 04:07:01.553
    STEP: Removing cronjob 04/18/23 04:07:01.655
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 18 04:07:01.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2777" for this suite. 04/18/23 04:07:01.752
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:07:01.996
Apr 18 04:07:01.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replication-controller 04/18/23 04:07:01.997
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:07:02.195
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:07:02.199
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 04/18/23 04:07:02.276
Apr 18 04:07:02.305: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-7903" to be "running and ready"
Apr 18 04:07:02.308: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 3.268467ms
Apr 18 04:07:02.308: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:07:04.338: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033713034s
Apr 18 04:07:04.338: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:07:06.313: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 4.008138057s
Apr 18 04:07:06.313: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Apr 18 04:07:06.313: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 04/18/23 04:07:06.316
STEP: Then the orphan pod is adopted 04/18/23 04:07:06.338
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 18 04:07:07.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7903" for this suite. 04/18/23 04:07:07.361
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":20,"skipped":357,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.393 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:07:01.996
    Apr 18 04:07:01.996: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replication-controller 04/18/23 04:07:01.997
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:07:02.195
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:07:02.199
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 04/18/23 04:07:02.276
    Apr 18 04:07:02.305: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-7903" to be "running and ready"
    Apr 18 04:07:02.308: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 3.268467ms
    Apr 18 04:07:02.308: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:07:04.338: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033713034s
    Apr 18 04:07:04.338: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:07:06.313: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 4.008138057s
    Apr 18 04:07:06.313: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Apr 18 04:07:06.313: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 04/18/23 04:07:06.316
    STEP: Then the orphan pod is adopted 04/18/23 04:07:06.338
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 18 04:07:07.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7903" for this suite. 04/18/23 04:07:07.361
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:07:07.389
Apr 18 04:07:07.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 04:07:07.391
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:07:07.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:07:07.516
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 04/18/23 04:07:07.596
STEP: watching for Pod to be ready 04/18/23 04:07:07.671
Apr 18 04:07:07.672: INFO: observed Pod pod-test in namespace pods-8096 in phase Pending with labels: map[test-pod-static:true] & conditions []
Apr 18 04:07:07.730: INFO: observed Pod pod-test in namespace pods-8096 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  }]
Apr 18 04:07:07.906: INFO: observed Pod pod-test in namespace pods-8096 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  }]
Apr 18 04:07:08.997: INFO: observed Pod pod-test in namespace pods-8096 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  }]
Apr 18 04:07:10.177: INFO: Found Pod pod-test in namespace pods-8096 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 04/18/23 04:07:10.181
STEP: getting the Pod and ensuring that it's patched 04/18/23 04:07:10.274
STEP: replacing the Pod's status Ready condition to False 04/18/23 04:07:10.28
STEP: check the Pod again to ensure its Ready conditions are False 04/18/23 04:07:10.364
STEP: deleting the Pod via a Collection with a LabelSelector 04/18/23 04:07:10.364
STEP: watching for the Pod to be deleted 04/18/23 04:07:10.448
Apr 18 04:07:10.450: INFO: observed event type MODIFIED
Apr 18 04:07:12.186: INFO: observed event type MODIFIED
Apr 18 04:07:12.882: INFO: observed event type MODIFIED
Apr 18 04:07:14.221: INFO: observed event type MODIFIED
Apr 18 04:07:14.280: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 04:07:14.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8096" for this suite. 04/18/23 04:07:14.363
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":21,"skipped":359,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.035 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:07:07.389
    Apr 18 04:07:07.389: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 04:07:07.391
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:07:07.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:07:07.516
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 04/18/23 04:07:07.596
    STEP: watching for Pod to be ready 04/18/23 04:07:07.671
    Apr 18 04:07:07.672: INFO: observed Pod pod-test in namespace pods-8096 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Apr 18 04:07:07.730: INFO: observed Pod pod-test in namespace pods-8096 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  }]
    Apr 18 04:07:07.906: INFO: observed Pod pod-test in namespace pods-8096 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  }]
    Apr 18 04:07:08.997: INFO: observed Pod pod-test in namespace pods-8096 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  }]
    Apr 18 04:07:10.177: INFO: Found Pod pod-test in namespace pods-8096 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:07:07 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 04/18/23 04:07:10.181
    STEP: getting the Pod and ensuring that it's patched 04/18/23 04:07:10.274
    STEP: replacing the Pod's status Ready condition to False 04/18/23 04:07:10.28
    STEP: check the Pod again to ensure its Ready conditions are False 04/18/23 04:07:10.364
    STEP: deleting the Pod via a Collection with a LabelSelector 04/18/23 04:07:10.364
    STEP: watching for the Pod to be deleted 04/18/23 04:07:10.448
    Apr 18 04:07:10.450: INFO: observed event type MODIFIED
    Apr 18 04:07:12.186: INFO: observed event type MODIFIED
    Apr 18 04:07:12.882: INFO: observed event type MODIFIED
    Apr 18 04:07:14.221: INFO: observed event type MODIFIED
    Apr 18 04:07:14.280: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 04:07:14.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8096" for this suite. 04/18/23 04:07:14.363
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:07:14.425
Apr 18 04:07:14.425: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename statefulset 04/18/23 04:07:14.426
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:07:14.481
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:07:14.484
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4857 04/18/23 04:07:14.486
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 04/18/23 04:07:14.548
STEP: Creating stateful set ss in namespace statefulset-4857 04/18/23 04:07:14.551
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4857 04/18/23 04:07:14.582
Apr 18 04:07:14.623: INFO: Found 0 stateful pods, waiting for 1
Apr 18 04:07:24.671: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/18/23 04:07:24.671
Apr 18 04:07:24.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 04:07:24.890: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 04:07:24.890: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 04:07:24.890: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 04:07:24.912: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 18 04:07:34.920: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 04:07:34.920: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 04:07:34.967: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999456s
Apr 18 04:07:35.985: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996166866s
Apr 18 04:07:36.990: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.978463543s
Apr 18 04:07:38.010: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.97446503s
Apr 18 04:07:39.015: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.953438103s
Apr 18 04:07:40.048: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.948487798s
Apr 18 04:07:41.065: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.915021232s
Apr 18 04:07:42.069: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.899300077s
Apr 18 04:07:43.104: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.895289477s
Apr 18 04:07:44.182: INFO: Verifying statefulset ss doesn't scale past 1 for another 859.479949ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4857 04/18/23 04:07:45.183
Apr 18 04:07:45.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 04:07:45.344: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 04:07:45.344: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 04:07:45.344: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 04:07:45.349: INFO: Found 1 stateful pods, waiting for 3
Apr 18 04:07:55.378: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 04:07:55.378: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 04:07:55.378: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 04/18/23 04:07:55.378
STEP: Scale down will halt with unhealthy stateful pod 04/18/23 04:07:55.379
Apr 18 04:07:55.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 04:07:55.586: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 04:07:55.586: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 04:07:55.586: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 04:07:55.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 04:07:55.773: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 04:07:55.773: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 04:07:55.773: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 04:07:55.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 04:07:55.961: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 04:07:55.961: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 04:07:55.961: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 04:07:55.961: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 04:07:55.965: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr 18 04:08:05.987: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 04:08:05.987: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 04:08:05.987: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 04:08:06.027: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999758s
Apr 18 04:08:07.032: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996543194s
Apr 18 04:08:08.039: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991352443s
Apr 18 04:08:09.045: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985266557s
Apr 18 04:08:10.050: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97900237s
Apr 18 04:08:11.054: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973976467s
Apr 18 04:08:12.080: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.969348932s
Apr 18 04:08:13.085: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.943352155s
Apr 18 04:08:14.090: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.938316902s
Apr 18 04:08:15.102: INFO: Verifying statefulset ss doesn't scale past 3 for another 932.611143ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4857 04/18/23 04:08:16.103
Apr 18 04:08:16.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 04:08:16.267: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 04:08:16.267: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 04:08:16.267: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 04:08:16.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 04:08:16.467: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 04:08:16.467: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 04:08:16.467: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 04:08:16.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 04:08:16.624: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 04:08:16.624: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 04:08:16.624: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 04:08:16.624: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 04/18/23 04:08:26.64
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 04:08:26.640: INFO: Deleting all statefulset in ns statefulset-4857
Apr 18 04:08:26.643: INFO: Scaling statefulset ss to 0
Apr 18 04:08:26.653: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 04:08:26.656: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 04:08:26.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4857" for this suite. 04/18/23 04:08:26.687
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":22,"skipped":365,"failed":0}
------------------------------
â€¢ [SLOW TEST] [72.344 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:07:14.425
    Apr 18 04:07:14.425: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename statefulset 04/18/23 04:07:14.426
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:07:14.481
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:07:14.484
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4857 04/18/23 04:07:14.486
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 04/18/23 04:07:14.548
    STEP: Creating stateful set ss in namespace statefulset-4857 04/18/23 04:07:14.551
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4857 04/18/23 04:07:14.582
    Apr 18 04:07:14.623: INFO: Found 0 stateful pods, waiting for 1
    Apr 18 04:07:24.671: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/18/23 04:07:24.671
    Apr 18 04:07:24.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 04:07:24.890: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 04:07:24.890: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 04:07:24.890: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 04:07:24.912: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 18 04:07:34.920: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 04:07:34.920: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 04:07:34.967: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999456s
    Apr 18 04:07:35.985: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996166866s
    Apr 18 04:07:36.990: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.978463543s
    Apr 18 04:07:38.010: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.97446503s
    Apr 18 04:07:39.015: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.953438103s
    Apr 18 04:07:40.048: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.948487798s
    Apr 18 04:07:41.065: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.915021232s
    Apr 18 04:07:42.069: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.899300077s
    Apr 18 04:07:43.104: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.895289477s
    Apr 18 04:07:44.182: INFO: Verifying statefulset ss doesn't scale past 1 for another 859.479949ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4857 04/18/23 04:07:45.183
    Apr 18 04:07:45.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 04:07:45.344: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 04:07:45.344: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 04:07:45.344: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 04:07:45.349: INFO: Found 1 stateful pods, waiting for 3
    Apr 18 04:07:55.378: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 04:07:55.378: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 04:07:55.378: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 04/18/23 04:07:55.378
    STEP: Scale down will halt with unhealthy stateful pod 04/18/23 04:07:55.379
    Apr 18 04:07:55.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 04:07:55.586: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 04:07:55.586: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 04:07:55.586: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 04:07:55.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 04:07:55.773: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 04:07:55.773: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 04:07:55.773: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 04:07:55.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 04:07:55.961: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 04:07:55.961: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 04:07:55.961: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 04:07:55.961: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 04:07:55.965: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Apr 18 04:08:05.987: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 04:08:05.987: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 04:08:05.987: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 04:08:06.027: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999758s
    Apr 18 04:08:07.032: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996543194s
    Apr 18 04:08:08.039: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991352443s
    Apr 18 04:08:09.045: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985266557s
    Apr 18 04:08:10.050: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97900237s
    Apr 18 04:08:11.054: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973976467s
    Apr 18 04:08:12.080: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.969348932s
    Apr 18 04:08:13.085: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.943352155s
    Apr 18 04:08:14.090: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.938316902s
    Apr 18 04:08:15.102: INFO: Verifying statefulset ss doesn't scale past 3 for another 932.611143ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4857 04/18/23 04:08:16.103
    Apr 18 04:08:16.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 04:08:16.267: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 04:08:16.267: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 04:08:16.267: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 04:08:16.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 04:08:16.467: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 04:08:16.467: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 04:08:16.467: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 04:08:16.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-4857 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 04:08:16.624: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 04:08:16.624: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 04:08:16.624: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 04:08:16.624: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 04/18/23 04:08:26.64
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 04:08:26.640: INFO: Deleting all statefulset in ns statefulset-4857
    Apr 18 04:08:26.643: INFO: Scaling statefulset ss to 0
    Apr 18 04:08:26.653: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 04:08:26.656: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 04:08:26.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4857" for this suite. 04/18/23 04:08:26.687
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:08:26.77
Apr 18 04:08:26.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 04:08:26.772
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:08:26.816
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:08:26.819
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-6966 04/18/23 04:08:26.912
STEP: creating service affinity-nodeport in namespace services-6966 04/18/23 04:08:26.912
STEP: creating replication controller affinity-nodeport in namespace services-6966 04/18/23 04:08:27.008
I0418 04:08:27.154394      22 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-6966, replica count: 3
I0418 04:08:30.206325      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 04:08:33.207403      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 04:08:33.244: INFO: Creating new exec pod
Apr 18 04:08:33.273: INFO: Waiting up to 5m0s for pod "execpod-affinityr4gql" in namespace "services-6966" to be "running"
Apr 18 04:08:33.359: INFO: Pod "execpod-affinityr4gql": Phase="Pending", Reason="", readiness=false. Elapsed: 86.067478ms
Apr 18 04:08:35.364: INFO: Pod "execpod-affinityr4gql": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090824912s
Apr 18 04:08:37.364: INFO: Pod "execpod-affinityr4gql": Phase="Running", Reason="", readiness=true. Elapsed: 4.090782255s
Apr 18 04:08:37.364: INFO: Pod "execpod-affinityr4gql" satisfied condition "running"
Apr 18 04:08:38.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6966 exec execpod-affinityr4gql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Apr 18 04:08:38.538: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Apr 18 04:08:38.538: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:08:38.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6966 exec execpod-affinityr4gql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.10.139 80'
Apr 18 04:08:38.754: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.10.139 80\nConnection to 10.96.10.139 80 port [tcp/http] succeeded!\n"
Apr 18 04:08:38.754: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:08:38.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6966 exec execpod-affinityr4gql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.108 32069'
Apr 18 04:08:38.912: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.108 32069\nConnection to 192.168.2.108 32069 port [tcp/*] succeeded!\n"
Apr 18 04:08:38.912: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:08:38.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6966 exec execpod-affinityr4gql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.109 32069'
Apr 18 04:08:39.070: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.109 32069\nConnection to 192.168.2.109 32069 port [tcp/*] succeeded!\n"
Apr 18 04:08:39.070: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:08:39.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6966 exec execpod-affinityr4gql -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.2.107:32069/ ; done'
Apr 18 04:08:39.295: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n"
Apr 18 04:08:39.295: INFO: stdout: "\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff"
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
Apr 18 04:08:39.295: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-6966, will wait for the garbage collector to delete the pods 04/18/23 04:08:39.652
Apr 18 04:08:39.733: INFO: Deleting ReplicationController affinity-nodeport took: 27.430699ms
Apr 18 04:08:40.134: INFO: Terminating ReplicationController affinity-nodeport pods took: 401.174212ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 04:08:44.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6966" for this suite. 04/18/23 04:08:44.373
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":23,"skipped":382,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.626 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:08:26.77
    Apr 18 04:08:26.770: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 04:08:26.772
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:08:26.816
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:08:26.819
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-6966 04/18/23 04:08:26.912
    STEP: creating service affinity-nodeport in namespace services-6966 04/18/23 04:08:26.912
    STEP: creating replication controller affinity-nodeport in namespace services-6966 04/18/23 04:08:27.008
    I0418 04:08:27.154394      22 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-6966, replica count: 3
    I0418 04:08:30.206325      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 04:08:33.207403      22 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 04:08:33.244: INFO: Creating new exec pod
    Apr 18 04:08:33.273: INFO: Waiting up to 5m0s for pod "execpod-affinityr4gql" in namespace "services-6966" to be "running"
    Apr 18 04:08:33.359: INFO: Pod "execpod-affinityr4gql": Phase="Pending", Reason="", readiness=false. Elapsed: 86.067478ms
    Apr 18 04:08:35.364: INFO: Pod "execpod-affinityr4gql": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090824912s
    Apr 18 04:08:37.364: INFO: Pod "execpod-affinityr4gql": Phase="Running", Reason="", readiness=true. Elapsed: 4.090782255s
    Apr 18 04:08:37.364: INFO: Pod "execpod-affinityr4gql" satisfied condition "running"
    Apr 18 04:08:38.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6966 exec execpod-affinityr4gql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Apr 18 04:08:38.538: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Apr 18 04:08:38.538: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:08:38.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6966 exec execpod-affinityr4gql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.10.139 80'
    Apr 18 04:08:38.754: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.10.139 80\nConnection to 10.96.10.139 80 port [tcp/http] succeeded!\n"
    Apr 18 04:08:38.754: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:08:38.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6966 exec execpod-affinityr4gql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.108 32069'
    Apr 18 04:08:38.912: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.108 32069\nConnection to 192.168.2.108 32069 port [tcp/*] succeeded!\n"
    Apr 18 04:08:38.912: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:08:38.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6966 exec execpod-affinityr4gql -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.109 32069'
    Apr 18 04:08:39.070: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.109 32069\nConnection to 192.168.2.109 32069 port [tcp/*] succeeded!\n"
    Apr 18 04:08:39.070: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:08:39.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6966 exec execpod-affinityr4gql -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.2.107:32069/ ; done'
    Apr 18 04:08:39.295: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32069/\n"
    Apr 18 04:08:39.295: INFO: stdout: "\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff\naffinity-nodeport-cnwff"
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Received response from host: affinity-nodeport-cnwff
    Apr 18 04:08:39.295: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-6966, will wait for the garbage collector to delete the pods 04/18/23 04:08:39.652
    Apr 18 04:08:39.733: INFO: Deleting ReplicationController affinity-nodeport took: 27.430699ms
    Apr 18 04:08:40.134: INFO: Terminating ReplicationController affinity-nodeport pods took: 401.174212ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 04:08:44.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6966" for this suite. 04/18/23 04:08:44.373
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:08:44.397
Apr 18 04:08:44.397: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-probe 04/18/23 04:08:44.398
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:08:44.526
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:08:44.53
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558 in namespace container-probe-7752 04/18/23 04:08:44.556
Apr 18 04:08:44.594: INFO: Waiting up to 5m0s for pod "liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558" in namespace "container-probe-7752" to be "not pending"
Apr 18 04:08:44.630: INFO: Pod "liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558": Phase="Pending", Reason="", readiness=false. Elapsed: 35.936163ms
Apr 18 04:08:46.669: INFO: Pod "liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074704553s
Apr 18 04:08:48.692: INFO: Pod "liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558": Phase="Running", Reason="", readiness=true. Elapsed: 4.097648963s
Apr 18 04:08:48.692: INFO: Pod "liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558" satisfied condition "not pending"
Apr 18 04:08:48.692: INFO: Started pod liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558 in namespace container-probe-7752
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 04:08:48.692
Apr 18 04:08:48.706: INFO: Initial restart count of pod liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558 is 0
STEP: deleting the pod 04/18/23 04:12:50.04
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 04:12:50.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7752" for this suite. 04/18/23 04:12:50.241
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":24,"skipped":390,"failed":0}
------------------------------
â€¢ [SLOW TEST] [245.929 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:08:44.397
    Apr 18 04:08:44.397: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-probe 04/18/23 04:08:44.398
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:08:44.526
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:08:44.53
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558 in namespace container-probe-7752 04/18/23 04:08:44.556
    Apr 18 04:08:44.594: INFO: Waiting up to 5m0s for pod "liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558" in namespace "container-probe-7752" to be "not pending"
    Apr 18 04:08:44.630: INFO: Pod "liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558": Phase="Pending", Reason="", readiness=false. Elapsed: 35.936163ms
    Apr 18 04:08:46.669: INFO: Pod "liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074704553s
    Apr 18 04:08:48.692: INFO: Pod "liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558": Phase="Running", Reason="", readiness=true. Elapsed: 4.097648963s
    Apr 18 04:08:48.692: INFO: Pod "liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558" satisfied condition "not pending"
    Apr 18 04:08:48.692: INFO: Started pod liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558 in namespace container-probe-7752
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 04:08:48.692
    Apr 18 04:08:48.706: INFO: Initial restart count of pod liveness-2bceea25-c8e9-4cf3-80a4-02e4222ac558 is 0
    STEP: deleting the pod 04/18/23 04:12:50.04
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 04:12:50.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7752" for this suite. 04/18/23 04:12:50.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:12:50.327
Apr 18 04:12:50.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 04:12:50.328
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:12:50.421
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:12:50.423
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7059 04/18/23 04:12:50.489
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/18/23 04:12:50.555
STEP: creating service externalsvc in namespace services-7059 04/18/23 04:12:50.555
STEP: creating replication controller externalsvc in namespace services-7059 04/18/23 04:12:50.785
I0418 04:12:50.914523      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7059, replica count: 2
I0418 04:12:53.966282      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 04:12:56.966505      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 04/18/23 04:12:57.022
Apr 18 04:12:57.093: INFO: Creating new exec pod
Apr 18 04:12:57.114: INFO: Waiting up to 5m0s for pod "execpoddv9mp" in namespace "services-7059" to be "running"
Apr 18 04:12:57.117: INFO: Pod "execpoddv9mp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.930549ms
Apr 18 04:12:59.139: INFO: Pod "execpoddv9mp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024926079s
Apr 18 04:13:01.122: INFO: Pod "execpoddv9mp": Phase="Running", Reason="", readiness=true. Elapsed: 4.007802453s
Apr 18 04:13:01.122: INFO: Pod "execpoddv9mp" satisfied condition "running"
Apr 18 04:13:01.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-7059 exec execpoddv9mp -- /bin/sh -x -c nslookup clusterip-service.services-7059.svc.cluster.local'
Apr 18 04:13:01.305: INFO: stderr: "+ nslookup clusterip-service.services-7059.svc.cluster.local\n"
Apr 18 04:13:01.305: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-7059.svc.cluster.local\tcanonical name = externalsvc.services-7059.svc.cluster.local.\nName:\texternalsvc.services-7059.svc.cluster.local\nAddress: 10.96.4.244\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7059, will wait for the garbage collector to delete the pods 04/18/23 04:13:01.305
Apr 18 04:13:01.385: INFO: Deleting ReplicationController externalsvc took: 25.389882ms
Apr 18 04:13:01.686: INFO: Terminating ReplicationController externalsvc pods took: 300.683242ms
Apr 18 04:13:04.981: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 04:13:05.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7059" for this suite. 04/18/23 04:13:05.254
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":25,"skipped":406,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.030 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:12:50.327
    Apr 18 04:12:50.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 04:12:50.328
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:12:50.421
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:12:50.423
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7059 04/18/23 04:12:50.489
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/18/23 04:12:50.555
    STEP: creating service externalsvc in namespace services-7059 04/18/23 04:12:50.555
    STEP: creating replication controller externalsvc in namespace services-7059 04/18/23 04:12:50.785
    I0418 04:12:50.914523      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-7059, replica count: 2
    I0418 04:12:53.966282      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 04:12:56.966505      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 04/18/23 04:12:57.022
    Apr 18 04:12:57.093: INFO: Creating new exec pod
    Apr 18 04:12:57.114: INFO: Waiting up to 5m0s for pod "execpoddv9mp" in namespace "services-7059" to be "running"
    Apr 18 04:12:57.117: INFO: Pod "execpoddv9mp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.930549ms
    Apr 18 04:12:59.139: INFO: Pod "execpoddv9mp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024926079s
    Apr 18 04:13:01.122: INFO: Pod "execpoddv9mp": Phase="Running", Reason="", readiness=true. Elapsed: 4.007802453s
    Apr 18 04:13:01.122: INFO: Pod "execpoddv9mp" satisfied condition "running"
    Apr 18 04:13:01.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-7059 exec execpoddv9mp -- /bin/sh -x -c nslookup clusterip-service.services-7059.svc.cluster.local'
    Apr 18 04:13:01.305: INFO: stderr: "+ nslookup clusterip-service.services-7059.svc.cluster.local\n"
    Apr 18 04:13:01.305: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-7059.svc.cluster.local\tcanonical name = externalsvc.services-7059.svc.cluster.local.\nName:\texternalsvc.services-7059.svc.cluster.local\nAddress: 10.96.4.244\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-7059, will wait for the garbage collector to delete the pods 04/18/23 04:13:01.305
    Apr 18 04:13:01.385: INFO: Deleting ReplicationController externalsvc took: 25.389882ms
    Apr 18 04:13:01.686: INFO: Terminating ReplicationController externalsvc pods took: 300.683242ms
    Apr 18 04:13:04.981: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 04:13:05.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7059" for this suite. 04/18/23 04:13:05.254
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:13:05.357
Apr 18 04:13:05.357: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename deployment 04/18/23 04:13:05.358
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:13:05.445
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:13:05.448
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Apr 18 04:13:05.513: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 18 04:13:10.531: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 04:13:10.531
Apr 18 04:13:10.531: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 18 04:13:12.704: INFO: Creating deployment "test-rollover-deployment"
Apr 18 04:13:12.722: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 18 04:13:14.738: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 18 04:13:14.849: INFO: Ensure that both replica sets have 1 created replica
Apr 18 04:13:14.891: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 18 04:13:14.954: INFO: Updating deployment test-rollover-deployment
Apr 18 04:13:14.954: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 18 04:13:17.122: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 18 04:13:17.141: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 18 04:13:17.163: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 04:13:17.163: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 04:13:19.171: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 04:13:19.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 04:13:21.171: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 04:13:21.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 04:13:23.172: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 04:13:23.173: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 04:13:25.171: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 04:13:25.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 04:13:27.170: INFO: all replica sets need to contain the pod-template-hash label
Apr 18 04:13:27.170: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 04:13:29.197: INFO: 
Apr 18 04:13:29.197: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 04:13:29.237: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-977  d05b14c6-d73c-46ab-a124-f8240a044d34 4082180 2 2023-04-18 04:13:12 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-18 04:13:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:13:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003188f48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 04:13:13 +0000 UTC,LastTransitionTime:2023-04-18 04:13:13 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-04-18 04:13:28 +0000 UTC,LastTransitionTime:2023-04-18 04:13:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 18 04:13:29.240: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-977  9ac5cc51-2fb9-4dc1-b855-daf0ab066bba 4082165 2 2023-04-18 04:13:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment d05b14c6-d73c-46ab-a124-f8240a044d34 0xc003189507 0xc003189508}] [] [{kube-controller-manager Update apps/v1 2023-04-18 04:13:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d05b14c6-d73c-46ab-a124-f8240a044d34\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:13:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0031895b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 18 04:13:29.240: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 18 04:13:29.240: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-977  2d0b3529-79e5-48d7-ae8f-ffe4a5b43e62 4082178 2 2023-04-18 04:13:05 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment d05b14c6-d73c-46ab-a124-f8240a044d34 0xc0031892af 0xc0031892c0}] [] [{e2e.test Update apps/v1 2023-04-18 04:13:05 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:13:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d05b14c6-d73c-46ab-a124-f8240a044d34\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:13:28 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003189378 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 04:13:29.241: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-977  7a4d87a0-631f-4f9b-a011-29bba633879d 4082110 2 2023-04-18 04:13:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment d05b14c6-d73c-46ab-a124-f8240a044d34 0xc0031893e7 0xc0031893e8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 04:13:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d05b14c6-d73c-46ab-a124-f8240a044d34\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:13:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003189498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 04:13:29.244: INFO: Pod "test-rollover-deployment-6d45fd857b-2tpqc" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-2tpqc test-rollover-deployment-6d45fd857b- deployment-977  09eedc19-b63a-4466-b5f2-0aa0c71c7807 4082131 0 2023-04-18 04:13:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:70c8cfb00144d9ddef7cfb7729e74a34a3010692caf85e89946f5f2d6383c7ed cni.projectcalico.org/podIP:172.16.125.48/32 cni.projectcalico.org/podIPs:172.16.125.48/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 9ac5cc51-2fb9-4dc1-b855-daf0ab066bba 0xc003189b27 0xc003189b28}] [] [{kube-controller-manager Update v1 2023-04-18 04:13:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ac5cc51-2fb9-4dc1-b855-daf0ab066bba\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 04:13:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 04:13:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9mfsl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9mfsl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:13:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:13:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:13:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:13:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.48,StartTime:2023-04-18 04:13:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 04:13:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://9118429c4d17ac550d756c9c4ed9bc2a2201a5c36cbc04d0f00fc18de40e937e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 04:13:29.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-977" for this suite. 04/18/23 04:13:29.279
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":26,"skipped":406,"failed":0}
------------------------------
â€¢ [SLOW TEST] [23.941 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:13:05.357
    Apr 18 04:13:05.357: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename deployment 04/18/23 04:13:05.358
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:13:05.445
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:13:05.448
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Apr 18 04:13:05.513: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Apr 18 04:13:10.531: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 04:13:10.531
    Apr 18 04:13:10.531: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Apr 18 04:13:12.704: INFO: Creating deployment "test-rollover-deployment"
    Apr 18 04:13:12.722: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Apr 18 04:13:14.738: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Apr 18 04:13:14.849: INFO: Ensure that both replica sets have 1 created replica
    Apr 18 04:13:14.891: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Apr 18 04:13:14.954: INFO: Updating deployment test-rollover-deployment
    Apr 18 04:13:14.954: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Apr 18 04:13:17.122: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Apr 18 04:13:17.141: INFO: Make sure deployment "test-rollover-deployment" is complete
    Apr 18 04:13:17.163: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 04:13:17.163: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 15, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 04:13:19.171: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 04:13:19.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 04:13:21.171: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 04:13:21.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 04:13:23.172: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 04:13:23.173: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 04:13:25.171: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 04:13:25.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 04:13:27.170: INFO: all replica sets need to contain the pod-template-hash label
    Apr 18 04:13:27.170: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 13, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 13, 18, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 13, 12, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 04:13:29.197: INFO: 
    Apr 18 04:13:29.197: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 04:13:29.237: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-977  d05b14c6-d73c-46ab-a124-f8240a044d34 4082180 2 2023-04-18 04:13:12 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-18 04:13:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:13:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003188f48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 04:13:13 +0000 UTC,LastTransitionTime:2023-04-18 04:13:13 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2023-04-18 04:13:28 +0000 UTC,LastTransitionTime:2023-04-18 04:13:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 18 04:13:29.240: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-977  9ac5cc51-2fb9-4dc1-b855-daf0ab066bba 4082165 2 2023-04-18 04:13:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment d05b14c6-d73c-46ab-a124-f8240a044d34 0xc003189507 0xc003189508}] [] [{kube-controller-manager Update apps/v1 2023-04-18 04:13:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d05b14c6-d73c-46ab-a124-f8240a044d34\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:13:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0031895b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 04:13:29.240: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Apr 18 04:13:29.240: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-977  2d0b3529-79e5-48d7-ae8f-ffe4a5b43e62 4082178 2 2023-04-18 04:13:05 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment d05b14c6-d73c-46ab-a124-f8240a044d34 0xc0031892af 0xc0031892c0}] [] [{e2e.test Update apps/v1 2023-04-18 04:13:05 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:13:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d05b14c6-d73c-46ab-a124-f8240a044d34\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:13:28 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003189378 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 04:13:29.241: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-977  7a4d87a0-631f-4f9b-a011-29bba633879d 4082110 2 2023-04-18 04:13:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment d05b14c6-d73c-46ab-a124-f8240a044d34 0xc0031893e7 0xc0031893e8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 04:13:15 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d05b14c6-d73c-46ab-a124-f8240a044d34\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:13:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003189498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 04:13:29.244: INFO: Pod "test-rollover-deployment-6d45fd857b-2tpqc" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-2tpqc test-rollover-deployment-6d45fd857b- deployment-977  09eedc19-b63a-4466-b5f2-0aa0c71c7807 4082131 0 2023-04-18 04:13:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:70c8cfb00144d9ddef7cfb7729e74a34a3010692caf85e89946f5f2d6383c7ed cni.projectcalico.org/podIP:172.16.125.48/32 cni.projectcalico.org/podIPs:172.16.125.48/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 9ac5cc51-2fb9-4dc1-b855-daf0ab066bba 0xc003189b27 0xc003189b28}] [] [{kube-controller-manager Update v1 2023-04-18 04:13:15 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9ac5cc51-2fb9-4dc1-b855-daf0ab066bba\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 04:13:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 04:13:18 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9mfsl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9mfsl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:13:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:13:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:13:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:13:15 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.48,StartTime:2023-04-18 04:13:15 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 04:13:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://9118429c4d17ac550d756c9c4ed9bc2a2201a5c36cbc04d0f00fc18de40e937e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 04:13:29.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-977" for this suite. 04/18/23 04:13:29.279
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:13:29.299
Apr 18 04:13:29.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 04:13:29.3
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:13:29.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:13:29.432
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 04/18/23 04:13:29.443
STEP: watching for the Service to be added 04/18/23 04:13:29.53
Apr 18 04:13:29.532: INFO: Found Service test-service-px7pj in namespace services-4899 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Apr 18 04:13:29.532: INFO: Service test-service-px7pj created
STEP: Getting /status 04/18/23 04:13:29.532
Apr 18 04:13:29.555: INFO: Service test-service-px7pj has LoadBalancer: {[]}
STEP: patching the ServiceStatus 04/18/23 04:13:29.555
STEP: watching for the Service to be patched 04/18/23 04:13:29.59
Apr 18 04:13:29.592: INFO: observed Service test-service-px7pj in namespace services-4899 with annotations: map[] & LoadBalancer: {[]}
Apr 18 04:13:29.592: INFO: Found Service test-service-px7pj in namespace services-4899 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Apr 18 04:13:29.592: INFO: Service test-service-px7pj has service status patched
STEP: updating the ServiceStatus 04/18/23 04:13:29.592
Apr 18 04:13:29.622: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 04/18/23 04:13:29.622
Apr 18 04:13:29.623: INFO: Observed Service test-service-px7pj in namespace services-4899 with annotations: map[] & Conditions: {[]}
Apr 18 04:13:29.623: INFO: Observed event: &Service{ObjectMeta:{test-service-px7pj  services-4899  f85b7de5-fa75-47a5-9f97-50b24dd98056 4082191 0 2023-04-18 04:13:29 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-18 04:13:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-18 04:13:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.96.7.33,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.96.7.33],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Apr 18 04:13:29.623: INFO: Found Service test-service-px7pj in namespace services-4899 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 18 04:13:29.623: INFO: Service test-service-px7pj has service status updated
STEP: patching the service 04/18/23 04:13:29.623
STEP: watching for the Service to be patched 04/18/23 04:13:29.645
Apr 18 04:13:29.646: INFO: observed Service test-service-px7pj in namespace services-4899 with labels: map[test-service-static:true]
Apr 18 04:13:29.646: INFO: observed Service test-service-px7pj in namespace services-4899 with labels: map[test-service-static:true]
Apr 18 04:13:29.646: INFO: observed Service test-service-px7pj in namespace services-4899 with labels: map[test-service-static:true]
Apr 18 04:13:29.646: INFO: Found Service test-service-px7pj in namespace services-4899 with labels: map[test-service:patched test-service-static:true]
Apr 18 04:13:29.646: INFO: Service test-service-px7pj patched
STEP: deleting the service 04/18/23 04:13:29.646
STEP: watching for the Service to be deleted 04/18/23 04:13:29.757
Apr 18 04:13:29.758: INFO: Observed event: ADDED
Apr 18 04:13:29.758: INFO: Observed event: MODIFIED
Apr 18 04:13:29.758: INFO: Observed event: MODIFIED
Apr 18 04:13:29.758: INFO: Observed event: MODIFIED
Apr 18 04:13:29.759: INFO: Found Service test-service-px7pj in namespace services-4899 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Apr 18 04:13:29.759: INFO: Service test-service-px7pj deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 04:13:29.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4899" for this suite. 04/18/23 04:13:29.763
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":27,"skipped":414,"failed":0}
------------------------------
â€¢ [0.475 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:13:29.299
    Apr 18 04:13:29.299: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 04:13:29.3
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:13:29.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:13:29.432
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 04/18/23 04:13:29.443
    STEP: watching for the Service to be added 04/18/23 04:13:29.53
    Apr 18 04:13:29.532: INFO: Found Service test-service-px7pj in namespace services-4899 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Apr 18 04:13:29.532: INFO: Service test-service-px7pj created
    STEP: Getting /status 04/18/23 04:13:29.532
    Apr 18 04:13:29.555: INFO: Service test-service-px7pj has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 04/18/23 04:13:29.555
    STEP: watching for the Service to be patched 04/18/23 04:13:29.59
    Apr 18 04:13:29.592: INFO: observed Service test-service-px7pj in namespace services-4899 with annotations: map[] & LoadBalancer: {[]}
    Apr 18 04:13:29.592: INFO: Found Service test-service-px7pj in namespace services-4899 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Apr 18 04:13:29.592: INFO: Service test-service-px7pj has service status patched
    STEP: updating the ServiceStatus 04/18/23 04:13:29.592
    Apr 18 04:13:29.622: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 04/18/23 04:13:29.622
    Apr 18 04:13:29.623: INFO: Observed Service test-service-px7pj in namespace services-4899 with annotations: map[] & Conditions: {[]}
    Apr 18 04:13:29.623: INFO: Observed event: &Service{ObjectMeta:{test-service-px7pj  services-4899  f85b7de5-fa75-47a5-9f97-50b24dd98056 4082191 0 2023-04-18 04:13:29 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-04-18 04:13:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-04-18 04:13:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.96.7.33,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.96.7.33],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Apr 18 04:13:29.623: INFO: Found Service test-service-px7pj in namespace services-4899 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 18 04:13:29.623: INFO: Service test-service-px7pj has service status updated
    STEP: patching the service 04/18/23 04:13:29.623
    STEP: watching for the Service to be patched 04/18/23 04:13:29.645
    Apr 18 04:13:29.646: INFO: observed Service test-service-px7pj in namespace services-4899 with labels: map[test-service-static:true]
    Apr 18 04:13:29.646: INFO: observed Service test-service-px7pj in namespace services-4899 with labels: map[test-service-static:true]
    Apr 18 04:13:29.646: INFO: observed Service test-service-px7pj in namespace services-4899 with labels: map[test-service-static:true]
    Apr 18 04:13:29.646: INFO: Found Service test-service-px7pj in namespace services-4899 with labels: map[test-service:patched test-service-static:true]
    Apr 18 04:13:29.646: INFO: Service test-service-px7pj patched
    STEP: deleting the service 04/18/23 04:13:29.646
    STEP: watching for the Service to be deleted 04/18/23 04:13:29.757
    Apr 18 04:13:29.758: INFO: Observed event: ADDED
    Apr 18 04:13:29.758: INFO: Observed event: MODIFIED
    Apr 18 04:13:29.758: INFO: Observed event: MODIFIED
    Apr 18 04:13:29.758: INFO: Observed event: MODIFIED
    Apr 18 04:13:29.759: INFO: Found Service test-service-px7pj in namespace services-4899 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Apr 18 04:13:29.759: INFO: Service test-service-px7pj deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 04:13:29.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4899" for this suite. 04/18/23 04:13:29.763
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:13:29.774
Apr 18 04:13:29.774: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename ingressclass 04/18/23 04:13:29.775
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:13:29.902
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:13:29.905
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 04/18/23 04:13:29.907
STEP: getting /apis/networking.k8s.io 04/18/23 04:13:29.91
STEP: getting /apis/networking.k8s.iov1 04/18/23 04:13:29.911
STEP: creating 04/18/23 04:13:29.912
STEP: getting 04/18/23 04:13:29.948
STEP: listing 04/18/23 04:13:30.004
STEP: watching 04/18/23 04:13:30.007
Apr 18 04:13:30.007: INFO: starting watch
STEP: patching 04/18/23 04:13:30.009
STEP: updating 04/18/23 04:13:30.031
Apr 18 04:13:30.043: INFO: waiting for watch events with expected annotations
Apr 18 04:13:30.043: INFO: saw patched and updated annotations
STEP: deleting 04/18/23 04:13:30.043
STEP: deleting a collection 04/18/23 04:13:30.076
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Apr 18 04:13:30.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-4028" for this suite. 04/18/23 04:13:30.282
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":28,"skipped":419,"failed":0}
------------------------------
â€¢ [0.615 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:13:29.774
    Apr 18 04:13:29.774: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename ingressclass 04/18/23 04:13:29.775
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:13:29.902
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:13:29.905
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 04/18/23 04:13:29.907
    STEP: getting /apis/networking.k8s.io 04/18/23 04:13:29.91
    STEP: getting /apis/networking.k8s.iov1 04/18/23 04:13:29.911
    STEP: creating 04/18/23 04:13:29.912
    STEP: getting 04/18/23 04:13:29.948
    STEP: listing 04/18/23 04:13:30.004
    STEP: watching 04/18/23 04:13:30.007
    Apr 18 04:13:30.007: INFO: starting watch
    STEP: patching 04/18/23 04:13:30.009
    STEP: updating 04/18/23 04:13:30.031
    Apr 18 04:13:30.043: INFO: waiting for watch events with expected annotations
    Apr 18 04:13:30.043: INFO: saw patched and updated annotations
    STEP: deleting 04/18/23 04:13:30.043
    STEP: deleting a collection 04/18/23 04:13:30.076
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Apr 18 04:13:30.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-4028" for this suite. 04/18/23 04:13:30.282
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:13:30.392
Apr 18 04:13:30.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 04:13:30.393
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:13:30.477
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:13:30.48
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 04:13:30.53
Apr 18 04:13:30.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-3498 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 18 04:13:30.703: INFO: stderr: ""
Apr 18 04:13:30.703: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 04/18/23 04:13:30.703
Apr 18 04:13:30.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-3498 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Apr 18 04:13:33.022: INFO: stderr: ""
Apr 18 04:13:33.022: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 04:13:33.022
Apr 18 04:13:33.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-3498 delete pods e2e-test-httpd-pod'
Apr 18 04:13:36.695: INFO: stderr: ""
Apr 18 04:13:36.695: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 04:13:36.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3498" for this suite. 04/18/23 04:13:36.711
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":29,"skipped":471,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.357 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:13:30.392
    Apr 18 04:13:30.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 04:13:30.393
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:13:30.477
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:13:30.48
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 04:13:30.53
    Apr 18 04:13:30.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-3498 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 18 04:13:30.703: INFO: stderr: ""
    Apr 18 04:13:30.703: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 04/18/23 04:13:30.703
    Apr 18 04:13:30.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-3498 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Apr 18 04:13:33.022: INFO: stderr: ""
    Apr 18 04:13:33.022: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 04:13:33.022
    Apr 18 04:13:33.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-3498 delete pods e2e-test-httpd-pod'
    Apr 18 04:13:36.695: INFO: stderr: ""
    Apr 18 04:13:36.695: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 04:13:36.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3498" for this suite. 04/18/23 04:13:36.711
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:13:36.75
Apr 18 04:13:36.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir-wrapper 04/18/23 04:13:36.751
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:13:36.888
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:13:36.891
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 04/18/23 04:13:36.893
STEP: Creating RC which spawns configmap-volume pods 04/18/23 04:13:39.417
Apr 18 04:13:39.567: INFO: Pod name wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b: Found 1 pods out of 5
Apr 18 04:13:44.576: INFO: Pod name wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/18/23 04:13:44.576
Apr 18 04:13:44.576: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:13:44.580: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 3.679921ms
Apr 18 04:13:46.603: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026355625s
Apr 18 04:13:48.587: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01049472s
Apr 18 04:13:50.585: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009019684s
Apr 18 04:13:52.585: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008918008s
Apr 18 04:13:54.691: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 10.114395163s
Apr 18 04:13:57.241: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 12.66488175s
Apr 18 04:13:58.585: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 14.008093246s
Apr 18 04:14:00.600: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Running", Reason="", readiness=true. Elapsed: 16.023720443s
Apr 18 04:14:00.600: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69" satisfied condition "running"
Apr 18 04:14:00.600: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-9nc9s" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:00.604: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-9nc9s": Phase="Running", Reason="", readiness=true. Elapsed: 3.537078ms
Apr 18 04:14:00.604: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-9nc9s" satisfied condition "running"
Apr 18 04:14:00.604: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-ckdwc" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:00.607: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-ckdwc": Phase="Running", Reason="", readiness=true. Elapsed: 3.358697ms
Apr 18 04:14:00.607: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-ckdwc" satisfied condition "running"
Apr 18 04:14:00.607: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-qd2hz" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:00.671: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-qd2hz": Phase="Running", Reason="", readiness=true. Elapsed: 64.090642ms
Apr 18 04:14:00.671: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-qd2hz" satisfied condition "running"
Apr 18 04:14:00.671: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-v6sgj" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:00.675: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-v6sgj": Phase="Running", Reason="", readiness=true. Elapsed: 3.800749ms
Apr 18 04:14:00.675: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-v6sgj" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b in namespace emptydir-wrapper-3676, will wait for the garbage collector to delete the pods 04/18/23 04:14:00.675
Apr 18 04:14:00.757: INFO: Deleting ReplicationController wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b took: 26.870919ms
Apr 18 04:14:01.058: INFO: Terminating ReplicationController wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b pods took: 300.825985ms
STEP: Creating RC which spawns configmap-volume pods 04/18/23 04:14:06.164
Apr 18 04:14:06.229: INFO: Pod name wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d: Found 0 pods out of 5
Apr 18 04:14:11.282: INFO: Pod name wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/18/23 04:14:11.282
Apr 18 04:14:11.282: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:11.286: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.581184ms
Apr 18 04:14:13.291: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009106474s
Apr 18 04:14:15.384: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.101769011s
Apr 18 04:14:17.374: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 6.091651824s
Apr 18 04:14:19.609: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 8.32735968s
Apr 18 04:14:21.320: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 10.037996581s
Apr 18 04:14:23.312: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 12.030065517s
Apr 18 04:14:25.325: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 14.042788148s
Apr 18 04:14:27.347: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Running", Reason="", readiness=true. Elapsed: 16.065000212s
Apr 18 04:14:27.347: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28" satisfied condition "running"
Apr 18 04:14:27.347: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-drnkz" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:27.438: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-drnkz": Phase="Pending", Reason="", readiness=false. Elapsed: 90.908704ms
Apr 18 04:14:29.444: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-drnkz": Phase="Running", Reason="", readiness=true. Elapsed: 2.096318811s
Apr 18 04:14:29.444: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-drnkz" satisfied condition "running"
Apr 18 04:14:29.444: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-l7fbl" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:29.447: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-l7fbl": Phase="Running", Reason="", readiness=true. Elapsed: 3.877024ms
Apr 18 04:14:29.447: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-l7fbl" satisfied condition "running"
Apr 18 04:14:29.447: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-rd7vj" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:29.451: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-rd7vj": Phase="Running", Reason="", readiness=true. Elapsed: 3.367765ms
Apr 18 04:14:29.451: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-rd7vj" satisfied condition "running"
Apr 18 04:14:29.451: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-xhcq8" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:29.495: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-xhcq8": Phase="Running", Reason="", readiness=true. Elapsed: 44.329384ms
Apr 18 04:14:29.495: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-xhcq8" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d in namespace emptydir-wrapper-3676, will wait for the garbage collector to delete the pods 04/18/23 04:14:29.495
Apr 18 04:14:29.610: INFO: Deleting ReplicationController wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d took: 60.950728ms
Apr 18 04:14:30.411: INFO: Terminating ReplicationController wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d pods took: 800.468836ms
STEP: Creating RC which spawns configmap-volume pods 04/18/23 04:14:34.716
Apr 18 04:14:34.808: INFO: Pod name wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8: Found 0 pods out of 5
Apr 18 04:14:39.831: INFO: Pod name wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/18/23 04:14:39.831
Apr 18 04:14:39.831: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:39.835: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.628801ms
Apr 18 04:14:41.843: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012383857s
Apr 18 04:14:43.840: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008910365s
Apr 18 04:14:45.844: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012981717s
Apr 18 04:14:47.840: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008784144s
Apr 18 04:14:49.869: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038347042s
Apr 18 04:14:51.839: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.008002687s
Apr 18 04:14:53.841: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.009540717s
Apr 18 04:14:55.840: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Running", Reason="", readiness=true. Elapsed: 16.008478906s
Apr 18 04:14:55.840: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9" satisfied condition "running"
Apr 18 04:14:55.840: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-gq4nh" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:55.844: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-gq4nh": Phase="Running", Reason="", readiness=true. Elapsed: 4.056653ms
Apr 18 04:14:55.844: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-gq4nh" satisfied condition "running"
Apr 18 04:14:55.844: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-mvl6r" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:55.847: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-mvl6r": Phase="Running", Reason="", readiness=true. Elapsed: 3.584441ms
Apr 18 04:14:55.847: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-mvl6r" satisfied condition "running"
Apr 18 04:14:55.847: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-qwd77" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:55.851: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-qwd77": Phase="Running", Reason="", readiness=true. Elapsed: 3.436666ms
Apr 18 04:14:55.851: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-qwd77" satisfied condition "running"
Apr 18 04:14:55.851: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-rd4w2" in namespace "emptydir-wrapper-3676" to be "running"
Apr 18 04:14:55.854: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-rd4w2": Phase="Running", Reason="", readiness=true. Elapsed: 3.274211ms
Apr 18 04:14:55.854: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-rd4w2" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8 in namespace emptydir-wrapper-3676, will wait for the garbage collector to delete the pods 04/18/23 04:14:55.854
Apr 18 04:14:55.963: INFO: Deleting ReplicationController wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8 took: 54.653677ms
Apr 18 04:14:56.264: INFO: Terminating ReplicationController wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8 pods took: 300.625383ms
STEP: Cleaning up the configMaps 04/18/23 04:15:00.865
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Apr 18 04:15:02.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3676" for this suite. 04/18/23 04:15:02.88
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":30,"skipped":472,"failed":0}
------------------------------
â€¢ [SLOW TEST] [86.143 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:13:36.75
    Apr 18 04:13:36.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir-wrapper 04/18/23 04:13:36.751
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:13:36.888
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:13:36.891
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 04/18/23 04:13:36.893
    STEP: Creating RC which spawns configmap-volume pods 04/18/23 04:13:39.417
    Apr 18 04:13:39.567: INFO: Pod name wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b: Found 1 pods out of 5
    Apr 18 04:13:44.576: INFO: Pod name wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/18/23 04:13:44.576
    Apr 18 04:13:44.576: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:13:44.580: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 3.679921ms
    Apr 18 04:13:46.603: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026355625s
    Apr 18 04:13:48.587: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01049472s
    Apr 18 04:13:50.585: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009019684s
    Apr 18 04:13:52.585: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008918008s
    Apr 18 04:13:54.691: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 10.114395163s
    Apr 18 04:13:57.241: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 12.66488175s
    Apr 18 04:13:58.585: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Pending", Reason="", readiness=false. Elapsed: 14.008093246s
    Apr 18 04:14:00.600: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69": Phase="Running", Reason="", readiness=true. Elapsed: 16.023720443s
    Apr 18 04:14:00.600: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-28g69" satisfied condition "running"
    Apr 18 04:14:00.600: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-9nc9s" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:00.604: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-9nc9s": Phase="Running", Reason="", readiness=true. Elapsed: 3.537078ms
    Apr 18 04:14:00.604: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-9nc9s" satisfied condition "running"
    Apr 18 04:14:00.604: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-ckdwc" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:00.607: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-ckdwc": Phase="Running", Reason="", readiness=true. Elapsed: 3.358697ms
    Apr 18 04:14:00.607: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-ckdwc" satisfied condition "running"
    Apr 18 04:14:00.607: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-qd2hz" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:00.671: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-qd2hz": Phase="Running", Reason="", readiness=true. Elapsed: 64.090642ms
    Apr 18 04:14:00.671: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-qd2hz" satisfied condition "running"
    Apr 18 04:14:00.671: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-v6sgj" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:00.675: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-v6sgj": Phase="Running", Reason="", readiness=true. Elapsed: 3.800749ms
    Apr 18 04:14:00.675: INFO: Pod "wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b-v6sgj" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b in namespace emptydir-wrapper-3676, will wait for the garbage collector to delete the pods 04/18/23 04:14:00.675
    Apr 18 04:14:00.757: INFO: Deleting ReplicationController wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b took: 26.870919ms
    Apr 18 04:14:01.058: INFO: Terminating ReplicationController wrapped-volume-race-c725667b-dba3-461a-b129-e2b55a5da21b pods took: 300.825985ms
    STEP: Creating RC which spawns configmap-volume pods 04/18/23 04:14:06.164
    Apr 18 04:14:06.229: INFO: Pod name wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d: Found 0 pods out of 5
    Apr 18 04:14:11.282: INFO: Pod name wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/18/23 04:14:11.282
    Apr 18 04:14:11.282: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:11.286: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 3.581184ms
    Apr 18 04:14:13.291: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009106474s
    Apr 18 04:14:15.384: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.101769011s
    Apr 18 04:14:17.374: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 6.091651824s
    Apr 18 04:14:19.609: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 8.32735968s
    Apr 18 04:14:21.320: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 10.037996581s
    Apr 18 04:14:23.312: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 12.030065517s
    Apr 18 04:14:25.325: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Pending", Reason="", readiness=false. Elapsed: 14.042788148s
    Apr 18 04:14:27.347: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28": Phase="Running", Reason="", readiness=true. Elapsed: 16.065000212s
    Apr 18 04:14:27.347: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-bsd28" satisfied condition "running"
    Apr 18 04:14:27.347: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-drnkz" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:27.438: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-drnkz": Phase="Pending", Reason="", readiness=false. Elapsed: 90.908704ms
    Apr 18 04:14:29.444: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-drnkz": Phase="Running", Reason="", readiness=true. Elapsed: 2.096318811s
    Apr 18 04:14:29.444: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-drnkz" satisfied condition "running"
    Apr 18 04:14:29.444: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-l7fbl" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:29.447: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-l7fbl": Phase="Running", Reason="", readiness=true. Elapsed: 3.877024ms
    Apr 18 04:14:29.447: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-l7fbl" satisfied condition "running"
    Apr 18 04:14:29.447: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-rd7vj" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:29.451: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-rd7vj": Phase="Running", Reason="", readiness=true. Elapsed: 3.367765ms
    Apr 18 04:14:29.451: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-rd7vj" satisfied condition "running"
    Apr 18 04:14:29.451: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-xhcq8" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:29.495: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-xhcq8": Phase="Running", Reason="", readiness=true. Elapsed: 44.329384ms
    Apr 18 04:14:29.495: INFO: Pod "wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d-xhcq8" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d in namespace emptydir-wrapper-3676, will wait for the garbage collector to delete the pods 04/18/23 04:14:29.495
    Apr 18 04:14:29.610: INFO: Deleting ReplicationController wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d took: 60.950728ms
    Apr 18 04:14:30.411: INFO: Terminating ReplicationController wrapped-volume-race-21cf0ae3-8050-4b6b-a054-02bd38b5403d pods took: 800.468836ms
    STEP: Creating RC which spawns configmap-volume pods 04/18/23 04:14:34.716
    Apr 18 04:14:34.808: INFO: Pod name wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8: Found 0 pods out of 5
    Apr 18 04:14:39.831: INFO: Pod name wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/18/23 04:14:39.831
    Apr 18 04:14:39.831: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:39.835: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.628801ms
    Apr 18 04:14:41.843: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012383857s
    Apr 18 04:14:43.840: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008910365s
    Apr 18 04:14:45.844: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012981717s
    Apr 18 04:14:47.840: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008784144s
    Apr 18 04:14:49.869: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038347042s
    Apr 18 04:14:51.839: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.008002687s
    Apr 18 04:14:53.841: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.009540717s
    Apr 18 04:14:55.840: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9": Phase="Running", Reason="", readiness=true. Elapsed: 16.008478906s
    Apr 18 04:14:55.840: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-9v8h9" satisfied condition "running"
    Apr 18 04:14:55.840: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-gq4nh" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:55.844: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-gq4nh": Phase="Running", Reason="", readiness=true. Elapsed: 4.056653ms
    Apr 18 04:14:55.844: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-gq4nh" satisfied condition "running"
    Apr 18 04:14:55.844: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-mvl6r" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:55.847: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-mvl6r": Phase="Running", Reason="", readiness=true. Elapsed: 3.584441ms
    Apr 18 04:14:55.847: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-mvl6r" satisfied condition "running"
    Apr 18 04:14:55.847: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-qwd77" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:55.851: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-qwd77": Phase="Running", Reason="", readiness=true. Elapsed: 3.436666ms
    Apr 18 04:14:55.851: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-qwd77" satisfied condition "running"
    Apr 18 04:14:55.851: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-rd4w2" in namespace "emptydir-wrapper-3676" to be "running"
    Apr 18 04:14:55.854: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-rd4w2": Phase="Running", Reason="", readiness=true. Elapsed: 3.274211ms
    Apr 18 04:14:55.854: INFO: Pod "wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8-rd4w2" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8 in namespace emptydir-wrapper-3676, will wait for the garbage collector to delete the pods 04/18/23 04:14:55.854
    Apr 18 04:14:55.963: INFO: Deleting ReplicationController wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8 took: 54.653677ms
    Apr 18 04:14:56.264: INFO: Terminating ReplicationController wrapped-volume-race-224002a1-6e12-4770-aa5b-8ac73060bfb8 pods took: 300.625383ms
    STEP: Cleaning up the configMaps 04/18/23 04:15:00.865
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Apr 18 04:15:02.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-3676" for this suite. 04/18/23 04:15:02.88
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:15:02.894
Apr 18 04:15:02.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:15:02.895
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:15:02.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:15:02.997
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 04/18/23 04:15:02.999
Apr 18 04:15:03.043: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48" in namespace "projected-7539" to be "Succeeded or Failed"
Apr 18 04:15:03.070: INFO: Pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48": Phase="Pending", Reason="", readiness=false. Elapsed: 27.136609ms
Apr 18 04:15:05.141: INFO: Pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098194096s
Apr 18 04:15:07.075: INFO: Pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032029625s
Apr 18 04:15:09.086: INFO: Pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042823679s
STEP: Saw pod success 04/18/23 04:15:09.086
Apr 18 04:15:09.086: INFO: Pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48" satisfied condition "Succeeded or Failed"
Apr 18 04:15:09.153: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48 container client-container: <nil>
STEP: delete the pod 04/18/23 04:15:09.19
Apr 18 04:15:09.377: INFO: Waiting for pod downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48 to disappear
Apr 18 04:15:09.385: INFO: Pod downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 04:15:09.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7539" for this suite. 04/18/23 04:15:09.389
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":31,"skipped":490,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.508 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:15:02.894
    Apr 18 04:15:02.894: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:15:02.895
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:15:02.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:15:02.997
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 04/18/23 04:15:02.999
    Apr 18 04:15:03.043: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48" in namespace "projected-7539" to be "Succeeded or Failed"
    Apr 18 04:15:03.070: INFO: Pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48": Phase="Pending", Reason="", readiness=false. Elapsed: 27.136609ms
    Apr 18 04:15:05.141: INFO: Pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098194096s
    Apr 18 04:15:07.075: INFO: Pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032029625s
    Apr 18 04:15:09.086: INFO: Pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042823679s
    STEP: Saw pod success 04/18/23 04:15:09.086
    Apr 18 04:15:09.086: INFO: Pod "downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48" satisfied condition "Succeeded or Failed"
    Apr 18 04:15:09.153: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48 container client-container: <nil>
    STEP: delete the pod 04/18/23 04:15:09.19
    Apr 18 04:15:09.377: INFO: Waiting for pod downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48 to disappear
    Apr 18 04:15:09.385: INFO: Pod downwardapi-volume-a5aa0739-2eda-4778-ac08-aa89a073df48 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 04:15:09.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7539" for this suite. 04/18/23 04:15:09.389
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:15:09.403
Apr 18 04:15:09.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename cronjob 04/18/23 04:15:09.404
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:15:09.503
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:15:09.506
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 04/18/23 04:15:09.519
STEP: creating 04/18/23 04:15:09.519
STEP: getting 04/18/23 04:15:09.595
STEP: listing 04/18/23 04:15:09.652
STEP: watching 04/18/23 04:15:09.656
Apr 18 04:15:09.656: INFO: starting watch
STEP: cluster-wide listing 04/18/23 04:15:09.657
STEP: cluster-wide watching 04/18/23 04:15:09.677
Apr 18 04:15:09.677: INFO: starting watch
STEP: patching 04/18/23 04:15:09.678
STEP: updating 04/18/23 04:15:09.712
Apr 18 04:15:09.735: INFO: waiting for watch events with expected annotations
Apr 18 04:15:09.735: INFO: saw patched and updated annotations
STEP: patching /status 04/18/23 04:15:09.735
STEP: updating /status 04/18/23 04:15:09.844
STEP: get /status 04/18/23 04:15:09.857
STEP: deleting 04/18/23 04:15:09.865
STEP: deleting a collection 04/18/23 04:15:10.052
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 18 04:15:10.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5682" for this suite. 04/18/23 04:15:10.174
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":32,"skipped":516,"failed":0}
------------------------------
â€¢ [0.891 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:15:09.403
    Apr 18 04:15:09.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename cronjob 04/18/23 04:15:09.404
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:15:09.503
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:15:09.506
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 04/18/23 04:15:09.519
    STEP: creating 04/18/23 04:15:09.519
    STEP: getting 04/18/23 04:15:09.595
    STEP: listing 04/18/23 04:15:09.652
    STEP: watching 04/18/23 04:15:09.656
    Apr 18 04:15:09.656: INFO: starting watch
    STEP: cluster-wide listing 04/18/23 04:15:09.657
    STEP: cluster-wide watching 04/18/23 04:15:09.677
    Apr 18 04:15:09.677: INFO: starting watch
    STEP: patching 04/18/23 04:15:09.678
    STEP: updating 04/18/23 04:15:09.712
    Apr 18 04:15:09.735: INFO: waiting for watch events with expected annotations
    Apr 18 04:15:09.735: INFO: saw patched and updated annotations
    STEP: patching /status 04/18/23 04:15:09.735
    STEP: updating /status 04/18/23 04:15:09.844
    STEP: get /status 04/18/23 04:15:09.857
    STEP: deleting 04/18/23 04:15:09.865
    STEP: deleting a collection 04/18/23 04:15:10.052
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 18 04:15:10.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5682" for this suite. 04/18/23 04:15:10.174
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:15:10.295
Apr 18 04:15:10.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 04:15:10.297
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:15:10.462
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:15:10.466
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 04/18/23 04:15:10.468
Apr 18 04:15:10.470: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: rename a version 04/18/23 04:15:34.492
STEP: check the new version name is served 04/18/23 04:15:34.585
STEP: check the old version name is removed 04/18/23 04:15:43.101
STEP: check the other version is not changed 04/18/23 04:15:46.225
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:16:01.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7063" for this suite. 04/18/23 04:16:01.431
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":33,"skipped":530,"failed":0}
------------------------------
â€¢ [SLOW TEST] [51.154 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:15:10.295
    Apr 18 04:15:10.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 04:15:10.297
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:15:10.462
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:15:10.466
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 04/18/23 04:15:10.468
    Apr 18 04:15:10.470: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: rename a version 04/18/23 04:15:34.492
    STEP: check the new version name is served 04/18/23 04:15:34.585
    STEP: check the old version name is removed 04/18/23 04:15:43.101
    STEP: check the other version is not changed 04/18/23 04:15:46.225
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:16:01.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7063" for this suite. 04/18/23 04:16:01.431
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:16:01.45
Apr 18 04:16:01.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename var-expansion 04/18/23 04:16:01.451
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:01.6
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:01.603
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 04/18/23 04:16:01.607
Apr 18 04:16:01.687: INFO: Waiting up to 5m0s for pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200" in namespace "var-expansion-4881" to be "Succeeded or Failed"
Apr 18 04:16:01.690: INFO: Pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200": Phase="Pending", Reason="", readiness=false. Elapsed: 3.606018ms
Apr 18 04:16:03.800: INFO: Pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200": Phase="Pending", Reason="", readiness=false. Elapsed: 2.113427969s
Apr 18 04:16:05.696: INFO: Pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200": Phase="Running", Reason="", readiness=false. Elapsed: 4.009109867s
Apr 18 04:16:07.699: INFO: Pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012073651s
STEP: Saw pod success 04/18/23 04:16:07.699
Apr 18 04:16:07.699: INFO: Pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200" satisfied condition "Succeeded or Failed"
Apr 18 04:16:07.702: INFO: Trying to get logs from node apps-208 pod var-expansion-1ef06bf1-846e-4598-9863-b796c8556200 container dapi-container: <nil>
STEP: delete the pod 04/18/23 04:16:07.744
Apr 18 04:16:07.985: INFO: Waiting for pod var-expansion-1ef06bf1-846e-4598-9863-b796c8556200 to disappear
Apr 18 04:16:07.989: INFO: Pod var-expansion-1ef06bf1-846e-4598-9863-b796c8556200 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 04:16:07.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4881" for this suite. 04/18/23 04:16:07.994
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":34,"skipped":541,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.595 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:16:01.45
    Apr 18 04:16:01.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename var-expansion 04/18/23 04:16:01.451
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:01.6
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:01.603
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 04/18/23 04:16:01.607
    Apr 18 04:16:01.687: INFO: Waiting up to 5m0s for pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200" in namespace "var-expansion-4881" to be "Succeeded or Failed"
    Apr 18 04:16:01.690: INFO: Pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200": Phase="Pending", Reason="", readiness=false. Elapsed: 3.606018ms
    Apr 18 04:16:03.800: INFO: Pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200": Phase="Pending", Reason="", readiness=false. Elapsed: 2.113427969s
    Apr 18 04:16:05.696: INFO: Pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200": Phase="Running", Reason="", readiness=false. Elapsed: 4.009109867s
    Apr 18 04:16:07.699: INFO: Pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012073651s
    STEP: Saw pod success 04/18/23 04:16:07.699
    Apr 18 04:16:07.699: INFO: Pod "var-expansion-1ef06bf1-846e-4598-9863-b796c8556200" satisfied condition "Succeeded or Failed"
    Apr 18 04:16:07.702: INFO: Trying to get logs from node apps-208 pod var-expansion-1ef06bf1-846e-4598-9863-b796c8556200 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 04:16:07.744
    Apr 18 04:16:07.985: INFO: Waiting for pod var-expansion-1ef06bf1-846e-4598-9863-b796c8556200 to disappear
    Apr 18 04:16:07.989: INFO: Pod var-expansion-1ef06bf1-846e-4598-9863-b796c8556200 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 04:16:07.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4881" for this suite. 04/18/23 04:16:07.994
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:16:08.046
Apr 18 04:16:08.046: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:16:08.047
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:08.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:08.16
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 04/18/23 04:16:08.162
Apr 18 04:16:08.219: INFO: Waiting up to 5m0s for pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196" in namespace "projected-6850" to be "running and ready"
Apr 18 04:16:08.221: INFO: Pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196": Phase="Pending", Reason="", readiness=false. Elapsed: 2.541283ms
Apr 18 04:16:08.221: INFO: The phase of Pod annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:16:10.273: INFO: Pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054176705s
Apr 18 04:16:10.273: INFO: The phase of Pod annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:16:12.226: INFO: Pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196": Phase="Running", Reason="", readiness=true. Elapsed: 4.007097575s
Apr 18 04:16:12.226: INFO: The phase of Pod annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196 is Running (Ready = true)
Apr 18 04:16:12.226: INFO: Pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196" satisfied condition "running and ready"
Apr 18 04:16:12.830: INFO: Successfully updated pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 04:16:14.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6850" for this suite. 04/18/23 04:16:14.873
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":35,"skipped":557,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.882 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:16:08.046
    Apr 18 04:16:08.046: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:16:08.047
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:08.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:08.16
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 04/18/23 04:16:08.162
    Apr 18 04:16:08.219: INFO: Waiting up to 5m0s for pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196" in namespace "projected-6850" to be "running and ready"
    Apr 18 04:16:08.221: INFO: Pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196": Phase="Pending", Reason="", readiness=false. Elapsed: 2.541283ms
    Apr 18 04:16:08.221: INFO: The phase of Pod annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:16:10.273: INFO: Pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054176705s
    Apr 18 04:16:10.273: INFO: The phase of Pod annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:16:12.226: INFO: Pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196": Phase="Running", Reason="", readiness=true. Elapsed: 4.007097575s
    Apr 18 04:16:12.226: INFO: The phase of Pod annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196 is Running (Ready = true)
    Apr 18 04:16:12.226: INFO: Pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196" satisfied condition "running and ready"
    Apr 18 04:16:12.830: INFO: Successfully updated pod "annotationupdate7ebf26c9-ab06-43d2-805f-6f02c5dc2196"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 04:16:14.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6850" for this suite. 04/18/23 04:16:14.873
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:16:14.929
Apr 18 04:16:14.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename ephemeral-containers-test 04/18/23 04:16:14.93
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:15.367
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:15.37
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 04/18/23 04:16:15.373
Apr 18 04:16:15.421: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3681" to be "running and ready"
Apr 18 04:16:15.424: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.067589ms
Apr 18 04:16:15.424: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:16:17.452: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030986162s
Apr 18 04:16:17.452: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:16:19.468: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.047050692s
Apr 18 04:16:19.468: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Apr 18 04:16:19.468: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 04/18/23 04:16:19.471
Apr 18 04:16:19.522: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3681" to be "container debugger running"
Apr 18 04:16:19.525: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.509564ms
Apr 18 04:16:21.530: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007172308s
Apr 18 04:16:23.551: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.028646263s
Apr 18 04:16:23.551: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 04/18/23 04:16:23.551
Apr 18 04:16:23.551: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3681 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:16:23.551: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:16:23.552: INFO: ExecWithOptions: Clientset creation
Apr 18 04:16:23.552: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-3681/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Apr 18 04:16:23.692: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 04:16:23.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-3681" for this suite. 04/18/23 04:16:23.704
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":36,"skipped":558,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.789 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:16:14.929
    Apr 18 04:16:14.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename ephemeral-containers-test 04/18/23 04:16:14.93
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:15.367
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:15.37
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 04/18/23 04:16:15.373
    Apr 18 04:16:15.421: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3681" to be "running and ready"
    Apr 18 04:16:15.424: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.067589ms
    Apr 18 04:16:15.424: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:16:17.452: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030986162s
    Apr 18 04:16:17.452: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:16:19.468: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.047050692s
    Apr 18 04:16:19.468: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Apr 18 04:16:19.468: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 04/18/23 04:16:19.471
    Apr 18 04:16:19.522: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-3681" to be "container debugger running"
    Apr 18 04:16:19.525: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.509564ms
    Apr 18 04:16:21.530: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007172308s
    Apr 18 04:16:23.551: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.028646263s
    Apr 18 04:16:23.551: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 04/18/23 04:16:23.551
    Apr 18 04:16:23.551: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-3681 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:16:23.551: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:16:23.552: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:16:23.552: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/ephemeral-containers-test-3681/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Apr 18 04:16:23.692: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 04:16:23.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-3681" for this suite. 04/18/23 04:16:23.704
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:16:23.719
Apr 18 04:16:23.719: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-runtime 04/18/23 04:16:23.72
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:23.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:23.838
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 04/18/23 04:16:23.841
STEP: wait for the container to reach Failed 04/18/23 04:16:23.863
STEP: get the container status 04/18/23 04:16:28.887
STEP: the container should be terminated 04/18/23 04:16:28.89
STEP: the termination message should be set 04/18/23 04:16:28.89
Apr 18 04:16:28.890: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/18/23 04:16:28.89
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 18 04:16:29.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9721" for this suite. 04/18/23 04:16:29.031
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":37,"skipped":576,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.341 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:16:23.719
    Apr 18 04:16:23.719: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-runtime 04/18/23 04:16:23.72
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:23.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:23.838
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 04/18/23 04:16:23.841
    STEP: wait for the container to reach Failed 04/18/23 04:16:23.863
    STEP: get the container status 04/18/23 04:16:28.887
    STEP: the container should be terminated 04/18/23 04:16:28.89
    STEP: the termination message should be set 04/18/23 04:16:28.89
    Apr 18 04:16:28.890: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/18/23 04:16:28.89
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 18 04:16:29.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-9721" for this suite. 04/18/23 04:16:29.031
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:16:29.063
Apr 18 04:16:29.063: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename containers 04/18/23 04:16:29.064
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:29.202
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:29.205
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Apr 18 04:16:29.253: INFO: Waiting up to 5m0s for pod "client-containers-06e4f007-236b-45c2-b235-6088a3789256" in namespace "containers-8393" to be "running"
Apr 18 04:16:29.338: INFO: Pod "client-containers-06e4f007-236b-45c2-b235-6088a3789256": Phase="Pending", Reason="", readiness=false. Elapsed: 84.163908ms
Apr 18 04:16:31.342: INFO: Pod "client-containers-06e4f007-236b-45c2-b235-6088a3789256": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088978631s
Apr 18 04:16:33.343: INFO: Pod "client-containers-06e4f007-236b-45c2-b235-6088a3789256": Phase="Running", Reason="", readiness=true. Elapsed: 4.089506569s
Apr 18 04:16:33.343: INFO: Pod "client-containers-06e4f007-236b-45c2-b235-6088a3789256" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 18 04:16:33.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8393" for this suite. 04/18/23 04:16:33.366
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":38,"skipped":636,"failed":0}
------------------------------
â€¢ [4.331 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:16:29.063
    Apr 18 04:16:29.063: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename containers 04/18/23 04:16:29.064
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:29.202
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:29.205
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Apr 18 04:16:29.253: INFO: Waiting up to 5m0s for pod "client-containers-06e4f007-236b-45c2-b235-6088a3789256" in namespace "containers-8393" to be "running"
    Apr 18 04:16:29.338: INFO: Pod "client-containers-06e4f007-236b-45c2-b235-6088a3789256": Phase="Pending", Reason="", readiness=false. Elapsed: 84.163908ms
    Apr 18 04:16:31.342: INFO: Pod "client-containers-06e4f007-236b-45c2-b235-6088a3789256": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088978631s
    Apr 18 04:16:33.343: INFO: Pod "client-containers-06e4f007-236b-45c2-b235-6088a3789256": Phase="Running", Reason="", readiness=true. Elapsed: 4.089506569s
    Apr 18 04:16:33.343: INFO: Pod "client-containers-06e4f007-236b-45c2-b235-6088a3789256" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 18 04:16:33.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-8393" for this suite. 04/18/23 04:16:33.366
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:16:33.396
Apr 18 04:16:33.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-runtime 04/18/23 04:16:33.397
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:33.538
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:33.541
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 04/18/23 04:16:33.543
STEP: wait for the container to reach Succeeded 04/18/23 04:16:33.569
STEP: get the container status 04/18/23 04:16:38.728
STEP: the container should be terminated 04/18/23 04:16:38.769
STEP: the termination message should be set 04/18/23 04:16:38.769
Apr 18 04:16:38.769: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 04/18/23 04:16:38.769
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 18 04:16:38.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9326" for this suite. 04/18/23 04:16:38.994
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":39,"skipped":674,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.621 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:16:33.396
    Apr 18 04:16:33.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-runtime 04/18/23 04:16:33.397
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:33.538
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:33.541
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 04/18/23 04:16:33.543
    STEP: wait for the container to reach Succeeded 04/18/23 04:16:33.569
    STEP: get the container status 04/18/23 04:16:38.728
    STEP: the container should be terminated 04/18/23 04:16:38.769
    STEP: the termination message should be set 04/18/23 04:16:38.769
    Apr 18 04:16:38.769: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 04/18/23 04:16:38.769
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 18 04:16:38.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-9326" for this suite. 04/18/23 04:16:38.994
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:16:39.018
Apr 18 04:16:39.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename podtemplate 04/18/23 04:16:39.019
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:39.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:39.13
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 18 04:16:39.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-306" for this suite. 04/18/23 04:16:39.397
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":40,"skipped":713,"failed":0}
------------------------------
â€¢ [0.441 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:16:39.018
    Apr 18 04:16:39.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename podtemplate 04/18/23 04:16:39.019
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:39.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:39.13
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 18 04:16:39.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-306" for this suite. 04/18/23 04:16:39.397
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:16:39.46
Apr 18 04:16:39.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 04:16:39.461
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:39.562
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:39.565
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Apr 18 04:16:39.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 create -f -'
Apr 18 04:16:41.154: INFO: stderr: ""
Apr 18 04:16:41.154: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Apr 18 04:16:41.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 create -f -'
Apr 18 04:16:42.626: INFO: stderr: ""
Apr 18 04:16:42.626: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/18/23 04:16:42.626
Apr 18 04:16:43.746: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 04:16:43.746: INFO: Found 1 / 1
Apr 18 04:16:43.746: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 18 04:16:43.765: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 04:16:43.765: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 18 04:16:43.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 describe pod agnhost-primary-mcdk2'
Apr 18 04:16:43.876: INFO: stderr: ""
Apr 18 04:16:43.876: INFO: stdout: "Name:             agnhost-primary-mcdk2\nNamespace:        kubectl-6131\nPriority:         0\nService Account:  default\nNode:             apps-208/192.168.2.108\nStart Time:       Tue, 18 Apr 2023 04:16:41 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 0238ac0928c4317e481dcb382958c3f704e038feef0d45ab3760a26f2e877001\n                  cni.projectcalico.org/podIP: 172.16.125.25/32\n                  cni.projectcalico.org/podIPs: 172.16.125.25/32\nStatus:           Running\nIP:               172.16.125.25\nIPs:\n  IP:           172.16.125.25\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://524d13359f57d7c15c7f9e191d98272e3cb27f2aa98b7f0e7c24e6a098d0241e\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 18 Apr 2023 04:16:43 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-95zbr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-95zbr:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 30s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 30s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-6131/agnhost-primary-mcdk2 to apps-208\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    0s    kubelet            Created container agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
Apr 18 04:16:43.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 describe rc agnhost-primary'
Apr 18 04:16:43.964: INFO: stderr: ""
Apr 18 04:16:43.964: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-6131\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-mcdk2\n"
Apr 18 04:16:43.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 describe service agnhost-primary'
Apr 18 04:16:44.049: INFO: stderr: ""
Apr 18 04:16:44.049: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-6131\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.8.135\nIPs:               10.96.8.135\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.16.125.25:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 18 04:16:44.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 describe node apps-207'
Apr 18 04:16:44.205: INFO: stderr: ""
Apr 18 04:16:44.205: INFO: stdout: "Name:               apps-207\nRoles:              control-plane,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    cubectl.acornsoft.io/ansible_ssh_host=192.168.2.107\n                    cubectl.acornsoft.io/clusterid=kubernetes\n                    cubectl.acornsoft.io/role=master\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=apps-207\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"nfs.csi.k8s.io\":\"apps-207\"}\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 192.168.2.107/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.16.100.128\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 05 Apr 2023 06:51:40 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  apps-207\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 18 Apr 2023 04:16:38 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 11 Apr 2023 08:28:44 +0000   Tue, 11 Apr 2023 08:28:44 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 18 Apr 2023 04:16:40 +0000   Wed, 05 Apr 2023 06:51:37 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 18 Apr 2023 04:16:40 +0000   Wed, 05 Apr 2023 06:51:37 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 18 Apr 2023 04:16:40 +0000   Wed, 05 Apr 2023 06:51:37 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 18 Apr 2023 04:16:40 +0000   Wed, 05 Apr 2023 06:52:45 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.2.107\n  Hostname:    apps-207\nCapacity:\n  cpu:                8\n  ephemeral-storage:  470863224Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16177576Ki\n  pods:               110\nAllocatable:\n  cpu:                8\n  ephemeral-storage:  433947546520\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16075176Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 b0d6223a38a544839acd4cf388435bc4\n  System UUID:                cec01814-d21d-b211-aced-000000821800\n  Boot ID:                    1833bc94-b993-415c-a116-c45673d82f51\n  Kernel Version:             4.18.0-372.19.1.el8_6.x86_64\n  OS Image:                   Rocky Linux 8.7 (Green Obsidian)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.18\n  Kubelet Version:            v1.25.6\n  Kube-Proxy Version:         v1.25.6\nPodCIDR:                      172.16.1.0/24\nPodCIDRs:                     172.16.1.0/24\nNon-terminated Pods:          (28 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits   Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------   ---------------  -------------  ---\n  cocktail-addon              addon-manager-5d75c94878-q9nwx                             200m (2%)     200m (2%)    300Mi (1%)       600Mi (3%)     3d20h\n  cocktail-addon              agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w                100m (1%)     200m (2%)    128Mi (0%)       256Mi (1%)     3d20h\n  cocktail-addon              alertmanager-monitoring-kube-prometheus-alertmanager-0     200m (2%)     300m (3%)    150Mi (0%)       250Mi (1%)     3d20h\n  cocktail-addon              monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj       100m (1%)     200m (2%)    100Mi (0%)       200Mi (1%)     3d20h\n  cocktail-addon              monitoring-kube-state-metrics-7dddf6695f-l8mlh             100m (1%)     200m (2%)    64Mi (0%)        128Mi (0%)     3d20h\n  cocktail-addon              monitoring-prometheus-node-exporter-d9xr5                  200m (2%)     400m (5%)    128Mi (0%)       256Mi (1%)     3d20h\n  cocktail-addon              prometheus-monitoring-kube-prometheus-prometheus-0         600m (7%)     1100m (13%)  2098Mi (13%)     8242Mi (52%)   3d16h\n  cocktail-addon              promtail-fjjqt                                             0 (0%)        0 (0%)       0 (0%)           0 (0%)         3d20h\n  cocktail-system             cocktail-api-gateway-648577694-g7lzt                       500m (6%)     1 (12%)      512Mi (3%)       2Gi (13%)      3d21h\n  cocktail-system             cocktail-batch-server-5895cd6748-x5qsz                     100m (1%)     100m (1%)    100Mi (0%)       100Mi (0%)     3d21h\n  cocktail-system             cocktail-build-api-5d65b8dd6-8tb9g                         500m (6%)     500m (6%)    512Mi (3%)       512Mi (3%)     3d21h\n  cocktail-system             cocktail-build-queue-7855f6f4dd-vsc6p                      500m (6%)     800m (10%)   256Mi (1%)       1Gi (6%)       3d21h\n  cocktail-system             cocktail-cluster-api-6b5df5884f-4nbvz                      500m (6%)     1 (12%)      512Mi (3%)       1Gi (6%)       3d21h\n  cocktail-system             cocktail-dashboard-86844bcfbd-wbnzx                        300m (3%)     300m (3%)    300Mi (1%)       300Mi (1%)     3d21h\n  cocktail-system             cocktail-dashboard-proxy-5476f6847-ptzhj                   500m (6%)     1 (12%)      512Mi (3%)       1Gi (6%)       3d17h\n  cocktail-system             cocktail-dashboard-queue-5745c9f74c-2gks8                  500m (6%)     1 (12%)      512Mi (3%)       1Gi (6%)       3d16h\n  cocktail-system             cocktail-dashboard-session-9d746547b-gk8d5                 100m (1%)     200m (2%)    100Mi (0%)       300Mi (1%)     3d21h\n  cocktail-system             cocktail-monitoring-metric-collector-5695cb8669-mktvm      200m (2%)     300m (3%)    500Mi (3%)       600Mi (3%)     3d16h\n  kube-system                 calico-kube-controllers-74677b4c5f-rjqrf                   0 (0%)        0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 calico-node-nmmjb                                          250m (3%)     0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 coredns-7ffbbc99d-5xc7c                                    100m (1%)     0 (0%)       70Mi (0%)        170Mi (1%)     6d19h\n  kube-system                 csi-nfs-node-w5rjr                                         30m (0%)      0 (0%)       60Mi (0%)        500Mi (3%)     6d19h\n  kube-system                 kube-apiserver-apps-207                                    250m (3%)     0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 kube-controller-manager-apps-207                           200m (2%)     0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 kube-proxy-clw95                                           0 (0%)        0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 kube-scheduler-apps-207                                    100m (1%)     0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 metrics-server-7b879bf57b-vfp7l                            100m (1%)     0 (0%)       200Mi (1%)       0 (0%)         4d22h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn    0 (0%)        0 (0%)       0 (0%)           0 (0%)         15m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests      Limits\n  --------           --------      ------\n  cpu                6230m (77%)   8800m (110%)\n  memory             7114Mi (45%)  18558Mi (118%)\n  ephemeral-storage  0 (0%)        0 (0%)\n  hugepages-1Gi      0 (0%)        0 (0%)\n  hugepages-2Mi      0 (0%)        0 (0%)\nEvents:              <none>\n"
Apr 18 04:16:44.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 describe namespace kubectl-6131'
Apr 18 04:16:44.332: INFO: stderr: ""
Apr 18 04:16:44.332: INFO: stdout: "Name:         kubectl-6131\nLabels:       e2e-framework=kubectl\n              e2e-run=899f438d-034f-4171-9b0e-85efb09fb82d\n              kubernetes.io/metadata.name=kubectl-6131\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 04:16:44.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6131" for this suite. 04/18/23 04:16:44.337
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":41,"skipped":726,"failed":0}
------------------------------
â€¢ [4.903 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:16:39.46
    Apr 18 04:16:39.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 04:16:39.461
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:39.562
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:39.565
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Apr 18 04:16:39.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 create -f -'
    Apr 18 04:16:41.154: INFO: stderr: ""
    Apr 18 04:16:41.154: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Apr 18 04:16:41.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 create -f -'
    Apr 18 04:16:42.626: INFO: stderr: ""
    Apr 18 04:16:42.626: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/18/23 04:16:42.626
    Apr 18 04:16:43.746: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 04:16:43.746: INFO: Found 1 / 1
    Apr 18 04:16:43.746: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 18 04:16:43.765: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 04:16:43.765: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 18 04:16:43.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 describe pod agnhost-primary-mcdk2'
    Apr 18 04:16:43.876: INFO: stderr: ""
    Apr 18 04:16:43.876: INFO: stdout: "Name:             agnhost-primary-mcdk2\nNamespace:        kubectl-6131\nPriority:         0\nService Account:  default\nNode:             apps-208/192.168.2.108\nStart Time:       Tue, 18 Apr 2023 04:16:41 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 0238ac0928c4317e481dcb382958c3f704e038feef0d45ab3760a26f2e877001\n                  cni.projectcalico.org/podIP: 172.16.125.25/32\n                  cni.projectcalico.org/podIPs: 172.16.125.25/32\nStatus:           Running\nIP:               172.16.125.25\nIPs:\n  IP:           172.16.125.25\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://524d13359f57d7c15c7f9e191d98272e3cb27f2aa98b7f0e7c24e6a098d0241e\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 18 Apr 2023 04:16:43 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-95zbr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-95zbr:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 30s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 30s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-6131/agnhost-primary-mcdk2 to apps-208\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    0s    kubelet            Created container agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
    Apr 18 04:16:43.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 describe rc agnhost-primary'
    Apr 18 04:16:43.964: INFO: stderr: ""
    Apr 18 04:16:43.964: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-6131\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-mcdk2\n"
    Apr 18 04:16:43.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 describe service agnhost-primary'
    Apr 18 04:16:44.049: INFO: stderr: ""
    Apr 18 04:16:44.049: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-6131\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.96.8.135\nIPs:               10.96.8.135\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.16.125.25:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Apr 18 04:16:44.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 describe node apps-207'
    Apr 18 04:16:44.205: INFO: stderr: ""
    Apr 18 04:16:44.205: INFO: stdout: "Name:               apps-207\nRoles:              control-plane,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    cubectl.acornsoft.io/ansible_ssh_host=192.168.2.107\n                    cubectl.acornsoft.io/clusterid=kubernetes\n                    cubectl.acornsoft.io/role=master\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=apps-207\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node-role.kubernetes.io/master=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"nfs.csi.k8s.io\":\"apps-207\"}\n                    kubeadm.alpha.kubernetes.io/cri-socket: unix:///run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 192.168.2.107/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 172.16.100.128\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 05 Apr 2023 06:51:40 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  apps-207\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 18 Apr 2023 04:16:38 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 11 Apr 2023 08:28:44 +0000   Tue, 11 Apr 2023 08:28:44 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 18 Apr 2023 04:16:40 +0000   Wed, 05 Apr 2023 06:51:37 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 18 Apr 2023 04:16:40 +0000   Wed, 05 Apr 2023 06:51:37 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 18 Apr 2023 04:16:40 +0000   Wed, 05 Apr 2023 06:51:37 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 18 Apr 2023 04:16:40 +0000   Wed, 05 Apr 2023 06:52:45 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.2.107\n  Hostname:    apps-207\nCapacity:\n  cpu:                8\n  ephemeral-storage:  470863224Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16177576Ki\n  pods:               110\nAllocatable:\n  cpu:                8\n  ephemeral-storage:  433947546520\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16075176Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 b0d6223a38a544839acd4cf388435bc4\n  System UUID:                cec01814-d21d-b211-aced-000000821800\n  Boot ID:                    1833bc94-b993-415c-a116-c45673d82f51\n  Kernel Version:             4.18.0-372.19.1.el8_6.x86_64\n  OS Image:                   Rocky Linux 8.7 (Green Obsidian)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.18\n  Kubelet Version:            v1.25.6\n  Kube-Proxy Version:         v1.25.6\nPodCIDR:                      172.16.1.0/24\nPodCIDRs:                     172.16.1.0/24\nNon-terminated Pods:          (28 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits   Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------   ---------------  -------------  ---\n  cocktail-addon              addon-manager-5d75c94878-q9nwx                             200m (2%)     200m (2%)    300Mi (1%)       600Mi (3%)     3d20h\n  cocktail-addon              agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w                100m (1%)     200m (2%)    128Mi (0%)       256Mi (1%)     3d20h\n  cocktail-addon              alertmanager-monitoring-kube-prometheus-alertmanager-0     200m (2%)     300m (3%)    150Mi (0%)       250Mi (1%)     3d20h\n  cocktail-addon              monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj       100m (1%)     200m (2%)    100Mi (0%)       200Mi (1%)     3d20h\n  cocktail-addon              monitoring-kube-state-metrics-7dddf6695f-l8mlh             100m (1%)     200m (2%)    64Mi (0%)        128Mi (0%)     3d20h\n  cocktail-addon              monitoring-prometheus-node-exporter-d9xr5                  200m (2%)     400m (5%)    128Mi (0%)       256Mi (1%)     3d20h\n  cocktail-addon              prometheus-monitoring-kube-prometheus-prometheus-0         600m (7%)     1100m (13%)  2098Mi (13%)     8242Mi (52%)   3d16h\n  cocktail-addon              promtail-fjjqt                                             0 (0%)        0 (0%)       0 (0%)           0 (0%)         3d20h\n  cocktail-system             cocktail-api-gateway-648577694-g7lzt                       500m (6%)     1 (12%)      512Mi (3%)       2Gi (13%)      3d21h\n  cocktail-system             cocktail-batch-server-5895cd6748-x5qsz                     100m (1%)     100m (1%)    100Mi (0%)       100Mi (0%)     3d21h\n  cocktail-system             cocktail-build-api-5d65b8dd6-8tb9g                         500m (6%)     500m (6%)    512Mi (3%)       512Mi (3%)     3d21h\n  cocktail-system             cocktail-build-queue-7855f6f4dd-vsc6p                      500m (6%)     800m (10%)   256Mi (1%)       1Gi (6%)       3d21h\n  cocktail-system             cocktail-cluster-api-6b5df5884f-4nbvz                      500m (6%)     1 (12%)      512Mi (3%)       1Gi (6%)       3d21h\n  cocktail-system             cocktail-dashboard-86844bcfbd-wbnzx                        300m (3%)     300m (3%)    300Mi (1%)       300Mi (1%)     3d21h\n  cocktail-system             cocktail-dashboard-proxy-5476f6847-ptzhj                   500m (6%)     1 (12%)      512Mi (3%)       1Gi (6%)       3d17h\n  cocktail-system             cocktail-dashboard-queue-5745c9f74c-2gks8                  500m (6%)     1 (12%)      512Mi (3%)       1Gi (6%)       3d16h\n  cocktail-system             cocktail-dashboard-session-9d746547b-gk8d5                 100m (1%)     200m (2%)    100Mi (0%)       300Mi (1%)     3d21h\n  cocktail-system             cocktail-monitoring-metric-collector-5695cb8669-mktvm      200m (2%)     300m (3%)    500Mi (3%)       600Mi (3%)     3d16h\n  kube-system                 calico-kube-controllers-74677b4c5f-rjqrf                   0 (0%)        0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 calico-node-nmmjb                                          250m (3%)     0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 coredns-7ffbbc99d-5xc7c                                    100m (1%)     0 (0%)       70Mi (0%)        170Mi (1%)     6d19h\n  kube-system                 csi-nfs-node-w5rjr                                         30m (0%)      0 (0%)       60Mi (0%)        500Mi (3%)     6d19h\n  kube-system                 kube-apiserver-apps-207                                    250m (3%)     0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 kube-controller-manager-apps-207                           200m (2%)     0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 kube-proxy-clw95                                           0 (0%)        0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 kube-scheduler-apps-207                                    100m (1%)     0 (0%)       0 (0%)           0 (0%)         6d19h\n  kube-system                 metrics-server-7b879bf57b-vfp7l                            100m (1%)     0 (0%)       200Mi (1%)       0 (0%)         4d22h\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn    0 (0%)        0 (0%)       0 (0%)           0 (0%)         15m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests      Limits\n  --------           --------      ------\n  cpu                6230m (77%)   8800m (110%)\n  memory             7114Mi (45%)  18558Mi (118%)\n  ephemeral-storage  0 (0%)        0 (0%)\n  hugepages-1Gi      0 (0%)        0 (0%)\n  hugepages-2Mi      0 (0%)        0 (0%)\nEvents:              <none>\n"
    Apr 18 04:16:44.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6131 describe namespace kubectl-6131'
    Apr 18 04:16:44.332: INFO: stderr: ""
    Apr 18 04:16:44.332: INFO: stdout: "Name:         kubectl-6131\nLabels:       e2e-framework=kubectl\n              e2e-run=899f438d-034f-4171-9b0e-85efb09fb82d\n              kubernetes.io/metadata.name=kubectl-6131\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 04:16:44.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6131" for this suite. 04/18/23 04:16:44.337
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:16:44.364
Apr 18 04:16:44.364: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 04:16:44.365
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:44.495
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:44.499
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 04/18/23 04:16:44.504
STEP: Counting existing ResourceQuota 04/18/23 04:16:49.525
STEP: Creating a ResourceQuota 04/18/23 04:16:54.53
STEP: Ensuring resource quota status is calculated 04/18/23 04:16:54.573
STEP: Creating a Secret 04/18/23 04:16:56.578
STEP: Ensuring resource quota status captures secret creation 04/18/23 04:16:56.638
STEP: Deleting a secret 04/18/23 04:16:58.643
STEP: Ensuring resource quota status released usage 04/18/23 04:16:58.719
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 04:17:00.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-517" for this suite. 04/18/23 04:17:00.728
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":42,"skipped":729,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.430 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:16:44.364
    Apr 18 04:16:44.364: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 04:16:44.365
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:16:44.495
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:16:44.499
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 04/18/23 04:16:44.504
    STEP: Counting existing ResourceQuota 04/18/23 04:16:49.525
    STEP: Creating a ResourceQuota 04/18/23 04:16:54.53
    STEP: Ensuring resource quota status is calculated 04/18/23 04:16:54.573
    STEP: Creating a Secret 04/18/23 04:16:56.578
    STEP: Ensuring resource quota status captures secret creation 04/18/23 04:16:56.638
    STEP: Deleting a secret 04/18/23 04:16:58.643
    STEP: Ensuring resource quota status released usage 04/18/23 04:16:58.719
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 04:17:00.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-517" for this suite. 04/18/23 04:17:00.728
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:17:00.795
Apr 18 04:17:00.795: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 04:17:00.796
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:00.883
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:00.886
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 04/18/23 04:17:00.888
Apr 18 04:17:00.889: INFO: Creating e2e-svc-a-2gdpn
Apr 18 04:17:01.042: INFO: Creating e2e-svc-b-2r7dh
Apr 18 04:17:01.155: INFO: Creating e2e-svc-c-gqfwg
STEP: deleting service collection 04/18/23 04:17:01.314
Apr 18 04:17:01.760: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 04:17:01.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3835" for this suite. 04/18/23 04:17:01.764
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":43,"skipped":765,"failed":0}
------------------------------
â€¢ [0.979 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:17:00.795
    Apr 18 04:17:00.795: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 04:17:00.796
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:00.883
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:00.886
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 04/18/23 04:17:00.888
    Apr 18 04:17:00.889: INFO: Creating e2e-svc-a-2gdpn
    Apr 18 04:17:01.042: INFO: Creating e2e-svc-b-2r7dh
    Apr 18 04:17:01.155: INFO: Creating e2e-svc-c-gqfwg
    STEP: deleting service collection 04/18/23 04:17:01.314
    Apr 18 04:17:01.760: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 04:17:01.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3835" for this suite. 04/18/23 04:17:01.764
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:17:01.776
Apr 18 04:17:01.776: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 04:17:01.777
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:02.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:02.049
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-64e384a4-f5c1-4efb-aaad-0c9204d9bc33 04/18/23 04:17:02.052
STEP: Creating a pod to test consume configMaps 04/18/23 04:17:02.13
Apr 18 04:17:02.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49" in namespace "configmap-9435" to be "Succeeded or Failed"
Apr 18 04:17:02.202: INFO: Pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49": Phase="Pending", Reason="", readiness=false. Elapsed: 46.055703ms
Apr 18 04:17:04.261: INFO: Pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104770307s
Apr 18 04:17:06.241: INFO: Pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49": Phase="Running", Reason="", readiness=false. Elapsed: 4.08434639s
Apr 18 04:17:08.216: INFO: Pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059931788s
STEP: Saw pod success 04/18/23 04:17:08.216
Apr 18 04:17:08.216: INFO: Pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49" satisfied condition "Succeeded or Failed"
Apr 18 04:17:08.219: INFO: Trying to get logs from node apps-208 pod pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 04:17:08.225
Apr 18 04:17:08.342: INFO: Waiting for pod pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49 to disappear
Apr 18 04:17:08.345: INFO: Pod pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 04:17:08.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9435" for this suite. 04/18/23 04:17:08.366
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":44,"skipped":799,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.613 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:17:01.776
    Apr 18 04:17:01.776: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 04:17:01.777
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:02.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:02.049
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-64e384a4-f5c1-4efb-aaad-0c9204d9bc33 04/18/23 04:17:02.052
    STEP: Creating a pod to test consume configMaps 04/18/23 04:17:02.13
    Apr 18 04:17:02.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49" in namespace "configmap-9435" to be "Succeeded or Failed"
    Apr 18 04:17:02.202: INFO: Pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49": Phase="Pending", Reason="", readiness=false. Elapsed: 46.055703ms
    Apr 18 04:17:04.261: INFO: Pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104770307s
    Apr 18 04:17:06.241: INFO: Pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49": Phase="Running", Reason="", readiness=false. Elapsed: 4.08434639s
    Apr 18 04:17:08.216: INFO: Pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059931788s
    STEP: Saw pod success 04/18/23 04:17:08.216
    Apr 18 04:17:08.216: INFO: Pod "pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49" satisfied condition "Succeeded or Failed"
    Apr 18 04:17:08.219: INFO: Trying to get logs from node apps-208 pod pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 04:17:08.225
    Apr 18 04:17:08.342: INFO: Waiting for pod pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49 to disappear
    Apr 18 04:17:08.345: INFO: Pod pod-configmaps-d3ecdc41-cdf4-44e9-aef6-99b268ed5f49 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 04:17:08.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9435" for this suite. 04/18/23 04:17:08.366
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:17:08.391
Apr 18 04:17:08.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 04:17:08.392
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:08.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:08.501
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-e133f4ba-a837-43b2-a227-e2b6d9da3f8c 04/18/23 04:17:08.525
STEP: Creating the pod 04/18/23 04:17:08.539
Apr 18 04:17:08.562: INFO: Waiting up to 5m0s for pod "pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3" in namespace "configmap-2408" to be "running and ready"
Apr 18 04:17:08.565: INFO: Pod "pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.638115ms
Apr 18 04:17:08.565: INFO: The phase of Pod pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:17:10.574: INFO: Pod "pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011757367s
Apr 18 04:17:10.574: INFO: The phase of Pod pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:17:12.569: INFO: Pod "pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3": Phase="Running", Reason="", readiness=true. Elapsed: 4.006625615s
Apr 18 04:17:12.569: INFO: The phase of Pod pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3 is Running (Ready = true)
Apr 18 04:17:12.569: INFO: Pod "pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-e133f4ba-a837-43b2-a227-e2b6d9da3f8c 04/18/23 04:17:12.68
STEP: waiting to observe update in volume 04/18/23 04:17:12.7
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 04:17:14.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2408" for this suite. 04/18/23 04:17:14.851
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":45,"skipped":829,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.529 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:17:08.391
    Apr 18 04:17:08.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 04:17:08.392
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:08.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:08.501
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-e133f4ba-a837-43b2-a227-e2b6d9da3f8c 04/18/23 04:17:08.525
    STEP: Creating the pod 04/18/23 04:17:08.539
    Apr 18 04:17:08.562: INFO: Waiting up to 5m0s for pod "pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3" in namespace "configmap-2408" to be "running and ready"
    Apr 18 04:17:08.565: INFO: Pod "pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.638115ms
    Apr 18 04:17:08.565: INFO: The phase of Pod pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:17:10.574: INFO: Pod "pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011757367s
    Apr 18 04:17:10.574: INFO: The phase of Pod pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:17:12.569: INFO: Pod "pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3": Phase="Running", Reason="", readiness=true. Elapsed: 4.006625615s
    Apr 18 04:17:12.569: INFO: The phase of Pod pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3 is Running (Ready = true)
    Apr 18 04:17:12.569: INFO: Pod "pod-configmaps-3372a7df-530b-4367-ba54-34e0b93bf4f3" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-e133f4ba-a837-43b2-a227-e2b6d9da3f8c 04/18/23 04:17:12.68
    STEP: waiting to observe update in volume 04/18/23 04:17:12.7
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 04:17:14.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2408" for this suite. 04/18/23 04:17:14.851
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:17:14.921
Apr 18 04:17:14.922: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 04:17:14.923
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:14.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:15
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 04/18/23 04:17:15.003
Apr 18 04:17:15.261: INFO: Waiting up to 5m0s for pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869" in namespace "emptydir-849" to be "Succeeded or Failed"
Apr 18 04:17:15.265: INFO: Pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869": Phase="Pending", Reason="", readiness=false. Elapsed: 3.085865ms
Apr 18 04:17:17.270: INFO: Pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008141965s
Apr 18 04:17:19.269: INFO: Pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869": Phase="Running", Reason="", readiness=false. Elapsed: 4.007639166s
Apr 18 04:17:21.292: INFO: Pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030366185s
STEP: Saw pod success 04/18/23 04:17:21.292
Apr 18 04:17:21.292: INFO: Pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869" satisfied condition "Succeeded or Failed"
Apr 18 04:17:21.308: INFO: Trying to get logs from node apps-208 pod pod-af2070f8-9c3f-4877-bc0f-f58346e70869 container test-container: <nil>
STEP: delete the pod 04/18/23 04:17:21.389
Apr 18 04:17:22.077: INFO: Waiting for pod pod-af2070f8-9c3f-4877-bc0f-f58346e70869 to disappear
Apr 18 04:17:22.080: INFO: Pod pod-af2070f8-9c3f-4877-bc0f-f58346e70869 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 04:17:22.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-849" for this suite. 04/18/23 04:17:22.085
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":46,"skipped":848,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.172 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:17:14.921
    Apr 18 04:17:14.922: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 04:17:14.923
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:14.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:15
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/18/23 04:17:15.003
    Apr 18 04:17:15.261: INFO: Waiting up to 5m0s for pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869" in namespace "emptydir-849" to be "Succeeded or Failed"
    Apr 18 04:17:15.265: INFO: Pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869": Phase="Pending", Reason="", readiness=false. Elapsed: 3.085865ms
    Apr 18 04:17:17.270: INFO: Pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008141965s
    Apr 18 04:17:19.269: INFO: Pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869": Phase="Running", Reason="", readiness=false. Elapsed: 4.007639166s
    Apr 18 04:17:21.292: INFO: Pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030366185s
    STEP: Saw pod success 04/18/23 04:17:21.292
    Apr 18 04:17:21.292: INFO: Pod "pod-af2070f8-9c3f-4877-bc0f-f58346e70869" satisfied condition "Succeeded or Failed"
    Apr 18 04:17:21.308: INFO: Trying to get logs from node apps-208 pod pod-af2070f8-9c3f-4877-bc0f-f58346e70869 container test-container: <nil>
    STEP: delete the pod 04/18/23 04:17:21.389
    Apr 18 04:17:22.077: INFO: Waiting for pod pod-af2070f8-9c3f-4877-bc0f-f58346e70869 to disappear
    Apr 18 04:17:22.080: INFO: Pod pod-af2070f8-9c3f-4877-bc0f-f58346e70869 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 04:17:22.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-849" for this suite. 04/18/23 04:17:22.085
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:17:22.094
Apr 18 04:17:22.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 04:17:22.095
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:22.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:22.251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 04:17:22.343
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 04:17:23.285
STEP: Deploying the webhook pod 04/18/23 04:17:23.309
STEP: Wait for the deployment to be ready 04/18/23 04:17:23.459
Apr 18 04:17:23.476: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 18 04:17:25.544: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 17, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 17, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 17, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 17, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 04:17:27.548
STEP: Verifying the service has paired with the endpoint 04/18/23 04:17:27.668
Apr 18 04:17:28.668: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 04/18/23 04:17:28.716
STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 04:17:28.766
STEP: Updating a validating webhook configuration's rules to not include the create operation 04/18/23 04:17:28.774
STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 04:17:28.841
STEP: Patching a validating webhook configuration's rules to include the create operation 04/18/23 04:17:28.89
STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 04:17:28.917
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:17:29.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1658" for this suite. 04/18/23 04:17:29.039
STEP: Destroying namespace "webhook-1658-markers" for this suite. 04/18/23 04:17:29.071
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":47,"skipped":857,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.402 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:17:22.094
    Apr 18 04:17:22.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 04:17:22.095
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:22.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:22.251
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 04:17:22.343
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 04:17:23.285
    STEP: Deploying the webhook pod 04/18/23 04:17:23.309
    STEP: Wait for the deployment to be ready 04/18/23 04:17:23.459
    Apr 18 04:17:23.476: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 18 04:17:25.544: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 17, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 17, 23, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 17, 23, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 17, 23, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 04:17:27.548
    STEP: Verifying the service has paired with the endpoint 04/18/23 04:17:27.668
    Apr 18 04:17:28.668: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 04/18/23 04:17:28.716
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 04:17:28.766
    STEP: Updating a validating webhook configuration's rules to not include the create operation 04/18/23 04:17:28.774
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 04:17:28.841
    STEP: Patching a validating webhook configuration's rules to include the create operation 04/18/23 04:17:28.89
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 04:17:28.917
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:17:29.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1658" for this suite. 04/18/23 04:17:29.039
    STEP: Destroying namespace "webhook-1658-markers" for this suite. 04/18/23 04:17:29.071
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:17:29.496
Apr 18 04:17:29.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename job 04/18/23 04:17:29.498
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:29.674
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:29.677
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 04/18/23 04:17:29.752
STEP: Ensuring active pods == parallelism 04/18/23 04:17:29.775
STEP: Orphaning one of the Job's Pods 04/18/23 04:17:35.78
Apr 18 04:17:36.318: INFO: Successfully updated pod "adopt-release-5skmd"
STEP: Checking that the Job readopts the Pod 04/18/23 04:17:36.318
Apr 18 04:17:36.318: INFO: Waiting up to 15m0s for pod "adopt-release-5skmd" in namespace "job-9077" to be "adopted"
Apr 18 04:17:36.321: INFO: Pod "adopt-release-5skmd": Phase="Running", Reason="", readiness=true. Elapsed: 3.469993ms
Apr 18 04:17:38.327: INFO: Pod "adopt-release-5skmd": Phase="Running", Reason="", readiness=true. Elapsed: 2.009430732s
Apr 18 04:17:38.327: INFO: Pod "adopt-release-5skmd" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 04/18/23 04:17:38.327
Apr 18 04:17:38.875: INFO: Successfully updated pod "adopt-release-5skmd"
STEP: Checking that the Job releases the Pod 04/18/23 04:17:38.875
Apr 18 04:17:38.875: INFO: Waiting up to 15m0s for pod "adopt-release-5skmd" in namespace "job-9077" to be "released"
Apr 18 04:17:38.879: INFO: Pod "adopt-release-5skmd": Phase="Running", Reason="", readiness=true. Elapsed: 4.331485ms
Apr 18 04:17:40.933: INFO: Pod "adopt-release-5skmd": Phase="Running", Reason="", readiness=true. Elapsed: 2.057837179s
Apr 18 04:17:40.933: INFO: Pod "adopt-release-5skmd" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 04:17:40.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9077" for this suite. 04/18/23 04:17:40.938
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":48,"skipped":872,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.495 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:17:29.496
    Apr 18 04:17:29.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename job 04/18/23 04:17:29.498
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:29.674
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:29.677
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 04/18/23 04:17:29.752
    STEP: Ensuring active pods == parallelism 04/18/23 04:17:29.775
    STEP: Orphaning one of the Job's Pods 04/18/23 04:17:35.78
    Apr 18 04:17:36.318: INFO: Successfully updated pod "adopt-release-5skmd"
    STEP: Checking that the Job readopts the Pod 04/18/23 04:17:36.318
    Apr 18 04:17:36.318: INFO: Waiting up to 15m0s for pod "adopt-release-5skmd" in namespace "job-9077" to be "adopted"
    Apr 18 04:17:36.321: INFO: Pod "adopt-release-5skmd": Phase="Running", Reason="", readiness=true. Elapsed: 3.469993ms
    Apr 18 04:17:38.327: INFO: Pod "adopt-release-5skmd": Phase="Running", Reason="", readiness=true. Elapsed: 2.009430732s
    Apr 18 04:17:38.327: INFO: Pod "adopt-release-5skmd" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 04/18/23 04:17:38.327
    Apr 18 04:17:38.875: INFO: Successfully updated pod "adopt-release-5skmd"
    STEP: Checking that the Job releases the Pod 04/18/23 04:17:38.875
    Apr 18 04:17:38.875: INFO: Waiting up to 15m0s for pod "adopt-release-5skmd" in namespace "job-9077" to be "released"
    Apr 18 04:17:38.879: INFO: Pod "adopt-release-5skmd": Phase="Running", Reason="", readiness=true. Elapsed: 4.331485ms
    Apr 18 04:17:40.933: INFO: Pod "adopt-release-5skmd": Phase="Running", Reason="", readiness=true. Elapsed: 2.057837179s
    Apr 18 04:17:40.933: INFO: Pod "adopt-release-5skmd" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 04:17:40.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9077" for this suite. 04/18/23 04:17:40.938
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:17:40.992
Apr 18 04:17:40.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 04:17:40.993
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:41.071
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:41.075
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-62e3c221-66d2-436c-9f31-5be9cabbff9d 04/18/23 04:17:41.078
STEP: Creating a pod to test consume secrets 04/18/23 04:17:41.099
Apr 18 04:17:41.122: INFO: Waiting up to 5m0s for pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046" in namespace "secrets-4865" to be "Succeeded or Failed"
Apr 18 04:17:41.234: INFO: Pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046": Phase="Pending", Reason="", readiness=false. Elapsed: 111.671961ms
Apr 18 04:17:43.239: INFO: Pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046": Phase="Pending", Reason="", readiness=false. Elapsed: 2.116423197s
Apr 18 04:17:45.239: INFO: Pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046": Phase="Pending", Reason="", readiness=false. Elapsed: 4.116157398s
Apr 18 04:17:47.258: INFO: Pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.135778506s
STEP: Saw pod success 04/18/23 04:17:47.258
Apr 18 04:17:47.258: INFO: Pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046" satisfied condition "Succeeded or Failed"
Apr 18 04:17:47.262: INFO: Trying to get logs from node apps-208 pod pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 04:17:47.292
Apr 18 04:17:47.454: INFO: Waiting for pod pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046 to disappear
Apr 18 04:17:47.458: INFO: Pod pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 04:17:47.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4865" for this suite. 04/18/23 04:17:47.479
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":49,"skipped":888,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.557 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:17:40.992
    Apr 18 04:17:40.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 04:17:40.993
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:41.071
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:41.075
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-62e3c221-66d2-436c-9f31-5be9cabbff9d 04/18/23 04:17:41.078
    STEP: Creating a pod to test consume secrets 04/18/23 04:17:41.099
    Apr 18 04:17:41.122: INFO: Waiting up to 5m0s for pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046" in namespace "secrets-4865" to be "Succeeded or Failed"
    Apr 18 04:17:41.234: INFO: Pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046": Phase="Pending", Reason="", readiness=false. Elapsed: 111.671961ms
    Apr 18 04:17:43.239: INFO: Pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046": Phase="Pending", Reason="", readiness=false. Elapsed: 2.116423197s
    Apr 18 04:17:45.239: INFO: Pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046": Phase="Pending", Reason="", readiness=false. Elapsed: 4.116157398s
    Apr 18 04:17:47.258: INFO: Pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.135778506s
    STEP: Saw pod success 04/18/23 04:17:47.258
    Apr 18 04:17:47.258: INFO: Pod "pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046" satisfied condition "Succeeded or Failed"
    Apr 18 04:17:47.262: INFO: Trying to get logs from node apps-208 pod pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 04:17:47.292
    Apr 18 04:17:47.454: INFO: Waiting for pod pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046 to disappear
    Apr 18 04:17:47.458: INFO: Pod pod-secrets-cc80bfe9-f207-4c65-adfd-3fc6b1b5a046 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 04:17:47.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4865" for this suite. 04/18/23 04:17:47.479
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:17:47.55
Apr 18 04:17:47.550: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename proxy 04/18/23 04:17:47.551
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:47.722
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:47.725
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 04/18/23 04:17:47.842
STEP: creating replication controller proxy-service-wf5kr in namespace proxy-4487 04/18/23 04:17:47.843
I0418 04:17:47.946180      22 runners.go:193] Created replication controller with name: proxy-service-wf5kr, namespace: proxy-4487, replica count: 1
I0418 04:17:48.997214      22 runners.go:193] proxy-service-wf5kr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 04:17:49.997515      22 runners.go:193] proxy-service-wf5kr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 04:17:50.998380      22 runners.go:193] proxy-service-wf5kr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0418 04:17:51.999291      22 runners.go:193] proxy-service-wf5kr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0418 04:17:52.999524      22 runners.go:193] proxy-service-wf5kr Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 04:17:53.013: INFO: setup took 5.213784966s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/18/23 04:17:53.013
Apr 18 04:17:53.018: INFO: (0) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.254764ms)
Apr 18 04:17:53.018: INFO: (0) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.196127ms)
Apr 18 04:17:53.018: INFO: (0) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.582886ms)
Apr 18 04:17:53.019: INFO: (0) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 5.09738ms)
Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 6.317391ms)
Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 6.342278ms)
Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 6.690909ms)
Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 6.498187ms)
Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 6.498029ms)
Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 6.426712ms)
Apr 18 04:17:53.023: INFO: (0) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 8.971731ms)
Apr 18 04:17:53.024: INFO: (0) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 10.002398ms)
Apr 18 04:17:53.024: INFO: (0) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 10.319492ms)
Apr 18 04:17:53.024: INFO: (0) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 10.11808ms)
Apr 18 04:17:53.024: INFO: (0) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 10.211085ms)
Apr 18 04:17:53.026: INFO: (0) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 11.892261ms)
Apr 18 04:17:53.029: INFO: (1) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.207652ms)
Apr 18 04:17:53.030: INFO: (1) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.781038ms)
Apr 18 04:17:53.030: INFO: (1) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 2.875788ms)
Apr 18 04:17:53.030: INFO: (1) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 4.514905ms)
Apr 18 04:17:53.030: INFO: (1) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.048775ms)
Apr 18 04:17:53.030: INFO: (1) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 3.978435ms)
Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 4.449725ms)
Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.517121ms)
Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.051995ms)
Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.03222ms)
Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.243125ms)
Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.720336ms)
Apr 18 04:17:53.032: INFO: (1) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.17181ms)
Apr 18 04:17:53.032: INFO: (1) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.586596ms)
Apr 18 04:17:53.032: INFO: (1) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 6.213346ms)
Apr 18 04:17:53.032: INFO: (1) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 5.652324ms)
Apr 18 04:17:53.037: INFO: (2) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 5.056683ms)
Apr 18 04:17:53.038: INFO: (2) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 5.384201ms)
Apr 18 04:17:53.038: INFO: (2) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 5.928173ms)
Apr 18 04:17:53.038: INFO: (2) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 6.026718ms)
Apr 18 04:17:53.038: INFO: (2) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 5.995019ms)
Apr 18 04:17:53.039: INFO: (2) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 5.924035ms)
Apr 18 04:17:53.039: INFO: (2) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.751727ms)
Apr 18 04:17:53.039: INFO: (2) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 6.848425ms)
Apr 18 04:17:53.039: INFO: (2) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 6.802629ms)
Apr 18 04:17:53.040: INFO: (2) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 7.600226ms)
Apr 18 04:17:53.040: INFO: (2) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 7.481198ms)
Apr 18 04:17:53.040: INFO: (2) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 7.58433ms)
Apr 18 04:17:53.041: INFO: (2) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 8.107088ms)
Apr 18 04:17:53.041: INFO: (2) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 8.078365ms)
Apr 18 04:17:53.041: INFO: (2) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 8.501503ms)
Apr 18 04:17:53.041: INFO: (2) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 8.65301ms)
Apr 18 04:17:53.044: INFO: (3) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 3.000877ms)
Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.07385ms)
Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.092072ms)
Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.307104ms)
Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.221255ms)
Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.592397ms)
Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.792009ms)
Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.896467ms)
Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 3.898763ms)
Apr 18 04:17:53.046: INFO: (3) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.256616ms)
Apr 18 04:17:53.046: INFO: (3) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 4.93207ms)
Apr 18 04:17:53.047: INFO: (3) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.932911ms)
Apr 18 04:17:53.047: INFO: (3) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.17485ms)
Apr 18 04:17:53.047: INFO: (3) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.34611ms)
Apr 18 04:17:53.047: INFO: (3) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.6907ms)
Apr 18 04:17:53.047: INFO: (3) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.743865ms)
Apr 18 04:17:53.051: INFO: (4) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.279041ms)
Apr 18 04:17:53.051: INFO: (4) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.808577ms)
Apr 18 04:17:53.051: INFO: (4) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.557344ms)
Apr 18 04:17:53.051: INFO: (4) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.74607ms)
Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.163672ms)
Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 4.337531ms)
Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.30079ms)
Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.571894ms)
Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 4.544804ms)
Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.688404ms)
Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 5.103575ms)
Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.123916ms)
Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.142902ms)
Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.474148ms)
Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.676207ms)
Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 5.98825ms)
Apr 18 04:17:53.064: INFO: (5) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 10.364183ms)
Apr 18 04:17:53.064: INFO: (5) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 10.47018ms)
Apr 18 04:17:53.064: INFO: (5) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 10.334546ms)
Apr 18 04:17:53.064: INFO: (5) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 10.154027ms)
Apr 18 04:17:53.065: INFO: (5) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 10.875265ms)
Apr 18 04:17:53.065: INFO: (5) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 10.818251ms)
Apr 18 04:17:53.065: INFO: (5) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 11.178422ms)
Apr 18 04:17:53.065: INFO: (5) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 11.532983ms)
Apr 18 04:17:53.065: INFO: (5) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 11.819291ms)
Apr 18 04:17:53.066: INFO: (5) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 12.081843ms)
Apr 18 04:17:53.066: INFO: (5) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 11.967244ms)
Apr 18 04:17:53.067: INFO: (5) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 12.70467ms)
Apr 18 04:17:53.067: INFO: (5) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 12.924845ms)
Apr 18 04:17:53.067: INFO: (5) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 12.931721ms)
Apr 18 04:17:53.068: INFO: (5) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 13.954774ms)
Apr 18 04:17:53.068: INFO: (5) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 14.193198ms)
Apr 18 04:17:53.071: INFO: (6) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.507878ms)
Apr 18 04:17:53.072: INFO: (6) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.153911ms)
Apr 18 04:17:53.072: INFO: (6) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 2.878448ms)
Apr 18 04:17:53.072: INFO: (6) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 2.396318ms)
Apr 18 04:17:53.074: INFO: (6) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 6.085743ms)
Apr 18 04:17:53.074: INFO: (6) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 5.711272ms)
Apr 18 04:17:53.074: INFO: (6) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 5.282095ms)
Apr 18 04:17:53.075: INFO: (6) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 6.002291ms)
Apr 18 04:17:53.076: INFO: (6) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 7.294997ms)
Apr 18 04:17:53.076: INFO: (6) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 6.978137ms)
Apr 18 04:17:53.111: INFO: (6) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 41.43019ms)
Apr 18 04:17:53.111: INFO: (6) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 42.493948ms)
Apr 18 04:17:53.111: INFO: (6) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 42.140208ms)
Apr 18 04:17:53.111: INFO: (6) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 42.811929ms)
Apr 18 04:17:53.112: INFO: (6) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 43.423293ms)
Apr 18 04:17:53.141: INFO: (6) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 71.767764ms)
Apr 18 04:17:53.144: INFO: (7) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.180766ms)
Apr 18 04:17:53.145: INFO: (7) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.486984ms)
Apr 18 04:17:53.145: INFO: (7) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.487133ms)
Apr 18 04:17:53.145: INFO: (7) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.506881ms)
Apr 18 04:17:53.145: INFO: (7) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.015689ms)
Apr 18 04:17:53.146: INFO: (7) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.154134ms)
Apr 18 04:17:53.146: INFO: (7) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 4.446086ms)
Apr 18 04:17:53.146: INFO: (7) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 4.620951ms)
Apr 18 04:17:53.147: INFO: (7) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.409333ms)
Apr 18 04:17:53.149: INFO: (7) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 8.007434ms)
Apr 18 04:17:53.150: INFO: (7) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 8.140106ms)
Apr 18 04:17:53.150: INFO: (7) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 8.201759ms)
Apr 18 04:17:53.150: INFO: (7) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 8.430146ms)
Apr 18 04:17:53.150: INFO: (7) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 8.542205ms)
Apr 18 04:17:53.150: INFO: (7) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 9.042139ms)
Apr 18 04:17:53.151: INFO: (7) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 9.459541ms)
Apr 18 04:17:53.154: INFO: (8) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.460451ms)
Apr 18 04:17:53.155: INFO: (8) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.941476ms)
Apr 18 04:17:53.155: INFO: (8) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.221503ms)
Apr 18 04:17:53.155: INFO: (8) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.503676ms)
Apr 18 04:17:53.155: INFO: (8) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.715901ms)
Apr 18 04:17:53.155: INFO: (8) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.197317ms)
Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.952116ms)
Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.247917ms)
Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 5.548573ms)
Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.485618ms)
Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 5.269013ms)
Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 5.475932ms)
Apr 18 04:17:53.157: INFO: (8) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.685951ms)
Apr 18 04:17:53.157: INFO: (8) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.835749ms)
Apr 18 04:17:53.158: INFO: (8) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 6.563291ms)
Apr 18 04:17:53.158: INFO: (8) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.639426ms)
Apr 18 04:17:53.161: INFO: (9) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.053889ms)
Apr 18 04:17:53.161: INFO: (9) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.128362ms)
Apr 18 04:17:53.162: INFO: (9) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 3.83561ms)
Apr 18 04:17:53.162: INFO: (9) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.0326ms)
Apr 18 04:17:53.162: INFO: (9) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.079518ms)
Apr 18 04:17:53.162: INFO: (9) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.442994ms)
Apr 18 04:17:53.163: INFO: (9) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.075403ms)
Apr 18 04:17:53.163: INFO: (9) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.096042ms)
Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 5.70931ms)
Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 5.723832ms)
Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.858143ms)
Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.929956ms)
Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 5.702818ms)
Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 5.753507ms)
Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.060287ms)
Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 6.523779ms)
Apr 18 04:17:53.168: INFO: (10) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.34723ms)
Apr 18 04:17:53.168: INFO: (10) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 3.524132ms)
Apr 18 04:17:53.168: INFO: (10) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 3.064673ms)
Apr 18 04:17:53.169: INFO: (10) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.120521ms)
Apr 18 04:17:53.169: INFO: (10) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.134838ms)
Apr 18 04:17:53.169: INFO: (10) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.651999ms)
Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.740353ms)
Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.180558ms)
Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.622574ms)
Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.824541ms)
Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 4.50737ms)
Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.284653ms)
Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.431739ms)
Apr 18 04:17:53.171: INFO: (10) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.602714ms)
Apr 18 04:17:53.171: INFO: (10) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.156206ms)
Apr 18 04:17:53.171: INFO: (10) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 5.412744ms)
Apr 18 04:17:53.175: INFO: (11) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.823854ms)
Apr 18 04:17:53.175: INFO: (11) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.827502ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.027407ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.857573ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.068088ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.982898ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.227885ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.223189ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.167483ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 4.30078ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.668607ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 4.686628ms)
Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 4.914364ms)
Apr 18 04:17:53.177: INFO: (11) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.183073ms)
Apr 18 04:17:53.177: INFO: (11) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.402315ms)
Apr 18 04:17:53.178: INFO: (11) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.50583ms)
Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.662986ms)
Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.61591ms)
Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.704236ms)
Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.650424ms)
Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.847572ms)
Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.911019ms)
Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.275989ms)
Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.373563ms)
Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.511434ms)
Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.597456ms)
Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.98582ms)
Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 4.877689ms)
Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 4.856926ms)
Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.057329ms)
Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.01412ms)
Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.256644ms)
Apr 18 04:17:53.187: INFO: (13) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.103032ms)
Apr 18 04:17:53.187: INFO: (13) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.145783ms)
Apr 18 04:17:53.187: INFO: (13) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.099806ms)
Apr 18 04:17:53.187: INFO: (13) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 3.451104ms)
Apr 18 04:17:53.187: INFO: (13) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.540878ms)
Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.905766ms)
Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.831357ms)
Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 3.984371ms)
Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 4.217556ms)
Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.294848ms)
Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.348515ms)
Apr 18 04:17:53.189: INFO: (13) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 4.87713ms)
Apr 18 04:17:53.189: INFO: (13) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.290299ms)
Apr 18 04:17:53.189: INFO: (13) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.585183ms)
Apr 18 04:17:53.189: INFO: (13) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.641857ms)
Apr 18 04:17:53.190: INFO: (13) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 6.318077ms)
Apr 18 04:17:53.193: INFO: (14) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.146806ms)
Apr 18 04:17:53.194: INFO: (14) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.31053ms)
Apr 18 04:17:53.194: INFO: (14) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.414625ms)
Apr 18 04:17:53.194: INFO: (14) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.416152ms)
Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.505891ms)
Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.48578ms)
Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 4.548764ms)
Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.498286ms)
Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.898206ms)
Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 5.058874ms)
Apr 18 04:17:53.196: INFO: (14) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 5.053212ms)
Apr 18 04:17:53.196: INFO: (14) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.805087ms)
Apr 18 04:17:53.196: INFO: (14) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.006877ms)
Apr 18 04:17:53.197: INFO: (14) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 6.479357ms)
Apr 18 04:17:53.197: INFO: (14) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 6.735844ms)
Apr 18 04:17:53.198: INFO: (14) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 7.05286ms)
Apr 18 04:17:53.201: INFO: (15) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.448649ms)
Apr 18 04:17:53.201: INFO: (15) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.577941ms)
Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.821719ms)
Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.683807ms)
Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 3.993283ms)
Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.250842ms)
Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.089675ms)
Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.173076ms)
Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.423914ms)
Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.55896ms)
Apr 18 04:17:53.203: INFO: (15) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.608577ms)
Apr 18 04:17:53.203: INFO: (15) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.970441ms)
Apr 18 04:17:53.203: INFO: (15) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 4.875107ms)
Apr 18 04:17:53.203: INFO: (15) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.200468ms)
Apr 18 04:17:53.203: INFO: (15) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.052085ms)
Apr 18 04:17:53.204: INFO: (15) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.655592ms)
Apr 18 04:17:53.207: INFO: (16) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.023216ms)
Apr 18 04:17:53.207: INFO: (16) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.138035ms)
Apr 18 04:17:53.207: INFO: (16) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.359848ms)
Apr 18 04:17:53.207: INFO: (16) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.473713ms)
Apr 18 04:17:53.208: INFO: (16) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.741038ms)
Apr 18 04:17:53.208: INFO: (16) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.88045ms)
Apr 18 04:17:53.209: INFO: (16) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.181799ms)
Apr 18 04:17:53.209: INFO: (16) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.19576ms)
Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.646706ms)
Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 5.902879ms)
Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 5.745182ms)
Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 5.898416ms)
Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 5.894065ms)
Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 6.228826ms)
Apr 18 04:17:53.211: INFO: (16) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.991243ms)
Apr 18 04:17:53.211: INFO: (16) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 7.342034ms)
Apr 18 04:17:53.214: INFO: (17) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.09844ms)
Apr 18 04:17:53.215: INFO: (17) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 3.109374ms)
Apr 18 04:17:53.215: INFO: (17) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.173081ms)
Apr 18 04:17:53.215: INFO: (17) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.566321ms)
Apr 18 04:17:53.215: INFO: (17) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.268193ms)
Apr 18 04:17:53.215: INFO: (17) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 3.848666ms)
Apr 18 04:17:53.216: INFO: (17) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.790677ms)
Apr 18 04:17:53.216: INFO: (17) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.157231ms)
Apr 18 04:17:53.216: INFO: (17) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.864743ms)
Apr 18 04:17:53.216: INFO: (17) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.37613ms)
Apr 18 04:17:53.216: INFO: (17) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.400093ms)
Apr 18 04:17:53.217: INFO: (17) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.020005ms)
Apr 18 04:17:53.217: INFO: (17) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 4.957705ms)
Apr 18 04:17:53.217: INFO: (17) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.649083ms)
Apr 18 04:17:53.217: INFO: (17) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.641063ms)
Apr 18 04:17:53.218: INFO: (17) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.114981ms)
Apr 18 04:17:53.221: INFO: (18) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 2.829712ms)
Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.493164ms)
Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.055263ms)
Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.840645ms)
Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.661319ms)
Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 2.82052ms)
Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.455181ms)
Apr 18 04:17:53.223: INFO: (18) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.175649ms)
Apr 18 04:17:53.223: INFO: (18) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.472062ms)
Apr 18 04:17:53.223: INFO: (18) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.180013ms)
Apr 18 04:17:53.223: INFO: (18) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 4.315356ms)
Apr 18 04:17:53.224: INFO: (18) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 5.143241ms)
Apr 18 04:17:53.224: INFO: (18) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.785796ms)
Apr 18 04:17:53.224: INFO: (18) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 4.959916ms)
Apr 18 04:17:53.224: INFO: (18) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.605843ms)
Apr 18 04:17:53.225: INFO: (18) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.625027ms)
Apr 18 04:17:53.228: INFO: (19) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 2.99226ms)
Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.375891ms)
Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.015158ms)
Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.644799ms)
Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 3.985882ms)
Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.758066ms)
Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.687135ms)
Apr 18 04:17:53.230: INFO: (19) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.077076ms)
Apr 18 04:17:53.230: INFO: (19) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.186339ms)
Apr 18 04:17:53.230: INFO: (19) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.421052ms)
Apr 18 04:17:53.231: INFO: (19) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.47229ms)
Apr 18 04:17:53.231: INFO: (19) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.388255ms)
Apr 18 04:17:53.231: INFO: (19) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.50505ms)
Apr 18 04:17:53.231: INFO: (19) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 4.81364ms)
Apr 18 04:17:53.231: INFO: (19) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.70061ms)
Apr 18 04:17:53.232: INFO: (19) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.400203ms)
STEP: deleting ReplicationController proxy-service-wf5kr in namespace proxy-4487, will wait for the garbage collector to delete the pods 04/18/23 04:17:53.232
Apr 18 04:17:53.385: INFO: Deleting ReplicationController proxy-service-wf5kr took: 99.309741ms
Apr 18 04:17:53.486: INFO: Terminating ReplicationController proxy-service-wf5kr pods took: 100.927645ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 18 04:17:56.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4487" for this suite. 04/18/23 04:17:56.226
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":50,"skipped":894,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.730 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:17:47.55
    Apr 18 04:17:47.550: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename proxy 04/18/23 04:17:47.551
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:47.722
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:47.725
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 04/18/23 04:17:47.842
    STEP: creating replication controller proxy-service-wf5kr in namespace proxy-4487 04/18/23 04:17:47.843
    I0418 04:17:47.946180      22 runners.go:193] Created replication controller with name: proxy-service-wf5kr, namespace: proxy-4487, replica count: 1
    I0418 04:17:48.997214      22 runners.go:193] proxy-service-wf5kr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 04:17:49.997515      22 runners.go:193] proxy-service-wf5kr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 04:17:50.998380      22 runners.go:193] proxy-service-wf5kr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I0418 04:17:51.999291      22 runners.go:193] proxy-service-wf5kr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I0418 04:17:52.999524      22 runners.go:193] proxy-service-wf5kr Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 04:17:53.013: INFO: setup took 5.213784966s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/18/23 04:17:53.013
    Apr 18 04:17:53.018: INFO: (0) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.254764ms)
    Apr 18 04:17:53.018: INFO: (0) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.196127ms)
    Apr 18 04:17:53.018: INFO: (0) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.582886ms)
    Apr 18 04:17:53.019: INFO: (0) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 5.09738ms)
    Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 6.317391ms)
    Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 6.342278ms)
    Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 6.690909ms)
    Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 6.498187ms)
    Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 6.498029ms)
    Apr 18 04:17:53.020: INFO: (0) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 6.426712ms)
    Apr 18 04:17:53.023: INFO: (0) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 8.971731ms)
    Apr 18 04:17:53.024: INFO: (0) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 10.002398ms)
    Apr 18 04:17:53.024: INFO: (0) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 10.319492ms)
    Apr 18 04:17:53.024: INFO: (0) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 10.11808ms)
    Apr 18 04:17:53.024: INFO: (0) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 10.211085ms)
    Apr 18 04:17:53.026: INFO: (0) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 11.892261ms)
    Apr 18 04:17:53.029: INFO: (1) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.207652ms)
    Apr 18 04:17:53.030: INFO: (1) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.781038ms)
    Apr 18 04:17:53.030: INFO: (1) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 2.875788ms)
    Apr 18 04:17:53.030: INFO: (1) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 4.514905ms)
    Apr 18 04:17:53.030: INFO: (1) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.048775ms)
    Apr 18 04:17:53.030: INFO: (1) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 3.978435ms)
    Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 4.449725ms)
    Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.517121ms)
    Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.051995ms)
    Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.03222ms)
    Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.243125ms)
    Apr 18 04:17:53.031: INFO: (1) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.720336ms)
    Apr 18 04:17:53.032: INFO: (1) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.17181ms)
    Apr 18 04:17:53.032: INFO: (1) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.586596ms)
    Apr 18 04:17:53.032: INFO: (1) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 6.213346ms)
    Apr 18 04:17:53.032: INFO: (1) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 5.652324ms)
    Apr 18 04:17:53.037: INFO: (2) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 5.056683ms)
    Apr 18 04:17:53.038: INFO: (2) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 5.384201ms)
    Apr 18 04:17:53.038: INFO: (2) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 5.928173ms)
    Apr 18 04:17:53.038: INFO: (2) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 6.026718ms)
    Apr 18 04:17:53.038: INFO: (2) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 5.995019ms)
    Apr 18 04:17:53.039: INFO: (2) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 5.924035ms)
    Apr 18 04:17:53.039: INFO: (2) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.751727ms)
    Apr 18 04:17:53.039: INFO: (2) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 6.848425ms)
    Apr 18 04:17:53.039: INFO: (2) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 6.802629ms)
    Apr 18 04:17:53.040: INFO: (2) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 7.600226ms)
    Apr 18 04:17:53.040: INFO: (2) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 7.481198ms)
    Apr 18 04:17:53.040: INFO: (2) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 7.58433ms)
    Apr 18 04:17:53.041: INFO: (2) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 8.107088ms)
    Apr 18 04:17:53.041: INFO: (2) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 8.078365ms)
    Apr 18 04:17:53.041: INFO: (2) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 8.501503ms)
    Apr 18 04:17:53.041: INFO: (2) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 8.65301ms)
    Apr 18 04:17:53.044: INFO: (3) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 3.000877ms)
    Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.07385ms)
    Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.092072ms)
    Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.307104ms)
    Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.221255ms)
    Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.592397ms)
    Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.792009ms)
    Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.896467ms)
    Apr 18 04:17:53.045: INFO: (3) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 3.898763ms)
    Apr 18 04:17:53.046: INFO: (3) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.256616ms)
    Apr 18 04:17:53.046: INFO: (3) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 4.93207ms)
    Apr 18 04:17:53.047: INFO: (3) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.932911ms)
    Apr 18 04:17:53.047: INFO: (3) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.17485ms)
    Apr 18 04:17:53.047: INFO: (3) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.34611ms)
    Apr 18 04:17:53.047: INFO: (3) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.6907ms)
    Apr 18 04:17:53.047: INFO: (3) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.743865ms)
    Apr 18 04:17:53.051: INFO: (4) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.279041ms)
    Apr 18 04:17:53.051: INFO: (4) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.808577ms)
    Apr 18 04:17:53.051: INFO: (4) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.557344ms)
    Apr 18 04:17:53.051: INFO: (4) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.74607ms)
    Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.163672ms)
    Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 4.337531ms)
    Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.30079ms)
    Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.571894ms)
    Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 4.544804ms)
    Apr 18 04:17:53.052: INFO: (4) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.688404ms)
    Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 5.103575ms)
    Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.123916ms)
    Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.142902ms)
    Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.474148ms)
    Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.676207ms)
    Apr 18 04:17:53.053: INFO: (4) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 5.98825ms)
    Apr 18 04:17:53.064: INFO: (5) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 10.364183ms)
    Apr 18 04:17:53.064: INFO: (5) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 10.47018ms)
    Apr 18 04:17:53.064: INFO: (5) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 10.334546ms)
    Apr 18 04:17:53.064: INFO: (5) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 10.154027ms)
    Apr 18 04:17:53.065: INFO: (5) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 10.875265ms)
    Apr 18 04:17:53.065: INFO: (5) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 10.818251ms)
    Apr 18 04:17:53.065: INFO: (5) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 11.178422ms)
    Apr 18 04:17:53.065: INFO: (5) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 11.532983ms)
    Apr 18 04:17:53.065: INFO: (5) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 11.819291ms)
    Apr 18 04:17:53.066: INFO: (5) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 12.081843ms)
    Apr 18 04:17:53.066: INFO: (5) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 11.967244ms)
    Apr 18 04:17:53.067: INFO: (5) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 12.70467ms)
    Apr 18 04:17:53.067: INFO: (5) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 12.924845ms)
    Apr 18 04:17:53.067: INFO: (5) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 12.931721ms)
    Apr 18 04:17:53.068: INFO: (5) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 13.954774ms)
    Apr 18 04:17:53.068: INFO: (5) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 14.193198ms)
    Apr 18 04:17:53.071: INFO: (6) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.507878ms)
    Apr 18 04:17:53.072: INFO: (6) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.153911ms)
    Apr 18 04:17:53.072: INFO: (6) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 2.878448ms)
    Apr 18 04:17:53.072: INFO: (6) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 2.396318ms)
    Apr 18 04:17:53.074: INFO: (6) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 6.085743ms)
    Apr 18 04:17:53.074: INFO: (6) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 5.711272ms)
    Apr 18 04:17:53.074: INFO: (6) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 5.282095ms)
    Apr 18 04:17:53.075: INFO: (6) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 6.002291ms)
    Apr 18 04:17:53.076: INFO: (6) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 7.294997ms)
    Apr 18 04:17:53.076: INFO: (6) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 6.978137ms)
    Apr 18 04:17:53.111: INFO: (6) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 41.43019ms)
    Apr 18 04:17:53.111: INFO: (6) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 42.493948ms)
    Apr 18 04:17:53.111: INFO: (6) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 42.140208ms)
    Apr 18 04:17:53.111: INFO: (6) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 42.811929ms)
    Apr 18 04:17:53.112: INFO: (6) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 43.423293ms)
    Apr 18 04:17:53.141: INFO: (6) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 71.767764ms)
    Apr 18 04:17:53.144: INFO: (7) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.180766ms)
    Apr 18 04:17:53.145: INFO: (7) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.486984ms)
    Apr 18 04:17:53.145: INFO: (7) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.487133ms)
    Apr 18 04:17:53.145: INFO: (7) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.506881ms)
    Apr 18 04:17:53.145: INFO: (7) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.015689ms)
    Apr 18 04:17:53.146: INFO: (7) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.154134ms)
    Apr 18 04:17:53.146: INFO: (7) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 4.446086ms)
    Apr 18 04:17:53.146: INFO: (7) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 4.620951ms)
    Apr 18 04:17:53.147: INFO: (7) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.409333ms)
    Apr 18 04:17:53.149: INFO: (7) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 8.007434ms)
    Apr 18 04:17:53.150: INFO: (7) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 8.140106ms)
    Apr 18 04:17:53.150: INFO: (7) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 8.201759ms)
    Apr 18 04:17:53.150: INFO: (7) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 8.430146ms)
    Apr 18 04:17:53.150: INFO: (7) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 8.542205ms)
    Apr 18 04:17:53.150: INFO: (7) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 9.042139ms)
    Apr 18 04:17:53.151: INFO: (7) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 9.459541ms)
    Apr 18 04:17:53.154: INFO: (8) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.460451ms)
    Apr 18 04:17:53.155: INFO: (8) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.941476ms)
    Apr 18 04:17:53.155: INFO: (8) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.221503ms)
    Apr 18 04:17:53.155: INFO: (8) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.503676ms)
    Apr 18 04:17:53.155: INFO: (8) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.715901ms)
    Apr 18 04:17:53.155: INFO: (8) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.197317ms)
    Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.952116ms)
    Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.247917ms)
    Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 5.548573ms)
    Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.485618ms)
    Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 5.269013ms)
    Apr 18 04:17:53.156: INFO: (8) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 5.475932ms)
    Apr 18 04:17:53.157: INFO: (8) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.685951ms)
    Apr 18 04:17:53.157: INFO: (8) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.835749ms)
    Apr 18 04:17:53.158: INFO: (8) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 6.563291ms)
    Apr 18 04:17:53.158: INFO: (8) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.639426ms)
    Apr 18 04:17:53.161: INFO: (9) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.053889ms)
    Apr 18 04:17:53.161: INFO: (9) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.128362ms)
    Apr 18 04:17:53.162: INFO: (9) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 3.83561ms)
    Apr 18 04:17:53.162: INFO: (9) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.0326ms)
    Apr 18 04:17:53.162: INFO: (9) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.079518ms)
    Apr 18 04:17:53.162: INFO: (9) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.442994ms)
    Apr 18 04:17:53.163: INFO: (9) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.075403ms)
    Apr 18 04:17:53.163: INFO: (9) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.096042ms)
    Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 5.70931ms)
    Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 5.723832ms)
    Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.858143ms)
    Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.929956ms)
    Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 5.702818ms)
    Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 5.753507ms)
    Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.060287ms)
    Apr 18 04:17:53.164: INFO: (9) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 6.523779ms)
    Apr 18 04:17:53.168: INFO: (10) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.34723ms)
    Apr 18 04:17:53.168: INFO: (10) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 3.524132ms)
    Apr 18 04:17:53.168: INFO: (10) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 3.064673ms)
    Apr 18 04:17:53.169: INFO: (10) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.120521ms)
    Apr 18 04:17:53.169: INFO: (10) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.134838ms)
    Apr 18 04:17:53.169: INFO: (10) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.651999ms)
    Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.740353ms)
    Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.180558ms)
    Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.622574ms)
    Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.824541ms)
    Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 4.50737ms)
    Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.284653ms)
    Apr 18 04:17:53.170: INFO: (10) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.431739ms)
    Apr 18 04:17:53.171: INFO: (10) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.602714ms)
    Apr 18 04:17:53.171: INFO: (10) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.156206ms)
    Apr 18 04:17:53.171: INFO: (10) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 5.412744ms)
    Apr 18 04:17:53.175: INFO: (11) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.823854ms)
    Apr 18 04:17:53.175: INFO: (11) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.827502ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.027407ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.857573ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.068088ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.982898ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.227885ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.223189ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.167483ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 4.30078ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.668607ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 4.686628ms)
    Apr 18 04:17:53.176: INFO: (11) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 4.914364ms)
    Apr 18 04:17:53.177: INFO: (11) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.183073ms)
    Apr 18 04:17:53.177: INFO: (11) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.402315ms)
    Apr 18 04:17:53.178: INFO: (11) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.50583ms)
    Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.662986ms)
    Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.61591ms)
    Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.704236ms)
    Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.650424ms)
    Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.847572ms)
    Apr 18 04:17:53.182: INFO: (12) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.911019ms)
    Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.275989ms)
    Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.373563ms)
    Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.511434ms)
    Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.597456ms)
    Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.98582ms)
    Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 4.877689ms)
    Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 4.856926ms)
    Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.057329ms)
    Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.01412ms)
    Apr 18 04:17:53.183: INFO: (12) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.256644ms)
    Apr 18 04:17:53.187: INFO: (13) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.103032ms)
    Apr 18 04:17:53.187: INFO: (13) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.145783ms)
    Apr 18 04:17:53.187: INFO: (13) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.099806ms)
    Apr 18 04:17:53.187: INFO: (13) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 3.451104ms)
    Apr 18 04:17:53.187: INFO: (13) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.540878ms)
    Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.905766ms)
    Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.831357ms)
    Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 3.984371ms)
    Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 4.217556ms)
    Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.294848ms)
    Apr 18 04:17:53.188: INFO: (13) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.348515ms)
    Apr 18 04:17:53.189: INFO: (13) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 4.87713ms)
    Apr 18 04:17:53.189: INFO: (13) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.290299ms)
    Apr 18 04:17:53.189: INFO: (13) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.585183ms)
    Apr 18 04:17:53.189: INFO: (13) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.641857ms)
    Apr 18 04:17:53.190: INFO: (13) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 6.318077ms)
    Apr 18 04:17:53.193: INFO: (14) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.146806ms)
    Apr 18 04:17:53.194: INFO: (14) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.31053ms)
    Apr 18 04:17:53.194: INFO: (14) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.414625ms)
    Apr 18 04:17:53.194: INFO: (14) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.416152ms)
    Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.505891ms)
    Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.48578ms)
    Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 4.548764ms)
    Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.498286ms)
    Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.898206ms)
    Apr 18 04:17:53.195: INFO: (14) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 5.058874ms)
    Apr 18 04:17:53.196: INFO: (14) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 5.053212ms)
    Apr 18 04:17:53.196: INFO: (14) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.805087ms)
    Apr 18 04:17:53.196: INFO: (14) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.006877ms)
    Apr 18 04:17:53.197: INFO: (14) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 6.479357ms)
    Apr 18 04:17:53.197: INFO: (14) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 6.735844ms)
    Apr 18 04:17:53.198: INFO: (14) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 7.05286ms)
    Apr 18 04:17:53.201: INFO: (15) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.448649ms)
    Apr 18 04:17:53.201: INFO: (15) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.577941ms)
    Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.821719ms)
    Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.683807ms)
    Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 3.993283ms)
    Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 4.250842ms)
    Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.089675ms)
    Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.173076ms)
    Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.423914ms)
    Apr 18 04:17:53.202: INFO: (15) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.55896ms)
    Apr 18 04:17:53.203: INFO: (15) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.608577ms)
    Apr 18 04:17:53.203: INFO: (15) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.970441ms)
    Apr 18 04:17:53.203: INFO: (15) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 4.875107ms)
    Apr 18 04:17:53.203: INFO: (15) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.200468ms)
    Apr 18 04:17:53.203: INFO: (15) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.052085ms)
    Apr 18 04:17:53.204: INFO: (15) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.655592ms)
    Apr 18 04:17:53.207: INFO: (16) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.023216ms)
    Apr 18 04:17:53.207: INFO: (16) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.138035ms)
    Apr 18 04:17:53.207: INFO: (16) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.359848ms)
    Apr 18 04:17:53.207: INFO: (16) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.473713ms)
    Apr 18 04:17:53.208: INFO: (16) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.741038ms)
    Apr 18 04:17:53.208: INFO: (16) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.88045ms)
    Apr 18 04:17:53.209: INFO: (16) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.181799ms)
    Apr 18 04:17:53.209: INFO: (16) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.19576ms)
    Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.646706ms)
    Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 5.902879ms)
    Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 5.745182ms)
    Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 5.898416ms)
    Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 5.894065ms)
    Apr 18 04:17:53.210: INFO: (16) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 6.228826ms)
    Apr 18 04:17:53.211: INFO: (16) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.991243ms)
    Apr 18 04:17:53.211: INFO: (16) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 7.342034ms)
    Apr 18 04:17:53.214: INFO: (17) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.09844ms)
    Apr 18 04:17:53.215: INFO: (17) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 3.109374ms)
    Apr 18 04:17:53.215: INFO: (17) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.173081ms)
    Apr 18 04:17:53.215: INFO: (17) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.566321ms)
    Apr 18 04:17:53.215: INFO: (17) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.268193ms)
    Apr 18 04:17:53.215: INFO: (17) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 3.848666ms)
    Apr 18 04:17:53.216: INFO: (17) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.790677ms)
    Apr 18 04:17:53.216: INFO: (17) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.157231ms)
    Apr 18 04:17:53.216: INFO: (17) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.864743ms)
    Apr 18 04:17:53.216: INFO: (17) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.37613ms)
    Apr 18 04:17:53.216: INFO: (17) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 4.400093ms)
    Apr 18 04:17:53.217: INFO: (17) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.020005ms)
    Apr 18 04:17:53.217: INFO: (17) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 4.957705ms)
    Apr 18 04:17:53.217: INFO: (17) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.649083ms)
    Apr 18 04:17:53.217: INFO: (17) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 5.641063ms)
    Apr 18 04:17:53.218: INFO: (17) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 6.114981ms)
    Apr 18 04:17:53.221: INFO: (18) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 2.829712ms)
    Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.493164ms)
    Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.055263ms)
    Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 3.840645ms)
    Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.661319ms)
    Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 2.82052ms)
    Apr 18 04:17:53.222: INFO: (18) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 3.455181ms)
    Apr 18 04:17:53.223: INFO: (18) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.175649ms)
    Apr 18 04:17:53.223: INFO: (18) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 4.472062ms)
    Apr 18 04:17:53.223: INFO: (18) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.180013ms)
    Apr 18 04:17:53.223: INFO: (18) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 4.315356ms)
    Apr 18 04:17:53.224: INFO: (18) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 5.143241ms)
    Apr 18 04:17:53.224: INFO: (18) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.785796ms)
    Apr 18 04:17:53.224: INFO: (18) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 4.959916ms)
    Apr 18 04:17:53.224: INFO: (18) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 5.605843ms)
    Apr 18 04:17:53.225: INFO: (18) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.625027ms)
    Apr 18 04:17:53.228: INFO: (19) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 2.99226ms)
    Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:460/proxy/: tls baz (200; 3.375891ms)
    Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.015158ms)
    Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v/proxy/rewriteme">test</a> (200; 3.644799ms)
    Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname2/proxy/: bar (200; 3.985882ms)
    Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">... (200; 3.758066ms)
    Apr 18 04:17:53.229: INFO: (19) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:160/proxy/: foo (200; 3.687135ms)
    Apr 18 04:17:53.230: INFO: (19) /api/v1/namespaces/proxy-4487/services/http:proxy-service-wf5kr:portname1/proxy/: foo (200; 4.077076ms)
    Apr 18 04:17:53.230: INFO: (19) /api/v1/namespaces/proxy-4487/pods/http:proxy-service-wf5kr-l9d5v:162/proxy/: bar (200; 4.186339ms)
    Apr 18 04:17:53.230: INFO: (19) /api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/proxy-service-wf5kr-l9d5v:1080/proxy/rewriteme">test<... (200; 4.421052ms)
    Apr 18 04:17:53.231: INFO: (19) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname2/proxy/: bar (200; 5.47229ms)
    Apr 18 04:17:53.231: INFO: (19) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:462/proxy/: tls qux (200; 4.388255ms)
    Apr 18 04:17:53.231: INFO: (19) /api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/: <a href="/api/v1/namespaces/proxy-4487/pods/https:proxy-service-wf5kr-l9d5v:443/proxy/tlsrewritem... (200; 4.50505ms)
    Apr 18 04:17:53.231: INFO: (19) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname2/proxy/: tls qux (200; 4.81364ms)
    Apr 18 04:17:53.231: INFO: (19) /api/v1/namespaces/proxy-4487/services/https:proxy-service-wf5kr:tlsportname1/proxy/: tls baz (200; 5.70061ms)
    Apr 18 04:17:53.232: INFO: (19) /api/v1/namespaces/proxy-4487/services/proxy-service-wf5kr:portname1/proxy/: foo (200; 5.400203ms)
    STEP: deleting ReplicationController proxy-service-wf5kr in namespace proxy-4487, will wait for the garbage collector to delete the pods 04/18/23 04:17:53.232
    Apr 18 04:17:53.385: INFO: Deleting ReplicationController proxy-service-wf5kr took: 99.309741ms
    Apr 18 04:17:53.486: INFO: Terminating ReplicationController proxy-service-wf5kr pods took: 100.927645ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 18 04:17:56.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-4487" for this suite. 04/18/23 04:17:56.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:17:56.281
Apr 18 04:17:56.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 04:17:56.282
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:56.33
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:56.333
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 04/18/23 04:17:56.4
Apr 18 04:17:56.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea" in namespace "downward-api-3268" to be "Succeeded or Failed"
Apr 18 04:17:56.470: INFO: Pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.97728ms
Apr 18 04:17:58.481: INFO: Pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014398059s
Apr 18 04:18:00.475: INFO: Pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea": Phase="Running", Reason="", readiness=false. Elapsed: 4.007993083s
Apr 18 04:18:02.474: INFO: Pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006964243s
STEP: Saw pod success 04/18/23 04:18:02.474
Apr 18 04:18:02.474: INFO: Pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea" satisfied condition "Succeeded or Failed"
Apr 18 04:18:02.478: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea container client-container: <nil>
STEP: delete the pod 04/18/23 04:18:02.483
Apr 18 04:18:02.673: INFO: Waiting for pod downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea to disappear
Apr 18 04:18:02.681: INFO: Pod downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 04:18:02.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3268" for this suite. 04/18/23 04:18:02.691
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":51,"skipped":901,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.427 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:17:56.281
    Apr 18 04:17:56.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 04:17:56.282
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:17:56.33
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:17:56.333
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 04/18/23 04:17:56.4
    Apr 18 04:17:56.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea" in namespace "downward-api-3268" to be "Succeeded or Failed"
    Apr 18 04:17:56.470: INFO: Pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.97728ms
    Apr 18 04:17:58.481: INFO: Pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014398059s
    Apr 18 04:18:00.475: INFO: Pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea": Phase="Running", Reason="", readiness=false. Elapsed: 4.007993083s
    Apr 18 04:18:02.474: INFO: Pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006964243s
    STEP: Saw pod success 04/18/23 04:18:02.474
    Apr 18 04:18:02.474: INFO: Pod "downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea" satisfied condition "Succeeded or Failed"
    Apr 18 04:18:02.478: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea container client-container: <nil>
    STEP: delete the pod 04/18/23 04:18:02.483
    Apr 18 04:18:02.673: INFO: Waiting for pod downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea to disappear
    Apr 18 04:18:02.681: INFO: Pod downwardapi-volume-97797422-052d-4142-b360-952240c2d3ea no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 04:18:02.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3268" for this suite. 04/18/23 04:18:02.691
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:18:02.71
Apr 18 04:18:02.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-runtime 04/18/23 04:18:02.71
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:18:02.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:18:02.845
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/18/23 04:18:02.875
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/18/23 04:18:22.789
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/18/23 04:18:22.792
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/18/23 04:18:22.819
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/18/23 04:18:22.819
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/18/23 04:18:23.269
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/18/23 04:18:27.288
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/18/23 04:18:29.393
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/18/23 04:18:29.399
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/18/23 04:18:29.399
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/18/23 04:18:29.619
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/18/23 04:18:30.718
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/18/23 04:18:35.864
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/18/23 04:18:35.869
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/18/23 04:18:35.869
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 18 04:18:36.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7466" for this suite. 04/18/23 04:18:36.144
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":52,"skipped":919,"failed":0}
------------------------------
â€¢ [SLOW TEST] [33.500 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:18:02.71
    Apr 18 04:18:02.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-runtime 04/18/23 04:18:02.71
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:18:02.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:18:02.845
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/18/23 04:18:02.875
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/18/23 04:18:22.789
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/18/23 04:18:22.792
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/18/23 04:18:22.819
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/18/23 04:18:22.819
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/18/23 04:18:23.269
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/18/23 04:18:27.288
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/18/23 04:18:29.393
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/18/23 04:18:29.399
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/18/23 04:18:29.399
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/18/23 04:18:29.619
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/18/23 04:18:30.718
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/18/23 04:18:35.864
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/18/23 04:18:35.869
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/18/23 04:18:35.869
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 18 04:18:36.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-7466" for this suite. 04/18/23 04:18:36.144
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:18:36.21
Apr 18 04:18:36.210: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 04:18:36.211
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:18:36.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:18:36.346
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-a0bb58fe-cfad-40e8-9f88-d1747111841e 04/18/23 04:18:36.386
STEP: Creating the pod 04/18/23 04:18:36.427
Apr 18 04:18:36.472: INFO: Waiting up to 5m0s for pod "pod-configmaps-e909a0a0-9021-47ec-8049-2abddbf399a6" in namespace "configmap-2190" to be "running"
Apr 18 04:18:36.475: INFO: Pod "pod-configmaps-e909a0a0-9021-47ec-8049-2abddbf399a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.816646ms
Apr 18 04:18:38.528: INFO: Pod "pod-configmaps-e909a0a0-9021-47ec-8049-2abddbf399a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055607466s
Apr 18 04:18:40.481: INFO: Pod "pod-configmaps-e909a0a0-9021-47ec-8049-2abddbf399a6": Phase="Running", Reason="", readiness=false. Elapsed: 4.00903634s
Apr 18 04:18:40.481: INFO: Pod "pod-configmaps-e909a0a0-9021-47ec-8049-2abddbf399a6" satisfied condition "running"
STEP: Waiting for pod with text data 04/18/23 04:18:40.481
STEP: Waiting for pod with binary data 04/18/23 04:18:40.488
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 04:18:40.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2190" for this suite. 04/18/23 04:18:40.499
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":53,"skipped":931,"failed":0}
------------------------------
â€¢ [4.328 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:18:36.21
    Apr 18 04:18:36.210: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 04:18:36.211
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:18:36.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:18:36.346
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-a0bb58fe-cfad-40e8-9f88-d1747111841e 04/18/23 04:18:36.386
    STEP: Creating the pod 04/18/23 04:18:36.427
    Apr 18 04:18:36.472: INFO: Waiting up to 5m0s for pod "pod-configmaps-e909a0a0-9021-47ec-8049-2abddbf399a6" in namespace "configmap-2190" to be "running"
    Apr 18 04:18:36.475: INFO: Pod "pod-configmaps-e909a0a0-9021-47ec-8049-2abddbf399a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.816646ms
    Apr 18 04:18:38.528: INFO: Pod "pod-configmaps-e909a0a0-9021-47ec-8049-2abddbf399a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055607466s
    Apr 18 04:18:40.481: INFO: Pod "pod-configmaps-e909a0a0-9021-47ec-8049-2abddbf399a6": Phase="Running", Reason="", readiness=false. Elapsed: 4.00903634s
    Apr 18 04:18:40.481: INFO: Pod "pod-configmaps-e909a0a0-9021-47ec-8049-2abddbf399a6" satisfied condition "running"
    STEP: Waiting for pod with text data 04/18/23 04:18:40.481
    STEP: Waiting for pod with binary data 04/18/23 04:18:40.488
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 04:18:40.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2190" for this suite. 04/18/23 04:18:40.499
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:18:40.539
Apr 18 04:18:40.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubelet-test 04/18/23 04:18:40.54
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:18:40.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:18:40.674
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Apr 18 04:18:40.701: INFO: Waiting up to 5m0s for pod "busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40" in namespace "kubelet-test-9389" to be "running and ready"
Apr 18 04:18:40.778: INFO: Pod "busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40": Phase="Pending", Reason="", readiness=false. Elapsed: 76.892578ms
Apr 18 04:18:40.778: INFO: The phase of Pod busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:18:42.781: INFO: Pod "busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080339021s
Apr 18 04:18:42.781: INFO: The phase of Pod busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:18:44.782: INFO: Pod "busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40": Phase="Running", Reason="", readiness=true. Elapsed: 4.081249299s
Apr 18 04:18:44.782: INFO: The phase of Pod busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40 is Running (Ready = true)
Apr 18 04:18:44.782: INFO: Pod "busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 18 04:18:44.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9389" for this suite. 04/18/23 04:18:44.834
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":54,"skipped":954,"failed":0}
------------------------------
â€¢ [4.322 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:18:40.539
    Apr 18 04:18:40.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubelet-test 04/18/23 04:18:40.54
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:18:40.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:18:40.674
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Apr 18 04:18:40.701: INFO: Waiting up to 5m0s for pod "busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40" in namespace "kubelet-test-9389" to be "running and ready"
    Apr 18 04:18:40.778: INFO: Pod "busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40": Phase="Pending", Reason="", readiness=false. Elapsed: 76.892578ms
    Apr 18 04:18:40.778: INFO: The phase of Pod busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:18:42.781: INFO: Pod "busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080339021s
    Apr 18 04:18:42.781: INFO: The phase of Pod busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:18:44.782: INFO: Pod "busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40": Phase="Running", Reason="", readiness=true. Elapsed: 4.081249299s
    Apr 18 04:18:44.782: INFO: The phase of Pod busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40 is Running (Ready = true)
    Apr 18 04:18:44.782: INFO: Pod "busybox-scheduling-80adbb17-ca34-41a0-86cc-6c55a24ddd40" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 18 04:18:44.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-9389" for this suite. 04/18/23 04:18:44.834
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:18:44.862
Apr 18 04:18:44.862: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:18:44.863
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:18:44.897
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:18:44.9
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-1aa651e9-9d26-4557-a9e0-6f7704b86afe 04/18/23 04:18:44.902
STEP: Creating a pod to test consume configMaps 04/18/23 04:18:44.961
Apr 18 04:18:45.002: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65" in namespace "projected-5722" to be "Succeeded or Failed"
Apr 18 04:18:45.036: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65": Phase="Pending", Reason="", readiness=false. Elapsed: 34.598739ms
Apr 18 04:18:47.046: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043691111s
Apr 18 04:18:49.042: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65": Phase="Running", Reason="", readiness=true. Elapsed: 4.039835693s
Apr 18 04:18:51.065: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65": Phase="Running", Reason="", readiness=false. Elapsed: 6.062863097s
Apr 18 04:18:53.042: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.040081222s
STEP: Saw pod success 04/18/23 04:18:53.042
Apr 18 04:18:53.042: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65" satisfied condition "Succeeded or Failed"
Apr 18 04:18:53.045: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 04:18:53.052
Apr 18 04:18:53.263: INFO: Waiting for pod pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65 to disappear
Apr 18 04:18:53.266: INFO: Pod pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 04:18:53.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5722" for this suite. 04/18/23 04:18:53.271
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":55,"skipped":960,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.449 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:18:44.862
    Apr 18 04:18:44.862: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:18:44.863
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:18:44.897
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:18:44.9
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-1aa651e9-9d26-4557-a9e0-6f7704b86afe 04/18/23 04:18:44.902
    STEP: Creating a pod to test consume configMaps 04/18/23 04:18:44.961
    Apr 18 04:18:45.002: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65" in namespace "projected-5722" to be "Succeeded or Failed"
    Apr 18 04:18:45.036: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65": Phase="Pending", Reason="", readiness=false. Elapsed: 34.598739ms
    Apr 18 04:18:47.046: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043691111s
    Apr 18 04:18:49.042: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65": Phase="Running", Reason="", readiness=true. Elapsed: 4.039835693s
    Apr 18 04:18:51.065: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65": Phase="Running", Reason="", readiness=false. Elapsed: 6.062863097s
    Apr 18 04:18:53.042: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.040081222s
    STEP: Saw pod success 04/18/23 04:18:53.042
    Apr 18 04:18:53.042: INFO: Pod "pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65" satisfied condition "Succeeded or Failed"
    Apr 18 04:18:53.045: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 04:18:53.052
    Apr 18 04:18:53.263: INFO: Waiting for pod pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65 to disappear
    Apr 18 04:18:53.266: INFO: Pod pod-projected-configmaps-8cbddc41-c64c-401c-95bf-489c62dfbd65 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 04:18:53.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5722" for this suite. 04/18/23 04:18:53.271
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:18:53.311
Apr 18 04:18:53.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename statefulset 04/18/23 04:18:53.312
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:18:53.421
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:18:53.423
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6061 04/18/23 04:18:53.435
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-6061 04/18/23 04:18:53.645
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6061 04/18/23 04:18:53.662
Apr 18 04:18:53.727: INFO: Found 0 stateful pods, waiting for 1
Apr 18 04:19:03.732: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/18/23 04:19:03.732
Apr 18 04:19:03.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 04:19:03.998: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 04:19:03.998: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 04:19:03.998: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 04:19:04.002: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 18 04:19:14.007: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 04:19:14.007: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 04:19:14.058: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Apr 18 04:19:14.058: INFO: ss-0  apps-208  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  }]
Apr 18 04:19:14.058: INFO: 
Apr 18 04:19:14.058: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 18 04:19:15.062: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996213977s
Apr 18 04:19:16.067: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991724304s
Apr 18 04:19:17.207: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986980087s
Apr 18 04:19:18.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.846553249s
Apr 18 04:19:19.218: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.841111385s
Apr 18 04:19:20.223: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.835483645s
Apr 18 04:19:21.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.830016294s
Apr 18 04:19:22.234: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.824508139s
Apr 18 04:19:23.441: INFO: Verifying statefulset ss doesn't scale past 3 for another 820.391976ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6061 04/18/23 04:19:24.443
Apr 18 04:19:24.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 04:19:24.607: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 04:19:24.607: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 04:19:24.607: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 04:19:24.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 04:19:24.761: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 18 04:19:24.761: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 04:19:24.761: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 04:19:24.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 04:19:24.916: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 18 04:19:24.916: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 04:19:24.916: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 18 04:19:24.920: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Apr 18 04:19:34.928: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 04:19:34.928: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 04:19:34.928: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 04/18/23 04:19:34.929
Apr 18 04:19:34.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 04:19:35.092: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 04:19:35.092: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 04:19:35.092: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 04:19:35.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 04:19:35.272: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 04:19:35.272: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 04:19:35.272: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 04:19:35.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 04:19:35.586: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 04:19:35.586: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 04:19:35.586: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 04:19:35.586: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 04:19:35.699: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 18 04:19:45.717: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 04:19:45.717: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 04:19:45.717: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 18 04:19:45.746: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Apr 18 04:19:45.746: INFO: ss-0  apps-208  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  }]
Apr 18 04:19:45.746: INFO: ss-1  apps-207  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
Apr 18 04:19:45.746: INFO: ss-2  apps-209  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
Apr 18 04:19:45.746: INFO: 
Apr 18 04:19:45.746: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 18 04:19:47.085: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Apr 18 04:19:47.085: INFO: ss-0  apps-208  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  }]
Apr 18 04:19:47.085: INFO: ss-1  apps-207  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
Apr 18 04:19:47.085: INFO: ss-2  apps-209  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
Apr 18 04:19:47.085: INFO: 
Apr 18 04:19:47.085: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 18 04:19:48.090: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Apr 18 04:19:48.090: INFO: ss-0  apps-208  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  }]
Apr 18 04:19:48.090: INFO: ss-1  apps-207  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
Apr 18 04:19:48.090: INFO: ss-2  apps-209  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
Apr 18 04:19:48.090: INFO: 
Apr 18 04:19:48.090: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 18 04:19:49.094: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.652018188s
Apr 18 04:19:50.132: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.648658103s
Apr 18 04:19:51.168: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.609416757s
Apr 18 04:19:52.172: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.574520707s
Apr 18 04:19:53.176: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.57051863s
Apr 18 04:19:54.180: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.566693054s
Apr 18 04:19:55.199: INFO: Verifying statefulset ss doesn't scale past 0 for another 562.827203ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6061 04/18/23 04:19:56.199
Apr 18 04:19:56.203: INFO: Scaling statefulset ss to 0
Apr 18 04:19:56.215: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 04:19:56.218: INFO: Deleting all statefulset in ns statefulset-6061
Apr 18 04:19:56.221: INFO: Scaling statefulset ss to 0
Apr 18 04:19:56.231: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 04:19:56.233: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 04:19:56.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6061" for this suite. 04/18/23 04:19:56.331
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":56,"skipped":962,"failed":0}
------------------------------
â€¢ [SLOW TEST] [63.065 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:18:53.311
    Apr 18 04:18:53.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename statefulset 04/18/23 04:18:53.312
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:18:53.421
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:18:53.423
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6061 04/18/23 04:18:53.435
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-6061 04/18/23 04:18:53.645
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6061 04/18/23 04:18:53.662
    Apr 18 04:18:53.727: INFO: Found 0 stateful pods, waiting for 1
    Apr 18 04:19:03.732: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/18/23 04:19:03.732
    Apr 18 04:19:03.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 04:19:03.998: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 04:19:03.998: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 04:19:03.998: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 04:19:04.002: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 18 04:19:14.007: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 04:19:14.007: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 04:19:14.058: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
    Apr 18 04:19:14.058: INFO: ss-0  apps-208  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:04 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  }]
    Apr 18 04:19:14.058: INFO: 
    Apr 18 04:19:14.058: INFO: StatefulSet ss has not reached scale 3, at 1
    Apr 18 04:19:15.062: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996213977s
    Apr 18 04:19:16.067: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991724304s
    Apr 18 04:19:17.207: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986980087s
    Apr 18 04:19:18.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.846553249s
    Apr 18 04:19:19.218: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.841111385s
    Apr 18 04:19:20.223: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.835483645s
    Apr 18 04:19:21.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.830016294s
    Apr 18 04:19:22.234: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.824508139s
    Apr 18 04:19:23.441: INFO: Verifying statefulset ss doesn't scale past 3 for another 820.391976ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6061 04/18/23 04:19:24.443
    Apr 18 04:19:24.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 04:19:24.607: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 04:19:24.607: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 04:19:24.607: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 04:19:24.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 04:19:24.761: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 18 04:19:24.761: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 04:19:24.761: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 04:19:24.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 04:19:24.916: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 18 04:19:24.916: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 04:19:24.916: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 18 04:19:24.920: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Apr 18 04:19:34.928: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 04:19:34.928: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 04:19:34.928: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 04/18/23 04:19:34.929
    Apr 18 04:19:34.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 04:19:35.092: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 04:19:35.092: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 04:19:35.092: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 04:19:35.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 04:19:35.272: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 04:19:35.272: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 04:19:35.272: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 04:19:35.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-6061 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 04:19:35.586: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 04:19:35.586: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 04:19:35.586: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 04:19:35.586: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 04:19:35.699: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Apr 18 04:19:45.717: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 04:19:45.717: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 04:19:45.717: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 18 04:19:45.746: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
    Apr 18 04:19:45.746: INFO: ss-0  apps-208  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  }]
    Apr 18 04:19:45.746: INFO: ss-1  apps-207  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
    Apr 18 04:19:45.746: INFO: ss-2  apps-209  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
    Apr 18 04:19:45.746: INFO: 
    Apr 18 04:19:45.746: INFO: StatefulSet ss has not reached scale 0, at 3
    Apr 18 04:19:47.085: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
    Apr 18 04:19:47.085: INFO: ss-0  apps-208  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  }]
    Apr 18 04:19:47.085: INFO: ss-1  apps-207  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
    Apr 18 04:19:47.085: INFO: ss-2  apps-209  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
    Apr 18 04:19:47.085: INFO: 
    Apr 18 04:19:47.085: INFO: StatefulSet ss has not reached scale 0, at 3
    Apr 18 04:19:48.090: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
    Apr 18 04:19:48.090: INFO: ss-0  apps-208  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:18:53 +0000 UTC  }]
    Apr 18 04:19:48.090: INFO: ss-1  apps-207  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
    Apr 18 04:19:48.090: INFO: ss-2  apps-209  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 04:19:14 +0000 UTC  }]
    Apr 18 04:19:48.090: INFO: 
    Apr 18 04:19:48.090: INFO: StatefulSet ss has not reached scale 0, at 3
    Apr 18 04:19:49.094: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.652018188s
    Apr 18 04:19:50.132: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.648658103s
    Apr 18 04:19:51.168: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.609416757s
    Apr 18 04:19:52.172: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.574520707s
    Apr 18 04:19:53.176: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.57051863s
    Apr 18 04:19:54.180: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.566693054s
    Apr 18 04:19:55.199: INFO: Verifying statefulset ss doesn't scale past 0 for another 562.827203ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6061 04/18/23 04:19:56.199
    Apr 18 04:19:56.203: INFO: Scaling statefulset ss to 0
    Apr 18 04:19:56.215: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 04:19:56.218: INFO: Deleting all statefulset in ns statefulset-6061
    Apr 18 04:19:56.221: INFO: Scaling statefulset ss to 0
    Apr 18 04:19:56.231: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 04:19:56.233: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 04:19:56.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6061" for this suite. 04/18/23 04:19:56.331
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:19:56.377
Apr 18 04:19:56.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename dns 04/18/23 04:19:56.379
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:19:56.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:19:56.51
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 04/18/23 04:19:56.512
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6147.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-6147.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 04/18/23 04:19:56.543
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6147.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-6147.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 04/18/23 04:19:56.543
STEP: creating a pod to probe DNS 04/18/23 04:19:56.543
STEP: submitting the pod to kubernetes 04/18/23 04:19:56.543
Apr 18 04:19:56.684: INFO: Waiting up to 15m0s for pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28" in namespace "dns-6147" to be "running"
Apr 18 04:19:56.786: INFO: Pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28": Phase="Pending", Reason="", readiness=false. Elapsed: 101.972635ms
Apr 18 04:19:58.792: INFO: Pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.107366592s
Apr 18 04:20:00.792: INFO: Pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.107096987s
Apr 18 04:20:02.825: INFO: Pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28": Phase="Running", Reason="", readiness=true. Elapsed: 6.140833976s
Apr 18 04:20:02.825: INFO: Pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28" satisfied condition "running"
STEP: retrieving the pod 04/18/23 04:20:02.825
STEP: looking for the results for each expected name from probers 04/18/23 04:20:02.83
Apr 18 04:20:02.844: INFO: DNS probes using dns-6147/dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28 succeeded

STEP: deleting the pod 04/18/23 04:20:02.844
STEP: deleting the test headless service 04/18/23 04:20:03.075
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 04:20:03.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6147" for this suite. 04/18/23 04:20:03.188
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":57,"skipped":983,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.892 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:19:56.377
    Apr 18 04:19:56.378: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename dns 04/18/23 04:19:56.379
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:19:56.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:19:56.51
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 04/18/23 04:19:56.512
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6147.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-6147.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     04/18/23 04:19:56.543
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6147.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-6147.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     04/18/23 04:19:56.543
    STEP: creating a pod to probe DNS 04/18/23 04:19:56.543
    STEP: submitting the pod to kubernetes 04/18/23 04:19:56.543
    Apr 18 04:19:56.684: INFO: Waiting up to 15m0s for pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28" in namespace "dns-6147" to be "running"
    Apr 18 04:19:56.786: INFO: Pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28": Phase="Pending", Reason="", readiness=false. Elapsed: 101.972635ms
    Apr 18 04:19:58.792: INFO: Pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.107366592s
    Apr 18 04:20:00.792: INFO: Pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.107096987s
    Apr 18 04:20:02.825: INFO: Pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28": Phase="Running", Reason="", readiness=true. Elapsed: 6.140833976s
    Apr 18 04:20:02.825: INFO: Pod "dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 04:20:02.825
    STEP: looking for the results for each expected name from probers 04/18/23 04:20:02.83
    Apr 18 04:20:02.844: INFO: DNS probes using dns-6147/dns-test-5842e40f-8134-4d0d-ae30-f8ea91992a28 succeeded

    STEP: deleting the pod 04/18/23 04:20:02.844
    STEP: deleting the test headless service 04/18/23 04:20:03.075
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 04:20:03.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6147" for this suite. 04/18/23 04:20:03.188
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:20:03.271
Apr 18 04:20:03.272: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 04:20:03.273
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:20:03.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:20:03.4
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-202f34c0-b9b1-4a87-bd97-25ca78d0c3fa 04/18/23 04:20:03.406
STEP: Creating secret with name s-test-opt-upd-8ca46fca-1ead-4b92-af36-854d4bb7e3c1 04/18/23 04:20:03.746
STEP: Creating the pod 04/18/23 04:20:03.778
Apr 18 04:20:03.804: INFO: Waiting up to 5m0s for pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4" in namespace "secrets-3843" to be "running and ready"
Apr 18 04:20:03.874: INFO: Pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4": Phase="Pending", Reason="", readiness=false. Elapsed: 69.800123ms
Apr 18 04:20:03.874: INFO: The phase of Pod pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:20:05.877: INFO: Pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073126218s
Apr 18 04:20:05.877: INFO: The phase of Pod pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:20:07.879: INFO: Pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074288835s
Apr 18 04:20:07.879: INFO: The phase of Pod pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:20:09.878: INFO: Pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4": Phase="Running", Reason="", readiness=true. Elapsed: 6.07375001s
Apr 18 04:20:09.878: INFO: The phase of Pod pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4 is Running (Ready = true)
Apr 18 04:20:09.878: INFO: Pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-202f34c0-b9b1-4a87-bd97-25ca78d0c3fa 04/18/23 04:20:09.907
STEP: Updating secret s-test-opt-upd-8ca46fca-1ead-4b92-af36-854d4bb7e3c1 04/18/23 04:20:09.933
STEP: Creating secret with name s-test-opt-create-2aff5ade-ef38-45c0-816e-8a54675edbd2 04/18/23 04:20:09.962
STEP: waiting to observe update in volume 04/18/23 04:20:10.047
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 04:21:22.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3843" for this suite. 04/18/23 04:21:22.852
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":58,"skipped":1014,"failed":0}
------------------------------
â€¢ [SLOW TEST] [79.623 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:20:03.271
    Apr 18 04:20:03.272: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 04:20:03.273
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:20:03.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:20:03.4
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-202f34c0-b9b1-4a87-bd97-25ca78d0c3fa 04/18/23 04:20:03.406
    STEP: Creating secret with name s-test-opt-upd-8ca46fca-1ead-4b92-af36-854d4bb7e3c1 04/18/23 04:20:03.746
    STEP: Creating the pod 04/18/23 04:20:03.778
    Apr 18 04:20:03.804: INFO: Waiting up to 5m0s for pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4" in namespace "secrets-3843" to be "running and ready"
    Apr 18 04:20:03.874: INFO: Pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4": Phase="Pending", Reason="", readiness=false. Elapsed: 69.800123ms
    Apr 18 04:20:03.874: INFO: The phase of Pod pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:20:05.877: INFO: Pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073126218s
    Apr 18 04:20:05.877: INFO: The phase of Pod pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:20:07.879: INFO: Pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074288835s
    Apr 18 04:20:07.879: INFO: The phase of Pod pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:20:09.878: INFO: Pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4": Phase="Running", Reason="", readiness=true. Elapsed: 6.07375001s
    Apr 18 04:20:09.878: INFO: The phase of Pod pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4 is Running (Ready = true)
    Apr 18 04:20:09.878: INFO: Pod "pod-secrets-99c09252-f8cf-4cf7-88d4-b93587aa64b4" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-202f34c0-b9b1-4a87-bd97-25ca78d0c3fa 04/18/23 04:20:09.907
    STEP: Updating secret s-test-opt-upd-8ca46fca-1ead-4b92-af36-854d4bb7e3c1 04/18/23 04:20:09.933
    STEP: Creating secret with name s-test-opt-create-2aff5ade-ef38-45c0-816e-8a54675edbd2 04/18/23 04:20:09.962
    STEP: waiting to observe update in volume 04/18/23 04:20:10.047
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 04:21:22.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3843" for this suite. 04/18/23 04:21:22.852
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:21:22.895
Apr 18 04:21:22.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:21:22.896
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:21:22.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:21:22.946
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 04/18/23 04:21:22.948
Apr 18 04:21:23.087: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2" in namespace "projected-3890" to be "Succeeded or Failed"
Apr 18 04:21:23.090: INFO: Pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.218257ms
Apr 18 04:21:25.095: INFO: Pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00826803s
Apr 18 04:21:27.094: INFO: Pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2": Phase="Running", Reason="", readiness=false. Elapsed: 4.00707816s
Apr 18 04:21:29.096: INFO: Pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00868577s
STEP: Saw pod success 04/18/23 04:21:29.096
Apr 18 04:21:29.096: INFO: Pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2" satisfied condition "Succeeded or Failed"
Apr 18 04:21:29.099: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2 container client-container: <nil>
STEP: delete the pod 04/18/23 04:21:29.104
Apr 18 04:21:29.270: INFO: Waiting for pod downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2 to disappear
Apr 18 04:21:29.273: INFO: Pod downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 04:21:29.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3890" for this suite. 04/18/23 04:21:29.277
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":59,"skipped":1018,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.454 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:21:22.895
    Apr 18 04:21:22.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:21:22.896
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:21:22.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:21:22.946
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 04/18/23 04:21:22.948
    Apr 18 04:21:23.087: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2" in namespace "projected-3890" to be "Succeeded or Failed"
    Apr 18 04:21:23.090: INFO: Pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.218257ms
    Apr 18 04:21:25.095: INFO: Pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00826803s
    Apr 18 04:21:27.094: INFO: Pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2": Phase="Running", Reason="", readiness=false. Elapsed: 4.00707816s
    Apr 18 04:21:29.096: INFO: Pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00868577s
    STEP: Saw pod success 04/18/23 04:21:29.096
    Apr 18 04:21:29.096: INFO: Pod "downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2" satisfied condition "Succeeded or Failed"
    Apr 18 04:21:29.099: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2 container client-container: <nil>
    STEP: delete the pod 04/18/23 04:21:29.104
    Apr 18 04:21:29.270: INFO: Waiting for pod downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2 to disappear
    Apr 18 04:21:29.273: INFO: Pod downwardapi-volume-5df78594-5c24-4769-9b57-e31e906ed3e2 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 04:21:29.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3890" for this suite. 04/18/23 04:21:29.277
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:21:29.35
Apr 18 04:21:29.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sched-preemption 04/18/23 04:21:29.351
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:21:29.568
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:21:29.57
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 18 04:21:29.707: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 04:22:29.769: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 04/18/23 04:22:29.773
Apr 18 04:22:29.912: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 18 04:22:29.977: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 18 04:22:30.086: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 18 04:22:30.216: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 18 04:22:30.444: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 18 04:22:30.529: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/18/23 04:22:30.53
Apr 18 04:22:30.530: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8445" to be "running"
Apr 18 04:22:30.599: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 69.428414ms
Apr 18 04:22:32.672: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.142414627s
Apr 18 04:22:34.760: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.230195806s
Apr 18 04:22:36.718: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.188763919s
Apr 18 04:22:38.669: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.139353888s
Apr 18 04:22:40.607: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.077164743s
Apr 18 04:22:40.607: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 18 04:22:40.607: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8445" to be "running"
Apr 18 04:22:40.612: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.067599ms
Apr 18 04:22:40.612: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 04:22:40.612: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8445" to be "running"
Apr 18 04:22:40.615: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.200957ms
Apr 18 04:22:40.615: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 04:22:40.615: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8445" to be "running"
Apr 18 04:22:40.634: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 18.683341ms
Apr 18 04:22:40.634: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 04:22:40.634: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8445" to be "running"
Apr 18 04:22:40.637: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.605577ms
Apr 18 04:22:40.637: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 04:22:40.637: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8445" to be "running"
Apr 18 04:22:40.639: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.824866ms
Apr 18 04:22:40.639: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 04/18/23 04:22:40.639
Apr 18 04:22:40.664: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Apr 18 04:22:40.667: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.014691ms
Apr 18 04:22:42.672: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007868209s
Apr 18 04:22:44.717: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052840663s
Apr 18 04:22:46.672: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007958408s
Apr 18 04:22:48.702: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.037815806s
Apr 18 04:22:48.702: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 18 04:22:48.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8445" for this suite. 04/18/23 04:22:48.949
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":60,"skipped":1027,"failed":0}
------------------------------
â€¢ [SLOW TEST] [79.831 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:21:29.35
    Apr 18 04:21:29.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sched-preemption 04/18/23 04:21:29.351
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:21:29.568
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:21:29.57
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 18 04:21:29.707: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 04:22:29.769: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 04/18/23 04:22:29.773
    Apr 18 04:22:29.912: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 18 04:22:29.977: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 18 04:22:30.086: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 18 04:22:30.216: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Apr 18 04:22:30.444: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Apr 18 04:22:30.529: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/18/23 04:22:30.53
    Apr 18 04:22:30.530: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8445" to be "running"
    Apr 18 04:22:30.599: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 69.428414ms
    Apr 18 04:22:32.672: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.142414627s
    Apr 18 04:22:34.760: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.230195806s
    Apr 18 04:22:36.718: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.188763919s
    Apr 18 04:22:38.669: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.139353888s
    Apr 18 04:22:40.607: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.077164743s
    Apr 18 04:22:40.607: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 18 04:22:40.607: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8445" to be "running"
    Apr 18 04:22:40.612: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.067599ms
    Apr 18 04:22:40.612: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 04:22:40.612: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8445" to be "running"
    Apr 18 04:22:40.615: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.200957ms
    Apr 18 04:22:40.615: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 04:22:40.615: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8445" to be "running"
    Apr 18 04:22:40.634: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 18.683341ms
    Apr 18 04:22:40.634: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 04:22:40.634: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8445" to be "running"
    Apr 18 04:22:40.637: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.605577ms
    Apr 18 04:22:40.637: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 04:22:40.637: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8445" to be "running"
    Apr 18 04:22:40.639: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.824866ms
    Apr 18 04:22:40.639: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 04/18/23 04:22:40.639
    Apr 18 04:22:40.664: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Apr 18 04:22:40.667: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.014691ms
    Apr 18 04:22:42.672: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007868209s
    Apr 18 04:22:44.717: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.052840663s
    Apr 18 04:22:46.672: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007958408s
    Apr 18 04:22:48.702: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.037815806s
    Apr 18 04:22:48.702: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 04:22:48.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8445" for this suite. 04/18/23 04:22:48.949
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:22:49.183
Apr 18 04:22:49.183: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 04:22:49.184
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:22:49.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:22:49.294
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/18/23 04:22:49.296
Apr 18 04:22:49.359: INFO: Waiting up to 5m0s for pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35" in namespace "emptydir-3404" to be "Succeeded or Failed"
Apr 18 04:22:49.468: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35": Phase="Pending", Reason="", readiness=false. Elapsed: 108.902013ms
Apr 18 04:22:51.485: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.125876174s
Apr 18 04:22:53.474: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35": Phase="Pending", Reason="", readiness=false. Elapsed: 4.115004419s
Apr 18 04:22:55.588: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35": Phase="Pending", Reason="", readiness=false. Elapsed: 6.228222955s
Apr 18 04:22:57.473: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.113641127s
STEP: Saw pod success 04/18/23 04:22:57.473
Apr 18 04:22:57.473: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35" satisfied condition "Succeeded or Failed"
Apr 18 04:22:57.527: INFO: Trying to get logs from node apps-208 pod pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35 container test-container: <nil>
STEP: delete the pod 04/18/23 04:22:57.564
Apr 18 04:22:57.879: INFO: Waiting for pod pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35 to disappear
Apr 18 04:22:57.882: INFO: Pod pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 04:22:57.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3404" for this suite. 04/18/23 04:22:57.889
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":61,"skipped":1064,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.796 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:22:49.183
    Apr 18 04:22:49.183: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 04:22:49.184
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:22:49.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:22:49.294
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/18/23 04:22:49.296
    Apr 18 04:22:49.359: INFO: Waiting up to 5m0s for pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35" in namespace "emptydir-3404" to be "Succeeded or Failed"
    Apr 18 04:22:49.468: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35": Phase="Pending", Reason="", readiness=false. Elapsed: 108.902013ms
    Apr 18 04:22:51.485: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.125876174s
    Apr 18 04:22:53.474: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35": Phase="Pending", Reason="", readiness=false. Elapsed: 4.115004419s
    Apr 18 04:22:55.588: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35": Phase="Pending", Reason="", readiness=false. Elapsed: 6.228222955s
    Apr 18 04:22:57.473: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.113641127s
    STEP: Saw pod success 04/18/23 04:22:57.473
    Apr 18 04:22:57.473: INFO: Pod "pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35" satisfied condition "Succeeded or Failed"
    Apr 18 04:22:57.527: INFO: Trying to get logs from node apps-208 pod pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35 container test-container: <nil>
    STEP: delete the pod 04/18/23 04:22:57.564
    Apr 18 04:22:57.879: INFO: Waiting for pod pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35 to disappear
    Apr 18 04:22:57.882: INFO: Pod pod-8fcc3a6a-e186-49dd-9aff-531eb9024a35 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 04:22:57.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3404" for this suite. 04/18/23 04:22:57.889
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:22:57.979
Apr 18 04:22:57.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:22:57.98
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:22:58.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:22:58.054
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-609f5e19-6aa2-4847-b0f5-1e5242ca28ba 04/18/23 04:22:58.056
STEP: Creating a pod to test consume secrets 04/18/23 04:22:58.118
Apr 18 04:22:58.160: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5" in namespace "projected-8274" to be "Succeeded or Failed"
Apr 18 04:22:58.203: INFO: Pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.635122ms
Apr 18 04:23:00.207: INFO: Pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047081845s
Apr 18 04:23:02.209: INFO: Pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5": Phase="Running", Reason="", readiness=false. Elapsed: 4.049053203s
Apr 18 04:23:04.207: INFO: Pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04678062s
STEP: Saw pod success 04/18/23 04:23:04.207
Apr 18 04:23:04.207: INFO: Pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5" satisfied condition "Succeeded or Failed"
Apr 18 04:23:04.210: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/18/23 04:23:04.216
Apr 18 04:23:04.271: INFO: Waiting for pod pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5 to disappear
Apr 18 04:23:04.273: INFO: Pod pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 04:23:04.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8274" for this suite. 04/18/23 04:23:04.278
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":62,"skipped":1064,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.324 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:22:57.979
    Apr 18 04:22:57.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:22:57.98
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:22:58.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:22:58.054
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-609f5e19-6aa2-4847-b0f5-1e5242ca28ba 04/18/23 04:22:58.056
    STEP: Creating a pod to test consume secrets 04/18/23 04:22:58.118
    Apr 18 04:22:58.160: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5" in namespace "projected-8274" to be "Succeeded or Failed"
    Apr 18 04:22:58.203: INFO: Pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.635122ms
    Apr 18 04:23:00.207: INFO: Pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047081845s
    Apr 18 04:23:02.209: INFO: Pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5": Phase="Running", Reason="", readiness=false. Elapsed: 4.049053203s
    Apr 18 04:23:04.207: INFO: Pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04678062s
    STEP: Saw pod success 04/18/23 04:23:04.207
    Apr 18 04:23:04.207: INFO: Pod "pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5" satisfied condition "Succeeded or Failed"
    Apr 18 04:23:04.210: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 04:23:04.216
    Apr 18 04:23:04.271: INFO: Waiting for pod pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5 to disappear
    Apr 18 04:23:04.273: INFO: Pod pod-projected-secrets-3867bdc6-ec01-4570-b96f-e1fd6f393fe5 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 04:23:04.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8274" for this suite. 04/18/23 04:23:04.278
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:23:04.303
Apr 18 04:23:04.303: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-probe 04/18/23 04:23:04.304
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:23:04.426
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:23:04.429
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc in namespace container-probe-5732 04/18/23 04:23:04.432
Apr 18 04:23:04.479: INFO: Waiting up to 5m0s for pod "liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc" in namespace "container-probe-5732" to be "not pending"
Apr 18 04:23:04.482: INFO: Pod "liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.537721ms
Apr 18 04:23:06.543: INFO: Pod "liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063608478s
Apr 18 04:23:08.486: INFO: Pod "liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc": Phase="Running", Reason="", readiness=true. Elapsed: 4.007307191s
Apr 18 04:23:08.486: INFO: Pod "liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc" satisfied condition "not pending"
Apr 18 04:23:08.486: INFO: Started pod liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc in namespace container-probe-5732
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 04:23:08.486
Apr 18 04:23:08.490: INFO: Initial restart count of pod liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc is 0
Apr 18 04:23:28.660: INFO: Restart count of pod container-probe-5732/liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc is now 1 (20.170312587s elapsed)
STEP: deleting the pod 04/18/23 04:23:28.66
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 04:23:28.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5732" for this suite. 04/18/23 04:23:28.817
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":63,"skipped":1070,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.530 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:23:04.303
    Apr 18 04:23:04.303: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-probe 04/18/23 04:23:04.304
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:23:04.426
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:23:04.429
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc in namespace container-probe-5732 04/18/23 04:23:04.432
    Apr 18 04:23:04.479: INFO: Waiting up to 5m0s for pod "liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc" in namespace "container-probe-5732" to be "not pending"
    Apr 18 04:23:04.482: INFO: Pod "liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.537721ms
    Apr 18 04:23:06.543: INFO: Pod "liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063608478s
    Apr 18 04:23:08.486: INFO: Pod "liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc": Phase="Running", Reason="", readiness=true. Elapsed: 4.007307191s
    Apr 18 04:23:08.486: INFO: Pod "liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc" satisfied condition "not pending"
    Apr 18 04:23:08.486: INFO: Started pod liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc in namespace container-probe-5732
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 04:23:08.486
    Apr 18 04:23:08.490: INFO: Initial restart count of pod liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc is 0
    Apr 18 04:23:28.660: INFO: Restart count of pod container-probe-5732/liveness-6aec5e59-877f-46f0-827f-d5ea5b5b67cc is now 1 (20.170312587s elapsed)
    STEP: deleting the pod 04/18/23 04:23:28.66
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 04:23:28.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5732" for this suite. 04/18/23 04:23:28.817
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:23:28.833
Apr 18 04:23:28.833: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename security-context-test 04/18/23 04:23:28.834
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:23:29.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:23:29.082
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Apr 18 04:23:29.200: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7" in namespace "security-context-test-3071" to be "Succeeded or Failed"
Apr 18 04:23:29.203: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.087013ms
Apr 18 04:23:31.307: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106871247s
Apr 18 04:23:33.207: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007346082s
Apr 18 04:23:35.208: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008007905s
Apr 18 04:23:37.208: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.008093766s
Apr 18 04:23:37.208: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 04:23:37.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3071" for this suite. 04/18/23 04:23:37.213
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":64,"skipped":1070,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.423 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:23:28.833
    Apr 18 04:23:28.833: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename security-context-test 04/18/23 04:23:28.834
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:23:29.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:23:29.082
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Apr 18 04:23:29.200: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7" in namespace "security-context-test-3071" to be "Succeeded or Failed"
    Apr 18 04:23:29.203: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.087013ms
    Apr 18 04:23:31.307: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106871247s
    Apr 18 04:23:33.207: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007346082s
    Apr 18 04:23:35.208: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008007905s
    Apr 18 04:23:37.208: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.008093766s
    Apr 18 04:23:37.208: INFO: Pod "busybox-readonly-false-55c56c43-0106-47c7-8ed3-a52a8f976ed7" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 04:23:37.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-3071" for this suite. 04/18/23 04:23:37.213
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:23:37.257
Apr 18 04:23:37.257: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename gc 04/18/23 04:23:37.258
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:23:37.362
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:23:37.365
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Apr 18 04:23:37.699: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"53d431d1-7b0c-4916-a768-09ffe90037fd", Controller:(*bool)(0xc003bfd592), BlockOwnerDeletion:(*bool)(0xc003bfd593)}}
Apr 18 04:23:37.842: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"05fe35c5-a74f-4f1d-82c3-7a4d52b79acf", Controller:(*bool)(0xc003bfd812), BlockOwnerDeletion:(*bool)(0xc003bfd813)}}
Apr 18 04:23:37.883: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"c55eb6bc-1345-4131-80ec-d6c84b575295", Controller:(*bool)(0xc003bfdaba), BlockOwnerDeletion:(*bool)(0xc003bfdabb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 04:23:43.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9446" for this suite. 04/18/23 04:23:43.151
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":65,"skipped":1083,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.918 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:23:37.257
    Apr 18 04:23:37.257: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename gc 04/18/23 04:23:37.258
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:23:37.362
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:23:37.365
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Apr 18 04:23:37.699: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"53d431d1-7b0c-4916-a768-09ffe90037fd", Controller:(*bool)(0xc003bfd592), BlockOwnerDeletion:(*bool)(0xc003bfd593)}}
    Apr 18 04:23:37.842: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"05fe35c5-a74f-4f1d-82c3-7a4d52b79acf", Controller:(*bool)(0xc003bfd812), BlockOwnerDeletion:(*bool)(0xc003bfd813)}}
    Apr 18 04:23:37.883: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"c55eb6bc-1345-4131-80ec-d6c84b575295", Controller:(*bool)(0xc003bfdaba), BlockOwnerDeletion:(*bool)(0xc003bfdabb)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 04:23:43.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9446" for this suite. 04/18/23 04:23:43.151
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:23:43.176
Apr 18 04:23:43.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 04:23:43.177
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:23:43.308
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:23:43.311
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 04/18/23 04:23:43.322
Apr 18 04:23:43.450: INFO: Waiting up to 5m0s for pod "pod-5tv8f" in namespace "pods-9802" to be "running"
Apr 18 04:23:43.475: INFO: Pod "pod-5tv8f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.425547ms
Apr 18 04:23:45.480: INFO: Pod "pod-5tv8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029783814s
Apr 18 04:23:47.480: INFO: Pod "pod-5tv8f": Phase="Running", Reason="", readiness=true. Elapsed: 4.029285483s
Apr 18 04:23:47.480: INFO: Pod "pod-5tv8f" satisfied condition "running"
STEP: patching /status 04/18/23 04:23:47.48
Apr 18 04:23:47.510: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 04:23:47.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9802" for this suite. 04/18/23 04:23:47.515
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":66,"skipped":1096,"failed":0}
------------------------------
â€¢ [4.366 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:23:43.176
    Apr 18 04:23:43.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 04:23:43.177
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:23:43.308
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:23:43.311
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 04/18/23 04:23:43.322
    Apr 18 04:23:43.450: INFO: Waiting up to 5m0s for pod "pod-5tv8f" in namespace "pods-9802" to be "running"
    Apr 18 04:23:43.475: INFO: Pod "pod-5tv8f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.425547ms
    Apr 18 04:23:45.480: INFO: Pod "pod-5tv8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029783814s
    Apr 18 04:23:47.480: INFO: Pod "pod-5tv8f": Phase="Running", Reason="", readiness=true. Elapsed: 4.029285483s
    Apr 18 04:23:47.480: INFO: Pod "pod-5tv8f" satisfied condition "running"
    STEP: patching /status 04/18/23 04:23:47.48
    Apr 18 04:23:47.510: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 04:23:47.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9802" for this suite. 04/18/23 04:23:47.515
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:23:47.545
Apr 18 04:23:47.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-webhook 04/18/23 04:23:47.546
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:23:47.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:23:47.683
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/18/23 04:23:47.685
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/18/23 04:23:48.25
STEP: Deploying the custom resource conversion webhook pod 04/18/23 04:23:48.553
STEP: Wait for the deployment to be ready 04/18/23 04:23:48.783
Apr 18 04:23:48.976: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Apr 18 04:23:51.150: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 23, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 23, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 23, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 23, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 04:23:53.155
STEP: Verifying the service has paired with the endpoint 04/18/23 04:23:53.384
Apr 18 04:23:54.385: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Apr 18 04:23:54.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Creating a v1 custom resource 04/18/23 04:24:01.896
STEP: v2 custom resource should be converted 04/18/23 04:24:01.943
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:24:02.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7044" for this suite. 04/18/23 04:24:02.51
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":67,"skipped":1164,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.267 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:23:47.545
    Apr 18 04:23:47.545: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-webhook 04/18/23 04:23:47.546
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:23:47.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:23:47.683
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/18/23 04:23:47.685
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/18/23 04:23:48.25
    STEP: Deploying the custom resource conversion webhook pod 04/18/23 04:23:48.553
    STEP: Wait for the deployment to be ready 04/18/23 04:23:48.783
    Apr 18 04:23:48.976: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Apr 18 04:23:51.150: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 23, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 23, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 23, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 23, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 04:23:53.155
    STEP: Verifying the service has paired with the endpoint 04/18/23 04:23:53.384
    Apr 18 04:23:54.385: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Apr 18 04:23:54.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Creating a v1 custom resource 04/18/23 04:24:01.896
    STEP: v2 custom resource should be converted 04/18/23 04:24:01.943
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:24:02.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-7044" for this suite. 04/18/23 04:24:02.51
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:24:02.815
Apr 18 04:24:02.815: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 04:24:02.816
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:24:02.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:24:02.936
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 04:24:03.326
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 04:24:04.258
STEP: Deploying the webhook pod 04/18/23 04:24:04.301
STEP: Wait for the deployment to be ready 04/18/23 04:24:04.438
Apr 18 04:24:04.502: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 18 04:24:06.587: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 24, 4, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 24, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 24, 4, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 24, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 04:24:08.637
STEP: Verifying the service has paired with the endpoint 04/18/23 04:24:08.698
Apr 18 04:24:09.699: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/18/23 04:24:09.702
STEP: create a pod that should be updated by the webhook 04/18/23 04:24:09.751
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:24:09.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8917" for this suite. 04/18/23 04:24:09.945
STEP: Destroying namespace "webhook-8917-markers" for this suite. 04/18/23 04:24:10.066
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":68,"skipped":1226,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.674 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:24:02.815
    Apr 18 04:24:02.815: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 04:24:02.816
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:24:02.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:24:02.936
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 04:24:03.326
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 04:24:04.258
    STEP: Deploying the webhook pod 04/18/23 04:24:04.301
    STEP: Wait for the deployment to be ready 04/18/23 04:24:04.438
    Apr 18 04:24:04.502: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 18 04:24:06.587: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 24, 4, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 24, 4, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 24, 4, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 24, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 04:24:08.637
    STEP: Verifying the service has paired with the endpoint 04/18/23 04:24:08.698
    Apr 18 04:24:09.699: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/18/23 04:24:09.702
    STEP: create a pod that should be updated by the webhook 04/18/23 04:24:09.751
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:24:09.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8917" for this suite. 04/18/23 04:24:09.945
    STEP: Destroying namespace "webhook-8917-markers" for this suite. 04/18/23 04:24:10.066
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:24:10.491
Apr 18 04:24:10.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-probe 04/18/23 04:24:10.492
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:24:10.618
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:24:10.621
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a in namespace container-probe-2209 04/18/23 04:24:10.624
Apr 18 04:24:10.733: INFO: Waiting up to 5m0s for pod "busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a" in namespace "container-probe-2209" to be "not pending"
Apr 18 04:24:10.780: INFO: Pod "busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a": Phase="Pending", Reason="", readiness=false. Elapsed: 46.438382ms
Apr 18 04:24:12.785: INFO: Pod "busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051464447s
Apr 18 04:24:14.785: INFO: Pod "busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a": Phase="Running", Reason="", readiness=true. Elapsed: 4.051954091s
Apr 18 04:24:14.785: INFO: Pod "busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a" satisfied condition "not pending"
Apr 18 04:24:14.785: INFO: Started pod busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a in namespace container-probe-2209
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 04:24:14.785
Apr 18 04:24:14.828: INFO: Initial restart count of pod busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a is 0
Apr 18 04:25:03.111: INFO: Restart count of pod container-probe-2209/busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a is now 1 (48.28225006s elapsed)
STEP: deleting the pod 04/18/23 04:25:03.111
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 04:25:03.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2209" for this suite. 04/18/23 04:25:03.163
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":69,"skipped":1244,"failed":0}
------------------------------
â€¢ [SLOW TEST] [52.736 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:24:10.491
    Apr 18 04:24:10.491: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-probe 04/18/23 04:24:10.492
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:24:10.618
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:24:10.621
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a in namespace container-probe-2209 04/18/23 04:24:10.624
    Apr 18 04:24:10.733: INFO: Waiting up to 5m0s for pod "busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a" in namespace "container-probe-2209" to be "not pending"
    Apr 18 04:24:10.780: INFO: Pod "busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a": Phase="Pending", Reason="", readiness=false. Elapsed: 46.438382ms
    Apr 18 04:24:12.785: INFO: Pod "busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051464447s
    Apr 18 04:24:14.785: INFO: Pod "busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a": Phase="Running", Reason="", readiness=true. Elapsed: 4.051954091s
    Apr 18 04:24:14.785: INFO: Pod "busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a" satisfied condition "not pending"
    Apr 18 04:24:14.785: INFO: Started pod busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a in namespace container-probe-2209
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 04:24:14.785
    Apr 18 04:24:14.828: INFO: Initial restart count of pod busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a is 0
    Apr 18 04:25:03.111: INFO: Restart count of pod container-probe-2209/busybox-6ec9ef5b-7ac1-43e5-b4db-f74bc040979a is now 1 (48.28225006s elapsed)
    STEP: deleting the pod 04/18/23 04:25:03.111
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 04:25:03.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2209" for this suite. 04/18/23 04:25:03.163
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:25:03.228
Apr 18 04:25:03.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 04:25:03.229
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:03.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:03.336
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 04:25:03.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7690" for this suite. 04/18/23 04:25:03.795
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":70,"skipped":1261,"failed":0}
------------------------------
â€¢ [0.599 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:25:03.228
    Apr 18 04:25:03.228: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 04:25:03.229
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:03.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:03.336
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 04:25:03.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7690" for this suite. 04/18/23 04:25:03.795
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:25:03.827
Apr 18 04:25:03.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 04:25:03.828
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:03.94
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:03.943
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/18/23 04:25:03.963
Apr 18 04:25:03.994: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4300" to be "running and ready"
Apr 18 04:25:04.036: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 42.308045ms
Apr 18 04:25:04.036: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:25:06.040: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04657458s
Apr 18 04:25:06.040: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:25:08.041: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.047459033s
Apr 18 04:25:08.041: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 18 04:25:08.041: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 04/18/23 04:25:08.044
Apr 18 04:25:08.078: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-4300" to be "running and ready"
Apr 18 04:25:08.082: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.641213ms
Apr 18 04:25:08.082: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:25:10.146: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067596863s
Apr 18 04:25:10.146: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:25:12.087: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.008560077s
Apr 18 04:25:12.087: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Apr 18 04:25:12.087: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/18/23 04:25:12.09
STEP: delete the pod with lifecycle hook 04/18/23 04:25:12.104
Apr 18 04:25:12.140: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 18 04:25:12.143: INFO: Pod pod-with-poststart-http-hook still exists
Apr 18 04:25:14.144: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 18 04:25:14.148: INFO: Pod pod-with-poststart-http-hook still exists
Apr 18 04:25:16.144: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 18 04:25:16.148: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 18 04:25:16.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4300" for this suite. 04/18/23 04:25:16.2
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":71,"skipped":1268,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.411 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:25:03.827
    Apr 18 04:25:03.827: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 04:25:03.828
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:03.94
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:03.943
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/18/23 04:25:03.963
    Apr 18 04:25:03.994: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4300" to be "running and ready"
    Apr 18 04:25:04.036: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 42.308045ms
    Apr 18 04:25:04.036: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:25:06.040: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04657458s
    Apr 18 04:25:06.040: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:25:08.041: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.047459033s
    Apr 18 04:25:08.041: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 18 04:25:08.041: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 04/18/23 04:25:08.044
    Apr 18 04:25:08.078: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-4300" to be "running and ready"
    Apr 18 04:25:08.082: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 3.641213ms
    Apr 18 04:25:08.082: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:25:10.146: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067596863s
    Apr 18 04:25:10.146: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:25:12.087: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.008560077s
    Apr 18 04:25:12.087: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Apr 18 04:25:12.087: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/18/23 04:25:12.09
    STEP: delete the pod with lifecycle hook 04/18/23 04:25:12.104
    Apr 18 04:25:12.140: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 18 04:25:12.143: INFO: Pod pod-with-poststart-http-hook still exists
    Apr 18 04:25:14.144: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 18 04:25:14.148: INFO: Pod pod-with-poststart-http-hook still exists
    Apr 18 04:25:16.144: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 18 04:25:16.148: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 18 04:25:16.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4300" for this suite. 04/18/23 04:25:16.2
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:25:16.239
Apr 18 04:25:16.239: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename proxy 04/18/23 04:25:16.24
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:16.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:16.27
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Apr 18 04:25:16.278: INFO: Creating pod...
Apr 18 04:25:16.348: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1315" to be "running"
Apr 18 04:25:16.388: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 39.583651ms
Apr 18 04:25:18.516: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.167242123s
Apr 18 04:25:20.394: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.045541797s
Apr 18 04:25:20.394: INFO: Pod "agnhost" satisfied condition "running"
Apr 18 04:25:20.394: INFO: Creating service...
Apr 18 04:25:20.511: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=DELETE
Apr 18 04:25:20.516: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 18 04:25:20.516: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=OPTIONS
Apr 18 04:25:20.530: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 18 04:25:20.530: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=PATCH
Apr 18 04:25:20.573: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 18 04:25:20.573: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=POST
Apr 18 04:25:20.577: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 18 04:25:20.577: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=PUT
Apr 18 04:25:20.580: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 18 04:25:20.580: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=DELETE
Apr 18 04:25:20.584: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 18 04:25:20.584: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=OPTIONS
Apr 18 04:25:20.588: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 18 04:25:20.588: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=PATCH
Apr 18 04:25:20.592: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 18 04:25:20.592: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=POST
Apr 18 04:25:20.619: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 18 04:25:20.619: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=PUT
Apr 18 04:25:20.623: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 18 04:25:20.623: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=GET
Apr 18 04:25:20.645: INFO: http.Client request:GET StatusCode:301
Apr 18 04:25:20.645: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=GET
Apr 18 04:25:20.649: INFO: http.Client request:GET StatusCode:301
Apr 18 04:25:20.649: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=HEAD
Apr 18 04:25:20.651: INFO: http.Client request:HEAD StatusCode:301
Apr 18 04:25:20.651: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=HEAD
Apr 18 04:25:20.655: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 18 04:25:20.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1315" for this suite. 04/18/23 04:25:20.659
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":72,"skipped":1280,"failed":0}
------------------------------
â€¢ [4.492 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:25:16.239
    Apr 18 04:25:16.239: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename proxy 04/18/23 04:25:16.24
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:16.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:16.27
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Apr 18 04:25:16.278: INFO: Creating pod...
    Apr 18 04:25:16.348: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1315" to be "running"
    Apr 18 04:25:16.388: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 39.583651ms
    Apr 18 04:25:18.516: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.167242123s
    Apr 18 04:25:20.394: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.045541797s
    Apr 18 04:25:20.394: INFO: Pod "agnhost" satisfied condition "running"
    Apr 18 04:25:20.394: INFO: Creating service...
    Apr 18 04:25:20.511: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=DELETE
    Apr 18 04:25:20.516: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 18 04:25:20.516: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=OPTIONS
    Apr 18 04:25:20.530: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 18 04:25:20.530: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=PATCH
    Apr 18 04:25:20.573: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 18 04:25:20.573: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=POST
    Apr 18 04:25:20.577: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 18 04:25:20.577: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=PUT
    Apr 18 04:25:20.580: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 18 04:25:20.580: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=DELETE
    Apr 18 04:25:20.584: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 18 04:25:20.584: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Apr 18 04:25:20.588: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 18 04:25:20.588: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=PATCH
    Apr 18 04:25:20.592: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 18 04:25:20.592: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=POST
    Apr 18 04:25:20.619: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 18 04:25:20.619: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=PUT
    Apr 18 04:25:20.623: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 18 04:25:20.623: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=GET
    Apr 18 04:25:20.645: INFO: http.Client request:GET StatusCode:301
    Apr 18 04:25:20.645: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=GET
    Apr 18 04:25:20.649: INFO: http.Client request:GET StatusCode:301
    Apr 18 04:25:20.649: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/pods/agnhost/proxy?method=HEAD
    Apr 18 04:25:20.651: INFO: http.Client request:HEAD StatusCode:301
    Apr 18 04:25:20.651: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-1315/services/e2e-proxy-test-service/proxy?method=HEAD
    Apr 18 04:25:20.655: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 18 04:25:20.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1315" for this suite. 04/18/23 04:25:20.659
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:25:20.732
Apr 18 04:25:20.732: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 04:25:20.733
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:20.848
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:20.851
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 04/18/23 04:25:20.853
Apr 18 04:25:20.913: INFO: Waiting up to 5m0s for pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4" in namespace "downward-api-9794" to be "Succeeded or Failed"
Apr 18 04:25:20.925: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.393904ms
Apr 18 04:25:22.998: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084488418s
Apr 18 04:25:25.011: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4": Phase="Running", Reason="", readiness=true. Elapsed: 4.097774449s
Apr 18 04:25:26.971: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4": Phase="Running", Reason="", readiness=false. Elapsed: 6.057043678s
Apr 18 04:25:28.930: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.016233782s
STEP: Saw pod success 04/18/23 04:25:28.93
Apr 18 04:25:28.930: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4" satisfied condition "Succeeded or Failed"
Apr 18 04:25:28.933: INFO: Trying to get logs from node apps-208 pod downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4 container dapi-container: <nil>
STEP: delete the pod 04/18/23 04:25:28.948
Apr 18 04:25:29.011: INFO: Waiting for pod downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4 to disappear
Apr 18 04:25:29.014: INFO: Pod downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 18 04:25:29.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9794" for this suite. 04/18/23 04:25:29.019
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":73,"skipped":1286,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.299 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:25:20.732
    Apr 18 04:25:20.732: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 04:25:20.733
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:20.848
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:20.851
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 04/18/23 04:25:20.853
    Apr 18 04:25:20.913: INFO: Waiting up to 5m0s for pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4" in namespace "downward-api-9794" to be "Succeeded or Failed"
    Apr 18 04:25:20.925: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.393904ms
    Apr 18 04:25:22.998: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084488418s
    Apr 18 04:25:25.011: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4": Phase="Running", Reason="", readiness=true. Elapsed: 4.097774449s
    Apr 18 04:25:26.971: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4": Phase="Running", Reason="", readiness=false. Elapsed: 6.057043678s
    Apr 18 04:25:28.930: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.016233782s
    STEP: Saw pod success 04/18/23 04:25:28.93
    Apr 18 04:25:28.930: INFO: Pod "downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4" satisfied condition "Succeeded or Failed"
    Apr 18 04:25:28.933: INFO: Trying to get logs from node apps-208 pod downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 04:25:28.948
    Apr 18 04:25:29.011: INFO: Waiting for pod downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4 to disappear
    Apr 18 04:25:29.014: INFO: Pod downward-api-2137a6b4-5e02-473c-af2b-fa524b1741b4 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 18 04:25:29.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9794" for this suite. 04/18/23 04:25:29.019
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:25:29.032
Apr 18 04:25:29.032: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 04:25:29.033
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:29.174
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:29.177
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 04:25:29.304
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 04:25:29.902
STEP: Deploying the webhook pod 04/18/23 04:25:29.928
STEP: Wait for the deployment to be ready 04/18/23 04:25:29.971
Apr 18 04:25:30.026: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Apr 18 04:25:32.075: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 25, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 25, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 25, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 25, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 04:25:34.08
STEP: Verifying the service has paired with the endpoint 04/18/23 04:25:34.137
Apr 18 04:25:35.138: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/18/23 04:25:35.171
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/18/23 04:25:35.201
STEP: Creating a dummy validating-webhook-configuration object 04/18/23 04:25:35.281
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/18/23 04:25:35.352
STEP: Creating a dummy mutating-webhook-configuration object 04/18/23 04:25:35.387
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/18/23 04:25:35.657
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:25:35.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2599" for this suite. 04/18/23 04:25:35.897
STEP: Destroying namespace "webhook-2599-markers" for this suite. 04/18/23 04:25:36.086
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":74,"skipped":1312,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.605 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:25:29.032
    Apr 18 04:25:29.032: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 04:25:29.033
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:29.174
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:29.177
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 04:25:29.304
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 04:25:29.902
    STEP: Deploying the webhook pod 04/18/23 04:25:29.928
    STEP: Wait for the deployment to be ready 04/18/23 04:25:29.971
    Apr 18 04:25:30.026: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Apr 18 04:25:32.075: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 25, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 25, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 25, 30, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 25, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 04:25:34.08
    STEP: Verifying the service has paired with the endpoint 04/18/23 04:25:34.137
    Apr 18 04:25:35.138: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/18/23 04:25:35.171
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/18/23 04:25:35.201
    STEP: Creating a dummy validating-webhook-configuration object 04/18/23 04:25:35.281
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/18/23 04:25:35.352
    STEP: Creating a dummy mutating-webhook-configuration object 04/18/23 04:25:35.387
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/18/23 04:25:35.657
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:25:35.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2599" for this suite. 04/18/23 04:25:35.897
    STEP: Destroying namespace "webhook-2599-markers" for this suite. 04/18/23 04:25:36.086
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:25:36.638
Apr 18 04:25:36.638: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sysctl 04/18/23 04:25:36.639
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:36.764
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:36.767
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/18/23 04:25:36.769
STEP: Watching for error events or started pod 04/18/23 04:25:36.834
STEP: Waiting for pod completion 04/18/23 04:25:40.838
Apr 18 04:25:40.838: INFO: Waiting up to 3m0s for pod "sysctl-bdd6616f-3373-4c67-a20a-d5be35d37bbf" in namespace "sysctl-9914" to be "completed"
Apr 18 04:25:40.842: INFO: Pod "sysctl-bdd6616f-3373-4c67-a20a-d5be35d37bbf": Phase="Running", Reason="", readiness=true. Elapsed: 3.40772ms
Apr 18 04:25:42.864: INFO: Pod "sysctl-bdd6616f-3373-4c67-a20a-d5be35d37bbf": Phase="Running", Reason="", readiness=false. Elapsed: 2.025438316s
Apr 18 04:25:44.846: INFO: Pod "sysctl-bdd6616f-3373-4c67-a20a-d5be35d37bbf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007847386s
Apr 18 04:25:44.846: INFO: Pod "sysctl-bdd6616f-3373-4c67-a20a-d5be35d37bbf" satisfied condition "completed"
STEP: Checking that the pod succeeded 04/18/23 04:25:44.849
STEP: Getting logs from the pod 04/18/23 04:25:44.849
STEP: Checking that the sysctl is actually updated 04/18/23 04:25:44.855
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 04:25:44.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-9914" for this suite. 04/18/23 04:25:44.86
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":75,"skipped":1325,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.258 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:25:36.638
    Apr 18 04:25:36.638: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sysctl 04/18/23 04:25:36.639
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:36.764
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:36.767
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/18/23 04:25:36.769
    STEP: Watching for error events or started pod 04/18/23 04:25:36.834
    STEP: Waiting for pod completion 04/18/23 04:25:40.838
    Apr 18 04:25:40.838: INFO: Waiting up to 3m0s for pod "sysctl-bdd6616f-3373-4c67-a20a-d5be35d37bbf" in namespace "sysctl-9914" to be "completed"
    Apr 18 04:25:40.842: INFO: Pod "sysctl-bdd6616f-3373-4c67-a20a-d5be35d37bbf": Phase="Running", Reason="", readiness=true. Elapsed: 3.40772ms
    Apr 18 04:25:42.864: INFO: Pod "sysctl-bdd6616f-3373-4c67-a20a-d5be35d37bbf": Phase="Running", Reason="", readiness=false. Elapsed: 2.025438316s
    Apr 18 04:25:44.846: INFO: Pod "sysctl-bdd6616f-3373-4c67-a20a-d5be35d37bbf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007847386s
    Apr 18 04:25:44.846: INFO: Pod "sysctl-bdd6616f-3373-4c67-a20a-d5be35d37bbf" satisfied condition "completed"
    STEP: Checking that the pod succeeded 04/18/23 04:25:44.849
    STEP: Getting logs from the pod 04/18/23 04:25:44.849
    STEP: Checking that the sysctl is actually updated 04/18/23 04:25:44.855
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 04:25:44.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-9914" for this suite. 04/18/23 04:25:44.86
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:25:44.897
Apr 18 04:25:44.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename var-expansion 04/18/23 04:25:44.898
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:45.006
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:45.008
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 04/18/23 04:25:45.014
Apr 18 04:25:45.227: INFO: Waiting up to 2m0s for pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726" in namespace "var-expansion-5879" to be "running"
Apr 18 04:25:45.306: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 78.525092ms
Apr 18 04:25:47.393: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 2.165427233s
Apr 18 04:25:49.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 4.084170195s
Apr 18 04:25:51.351: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 6.12388633s
Apr 18 04:25:53.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 8.083365899s
Apr 18 04:25:55.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 10.08317838s
Apr 18 04:25:57.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 12.083723314s
Apr 18 04:25:59.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 14.084479634s
Apr 18 04:26:01.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 16.083245008s
Apr 18 04:26:03.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 18.084247351s
Apr 18 04:26:05.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 20.083976949s
Apr 18 04:26:07.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 22.083408309s
Apr 18 04:26:09.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 24.08360761s
Apr 18 04:26:11.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 26.082460976s
Apr 18 04:26:13.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 28.083933692s
Apr 18 04:26:15.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 30.083814327s
Apr 18 04:26:17.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 32.0836605s
Apr 18 04:26:19.322: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 34.094655259s
Apr 18 04:26:21.339: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 36.111502234s
Apr 18 04:26:23.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 38.084442229s
Apr 18 04:26:25.322: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 40.094583581s
Apr 18 04:26:27.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 42.083357097s
Apr 18 04:26:29.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 44.082853304s
Apr 18 04:26:31.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 46.082506258s
Apr 18 04:26:33.326: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 48.098919499s
Apr 18 04:26:35.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 50.08326128s
Apr 18 04:26:37.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 52.084076993s
Apr 18 04:26:39.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 54.083517319s
Apr 18 04:26:41.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 56.083386184s
Apr 18 04:26:43.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 58.084484952s
Apr 18 04:26:45.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.084388173s
Apr 18 04:26:47.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.083474879s
Apr 18 04:26:49.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.084253063s
Apr 18 04:26:51.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.083473798s
Apr 18 04:26:53.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.083267407s
Apr 18 04:26:55.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.082774311s
Apr 18 04:26:57.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.083889593s
Apr 18 04:26:59.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.083560126s
Apr 18 04:27:01.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.084144165s
Apr 18 04:27:03.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.083904725s
Apr 18 04:27:05.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.084042577s
Apr 18 04:27:07.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.083154987s
Apr 18 04:27:09.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.083218321s
Apr 18 04:27:11.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.0837055s
Apr 18 04:27:13.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.084256641s
Apr 18 04:27:15.430: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.202599863s
Apr 18 04:27:17.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.084891366s
Apr 18 04:27:19.327: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.099387748s
Apr 18 04:27:21.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.08425267s
Apr 18 04:27:23.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.084027383s
Apr 18 04:27:25.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.083613251s
Apr 18 04:27:27.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.083389711s
Apr 18 04:27:29.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.083015413s
Apr 18 04:27:31.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.082826113s
Apr 18 04:27:33.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.082940331s
Apr 18 04:27:35.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.082414984s
Apr 18 04:27:37.335: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.107948123s
Apr 18 04:27:39.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.084103707s
Apr 18 04:27:41.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.083504425s
Apr 18 04:27:43.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.084007654s
Apr 18 04:27:45.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.083763755s
Apr 18 04:27:45.314: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.086699831s
STEP: updating the pod 04/18/23 04:27:45.314
Apr 18 04:27:45.863: INFO: Successfully updated pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726"
STEP: waiting for pod running 04/18/23 04:27:45.863
Apr 18 04:27:45.863: INFO: Waiting up to 2m0s for pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726" in namespace "var-expansion-5879" to be "running"
Apr 18 04:27:45.866: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 3.181392ms
Apr 18 04:27:47.871: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Running", Reason="", readiness=true. Elapsed: 2.008088317s
Apr 18 04:27:47.871: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726" satisfied condition "running"
STEP: deleting the pod gracefully 04/18/23 04:27:47.871
Apr 18 04:27:47.871: INFO: Deleting pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726" in namespace "var-expansion-5879"
Apr 18 04:27:47.913: INFO: Wait up to 5m0s for pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 04:28:20.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5879" for this suite. 04/18/23 04:28:20.255
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":76,"skipped":1330,"failed":0}
------------------------------
â€¢ [SLOW TEST] [155.387 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:25:44.897
    Apr 18 04:25:44.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename var-expansion 04/18/23 04:25:44.898
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:25:45.006
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:25:45.008
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 04/18/23 04:25:45.014
    Apr 18 04:25:45.227: INFO: Waiting up to 2m0s for pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726" in namespace "var-expansion-5879" to be "running"
    Apr 18 04:25:45.306: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 78.525092ms
    Apr 18 04:25:47.393: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 2.165427233s
    Apr 18 04:25:49.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 4.084170195s
    Apr 18 04:25:51.351: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 6.12388633s
    Apr 18 04:25:53.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 8.083365899s
    Apr 18 04:25:55.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 10.08317838s
    Apr 18 04:25:57.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 12.083723314s
    Apr 18 04:25:59.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 14.084479634s
    Apr 18 04:26:01.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 16.083245008s
    Apr 18 04:26:03.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 18.084247351s
    Apr 18 04:26:05.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 20.083976949s
    Apr 18 04:26:07.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 22.083408309s
    Apr 18 04:26:09.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 24.08360761s
    Apr 18 04:26:11.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 26.082460976s
    Apr 18 04:26:13.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 28.083933692s
    Apr 18 04:26:15.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 30.083814327s
    Apr 18 04:26:17.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 32.0836605s
    Apr 18 04:26:19.322: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 34.094655259s
    Apr 18 04:26:21.339: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 36.111502234s
    Apr 18 04:26:23.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 38.084442229s
    Apr 18 04:26:25.322: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 40.094583581s
    Apr 18 04:26:27.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 42.083357097s
    Apr 18 04:26:29.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 44.082853304s
    Apr 18 04:26:31.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 46.082506258s
    Apr 18 04:26:33.326: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 48.098919499s
    Apr 18 04:26:35.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 50.08326128s
    Apr 18 04:26:37.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 52.084076993s
    Apr 18 04:26:39.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 54.083517319s
    Apr 18 04:26:41.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 56.083386184s
    Apr 18 04:26:43.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 58.084484952s
    Apr 18 04:26:45.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.084388173s
    Apr 18 04:26:47.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.083474879s
    Apr 18 04:26:49.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.084253063s
    Apr 18 04:26:51.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.083473798s
    Apr 18 04:26:53.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.083267407s
    Apr 18 04:26:55.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.082774311s
    Apr 18 04:26:57.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.083889593s
    Apr 18 04:26:59.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.083560126s
    Apr 18 04:27:01.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.084144165s
    Apr 18 04:27:03.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.083904725s
    Apr 18 04:27:05.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.084042577s
    Apr 18 04:27:07.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.083154987s
    Apr 18 04:27:09.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.083218321s
    Apr 18 04:27:11.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.0837055s
    Apr 18 04:27:13.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.084256641s
    Apr 18 04:27:15.430: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.202599863s
    Apr 18 04:27:17.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.084891366s
    Apr 18 04:27:19.327: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.099387748s
    Apr 18 04:27:21.312: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.08425267s
    Apr 18 04:27:23.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.084027383s
    Apr 18 04:27:25.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.083613251s
    Apr 18 04:27:27.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.083389711s
    Apr 18 04:27:29.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.083015413s
    Apr 18 04:27:31.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.082826113s
    Apr 18 04:27:33.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.082940331s
    Apr 18 04:27:35.310: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.082414984s
    Apr 18 04:27:37.335: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.107948123s
    Apr 18 04:27:39.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.084103707s
    Apr 18 04:27:41.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.083504425s
    Apr 18 04:27:43.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.084007654s
    Apr 18 04:27:45.311: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.083763755s
    Apr 18 04:27:45.314: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.086699831s
    STEP: updating the pod 04/18/23 04:27:45.314
    Apr 18 04:27:45.863: INFO: Successfully updated pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726"
    STEP: waiting for pod running 04/18/23 04:27:45.863
    Apr 18 04:27:45.863: INFO: Waiting up to 2m0s for pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726" in namespace "var-expansion-5879" to be "running"
    Apr 18 04:27:45.866: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Pending", Reason="", readiness=false. Elapsed: 3.181392ms
    Apr 18 04:27:47.871: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726": Phase="Running", Reason="", readiness=true. Elapsed: 2.008088317s
    Apr 18 04:27:47.871: INFO: Pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726" satisfied condition "running"
    STEP: deleting the pod gracefully 04/18/23 04:27:47.871
    Apr 18 04:27:47.871: INFO: Deleting pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726" in namespace "var-expansion-5879"
    Apr 18 04:27:47.913: INFO: Wait up to 5m0s for pod "var-expansion-e6efa984-7584-44c5-80b1-6143a8e4d726" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 04:28:20.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5879" for this suite. 04/18/23 04:28:20.255
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:28:20.284
Apr 18 04:28:20.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename namespaces 04/18/23 04:28:20.285
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:20.321
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:20.323
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 04/18/23 04:28:20.326
Apr 18 04:28:20.329: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 04/18/23 04:28:20.329
Apr 18 04:28:20.391: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 04/18/23 04:28:20.391
Apr 18 04:28:20.438: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 18 04:28:20.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6743" for this suite. 04/18/23 04:28:20.447
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":77,"skipped":1338,"failed":0}
------------------------------
â€¢ [0.183 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:28:20.284
    Apr 18 04:28:20.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename namespaces 04/18/23 04:28:20.285
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:20.321
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:20.323
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 04/18/23 04:28:20.326
    Apr 18 04:28:20.329: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 04/18/23 04:28:20.329
    Apr 18 04:28:20.391: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 04/18/23 04:28:20.391
    Apr 18 04:28:20.438: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 04:28:20.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-6743" for this suite. 04/18/23 04:28:20.447
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:28:20.466
Apr 18 04:28:20.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename var-expansion 04/18/23 04:28:20.468
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:20.553
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:20.555
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Apr 18 04:28:20.618: INFO: Waiting up to 2m0s for pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9" in namespace "var-expansion-1708" to be "container 0 failed with reason CreateContainerConfigError"
Apr 18 04:28:20.650: INFO: Pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9": Phase="Pending", Reason="", readiness=false. Elapsed: 31.124971ms
Apr 18 04:28:22.654: INFO: Pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035043137s
Apr 18 04:28:24.702: INFO: Pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.083309303s
Apr 18 04:28:24.702: INFO: Pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 18 04:28:24.702: INFO: Deleting pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9" in namespace "var-expansion-1708"
Apr 18 04:28:24.756: INFO: Wait up to 5m0s for pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 04:28:26.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1708" for this suite. 04/18/23 04:28:26.768
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":78,"skipped":1338,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.345 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:28:20.466
    Apr 18 04:28:20.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename var-expansion 04/18/23 04:28:20.468
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:20.553
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:20.555
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Apr 18 04:28:20.618: INFO: Waiting up to 2m0s for pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9" in namespace "var-expansion-1708" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 18 04:28:20.650: INFO: Pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9": Phase="Pending", Reason="", readiness=false. Elapsed: 31.124971ms
    Apr 18 04:28:22.654: INFO: Pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035043137s
    Apr 18 04:28:24.702: INFO: Pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.083309303s
    Apr 18 04:28:24.702: INFO: Pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 18 04:28:24.702: INFO: Deleting pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9" in namespace "var-expansion-1708"
    Apr 18 04:28:24.756: INFO: Wait up to 5m0s for pod "var-expansion-bda43b3a-3aec-419e-afad-27533a7b39f9" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 04:28:26.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1708" for this suite. 04/18/23 04:28:26.768
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:28:26.812
Apr 18 04:28:26.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sched-pred 04/18/23 04:28:26.813
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:26.93
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:26.932
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 18 04:28:26.977: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 18 04:28:27.029: INFO: Waiting for terminating namespaces to be deleted...
Apr 18 04:28:27.032: INFO: 
Logging pods the apiserver thinks is on node apps-207 before test
Apr 18 04:28:27.051: INFO: addon-manager-5d75c94878-q9nwx from cocktail-addon started at 2023-04-14 07:23:24 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container addon-manager ready: true, restart count 1
Apr 18 04:28:27.051: INFO: agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w from cocktail-addon started at 2023-04-14 07:27:45 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container alarm-agent ready: true, restart count 0
Apr 18 04:28:27.051: INFO: alertmanager-monitoring-kube-prometheus-alertmanager-0 from cocktail-addon started at 2023-04-14 07:24:51 +0000 UTC (2 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container alertmanager ready: true, restart count 1
Apr 18 04:28:27.051: INFO: 	Container config-reloader ready: true, restart count 0
Apr 18 04:28:27.051: INFO: monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container kube-prometheus-stack ready: true, restart count 0
Apr 18 04:28:27.051: INFO: monitoring-kube-state-metrics-7dddf6695f-l8mlh from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container kube-state-metrics ready: true, restart count 0
Apr 18 04:28:27.051: INFO: monitoring-prometheus-node-exporter-d9xr5 from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 04:28:27.051: INFO: prometheus-monitoring-kube-prometheus-prometheus-0 from cocktail-addon started at 2023-04-14 11:20:12 +0000 UTC (2 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container config-reloader ready: true, restart count 0
Apr 18 04:28:27.051: INFO: 	Container prometheus ready: true, restart count 0
Apr 18 04:28:27.051: INFO: promtail-fjjqt from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container promtail ready: true, restart count 0
Apr 18 04:28:27.051: INFO: cocktail-api-gateway-648577694-g7lzt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container gateway ready: true, restart count 4
Apr 18 04:28:27.051: INFO: cocktail-batch-server-5895cd6748-x5qsz from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container batch ready: true, restart count 0
Apr 18 04:28:27.051: INFO: cocktail-build-api-5d65b8dd6-8tb9g from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container build-api ready: true, restart count 0
Apr 18 04:28:27.051: INFO: cocktail-build-queue-7855f6f4dd-vsc6p from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container nats-streaming ready: true, restart count 0
Apr 18 04:28:27.051: INFO: cocktail-cluster-api-6b5df5884f-4nbvz from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container cluster-api ready: true, restart count 2
Apr 18 04:28:27.051: INFO: cocktail-dashboard-86844bcfbd-wbnzx from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container dashboard ready: true, restart count 0
Apr 18 04:28:27.051: INFO: cocktail-dashboard-proxy-5476f6847-ptzhj from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container dashboard-proxy ready: true, restart count 0
Apr 18 04:28:27.051: INFO: cocktail-dashboard-queue-5745c9f74c-2gks8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container dashboard-queue ready: true, restart count 0
Apr 18 04:28:27.051: INFO: cocktail-dashboard-session-9d746547b-gk8d5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container dashboard-session ready: true, restart count 0
Apr 18 04:28:27.051: INFO: cocktail-monitoring-metric-collector-5695cb8669-mktvm from cocktail-system started at 2023-04-14 11:19:55 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container collector ready: true, restart count 4
Apr 18 04:28:27.051: INFO: calico-kube-controllers-74677b4c5f-rjqrf from kube-system started at 2023-04-11 08:28:10 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 18 04:28:27.051: INFO: calico-node-nmmjb from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 04:28:27.051: INFO: coredns-7ffbbc99d-5xc7c from kube-system started at 2023-04-11 08:28:13 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container coredns ready: true, restart count 0
Apr 18 04:28:27.051: INFO: csi-nfs-node-w5rjr from kube-system started at 2023-04-11 08:28:52 +0000 UTC (4 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 04:28:27.051: INFO: 	Container metrics ready: true, restart count 0
Apr 18 04:28:27.051: INFO: 	Container nfs ready: true, restart count 0
Apr 18 04:28:27.051: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 04:28:27.051: INFO: kube-apiserver-apps-207 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 04:28:27.051: INFO: kube-controller-manager-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container kube-controller-manager ready: true, restart count 1
Apr 18 04:28:27.051: INFO: kube-proxy-clw95 from kube-system started at 2023-04-11 08:28:27 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 04:28:27.051: INFO: kube-scheduler-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 18 04:28:27.051: INFO: metrics-server-7b879bf57b-vfp7l from kube-system started at 2023-04-13 06:15:39 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container metrics-server ready: true, restart count 0
Apr 18 04:28:27.051: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 04:28:27.051: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 04:28:27.051: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 04:28:27.051: INFO: 
Logging pods the apiserver thinks is on node apps-208 before test
Apr 18 04:28:27.065: INFO: monitoring-prometheus-node-exporter-n8nnw from cocktail-addon started at 2023-04-17 09:30:50 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 04:28:27.065: INFO: nginx-ingress-nginx-controller-865cbc698d-wnhvq from cocktail-addon started at 2023-04-18 03:56:13 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container controller ready: true, restart count 0
Apr 18 04:28:27.065: INFO: nginx-ingress-nginx-defaultbackend-649fd8955b-kn9ks from cocktail-addon started at 2023-04-18 03:56:12 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container ingress-nginx-default-backend ready: true, restart count 0
Apr 18 04:28:27.065: INFO: promtail-c9qhr from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container promtail ready: true, restart count 0
Apr 18 04:28:27.065: INFO: calico-node-jstls from kube-system started at 2023-04-11 08:28:11 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 04:28:27.065: INFO: csi-nfs-node-t4zm5 from kube-system started at 2023-04-11 08:28:48 +0000 UTC (4 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 04:28:27.065: INFO: 	Container metrics ready: true, restart count 0
Apr 18 04:28:27.065: INFO: 	Container nfs ready: true, restart count 0
Apr 18 04:28:27.065: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 04:28:27.065: INFO: kube-apiserver-apps-208 from kube-system started at 2023-04-11 08:26:44 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 04:28:27.065: INFO: kube-controller-manager-apps-208 from kube-system started at 2023-04-05 06:51:47 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 18 04:28:27.065: INFO: kube-proxy-vb944 from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 04:28:27.065: INFO: kube-scheduler-apps-208 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 18 04:28:27.065: INFO: sonobuoy from sonobuoy started at 2023-04-18 04:01:18 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 18 04:28:27.065: INFO: sonobuoy-e2e-job-5f413cbb3b804c34 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container e2e ready: true, restart count 0
Apr 18 04:28:27.065: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 04:28:27.065: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-lzt9z from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 04:28:27.065: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 04:28:27.065: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 04:28:27.065: INFO: 
Logging pods the apiserver thinks is on node apps-209 before test
Apr 18 04:28:27.085: INFO: agent-mdi1zj-1-event-agent-757455b86f-jzfp7 from cocktail-addon started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container event-agent ready: true, restart count 0
Apr 18 04:28:27.085: INFO: agent-mdi1zj-1-metric-agent-0 from cocktail-addon started at 2023-04-14 07:27:47 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container metric-agent ready: true, restart count 6
Apr 18 04:28:27.085: INFO: monitoring-extension-event-exporter-57bc857b7b-d2kgh from cocktail-addon started at 2023-04-14 07:26:55 +0000 UTC (2 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container caddy ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container event-exporter ready: true, restart count 0
Apr 18 04:28:27.085: INFO: monitoring-prometheus-node-exporter-tx7km from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 04:28:27.085: INFO: promtail-bgwzf from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container promtail ready: true, restart count 0
Apr 18 04:28:27.085: INFO: cocktail-api-cmdb-0 from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container api-cmdb ready: true, restart count 0
Apr 18 04:28:27.085: INFO: cocktail-api-server-5d47cb7fdd-5ptrt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container api-server ready: true, restart count 1
Apr 18 04:28:27.085: INFO: cocktail-log-api-6c69c456db-j8gr8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container api ready: true, restart count 0
Apr 18 04:28:27.085: INFO: cocktail-log-loki-0 from cocktail-system started at 2023-04-14 07:04:56 +0000 UTC (2 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container loki ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container tls-proxy ready: true, restart count 0
Apr 18 04:28:27.085: INFO: cocktail-monitoring-76bdf6974f-p5hs8 from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container monitoring ready: true, restart count 3
Apr 18 04:28:27.085: INFO: cocktail-monitoring-alarm-collector-78448f5d-gbmcs from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container collector ready: true, restart count 6
Apr 18 04:28:27.085: INFO: cocktail-monitoring-event-collector-7fd78d476d-9pw9f from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container collector ready: true, restart count 7
Apr 18 04:28:27.085: INFO: cocktail-monitoring-monitoring-db-0 from cocktail-system started at 2023-04-14 11:20:11 +0000 UTC (2 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container db ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container log-lotate ready: true, restart count 0
Apr 18 04:28:27.085: INFO: cocktail-monitoring-proxy-648c665797-jd2fs from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container monitoring-proxy ready: true, restart count 0
Apr 18 04:28:27.085: INFO: cocktail-mq-entity-operator-7964999574-5zzkb from cocktail-system started at 2023-04-14 07:07:37 +0000 UTC (3 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container tls-sidecar ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container topic-operator ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container user-operator ready: true, restart count 0
Apr 18 04:28:27.085: INFO: cocktail-mq-kafka-0 from cocktail-system started at 2023-04-14 07:08:16 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container kafka ready: true, restart count 0
Apr 18 04:28:27.085: INFO: cocktail-mq-zookeeper-0 from cocktail-system started at 2023-04-14 07:05:54 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container zookeeper ready: true, restart count 0
Apr 18 04:28:27.085: INFO: cocktail-package-5f59d96bd8-d2nj5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container package ready: true, restart count 1
Apr 18 04:28:27.085: INFO: strimzi-cluster-operator-668f4bff5c-zqqjr from cocktail-system started at 2023-04-14 11:05:05 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container strimzi-cluster-operator ready: true, restart count 0
Apr 18 04:28:27.085: INFO: calico-node-q6mxd from kube-system started at 2023-04-11 08:28:12 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 04:28:27.085: INFO: coredns-7ffbbc99d-mkf8k from kube-system started at 2023-04-14 11:05:04 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container coredns ready: true, restart count 0
Apr 18 04:28:27.085: INFO: csi-nfs-controller-7ccd7c4947-dw42l from kube-system started at 2023-04-14 11:05:06 +0000 UTC (3 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container csi-provisioner ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container nfs ready: true, restart count 0
Apr 18 04:28:27.085: INFO: csi-nfs-node-nh5wf from kube-system started at 2023-04-11 08:28:49 +0000 UTC (4 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container metrics ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container nfs ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 04:28:27.085: INFO: kube-apiserver-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 04:28:27.085: INFO: kube-controller-manager-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container kube-controller-manager ready: true, restart count 1
Apr 18 04:28:27.085: INFO: kube-proxy-vmwrf from kube-system started at 2023-04-11 08:28:28 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 04:28:27.085: INFO: kube-scheduler-apps-209 from kube-system started at 2023-04-07 08:18:47 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container kube-scheduler ready: true, restart count 1
Apr 18 04:28:27.085: INFO: metrics-server-7b879bf57b-6vnbg from kube-system started at 2023-04-13 06:15:03 +0000 UTC (1 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container metrics-server ready: true, restart count 0
Apr 18 04:28:27.085: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-j4n44 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 04:28:27.085: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 04:28:27.085: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 04:28:27.085
Apr 18 04:28:27.159: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-1752" to be "running"
Apr 18 04:28:27.162: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.117956ms
Apr 18 04:28:29.166: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00722007s
Apr 18 04:28:31.167: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.007906986s
Apr 18 04:28:31.167: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 04:28:31.17
STEP: Trying to apply a random label on the found node. 04/18/23 04:28:31.227
STEP: verifying the node has the label kubernetes.io/e2e-1fc8ce14-32df-4964-8516-f5161de60628 42 04/18/23 04:28:31.257
STEP: Trying to relaunch the pod, now with labels. 04/18/23 04:28:31.261
Apr 18 04:28:31.327: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-1752" to be "not pending"
Apr 18 04:28:31.344: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 17.158884ms
Apr 18 04:28:33.348: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020916907s
Apr 18 04:28:35.350: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 4.022704343s
Apr 18 04:28:35.350: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-1fc8ce14-32df-4964-8516-f5161de60628 off the node apps-208 04/18/23 04:28:35.353
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1fc8ce14-32df-4964-8516-f5161de60628 04/18/23 04:28:35.399
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 18 04:28:35.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1752" for this suite. 04/18/23 04:28:35.407
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":79,"skipped":1341,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.615 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:28:26.812
    Apr 18 04:28:26.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sched-pred 04/18/23 04:28:26.813
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:26.93
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:26.932
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 18 04:28:26.977: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 18 04:28:27.029: INFO: Waiting for terminating namespaces to be deleted...
    Apr 18 04:28:27.032: INFO: 
    Logging pods the apiserver thinks is on node apps-207 before test
    Apr 18 04:28:27.051: INFO: addon-manager-5d75c94878-q9nwx from cocktail-addon started at 2023-04-14 07:23:24 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container addon-manager ready: true, restart count 1
    Apr 18 04:28:27.051: INFO: agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w from cocktail-addon started at 2023-04-14 07:27:45 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container alarm-agent ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: alertmanager-monitoring-kube-prometheus-alertmanager-0 from cocktail-addon started at 2023-04-14 07:24:51 +0000 UTC (2 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container alertmanager ready: true, restart count 1
    Apr 18 04:28:27.051: INFO: 	Container config-reloader ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container kube-prometheus-stack ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: monitoring-kube-state-metrics-7dddf6695f-l8mlh from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: monitoring-prometheus-node-exporter-d9xr5 from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: prometheus-monitoring-kube-prometheus-prometheus-0 from cocktail-addon started at 2023-04-14 11:20:12 +0000 UTC (2 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container config-reloader ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: 	Container prometheus ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: promtail-fjjqt from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: cocktail-api-gateway-648577694-g7lzt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container gateway ready: true, restart count 4
    Apr 18 04:28:27.051: INFO: cocktail-batch-server-5895cd6748-x5qsz from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container batch ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: cocktail-build-api-5d65b8dd6-8tb9g from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container build-api ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: cocktail-build-queue-7855f6f4dd-vsc6p from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container nats-streaming ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: cocktail-cluster-api-6b5df5884f-4nbvz from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container cluster-api ready: true, restart count 2
    Apr 18 04:28:27.051: INFO: cocktail-dashboard-86844bcfbd-wbnzx from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container dashboard ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: cocktail-dashboard-proxy-5476f6847-ptzhj from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container dashboard-proxy ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: cocktail-dashboard-queue-5745c9f74c-2gks8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container dashboard-queue ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: cocktail-dashboard-session-9d746547b-gk8d5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container dashboard-session ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: cocktail-monitoring-metric-collector-5695cb8669-mktvm from cocktail-system started at 2023-04-14 11:19:55 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container collector ready: true, restart count 4
    Apr 18 04:28:27.051: INFO: calico-kube-controllers-74677b4c5f-rjqrf from kube-system started at 2023-04-11 08:28:10 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: calico-node-nmmjb from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: coredns-7ffbbc99d-5xc7c from kube-system started at 2023-04-11 08:28:13 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: csi-nfs-node-w5rjr from kube-system started at 2023-04-11 08:28:52 +0000 UTC (4 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: kube-apiserver-apps-207 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: kube-controller-manager-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Apr 18 04:28:27.051: INFO: kube-proxy-clw95 from kube-system started at 2023-04-11 08:28:27 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: kube-scheduler-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: metrics-server-7b879bf57b-vfp7l from kube-system started at 2023-04-13 06:15:39 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 04:28:27.051: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 04:28:27.051: INFO: 
    Logging pods the apiserver thinks is on node apps-208 before test
    Apr 18 04:28:27.065: INFO: monitoring-prometheus-node-exporter-n8nnw from cocktail-addon started at 2023-04-17 09:30:50 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: nginx-ingress-nginx-controller-865cbc698d-wnhvq from cocktail-addon started at 2023-04-18 03:56:13 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container controller ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: nginx-ingress-nginx-defaultbackend-649fd8955b-kn9ks from cocktail-addon started at 2023-04-18 03:56:12 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container ingress-nginx-default-backend ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: promtail-c9qhr from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: calico-node-jstls from kube-system started at 2023-04-11 08:28:11 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: csi-nfs-node-t4zm5 from kube-system started at 2023-04-11 08:28:48 +0000 UTC (4 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: kube-apiserver-apps-208 from kube-system started at 2023-04-11 08:26:44 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: kube-controller-manager-apps-208 from kube-system started at 2023-04-05 06:51:47 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: kube-proxy-vb944 from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: kube-scheduler-apps-208 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: sonobuoy from sonobuoy started at 2023-04-18 04:01:18 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: sonobuoy-e2e-job-5f413cbb3b804c34 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container e2e ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-lzt9z from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 04:28:27.065: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 04:28:27.065: INFO: 
    Logging pods the apiserver thinks is on node apps-209 before test
    Apr 18 04:28:27.085: INFO: agent-mdi1zj-1-event-agent-757455b86f-jzfp7 from cocktail-addon started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container event-agent ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: agent-mdi1zj-1-metric-agent-0 from cocktail-addon started at 2023-04-14 07:27:47 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container metric-agent ready: true, restart count 6
    Apr 18 04:28:27.085: INFO: monitoring-extension-event-exporter-57bc857b7b-d2kgh from cocktail-addon started at 2023-04-14 07:26:55 +0000 UTC (2 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container caddy ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container event-exporter ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: monitoring-prometheus-node-exporter-tx7km from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: promtail-bgwzf from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: cocktail-api-cmdb-0 from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container api-cmdb ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: cocktail-api-server-5d47cb7fdd-5ptrt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container api-server ready: true, restart count 1
    Apr 18 04:28:27.085: INFO: cocktail-log-api-6c69c456db-j8gr8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container api ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: cocktail-log-loki-0 from cocktail-system started at 2023-04-14 07:04:56 +0000 UTC (2 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container loki ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container tls-proxy ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: cocktail-monitoring-76bdf6974f-p5hs8 from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container monitoring ready: true, restart count 3
    Apr 18 04:28:27.085: INFO: cocktail-monitoring-alarm-collector-78448f5d-gbmcs from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container collector ready: true, restart count 6
    Apr 18 04:28:27.085: INFO: cocktail-monitoring-event-collector-7fd78d476d-9pw9f from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container collector ready: true, restart count 7
    Apr 18 04:28:27.085: INFO: cocktail-monitoring-monitoring-db-0 from cocktail-system started at 2023-04-14 11:20:11 +0000 UTC (2 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container db ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container log-lotate ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: cocktail-monitoring-proxy-648c665797-jd2fs from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container monitoring-proxy ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: cocktail-mq-entity-operator-7964999574-5zzkb from cocktail-system started at 2023-04-14 07:07:37 +0000 UTC (3 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container tls-sidecar ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container topic-operator ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container user-operator ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: cocktail-mq-kafka-0 from cocktail-system started at 2023-04-14 07:08:16 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container kafka ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: cocktail-mq-zookeeper-0 from cocktail-system started at 2023-04-14 07:05:54 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container zookeeper ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: cocktail-package-5f59d96bd8-d2nj5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container package ready: true, restart count 1
    Apr 18 04:28:27.085: INFO: strimzi-cluster-operator-668f4bff5c-zqqjr from cocktail-system started at 2023-04-14 11:05:05 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container strimzi-cluster-operator ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: calico-node-q6mxd from kube-system started at 2023-04-11 08:28:12 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: coredns-7ffbbc99d-mkf8k from kube-system started at 2023-04-14 11:05:04 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: csi-nfs-controller-7ccd7c4947-dw42l from kube-system started at 2023-04-14 11:05:06 +0000 UTC (3 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container csi-provisioner ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: csi-nfs-node-nh5wf from kube-system started at 2023-04-11 08:28:49 +0000 UTC (4 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: kube-apiserver-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: kube-controller-manager-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Apr 18 04:28:27.085: INFO: kube-proxy-vmwrf from kube-system started at 2023-04-11 08:28:28 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: kube-scheduler-apps-209 from kube-system started at 2023-04-07 08:18:47 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container kube-scheduler ready: true, restart count 1
    Apr 18 04:28:27.085: INFO: metrics-server-7b879bf57b-6vnbg from kube-system started at 2023-04-13 06:15:03 +0000 UTC (1 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-j4n44 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 04:28:27.085: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 04:28:27.085: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 04:28:27.085
    Apr 18 04:28:27.159: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-1752" to be "running"
    Apr 18 04:28:27.162: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.117956ms
    Apr 18 04:28:29.166: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00722007s
    Apr 18 04:28:31.167: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.007906986s
    Apr 18 04:28:31.167: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 04:28:31.17
    STEP: Trying to apply a random label on the found node. 04/18/23 04:28:31.227
    STEP: verifying the node has the label kubernetes.io/e2e-1fc8ce14-32df-4964-8516-f5161de60628 42 04/18/23 04:28:31.257
    STEP: Trying to relaunch the pod, now with labels. 04/18/23 04:28:31.261
    Apr 18 04:28:31.327: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-1752" to be "not pending"
    Apr 18 04:28:31.344: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 17.158884ms
    Apr 18 04:28:33.348: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020916907s
    Apr 18 04:28:35.350: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 4.022704343s
    Apr 18 04:28:35.350: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-1fc8ce14-32df-4964-8516-f5161de60628 off the node apps-208 04/18/23 04:28:35.353
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-1fc8ce14-32df-4964-8516-f5161de60628 04/18/23 04:28:35.399
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 04:28:35.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-1752" for this suite. 04/18/23 04:28:35.407
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:28:35.428
Apr 18 04:28:35.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:28:35.429
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:35.544
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:35.547
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 04/18/23 04:28:35.551
Apr 18 04:28:35.598: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2" in namespace "projected-9571" to be "Succeeded or Failed"
Apr 18 04:28:35.601: INFO: Pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.811027ms
Apr 18 04:28:37.606: INFO: Pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007731978s
Apr 18 04:28:39.605: INFO: Pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2": Phase="Running", Reason="", readiness=false. Elapsed: 4.006723767s
Apr 18 04:28:41.629: INFO: Pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030435414s
STEP: Saw pod success 04/18/23 04:28:41.629
Apr 18 04:28:41.629: INFO: Pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2" satisfied condition "Succeeded or Failed"
Apr 18 04:28:41.632: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2 container client-container: <nil>
STEP: delete the pod 04/18/23 04:28:41.644
Apr 18 04:28:41.736: INFO: Waiting for pod downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2 to disappear
Apr 18 04:28:41.755: INFO: Pod downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 04:28:41.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9571" for this suite. 04/18/23 04:28:41.787
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":80,"skipped":1352,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.393 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:28:35.428
    Apr 18 04:28:35.428: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:28:35.429
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:35.544
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:35.547
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 04/18/23 04:28:35.551
    Apr 18 04:28:35.598: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2" in namespace "projected-9571" to be "Succeeded or Failed"
    Apr 18 04:28:35.601: INFO: Pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.811027ms
    Apr 18 04:28:37.606: INFO: Pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007731978s
    Apr 18 04:28:39.605: INFO: Pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2": Phase="Running", Reason="", readiness=false. Elapsed: 4.006723767s
    Apr 18 04:28:41.629: INFO: Pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030435414s
    STEP: Saw pod success 04/18/23 04:28:41.629
    Apr 18 04:28:41.629: INFO: Pod "downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2" satisfied condition "Succeeded or Failed"
    Apr 18 04:28:41.632: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2 container client-container: <nil>
    STEP: delete the pod 04/18/23 04:28:41.644
    Apr 18 04:28:41.736: INFO: Waiting for pod downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2 to disappear
    Apr 18 04:28:41.755: INFO: Pod downwardapi-volume-79447f60-c9e2-494d-a0e2-4a79f36a78f2 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 04:28:41.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9571" for this suite. 04/18/23 04:28:41.787
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:28:41.821
Apr 18 04:28:41.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename endpointslice 04/18/23 04:28:41.822
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:41.905
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:41.907
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 18 04:28:44.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1324" for this suite. 04/18/23 04:28:44.332
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":81,"skipped":1355,"failed":0}
------------------------------
â€¢ [2.574 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:28:41.821
    Apr 18 04:28:41.821: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename endpointslice 04/18/23 04:28:41.822
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:41.905
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:41.907
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 18 04:28:44.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-1324" for this suite. 04/18/23 04:28:44.332
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:28:44.395
Apr 18 04:28:44.395: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 04:28:44.396
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:44.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:44.474
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 04/18/23 04:28:44.477
Apr 18 04:28:44.539: INFO: Waiting up to 5m0s for pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f" in namespace "emptydir-2093" to be "Succeeded or Failed"
Apr 18 04:28:44.607: INFO: Pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f": Phase="Pending", Reason="", readiness=false. Elapsed: 67.410363ms
Apr 18 04:28:46.649: INFO: Pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.109757864s
Apr 18 04:28:48.614: INFO: Pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f": Phase="Running", Reason="", readiness=false. Elapsed: 4.074289913s
Apr 18 04:28:50.660: INFO: Pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.120971761s
STEP: Saw pod success 04/18/23 04:28:50.661
Apr 18 04:28:50.661: INFO: Pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f" satisfied condition "Succeeded or Failed"
Apr 18 04:28:50.664: INFO: Trying to get logs from node apps-208 pod pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f container test-container: <nil>
STEP: delete the pod 04/18/23 04:28:50.67
Apr 18 04:28:50.757: INFO: Waiting for pod pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f to disappear
Apr 18 04:28:50.759: INFO: Pod pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 04:28:50.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2093" for this suite. 04/18/23 04:28:50.809
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":82,"skipped":1364,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.443 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:28:44.395
    Apr 18 04:28:44.395: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 04:28:44.396
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:44.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:44.474
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/18/23 04:28:44.477
    Apr 18 04:28:44.539: INFO: Waiting up to 5m0s for pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f" in namespace "emptydir-2093" to be "Succeeded or Failed"
    Apr 18 04:28:44.607: INFO: Pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f": Phase="Pending", Reason="", readiness=false. Elapsed: 67.410363ms
    Apr 18 04:28:46.649: INFO: Pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.109757864s
    Apr 18 04:28:48.614: INFO: Pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f": Phase="Running", Reason="", readiness=false. Elapsed: 4.074289913s
    Apr 18 04:28:50.660: INFO: Pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.120971761s
    STEP: Saw pod success 04/18/23 04:28:50.661
    Apr 18 04:28:50.661: INFO: Pod "pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f" satisfied condition "Succeeded or Failed"
    Apr 18 04:28:50.664: INFO: Trying to get logs from node apps-208 pod pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f container test-container: <nil>
    STEP: delete the pod 04/18/23 04:28:50.67
    Apr 18 04:28:50.757: INFO: Waiting for pod pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f to disappear
    Apr 18 04:28:50.759: INFO: Pod pod-4b73a6d9-1c83-4fc1-bde8-a7c46e556a0f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 04:28:50.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2093" for this suite. 04/18/23 04:28:50.809
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:28:50.84
Apr 18 04:28:50.840: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 04:28:50.841
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:50.96
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:50.963
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 04/18/23 04:28:50.965
Apr 18 04:28:50.999: INFO: Waiting up to 5m0s for pod "pod-43cedef2-eab5-4b37-9b59-492c65546921" in namespace "emptydir-9532" to be "Succeeded or Failed"
Apr 18 04:28:51.003: INFO: Pod "pod-43cedef2-eab5-4b37-9b59-492c65546921": Phase="Pending", Reason="", readiness=false. Elapsed: 3.496253ms
Apr 18 04:28:53.072: INFO: Pod "pod-43cedef2-eab5-4b37-9b59-492c65546921": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072875429s
Apr 18 04:28:55.008: INFO: Pod "pod-43cedef2-eab5-4b37-9b59-492c65546921": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009017295s
Apr 18 04:28:57.010: INFO: Pod "pod-43cedef2-eab5-4b37-9b59-492c65546921": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011124002s
STEP: Saw pod success 04/18/23 04:28:57.01
Apr 18 04:28:57.011: INFO: Pod "pod-43cedef2-eab5-4b37-9b59-492c65546921" satisfied condition "Succeeded or Failed"
Apr 18 04:28:57.014: INFO: Trying to get logs from node apps-208 pod pod-43cedef2-eab5-4b37-9b59-492c65546921 container test-container: <nil>
STEP: delete the pod 04/18/23 04:28:57.02
Apr 18 04:28:57.123: INFO: Waiting for pod pod-43cedef2-eab5-4b37-9b59-492c65546921 to disappear
Apr 18 04:28:57.177: INFO: Pod pod-43cedef2-eab5-4b37-9b59-492c65546921 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 04:28:57.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9532" for this suite. 04/18/23 04:28:57.181
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":83,"skipped":1403,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.412 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:28:50.84
    Apr 18 04:28:50.840: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 04:28:50.841
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:50.96
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:50.963
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/18/23 04:28:50.965
    Apr 18 04:28:50.999: INFO: Waiting up to 5m0s for pod "pod-43cedef2-eab5-4b37-9b59-492c65546921" in namespace "emptydir-9532" to be "Succeeded or Failed"
    Apr 18 04:28:51.003: INFO: Pod "pod-43cedef2-eab5-4b37-9b59-492c65546921": Phase="Pending", Reason="", readiness=false. Elapsed: 3.496253ms
    Apr 18 04:28:53.072: INFO: Pod "pod-43cedef2-eab5-4b37-9b59-492c65546921": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072875429s
    Apr 18 04:28:55.008: INFO: Pod "pod-43cedef2-eab5-4b37-9b59-492c65546921": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009017295s
    Apr 18 04:28:57.010: INFO: Pod "pod-43cedef2-eab5-4b37-9b59-492c65546921": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011124002s
    STEP: Saw pod success 04/18/23 04:28:57.01
    Apr 18 04:28:57.011: INFO: Pod "pod-43cedef2-eab5-4b37-9b59-492c65546921" satisfied condition "Succeeded or Failed"
    Apr 18 04:28:57.014: INFO: Trying to get logs from node apps-208 pod pod-43cedef2-eab5-4b37-9b59-492c65546921 container test-container: <nil>
    STEP: delete the pod 04/18/23 04:28:57.02
    Apr 18 04:28:57.123: INFO: Waiting for pod pod-43cedef2-eab5-4b37-9b59-492c65546921 to disappear
    Apr 18 04:28:57.177: INFO: Pod pod-43cedef2-eab5-4b37-9b59-492c65546921 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 04:28:57.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9532" for this suite. 04/18/23 04:28:57.181
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:28:57.253
Apr 18 04:28:57.253: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 04:28:57.254
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:57.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:57.332
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 04/18/23 04:28:57.379
STEP: waiting for available Endpoint 04/18/23 04:28:57.405
STEP: listing all Endpoints 04/18/23 04:28:57.407
STEP: updating the Endpoint 04/18/23 04:28:57.411
STEP: fetching the Endpoint 04/18/23 04:28:57.457
STEP: patching the Endpoint 04/18/23 04:28:57.459
STEP: fetching the Endpoint 04/18/23 04:28:57.475
STEP: deleting the Endpoint by Collection 04/18/23 04:28:57.515
STEP: waiting for Endpoint deletion 04/18/23 04:28:57.547
STEP: fetching the Endpoint 04/18/23 04:28:57.548
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 04:28:57.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8593" for this suite. 04/18/23 04:28:57.555
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":84,"skipped":1408,"failed":0}
------------------------------
â€¢ [0.326 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:28:57.253
    Apr 18 04:28:57.253: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 04:28:57.254
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:57.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:57.332
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 04/18/23 04:28:57.379
    STEP: waiting for available Endpoint 04/18/23 04:28:57.405
    STEP: listing all Endpoints 04/18/23 04:28:57.407
    STEP: updating the Endpoint 04/18/23 04:28:57.411
    STEP: fetching the Endpoint 04/18/23 04:28:57.457
    STEP: patching the Endpoint 04/18/23 04:28:57.459
    STEP: fetching the Endpoint 04/18/23 04:28:57.475
    STEP: deleting the Endpoint by Collection 04/18/23 04:28:57.515
    STEP: waiting for Endpoint deletion 04/18/23 04:28:57.547
    STEP: fetching the Endpoint 04/18/23 04:28:57.548
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 04:28:57.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8593" for this suite. 04/18/23 04:28:57.555
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:28:57.58
Apr 18 04:28:57.580: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 04:28:57.581
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:57.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:57.722
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 04/18/23 04:28:57.724
Apr 18 04:28:57.724: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1443 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 04/18/23 04:28:57.777
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 04:28:57.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1443" for this suite. 04/18/23 04:28:57.817
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":85,"skipped":1412,"failed":0}
------------------------------
â€¢ [0.309 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:28:57.58
    Apr 18 04:28:57.580: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 04:28:57.581
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:57.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:57.722
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 04/18/23 04:28:57.724
    Apr 18 04:28:57.724: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1443 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 04/18/23 04:28:57.777
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 04:28:57.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1443" for this suite. 04/18/23 04:28:57.817
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:28:57.89
Apr 18 04:28:57.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename init-container 04/18/23 04:28:57.891
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:58.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:58.069
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 04/18/23 04:28:58.071
Apr 18 04:28:58.071: INFO: PodSpec: initContainers in spec.initContainers
Apr 18 04:29:47.159: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-5a5b2557-8dcb-457f-bda5-ffb4639f0e92", GenerateName:"", Namespace:"init-container-4748", SelfLink:"", UID:"14151f6a-8c7f-4400-90f6-60622e642d02", ResourceVersion:"4088731", Generation:0, CreationTimestamp:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"71986990"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"e87a83f1b8390190effff56229af02b6bc4fbacdc6e4b4daa106175191de2dfb", "cni.projectcalico.org/podIP":"172.16.125.21/32", "cni.projectcalico.org/podIPs":"172.16.125.21/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000240558), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 18, 4, 28, 59, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000240588), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 18, 4, 29, 46, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0002405d0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-xvcfb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004cb2140), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xvcfb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xvcfb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xvcfb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc006f6c978), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"apps-208", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003767e30), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006f6ca00)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006f6ca20)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc006f6ca28), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc006f6ca2c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000b61980), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.2.108", PodIP:"172.16.125.21", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.16.125.21"}}, StartTime:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003767f10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003767f80)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://def35cdb835ec3ea11225fd1a90d060692c3f475b3310b3f78e396eb3fadbc76", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004cb21c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004cb21a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc006f6cab4)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 04:29:47.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4748" for this suite. 04/18/23 04:29:47.165
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":86,"skipped":1418,"failed":0}
------------------------------
â€¢ [SLOW TEST] [49.302 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:28:57.89
    Apr 18 04:28:57.890: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename init-container 04/18/23 04:28:57.891
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:28:58.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:28:58.069
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 04/18/23 04:28:58.071
    Apr 18 04:28:58.071: INFO: PodSpec: initContainers in spec.initContainers
    Apr 18 04:29:47.159: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-5a5b2557-8dcb-457f-bda5-ffb4639f0e92", GenerateName:"", Namespace:"init-container-4748", SelfLink:"", UID:"14151f6a-8c7f-4400-90f6-60622e642d02", ResourceVersion:"4088731", Generation:0, CreationTimestamp:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"71986990"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"e87a83f1b8390190effff56229af02b6bc4fbacdc6e4b4daa106175191de2dfb", "cni.projectcalico.org/podIP":"172.16.125.21/32", "cni.projectcalico.org/podIPs":"172.16.125.21/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000240558), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 18, 4, 28, 59, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000240588), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.April, 18, 4, 29, 46, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0002405d0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-xvcfb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004cb2140), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xvcfb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xvcfb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xvcfb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc006f6c978), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"apps-208", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003767e30), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006f6ca00)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006f6ca20)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc006f6ca28), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc006f6ca2c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000b61980), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.2.108", PodIP:"172.16.125.21", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.16.125.21"}}, StartTime:time.Date(2023, time.April, 18, 4, 28, 58, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003767f10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003767f80)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://def35cdb835ec3ea11225fd1a90d060692c3f475b3310b3f78e396eb3fadbc76", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004cb21c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004cb21a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc006f6cab4)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 04:29:47.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-4748" for this suite. 04/18/23 04:29:47.165
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:29:47.193
Apr 18 04:29:47.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename taint-single-pod 04/18/23 04:29:47.195
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:29:47.272
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:29:47.275
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Apr 18 04:29:47.278: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 04:30:47.337: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Apr 18 04:30:47.341: INFO: Starting informer...
STEP: Starting pod... 04/18/23 04:30:47.341
Apr 18 04:30:47.581: INFO: Pod is running on apps-208. Tainting Node
STEP: Trying to apply a taint on the Node 04/18/23 04:30:47.581
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 04:30:47.661
STEP: Waiting short time to make sure Pod is queued for deletion 04/18/23 04:30:47.666
Apr 18 04:30:47.666: INFO: Pod wasn't evicted. Proceeding
Apr 18 04:30:47.666: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 04:30:47.826
STEP: Waiting some time to make sure that toleration time passed. 04/18/23 04:30:47.851
Apr 18 04:32:02.852: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Apr 18 04:32:02.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-5872" for this suite. 04/18/23 04:32:02.857
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":87,"skipped":1440,"failed":0}
------------------------------
â€¢ [SLOW TEST] [135.720 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:29:47.193
    Apr 18 04:29:47.194: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename taint-single-pod 04/18/23 04:29:47.195
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:29:47.272
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:29:47.275
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Apr 18 04:29:47.278: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 04:30:47.337: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Apr 18 04:30:47.341: INFO: Starting informer...
    STEP: Starting pod... 04/18/23 04:30:47.341
    Apr 18 04:30:47.581: INFO: Pod is running on apps-208. Tainting Node
    STEP: Trying to apply a taint on the Node 04/18/23 04:30:47.581
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 04:30:47.661
    STEP: Waiting short time to make sure Pod is queued for deletion 04/18/23 04:30:47.666
    Apr 18 04:30:47.666: INFO: Pod wasn't evicted. Proceeding
    Apr 18 04:30:47.666: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 04:30:47.826
    STEP: Waiting some time to make sure that toleration time passed. 04/18/23 04:30:47.851
    Apr 18 04:32:02.852: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 04:32:02.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-5872" for this suite. 04/18/23 04:32:02.857
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:32:02.914
Apr 18 04:32:02.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename subpath 04/18/23 04:32:02.915
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:32:03.017
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:32:03.02
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/18/23 04:32:03.023
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-j8z6 04/18/23 04:32:03.148
STEP: Creating a pod to test atomic-volume-subpath 04/18/23 04:32:03.148
Apr 18 04:32:03.168: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-j8z6" in namespace "subpath-3801" to be "Succeeded or Failed"
Apr 18 04:32:03.171: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.784929ms
Apr 18 04:32:05.175: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00723463s
Apr 18 04:32:07.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 4.007540494s
Apr 18 04:32:09.214: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 6.046201286s
Apr 18 04:32:11.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 8.007475965s
Apr 18 04:32:13.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 10.008161553s
Apr 18 04:32:15.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 12.007427104s
Apr 18 04:32:17.221: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 14.052628215s
Apr 18 04:32:19.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 16.007945976s
Apr 18 04:32:21.187: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 18.019026479s
Apr 18 04:32:23.175: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 20.007160355s
Apr 18 04:32:25.177: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 22.008896965s
Apr 18 04:32:27.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=false. Elapsed: 24.007516098s
Apr 18 04:32:29.177: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.008527993s
STEP: Saw pod success 04/18/23 04:32:29.177
Apr 18 04:32:29.177: INFO: Pod "pod-subpath-test-secret-j8z6" satisfied condition "Succeeded or Failed"
Apr 18 04:32:29.180: INFO: Trying to get logs from node apps-208 pod pod-subpath-test-secret-j8z6 container test-container-subpath-secret-j8z6: <nil>
STEP: delete the pod 04/18/23 04:32:29.194
Apr 18 04:32:29.306: INFO: Waiting for pod pod-subpath-test-secret-j8z6 to disappear
Apr 18 04:32:29.309: INFO: Pod pod-subpath-test-secret-j8z6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-j8z6 04/18/23 04:32:29.309
Apr 18 04:32:29.309: INFO: Deleting pod "pod-subpath-test-secret-j8z6" in namespace "subpath-3801"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 18 04:32:29.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3801" for this suite. 04/18/23 04:32:29.317
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":88,"skipped":1442,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.415 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:32:02.914
    Apr 18 04:32:02.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename subpath 04/18/23 04:32:02.915
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:32:03.017
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:32:03.02
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/18/23 04:32:03.023
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-j8z6 04/18/23 04:32:03.148
    STEP: Creating a pod to test atomic-volume-subpath 04/18/23 04:32:03.148
    Apr 18 04:32:03.168: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-j8z6" in namespace "subpath-3801" to be "Succeeded or Failed"
    Apr 18 04:32:03.171: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.784929ms
    Apr 18 04:32:05.175: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00723463s
    Apr 18 04:32:07.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 4.007540494s
    Apr 18 04:32:09.214: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 6.046201286s
    Apr 18 04:32:11.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 8.007475965s
    Apr 18 04:32:13.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 10.008161553s
    Apr 18 04:32:15.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 12.007427104s
    Apr 18 04:32:17.221: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 14.052628215s
    Apr 18 04:32:19.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 16.007945976s
    Apr 18 04:32:21.187: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 18.019026479s
    Apr 18 04:32:23.175: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 20.007160355s
    Apr 18 04:32:25.177: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=true. Elapsed: 22.008896965s
    Apr 18 04:32:27.176: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Running", Reason="", readiness=false. Elapsed: 24.007516098s
    Apr 18 04:32:29.177: INFO: Pod "pod-subpath-test-secret-j8z6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.008527993s
    STEP: Saw pod success 04/18/23 04:32:29.177
    Apr 18 04:32:29.177: INFO: Pod "pod-subpath-test-secret-j8z6" satisfied condition "Succeeded or Failed"
    Apr 18 04:32:29.180: INFO: Trying to get logs from node apps-208 pod pod-subpath-test-secret-j8z6 container test-container-subpath-secret-j8z6: <nil>
    STEP: delete the pod 04/18/23 04:32:29.194
    Apr 18 04:32:29.306: INFO: Waiting for pod pod-subpath-test-secret-j8z6 to disappear
    Apr 18 04:32:29.309: INFO: Pod pod-subpath-test-secret-j8z6 no longer exists
    STEP: Deleting pod pod-subpath-test-secret-j8z6 04/18/23 04:32:29.309
    Apr 18 04:32:29.309: INFO: Deleting pod "pod-subpath-test-secret-j8z6" in namespace "subpath-3801"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 18 04:32:29.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-3801" for this suite. 04/18/23 04:32:29.317
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:32:29.331
Apr 18 04:32:29.331: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 04:32:29.332
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:32:29.38
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:32:29.383
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Apr 18 04:32:29.430: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:32:37.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7214" for this suite. 04/18/23 04:32:37.833
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":89,"skipped":1480,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.556 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:32:29.331
    Apr 18 04:32:29.331: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 04:32:29.332
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:32:29.38
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:32:29.383
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Apr 18 04:32:29.430: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:32:37.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7214" for this suite. 04/18/23 04:32:37.833
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:32:37.888
Apr 18 04:32:37.888: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename job 04/18/23 04:32:37.889
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:32:37.992
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:32:37.995
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 04/18/23 04:32:38.012
STEP: Ensuring job reaches completions 04/18/23 04:32:38.04
STEP: Ensuring pods with index for job exist 04/18/23 04:32:54.045
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 04:32:54.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-176" for this suite. 04/18/23 04:32:54.054
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":90,"skipped":1498,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.191 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:32:37.888
    Apr 18 04:32:37.888: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename job 04/18/23 04:32:37.889
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:32:37.992
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:32:37.995
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 04/18/23 04:32:38.012
    STEP: Ensuring job reaches completions 04/18/23 04:32:38.04
    STEP: Ensuring pods with index for job exist 04/18/23 04:32:54.045
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 04:32:54.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-176" for this suite. 04/18/23 04:32:54.054
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:32:54.08
Apr 18 04:32:54.080: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:32:54.081
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:32:54.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:32:54.189
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-08428e27-408e-428c-82db-54aaf748f59b 04/18/23 04:32:54.192
STEP: Creating a pod to test consume secrets 04/18/23 04:32:54.211
Apr 18 04:32:54.287: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161" in namespace "projected-3594" to be "Succeeded or Failed"
Apr 18 04:32:54.387: INFO: Pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161": Phase="Pending", Reason="", readiness=false. Elapsed: 100.215993ms
Apr 18 04:32:56.416: INFO: Pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12908944s
Apr 18 04:32:58.393: INFO: Pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161": Phase="Running", Reason="", readiness=false. Elapsed: 4.1057443s
Apr 18 04:33:00.420: INFO: Pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.132576889s
STEP: Saw pod success 04/18/23 04:33:00.42
Apr 18 04:33:00.420: INFO: Pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161" satisfied condition "Succeeded or Failed"
Apr 18 04:33:00.437: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/18/23 04:33:00.448
Apr 18 04:33:00.588: INFO: Waiting for pod pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161 to disappear
Apr 18 04:33:00.590: INFO: Pod pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 04:33:00.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3594" for this suite. 04/18/23 04:33:00.595
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":91,"skipped":1528,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.544 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:32:54.08
    Apr 18 04:32:54.080: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:32:54.081
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:32:54.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:32:54.189
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-08428e27-408e-428c-82db-54aaf748f59b 04/18/23 04:32:54.192
    STEP: Creating a pod to test consume secrets 04/18/23 04:32:54.211
    Apr 18 04:32:54.287: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161" in namespace "projected-3594" to be "Succeeded or Failed"
    Apr 18 04:32:54.387: INFO: Pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161": Phase="Pending", Reason="", readiness=false. Elapsed: 100.215993ms
    Apr 18 04:32:56.416: INFO: Pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12908944s
    Apr 18 04:32:58.393: INFO: Pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161": Phase="Running", Reason="", readiness=false. Elapsed: 4.1057443s
    Apr 18 04:33:00.420: INFO: Pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.132576889s
    STEP: Saw pod success 04/18/23 04:33:00.42
    Apr 18 04:33:00.420: INFO: Pod "pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161" satisfied condition "Succeeded or Failed"
    Apr 18 04:33:00.437: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 04:33:00.448
    Apr 18 04:33:00.588: INFO: Waiting for pod pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161 to disappear
    Apr 18 04:33:00.590: INFO: Pod pod-projected-secrets-aa7a4ff9-fdc6-4cd2-b65c-4968dafc7161 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 04:33:00.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3594" for this suite. 04/18/23 04:33:00.595
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:33:00.624
Apr 18 04:33:00.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 04:33:00.625
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:33:00.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:33:00.736
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 04/18/23 04:33:00.738
STEP: submitting the pod to kubernetes 04/18/23 04:33:00.738
Apr 18 04:33:00.775: INFO: Waiting up to 5m0s for pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841" in namespace "pods-2182" to be "running and ready"
Apr 18 04:33:00.797: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841": Phase="Pending", Reason="", readiness=false. Elapsed: 21.943331ms
Apr 18 04:33:00.797: INFO: The phase of Pod pod-update-d89950d9-2129-4c80-a9e7-e620f3755841 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:33:02.800: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025433886s
Apr 18 04:33:02.800: INFO: The phase of Pod pod-update-d89950d9-2129-4c80-a9e7-e620f3755841 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:33:04.801: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841": Phase="Running", Reason="", readiness=true. Elapsed: 4.026437043s
Apr 18 04:33:04.801: INFO: The phase of Pod pod-update-d89950d9-2129-4c80-a9e7-e620f3755841 is Running (Ready = true)
Apr 18 04:33:04.801: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/18/23 04:33:04.804
STEP: updating the pod 04/18/23 04:33:04.855
Apr 18 04:33:05.388: INFO: Successfully updated pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841"
Apr 18 04:33:05.388: INFO: Waiting up to 5m0s for pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841" in namespace "pods-2182" to be "running"
Apr 18 04:33:05.397: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841": Phase="Running", Reason="", readiness=true. Elapsed: 8.644782ms
Apr 18 04:33:05.397: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 04/18/23 04:33:05.397
Apr 18 04:33:05.444: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 04:33:05.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2182" for this suite. 04/18/23 04:33:05.449
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":92,"skipped":1534,"failed":0}
------------------------------
â€¢ [4.858 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:33:00.624
    Apr 18 04:33:00.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 04:33:00.625
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:33:00.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:33:00.736
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 04/18/23 04:33:00.738
    STEP: submitting the pod to kubernetes 04/18/23 04:33:00.738
    Apr 18 04:33:00.775: INFO: Waiting up to 5m0s for pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841" in namespace "pods-2182" to be "running and ready"
    Apr 18 04:33:00.797: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841": Phase="Pending", Reason="", readiness=false. Elapsed: 21.943331ms
    Apr 18 04:33:00.797: INFO: The phase of Pod pod-update-d89950d9-2129-4c80-a9e7-e620f3755841 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:33:02.800: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025433886s
    Apr 18 04:33:02.800: INFO: The phase of Pod pod-update-d89950d9-2129-4c80-a9e7-e620f3755841 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:33:04.801: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841": Phase="Running", Reason="", readiness=true. Elapsed: 4.026437043s
    Apr 18 04:33:04.801: INFO: The phase of Pod pod-update-d89950d9-2129-4c80-a9e7-e620f3755841 is Running (Ready = true)
    Apr 18 04:33:04.801: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/18/23 04:33:04.804
    STEP: updating the pod 04/18/23 04:33:04.855
    Apr 18 04:33:05.388: INFO: Successfully updated pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841"
    Apr 18 04:33:05.388: INFO: Waiting up to 5m0s for pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841" in namespace "pods-2182" to be "running"
    Apr 18 04:33:05.397: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841": Phase="Running", Reason="", readiness=true. Elapsed: 8.644782ms
    Apr 18 04:33:05.397: INFO: Pod "pod-update-d89950d9-2129-4c80-a9e7-e620f3755841" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 04/18/23 04:33:05.397
    Apr 18 04:33:05.444: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 04:33:05.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2182" for this suite. 04/18/23 04:33:05.449
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:33:05.484
Apr 18 04:33:05.484: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:33:05.485
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:33:05.613
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:33:05.615
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-f8fac3fc-68c5-4c05-a6aa-967aff2a2dd8 04/18/23 04:33:05.618
STEP: Creating a pod to test consume secrets 04/18/23 04:33:05.644
Apr 18 04:33:05.663: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53" in namespace "projected-8294" to be "Succeeded or Failed"
Apr 18 04:33:05.666: INFO: Pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53": Phase="Pending", Reason="", readiness=false. Elapsed: 3.14302ms
Apr 18 04:33:07.764: INFO: Pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100598406s
Apr 18 04:33:09.671: INFO: Pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008006974s
Apr 18 04:33:11.670: INFO: Pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007413778s
STEP: Saw pod success 04/18/23 04:33:11.67
Apr 18 04:33:11.670: INFO: Pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53" satisfied condition "Succeeded or Failed"
Apr 18 04:33:11.673: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 04:33:11.701
Apr 18 04:33:11.982: INFO: Waiting for pod pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53 to disappear
Apr 18 04:33:11.986: INFO: Pod pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 04:33:11.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8294" for this suite. 04/18/23 04:33:12.037
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":93,"skipped":1553,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.672 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:33:05.484
    Apr 18 04:33:05.484: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:33:05.485
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:33:05.613
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:33:05.615
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-f8fac3fc-68c5-4c05-a6aa-967aff2a2dd8 04/18/23 04:33:05.618
    STEP: Creating a pod to test consume secrets 04/18/23 04:33:05.644
    Apr 18 04:33:05.663: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53" in namespace "projected-8294" to be "Succeeded or Failed"
    Apr 18 04:33:05.666: INFO: Pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53": Phase="Pending", Reason="", readiness=false. Elapsed: 3.14302ms
    Apr 18 04:33:07.764: INFO: Pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100598406s
    Apr 18 04:33:09.671: INFO: Pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008006974s
    Apr 18 04:33:11.670: INFO: Pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007413778s
    STEP: Saw pod success 04/18/23 04:33:11.67
    Apr 18 04:33:11.670: INFO: Pod "pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53" satisfied condition "Succeeded or Failed"
    Apr 18 04:33:11.673: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 04:33:11.701
    Apr 18 04:33:11.982: INFO: Waiting for pod pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53 to disappear
    Apr 18 04:33:11.986: INFO: Pod pod-projected-secrets-faddca59-1a19-4b37-8166-845db7f29a53 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 04:33:11.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8294" for this suite. 04/18/23 04:33:12.037
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:33:12.157
Apr 18 04:33:12.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replication-controller 04/18/23 04:33:12.158
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:33:12.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:33:12.405
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 04/18/23 04:33:12.408
STEP: When the matched label of one of its pods change 04/18/23 04:33:12.473
Apr 18 04:33:12.492: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 18 04:33:17.509: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 04/18/23 04:33:17.591
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 18 04:33:18.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3962" for this suite. 04/18/23 04:33:18.645
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":94,"skipped":1570,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.522 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:33:12.157
    Apr 18 04:33:12.157: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replication-controller 04/18/23 04:33:12.158
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:33:12.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:33:12.405
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 04/18/23 04:33:12.408
    STEP: When the matched label of one of its pods change 04/18/23 04:33:12.473
    Apr 18 04:33:12.492: INFO: Pod name pod-release: Found 0 pods out of 1
    Apr 18 04:33:17.509: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/18/23 04:33:17.591
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 18 04:33:18.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-3962" for this suite. 04/18/23 04:33:18.645
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:33:18.68
Apr 18 04:33:18.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename prestop 04/18/23 04:33:18.681
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:33:18.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:33:18.97
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-9319 04/18/23 04:33:19.033
STEP: Waiting for pods to come up. 04/18/23 04:33:19.113
Apr 18 04:33:19.113: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-9319" to be "running"
Apr 18 04:33:19.115: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.677926ms
Apr 18 04:33:21.121: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00798519s
Apr 18 04:33:23.120: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 4.006895807s
Apr 18 04:33:23.120: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-9319 04/18/23 04:33:23.123
Apr 18 04:33:23.153: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-9319" to be "running"
Apr 18 04:33:23.156: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 3.27211ms
Apr 18 04:33:25.243: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090335843s
Apr 18 04:33:27.160: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.007478364s
Apr 18 04:33:27.160: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 04/18/23 04:33:27.16
Apr 18 04:33:32.203: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 04/18/23 04:33:32.203
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Apr 18 04:33:32.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9319" for this suite. 04/18/23 04:33:32.367
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":95,"skipped":1573,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.701 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:33:18.68
    Apr 18 04:33:18.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename prestop 04/18/23 04:33:18.681
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:33:18.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:33:18.97
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-9319 04/18/23 04:33:19.033
    STEP: Waiting for pods to come up. 04/18/23 04:33:19.113
    Apr 18 04:33:19.113: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-9319" to be "running"
    Apr 18 04:33:19.115: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.677926ms
    Apr 18 04:33:21.121: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00798519s
    Apr 18 04:33:23.120: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 4.006895807s
    Apr 18 04:33:23.120: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-9319 04/18/23 04:33:23.123
    Apr 18 04:33:23.153: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-9319" to be "running"
    Apr 18 04:33:23.156: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 3.27211ms
    Apr 18 04:33:25.243: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090335843s
    Apr 18 04:33:27.160: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 4.007478364s
    Apr 18 04:33:27.160: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 04/18/23 04:33:27.16
    Apr 18 04:33:32.203: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 04/18/23 04:33:32.203
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Apr 18 04:33:32.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-9319" for this suite. 04/18/23 04:33:32.367
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:33:32.381
Apr 18 04:33:32.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 04:33:32.382
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:33:32.568
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:33:32.571
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/18/23 04:33:32.629
Apr 18 04:33:32.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:33:47.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:34:25.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7053" for this suite. 04/18/23 04:34:25.634
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":96,"skipped":1587,"failed":0}
------------------------------
â€¢ [SLOW TEST] [53.273 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:33:32.381
    Apr 18 04:33:32.381: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 04:33:32.382
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:33:32.568
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:33:32.571
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/18/23 04:33:32.629
    Apr 18 04:33:32.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:33:47.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:34:25.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7053" for this suite. 04/18/23 04:34:25.634
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:34:25.655
Apr 18 04:34:25.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 04:34:25.656
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:34:25.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:34:25.767
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 04/18/23 04:34:25.774
Apr 18 04:34:25.800: INFO: Waiting up to 5m0s for pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0" in namespace "emptydir-5501" to be "Succeeded or Failed"
Apr 18 04:34:25.816: INFO: Pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.013731ms
Apr 18 04:34:27.820: INFO: Pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019932613s
Apr 18 04:34:29.822: INFO: Pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02159361s
Apr 18 04:34:31.820: INFO: Pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019667988s
STEP: Saw pod success 04/18/23 04:34:31.82
Apr 18 04:34:31.820: INFO: Pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0" satisfied condition "Succeeded or Failed"
Apr 18 04:34:31.823: INFO: Trying to get logs from node apps-208 pod pod-98a84196-96c3-4bc3-a59f-066e00950cb0 container test-container: <nil>
STEP: delete the pod 04/18/23 04:34:31.835
Apr 18 04:34:31.880: INFO: Waiting for pod pod-98a84196-96c3-4bc3-a59f-066e00950cb0 to disappear
Apr 18 04:34:31.883: INFO: Pod pod-98a84196-96c3-4bc3-a59f-066e00950cb0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 04:34:31.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5501" for this suite. 04/18/23 04:34:31.888
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":97,"skipped":1594,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.242 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:34:25.655
    Apr 18 04:34:25.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 04:34:25.656
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:34:25.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:34:25.767
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 04/18/23 04:34:25.774
    Apr 18 04:34:25.800: INFO: Waiting up to 5m0s for pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0" in namespace "emptydir-5501" to be "Succeeded or Failed"
    Apr 18 04:34:25.816: INFO: Pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.013731ms
    Apr 18 04:34:27.820: INFO: Pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019932613s
    Apr 18 04:34:29.822: INFO: Pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02159361s
    Apr 18 04:34:31.820: INFO: Pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019667988s
    STEP: Saw pod success 04/18/23 04:34:31.82
    Apr 18 04:34:31.820: INFO: Pod "pod-98a84196-96c3-4bc3-a59f-066e00950cb0" satisfied condition "Succeeded or Failed"
    Apr 18 04:34:31.823: INFO: Trying to get logs from node apps-208 pod pod-98a84196-96c3-4bc3-a59f-066e00950cb0 container test-container: <nil>
    STEP: delete the pod 04/18/23 04:34:31.835
    Apr 18 04:34:31.880: INFO: Waiting for pod pod-98a84196-96c3-4bc3-a59f-066e00950cb0 to disappear
    Apr 18 04:34:31.883: INFO: Pod pod-98a84196-96c3-4bc3-a59f-066e00950cb0 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 04:34:31.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5501" for this suite. 04/18/23 04:34:31.888
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:34:31.898
Apr 18 04:34:31.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pod-network-test 04/18/23 04:34:31.899
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:34:32.057
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:34:32.06
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-3979 04/18/23 04:34:32.118
STEP: creating a selector 04/18/23 04:34:32.118
STEP: Creating the service pods in kubernetes 04/18/23 04:34:32.118
Apr 18 04:34:32.118: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 18 04:34:32.403: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3979" to be "running and ready"
Apr 18 04:34:32.496: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 92.220732ms
Apr 18 04:34:32.496: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:34:34.723: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.319266272s
Apr 18 04:34:34.723: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:34:36.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.09662267s
Apr 18 04:34:36.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:34:38.502: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.098092897s
Apr 18 04:34:38.502: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:34:40.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.097175244s
Apr 18 04:34:40.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:34:42.537: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.133560242s
Apr 18 04:34:42.537: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:34:44.510: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.106162817s
Apr 18 04:34:44.510: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:34:46.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.096479559s
Apr 18 04:34:46.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:34:48.507: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.10392926s
Apr 18 04:34:48.507: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:34:50.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.097196281s
Apr 18 04:34:50.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:34:52.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.096622455s
Apr 18 04:34:52.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 04:34:54.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.097324938s
Apr 18 04:34:54.501: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 18 04:34:54.501: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 18 04:34:54.505: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3979" to be "running and ready"
Apr 18 04:34:54.508: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.078935ms
Apr 18 04:34:54.508: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 18 04:34:54.508: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 18 04:34:54.510: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3979" to be "running and ready"
Apr 18 04:34:54.513: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.861757ms
Apr 18 04:34:54.513: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 18 04:34:54.513: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/18/23 04:34:54.516
Apr 18 04:34:54.540: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3979" to be "running"
Apr 18 04:34:54.543: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.123514ms
Apr 18 04:34:56.548: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007510638s
Apr 18 04:34:58.561: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.021243056s
Apr 18 04:34:58.561: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 18 04:34:58.564: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 18 04:34:58.564: INFO: Breadth first check of 172.16.100.158 on host 192.168.2.107...
Apr 18 04:34:58.567: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.44:9080/dial?request=hostname&protocol=udp&host=172.16.100.158&port=8081&tries=1'] Namespace:pod-network-test-3979 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:34:58.567: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:34:58.568: INFO: ExecWithOptions: Clientset creation
Apr 18 04:34:58.568: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3979/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.44%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.100.158%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 04:34:58.650: INFO: Waiting for responses: map[]
Apr 18 04:34:58.650: INFO: reached 172.16.100.158 after 0/1 tries
Apr 18 04:34:58.650: INFO: Breadth first check of 172.16.125.9 on host 192.168.2.108...
Apr 18 04:34:58.654: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.44:9080/dial?request=hostname&protocol=udp&host=172.16.125.9&port=8081&tries=1'] Namespace:pod-network-test-3979 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:34:58.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:34:58.654: INFO: ExecWithOptions: Clientset creation
Apr 18 04:34:58.655: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3979/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.44%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.125.9%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 04:34:58.769: INFO: Waiting for responses: map[]
Apr 18 04:34:58.769: INFO: reached 172.16.125.9 after 0/1 tries
Apr 18 04:34:58.769: INFO: Breadth first check of 172.16.144.40 on host 192.168.2.109...
Apr 18 04:34:58.772: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.44:9080/dial?request=hostname&protocol=udp&host=172.16.144.40&port=8081&tries=1'] Namespace:pod-network-test-3979 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 04:34:58.772: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:34:58.773: INFO: ExecWithOptions: Clientset creation
Apr 18 04:34:58.773: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3979/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.44%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.144.40%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 04:34:59.285: INFO: Waiting for responses: map[]
Apr 18 04:34:59.285: INFO: reached 172.16.144.40 after 0/1 tries
Apr 18 04:34:59.285: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 18 04:34:59.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3979" for this suite. 04/18/23 04:34:59.313
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":98,"skipped":1609,"failed":0}
------------------------------
â€¢ [SLOW TEST] [27.493 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:34:31.898
    Apr 18 04:34:31.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pod-network-test 04/18/23 04:34:31.899
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:34:32.057
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:34:32.06
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-3979 04/18/23 04:34:32.118
    STEP: creating a selector 04/18/23 04:34:32.118
    STEP: Creating the service pods in kubernetes 04/18/23 04:34:32.118
    Apr 18 04:34:32.118: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 18 04:34:32.403: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3979" to be "running and ready"
    Apr 18 04:34:32.496: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 92.220732ms
    Apr 18 04:34:32.496: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:34:34.723: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.319266272s
    Apr 18 04:34:34.723: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:34:36.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.09662267s
    Apr 18 04:34:36.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:34:38.502: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.098092897s
    Apr 18 04:34:38.502: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:34:40.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.097175244s
    Apr 18 04:34:40.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:34:42.537: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.133560242s
    Apr 18 04:34:42.537: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:34:44.510: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.106162817s
    Apr 18 04:34:44.510: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:34:46.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.096479559s
    Apr 18 04:34:46.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:34:48.507: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.10392926s
    Apr 18 04:34:48.507: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:34:50.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.097196281s
    Apr 18 04:34:50.501: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:34:52.500: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.096622455s
    Apr 18 04:34:52.500: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 04:34:54.501: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.097324938s
    Apr 18 04:34:54.501: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 18 04:34:54.501: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 18 04:34:54.505: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3979" to be "running and ready"
    Apr 18 04:34:54.508: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.078935ms
    Apr 18 04:34:54.508: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 18 04:34:54.508: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 18 04:34:54.510: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3979" to be "running and ready"
    Apr 18 04:34:54.513: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.861757ms
    Apr 18 04:34:54.513: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 18 04:34:54.513: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/18/23 04:34:54.516
    Apr 18 04:34:54.540: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3979" to be "running"
    Apr 18 04:34:54.543: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.123514ms
    Apr 18 04:34:56.548: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007510638s
    Apr 18 04:34:58.561: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.021243056s
    Apr 18 04:34:58.561: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 18 04:34:58.564: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 18 04:34:58.564: INFO: Breadth first check of 172.16.100.158 on host 192.168.2.107...
    Apr 18 04:34:58.567: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.44:9080/dial?request=hostname&protocol=udp&host=172.16.100.158&port=8081&tries=1'] Namespace:pod-network-test-3979 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:34:58.567: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:34:58.568: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:34:58.568: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3979/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.44%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.100.158%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 04:34:58.650: INFO: Waiting for responses: map[]
    Apr 18 04:34:58.650: INFO: reached 172.16.100.158 after 0/1 tries
    Apr 18 04:34:58.650: INFO: Breadth first check of 172.16.125.9 on host 192.168.2.108...
    Apr 18 04:34:58.654: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.44:9080/dial?request=hostname&protocol=udp&host=172.16.125.9&port=8081&tries=1'] Namespace:pod-network-test-3979 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:34:58.654: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:34:58.654: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:34:58.655: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3979/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.44%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.125.9%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 04:34:58.769: INFO: Waiting for responses: map[]
    Apr 18 04:34:58.769: INFO: reached 172.16.125.9 after 0/1 tries
    Apr 18 04:34:58.769: INFO: Breadth first check of 172.16.144.40 on host 192.168.2.109...
    Apr 18 04:34:58.772: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.44:9080/dial?request=hostname&protocol=udp&host=172.16.144.40&port=8081&tries=1'] Namespace:pod-network-test-3979 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 04:34:58.772: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:34:58.773: INFO: ExecWithOptions: Clientset creation
    Apr 18 04:34:58.773: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-3979/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.44%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D172.16.144.40%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 04:34:59.285: INFO: Waiting for responses: map[]
    Apr 18 04:34:59.285: INFO: reached 172.16.144.40 after 0/1 tries
    Apr 18 04:34:59.285: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 18 04:34:59.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3979" for this suite. 04/18/23 04:34:59.313
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:34:59.392
Apr 18 04:34:59.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 04:34:59.393
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:34:59.453
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:34:59.456
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 04/18/23 04:34:59.532
Apr 18 04:34:59.565: INFO: Waiting up to 5m0s for pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9" in namespace "emptydir-8722" to be "Succeeded or Failed"
Apr 18 04:34:59.623: INFO: Pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9": Phase="Pending", Reason="", readiness=false. Elapsed: 58.155795ms
Apr 18 04:35:01.688: INFO: Pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123215066s
Apr 18 04:35:03.629: INFO: Pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9": Phase="Running", Reason="", readiness=false. Elapsed: 4.063541812s
Apr 18 04:35:05.660: INFO: Pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.095083485s
STEP: Saw pod success 04/18/23 04:35:05.66
Apr 18 04:35:05.660: INFO: Pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9" satisfied condition "Succeeded or Failed"
Apr 18 04:35:05.717: INFO: Trying to get logs from node apps-208 pod pod-a51d331f-9466-4b19-9bdc-52d200ec96e9 container test-container: <nil>
STEP: delete the pod 04/18/23 04:35:05.722
Apr 18 04:35:05.884: INFO: Waiting for pod pod-a51d331f-9466-4b19-9bdc-52d200ec96e9 to disappear
Apr 18 04:35:05.887: INFO: Pod pod-a51d331f-9466-4b19-9bdc-52d200ec96e9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 04:35:05.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8722" for this suite. 04/18/23 04:35:05.894
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":99,"skipped":1614,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.549 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:34:59.392
    Apr 18 04:34:59.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 04:34:59.393
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:34:59.453
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:34:59.456
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/18/23 04:34:59.532
    Apr 18 04:34:59.565: INFO: Waiting up to 5m0s for pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9" in namespace "emptydir-8722" to be "Succeeded or Failed"
    Apr 18 04:34:59.623: INFO: Pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9": Phase="Pending", Reason="", readiness=false. Elapsed: 58.155795ms
    Apr 18 04:35:01.688: INFO: Pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123215066s
    Apr 18 04:35:03.629: INFO: Pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9": Phase="Running", Reason="", readiness=false. Elapsed: 4.063541812s
    Apr 18 04:35:05.660: INFO: Pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.095083485s
    STEP: Saw pod success 04/18/23 04:35:05.66
    Apr 18 04:35:05.660: INFO: Pod "pod-a51d331f-9466-4b19-9bdc-52d200ec96e9" satisfied condition "Succeeded or Failed"
    Apr 18 04:35:05.717: INFO: Trying to get logs from node apps-208 pod pod-a51d331f-9466-4b19-9bdc-52d200ec96e9 container test-container: <nil>
    STEP: delete the pod 04/18/23 04:35:05.722
    Apr 18 04:35:05.884: INFO: Waiting for pod pod-a51d331f-9466-4b19-9bdc-52d200ec96e9 to disappear
    Apr 18 04:35:05.887: INFO: Pod pod-a51d331f-9466-4b19-9bdc-52d200ec96e9 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 04:35:05.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8722" for this suite. 04/18/23 04:35:05.894
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:35:05.941
Apr 18 04:35:05.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename deployment 04/18/23 04:35:05.942
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:35:06.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:35:06.071
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 04/18/23 04:35:06.14
Apr 18 04:35:06.140: INFO: Creating simple deployment test-deployment-wvgs6
Apr 18 04:35:06.225: INFO: deployment "test-deployment-wvgs6" doesn't have the required revision set
Apr 18 04:35:08.281: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-wvgs6-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 04:35:10.285: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-wvgs6-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Getting /status 04/18/23 04:35:12.289
Apr 18 04:35:12.293: INFO: Deployment test-deployment-wvgs6 has Conditions: [{Available True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wvgs6-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 04/18/23 04:35:12.293
Apr 18 04:35:12.320: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 11, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-wvgs6-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 04/18/23 04:35:12.32
Apr 18 04:35:12.322: INFO: Observed &Deployment event: ADDED
Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wvgs6-777898ffcc"}
Apr 18 04:35:12.322: INFO: Observed &Deployment event: MODIFIED
Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wvgs6-777898ffcc"}
Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 18 04:35:12.322: INFO: Observed &Deployment event: MODIFIED
Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wvgs6-777898ffcc" is progressing.}
Apr 18 04:35:12.322: INFO: Observed &Deployment event: MODIFIED
Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wvgs6-777898ffcc" has successfully progressed.}
Apr 18 04:35:12.322: INFO: Observed &Deployment event: MODIFIED
Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wvgs6-777898ffcc" has successfully progressed.}
Apr 18 04:35:12.322: INFO: Found Deployment test-deployment-wvgs6 in namespace deployment-8349 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 18 04:35:12.322: INFO: Deployment test-deployment-wvgs6 has an updated status
STEP: patching the Statefulset Status 04/18/23 04:35:12.322
Apr 18 04:35:12.322: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 18 04:35:12.351: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 04/18/23 04:35:12.351
Apr 18 04:35:12.352: INFO: Observed &Deployment event: ADDED
Apr 18 04:35:12.352: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wvgs6-777898ffcc"}
Apr 18 04:35:12.352: INFO: Observed &Deployment event: MODIFIED
Apr 18 04:35:12.352: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wvgs6-777898ffcc"}
Apr 18 04:35:12.352: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 18 04:35:12.353: INFO: Observed &Deployment event: MODIFIED
Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wvgs6-777898ffcc" is progressing.}
Apr 18 04:35:12.353: INFO: Observed &Deployment event: MODIFIED
Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wvgs6-777898ffcc" has successfully progressed.}
Apr 18 04:35:12.353: INFO: Observed &Deployment event: MODIFIED
Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wvgs6-777898ffcc" has successfully progressed.}
Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 18 04:35:12.353: INFO: Observed &Deployment event: MODIFIED
Apr 18 04:35:12.427: INFO: Found deployment test-deployment-wvgs6 in namespace deployment-8349 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Apr 18 04:35:12.427: INFO: Deployment test-deployment-wvgs6 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 04:35:12.430: INFO: Deployment "test-deployment-wvgs6":
&Deployment{ObjectMeta:{test-deployment-wvgs6  deployment-8349  807350b5-a980-4f4f-89b5-11d4f7cb9a7e 4090538 1 2023-04-18 04:35:06 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-18 04:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-18 04:35:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-18 04:35:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0074084d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-wvgs6-777898ffcc",LastUpdateTime:2023-04-18 04:35:12 +0000 UTC,LastTransitionTime:2023-04-18 04:35:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 18 04:35:12.468: INFO: New ReplicaSet "test-deployment-wvgs6-777898ffcc" of Deployment "test-deployment-wvgs6":
&ReplicaSet{ObjectMeta:{test-deployment-wvgs6-777898ffcc  deployment-8349  9d25cc67-af22-4535-b8db-105c616b7773 4090528 1 2023-04-18 04:35:06 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-wvgs6 807350b5-a980-4f4f-89b5-11d4f7cb9a7e 0xc0059a3e97 0xc0059a3e98}] [] [{kube-controller-manager Update apps/v1 2023-04-18 04:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"807350b5-a980-4f4f-89b5-11d4f7cb9a7e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:35:11 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0059a3fb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 18 04:35:12.472: INFO: Pod "test-deployment-wvgs6-777898ffcc-4mf6j" is available:
&Pod{ObjectMeta:{test-deployment-wvgs6-777898ffcc-4mf6j test-deployment-wvgs6-777898ffcc- deployment-8349  ae4aae69-3795-418b-a96c-a69d4eac0c41 4090527 0 2023-04-18 04:35:06 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:9f70151029989ebb2d0e7f19f3206bb6729945f80d6353f4ce43fb184ca9945a cni.projectcalico.org/podIP:172.16.125.56/32 cni.projectcalico.org/podIPs:172.16.125.56/32] [{apps/v1 ReplicaSet test-deployment-wvgs6-777898ffcc 9d25cc67-af22-4535-b8db-105c616b7773 0xc004e364d7 0xc004e364d8}] [] [{kube-controller-manager Update v1 2023-04-18 04:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d25cc67-af22-4535-b8db-105c616b7773\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 04:35:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 04:35:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.56\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vf5z8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vf5z8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:35:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:35:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:35:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:35:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.56,StartTime:2023-04-18 04:35:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 04:35:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2a1cf1c6cdda7d7291fafe8612b3a49f5860a991eb06b2abdfc4025ccaa8e789,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.56,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 04:35:12.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8349" for this suite. 04/18/23 04:35:12.476
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":100,"skipped":1617,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.636 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:35:05.941
    Apr 18 04:35:05.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename deployment 04/18/23 04:35:05.942
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:35:06.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:35:06.071
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 04/18/23 04:35:06.14
    Apr 18 04:35:06.140: INFO: Creating simple deployment test-deployment-wvgs6
    Apr 18 04:35:06.225: INFO: deployment "test-deployment-wvgs6" doesn't have the required revision set
    Apr 18 04:35:08.281: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-wvgs6-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 04:35:10.285: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-deployment-wvgs6-777898ffcc\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Getting /status 04/18/23 04:35:12.289
    Apr 18 04:35:12.293: INFO: Deployment test-deployment-wvgs6 has Conditions: [{Available True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wvgs6-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 04/18/23 04:35:12.293
    Apr 18 04:35:12.320: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 11, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 35, 11, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 35, 6, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-wvgs6-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 04/18/23 04:35:12.32
    Apr 18 04:35:12.322: INFO: Observed &Deployment event: ADDED
    Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wvgs6-777898ffcc"}
    Apr 18 04:35:12.322: INFO: Observed &Deployment event: MODIFIED
    Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wvgs6-777898ffcc"}
    Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 18 04:35:12.322: INFO: Observed &Deployment event: MODIFIED
    Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wvgs6-777898ffcc" is progressing.}
    Apr 18 04:35:12.322: INFO: Observed &Deployment event: MODIFIED
    Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wvgs6-777898ffcc" has successfully progressed.}
    Apr 18 04:35:12.322: INFO: Observed &Deployment event: MODIFIED
    Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 18 04:35:12.322: INFO: Observed Deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wvgs6-777898ffcc" has successfully progressed.}
    Apr 18 04:35:12.322: INFO: Found Deployment test-deployment-wvgs6 in namespace deployment-8349 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 18 04:35:12.322: INFO: Deployment test-deployment-wvgs6 has an updated status
    STEP: patching the Statefulset Status 04/18/23 04:35:12.322
    Apr 18 04:35:12.322: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 18 04:35:12.351: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 04/18/23 04:35:12.351
    Apr 18 04:35:12.352: INFO: Observed &Deployment event: ADDED
    Apr 18 04:35:12.352: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wvgs6-777898ffcc"}
    Apr 18 04:35:12.352: INFO: Observed &Deployment event: MODIFIED
    Apr 18 04:35:12.352: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-wvgs6-777898ffcc"}
    Apr 18 04:35:12.352: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 18 04:35:12.353: INFO: Observed &Deployment event: MODIFIED
    Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:06 +0000 UTC 2023-04-18 04:35:06 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-wvgs6-777898ffcc" is progressing.}
    Apr 18 04:35:12.353: INFO: Observed &Deployment event: MODIFIED
    Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wvgs6-777898ffcc" has successfully progressed.}
    Apr 18 04:35:12.353: INFO: Observed &Deployment event: MODIFIED
    Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-04-18 04:35:11 +0000 UTC 2023-04-18 04:35:06 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-wvgs6-777898ffcc" has successfully progressed.}
    Apr 18 04:35:12.353: INFO: Observed deployment test-deployment-wvgs6 in namespace deployment-8349 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 18 04:35:12.353: INFO: Observed &Deployment event: MODIFIED
    Apr 18 04:35:12.427: INFO: Found deployment test-deployment-wvgs6 in namespace deployment-8349 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Apr 18 04:35:12.427: INFO: Deployment test-deployment-wvgs6 has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 04:35:12.430: INFO: Deployment "test-deployment-wvgs6":
    &Deployment{ObjectMeta:{test-deployment-wvgs6  deployment-8349  807350b5-a980-4f4f-89b5-11d4f7cb9a7e 4090538 1 2023-04-18 04:35:06 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-18 04:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2023-04-18 04:35:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2023-04-18 04:35:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0074084d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-wvgs6-777898ffcc",LastUpdateTime:2023-04-18 04:35:12 +0000 UTC,LastTransitionTime:2023-04-18 04:35:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 18 04:35:12.468: INFO: New ReplicaSet "test-deployment-wvgs6-777898ffcc" of Deployment "test-deployment-wvgs6":
    &ReplicaSet{ObjectMeta:{test-deployment-wvgs6-777898ffcc  deployment-8349  9d25cc67-af22-4535-b8db-105c616b7773 4090528 1 2023-04-18 04:35:06 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-wvgs6 807350b5-a980-4f4f-89b5-11d4f7cb9a7e 0xc0059a3e97 0xc0059a3e98}] [] [{kube-controller-manager Update apps/v1 2023-04-18 04:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"807350b5-a980-4f4f-89b5-11d4f7cb9a7e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:35:11 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0059a3fb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 04:35:12.472: INFO: Pod "test-deployment-wvgs6-777898ffcc-4mf6j" is available:
    &Pod{ObjectMeta:{test-deployment-wvgs6-777898ffcc-4mf6j test-deployment-wvgs6-777898ffcc- deployment-8349  ae4aae69-3795-418b-a96c-a69d4eac0c41 4090527 0 2023-04-18 04:35:06 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:9f70151029989ebb2d0e7f19f3206bb6729945f80d6353f4ce43fb184ca9945a cni.projectcalico.org/podIP:172.16.125.56/32 cni.projectcalico.org/podIPs:172.16.125.56/32] [{apps/v1 ReplicaSet test-deployment-wvgs6-777898ffcc 9d25cc67-af22-4535-b8db-105c616b7773 0xc004e364d7 0xc004e364d8}] [] [{kube-controller-manager Update v1 2023-04-18 04:35:06 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9d25cc67-af22-4535-b8db-105c616b7773\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 04:35:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 04:35:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.56\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vf5z8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vf5z8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:35:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:35:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:35:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:35:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.56,StartTime:2023-04-18 04:35:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 04:35:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2a1cf1c6cdda7d7291fafe8612b3a49f5860a991eb06b2abdfc4025ccaa8e789,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.56,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 04:35:12.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8349" for this suite. 04/18/23 04:35:12.476
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:35:12.579
Apr 18 04:35:12.579: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 04:35:12.58
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:35:12.825
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:35:12.829
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-8039 04/18/23 04:35:12.831
Apr 18 04:35:12.844: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-8039" to be "running and ready"
Apr 18 04:35:12.926: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 82.185705ms
Apr 18 04:35:12.926: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:35:14.951: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 2.107088899s
Apr 18 04:35:14.951: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:35:16.931: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 4.086445898s
Apr 18 04:35:16.931: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Apr 18 04:35:16.931: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Apr 18 04:35:16.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Apr 18 04:35:17.113: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Apr 18 04:35:17.113: INFO: stdout: "ipvs"
Apr 18 04:35:17.113: INFO: proxyMode: ipvs
Apr 18 04:35:17.163: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Apr 18 04:35:17.192: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-8039 04/18/23 04:35:17.192
STEP: creating replication controller affinity-nodeport-timeout in namespace services-8039 04/18/23 04:35:17.301
I0418 04:35:17.401353      22 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-8039, replica count: 3
I0418 04:35:20.452779      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 04:35:23.453902      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 04:35:23.544: INFO: Creating new exec pod
Apr 18 04:35:23.572: INFO: Waiting up to 5m0s for pod "execpod-affinity8t6pm" in namespace "services-8039" to be "running"
Apr 18 04:35:23.574: INFO: Pod "execpod-affinity8t6pm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.609934ms
Apr 18 04:35:25.579: INFO: Pod "execpod-affinity8t6pm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007087183s
Apr 18 04:35:27.586: INFO: Pod "execpod-affinity8t6pm": Phase="Running", Reason="", readiness=true. Elapsed: 4.01453227s
Apr 18 04:35:27.586: INFO: Pod "execpod-affinity8t6pm" satisfied condition "running"
Apr 18 04:35:28.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Apr 18 04:35:28.888: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Apr 18 04:35:28.888: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:35:28.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.11.23 80'
Apr 18 04:35:29.569: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.11.23 80\nConnection to 10.96.11.23 80 port [tcp/http] succeeded!\n"
Apr 18 04:35:29.569: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:35:29.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.109 32206'
Apr 18 04:35:29.727: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.109 32206\nConnection to 192.168.2.109 32206 port [tcp/*] succeeded!\n"
Apr 18 04:35:29.727: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:35:29.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.108 32206'
Apr 18 04:35:29.871: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.108 32206\nConnection to 192.168.2.108 32206 port [tcp/*] succeeded!\n"
Apr 18 04:35:29.871: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:35:29.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.2.107:32206/ ; done'
Apr 18 04:35:30.089: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n"
Apr 18 04:35:30.089: INFO: stdout: "\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl"
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
Apr 18 04:35:30.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.2.107:32206/'
Apr 18 04:35:30.245: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n"
Apr 18 04:35:30.245: INFO: stdout: "affinity-nodeport-timeout-q9mdl"
Apr 18 04:37:40.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.2.107:32206/'
Apr 18 04:37:40.417: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n"
Apr 18 04:37:40.417: INFO: stdout: "affinity-nodeport-timeout-rm7pd"
Apr 18 04:37:40.417: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-8039, will wait for the garbage collector to delete the pods 04/18/23 04:37:40.531
Apr 18 04:37:40.789: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 183.478436ms
Apr 18 04:37:41.090: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 300.460054ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 04:37:45.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8039" for this suite. 04/18/23 04:37:45.114
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":101,"skipped":1651,"failed":0}
------------------------------
â€¢ [SLOW TEST] [152.560 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:35:12.579
    Apr 18 04:35:12.579: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 04:35:12.58
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:35:12.825
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:35:12.829
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-8039 04/18/23 04:35:12.831
    Apr 18 04:35:12.844: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-8039" to be "running and ready"
    Apr 18 04:35:12.926: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 82.185705ms
    Apr 18 04:35:12.926: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:35:14.951: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 2.107088899s
    Apr 18 04:35:14.951: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:35:16.931: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 4.086445898s
    Apr 18 04:35:16.931: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Apr 18 04:35:16.931: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Apr 18 04:35:16.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Apr 18 04:35:17.113: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Apr 18 04:35:17.113: INFO: stdout: "ipvs"
    Apr 18 04:35:17.113: INFO: proxyMode: ipvs
    Apr 18 04:35:17.163: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Apr 18 04:35:17.192: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-8039 04/18/23 04:35:17.192
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-8039 04/18/23 04:35:17.301
    I0418 04:35:17.401353      22 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-8039, replica count: 3
    I0418 04:35:20.452779      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 04:35:23.453902      22 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 04:35:23.544: INFO: Creating new exec pod
    Apr 18 04:35:23.572: INFO: Waiting up to 5m0s for pod "execpod-affinity8t6pm" in namespace "services-8039" to be "running"
    Apr 18 04:35:23.574: INFO: Pod "execpod-affinity8t6pm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.609934ms
    Apr 18 04:35:25.579: INFO: Pod "execpod-affinity8t6pm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007087183s
    Apr 18 04:35:27.586: INFO: Pod "execpod-affinity8t6pm": Phase="Running", Reason="", readiness=true. Elapsed: 4.01453227s
    Apr 18 04:35:27.586: INFO: Pod "execpod-affinity8t6pm" satisfied condition "running"
    Apr 18 04:35:28.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Apr 18 04:35:28.888: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Apr 18 04:35:28.888: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:35:28.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.11.23 80'
    Apr 18 04:35:29.569: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.11.23 80\nConnection to 10.96.11.23 80 port [tcp/http] succeeded!\n"
    Apr 18 04:35:29.569: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:35:29.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.109 32206'
    Apr 18 04:35:29.727: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.109 32206\nConnection to 192.168.2.109 32206 port [tcp/*] succeeded!\n"
    Apr 18 04:35:29.727: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:35:29.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.108 32206'
    Apr 18 04:35:29.871: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.108 32206\nConnection to 192.168.2.108 32206 port [tcp/*] succeeded!\n"
    Apr 18 04:35:29.871: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:35:29.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.2.107:32206/ ; done'
    Apr 18 04:35:30.089: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n"
    Apr 18 04:35:30.089: INFO: stdout: "\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl\naffinity-nodeport-timeout-q9mdl"
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Received response from host: affinity-nodeport-timeout-q9mdl
    Apr 18 04:35:30.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.2.107:32206/'
    Apr 18 04:35:30.245: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n"
    Apr 18 04:35:30.245: INFO: stdout: "affinity-nodeport-timeout-q9mdl"
    Apr 18 04:37:40.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8039 exec execpod-affinity8t6pm -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://192.168.2.107:32206/'
    Apr 18 04:37:40.417: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://192.168.2.107:32206/\n"
    Apr 18 04:37:40.417: INFO: stdout: "affinity-nodeport-timeout-rm7pd"
    Apr 18 04:37:40.417: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-8039, will wait for the garbage collector to delete the pods 04/18/23 04:37:40.531
    Apr 18 04:37:40.789: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 183.478436ms
    Apr 18 04:37:41.090: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 300.460054ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 04:37:45.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8039" for this suite. 04/18/23 04:37:45.114
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:37:45.14
Apr 18 04:37:45.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 04:37:45.141
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:37:45.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:37:45.283
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 04/18/23 04:37:45.331
STEP: Getting a ResourceQuota 04/18/23 04:37:45.347
STEP: Updating a ResourceQuota 04/18/23 04:37:45.35
STEP: Verifying a ResourceQuota was modified 04/18/23 04:37:45.456
STEP: Deleting a ResourceQuota 04/18/23 04:37:45.507
STEP: Verifying the deleted ResourceQuota 04/18/23 04:37:45.523
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 04:37:45.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3551" for this suite. 04/18/23 04:37:45.53
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":102,"skipped":1657,"failed":0}
------------------------------
â€¢ [0.399 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:37:45.14
    Apr 18 04:37:45.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 04:37:45.141
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:37:45.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:37:45.283
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 04/18/23 04:37:45.331
    STEP: Getting a ResourceQuota 04/18/23 04:37:45.347
    STEP: Updating a ResourceQuota 04/18/23 04:37:45.35
    STEP: Verifying a ResourceQuota was modified 04/18/23 04:37:45.456
    STEP: Deleting a ResourceQuota 04/18/23 04:37:45.507
    STEP: Verifying the deleted ResourceQuota 04/18/23 04:37:45.523
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 04:37:45.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3551" for this suite. 04/18/23 04:37:45.53
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:37:45.539
Apr 18 04:37:45.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 04:37:45.54
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:37:45.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:37:45.677
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 04/18/23 04:37:45.69
Apr 18 04:37:45.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 create -f -'
Apr 18 04:37:47.274: INFO: stderr: ""
Apr 18 04:37:47.274: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 04:37:47.274
Apr 18 04:37:47.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 04:37:47.445: INFO: stderr: ""
Apr 18 04:37:47.445: INFO: stdout: "update-demo-nautilus-km57g update-demo-nautilus-qfklk "
Apr 18 04:37:47.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods update-demo-nautilus-km57g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 04:37:47.552: INFO: stderr: ""
Apr 18 04:37:47.552: INFO: stdout: ""
Apr 18 04:37:47.552: INFO: update-demo-nautilus-km57g is created but not running
Apr 18 04:37:52.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 04:37:52.691: INFO: stderr: ""
Apr 18 04:37:52.691: INFO: stdout: "update-demo-nautilus-km57g update-demo-nautilus-qfklk "
Apr 18 04:37:52.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods update-demo-nautilus-km57g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 04:37:52.765: INFO: stderr: ""
Apr 18 04:37:52.765: INFO: stdout: "true"
Apr 18 04:37:52.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods update-demo-nautilus-km57g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 04:37:52.839: INFO: stderr: ""
Apr 18 04:37:52.839: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 04:37:52.839: INFO: validating pod update-demo-nautilus-km57g
Apr 18 04:37:52.866: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 04:37:52.866: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 04:37:52.866: INFO: update-demo-nautilus-km57g is verified up and running
Apr 18 04:37:52.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods update-demo-nautilus-qfklk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 04:37:52.969: INFO: stderr: ""
Apr 18 04:37:52.969: INFO: stdout: "true"
Apr 18 04:37:52.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods update-demo-nautilus-qfklk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 04:37:53.069: INFO: stderr: ""
Apr 18 04:37:53.069: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 04:37:53.069: INFO: validating pod update-demo-nautilus-qfklk
Apr 18 04:37:53.074: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 04:37:53.074: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 04:37:53.074: INFO: update-demo-nautilus-qfklk is verified up and running
STEP: using delete to clean up resources 04/18/23 04:37:53.074
Apr 18 04:37:53.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 delete --grace-period=0 --force -f -'
Apr 18 04:37:53.170: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 04:37:53.170: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 18 04:37:53.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get rc,svc -l name=update-demo --no-headers'
Apr 18 04:37:53.379: INFO: stderr: "No resources found in kubectl-1695 namespace.\n"
Apr 18 04:37:53.379: INFO: stdout: ""
Apr 18 04:37:53.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 18 04:37:53.681: INFO: stderr: ""
Apr 18 04:37:53.682: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 04:37:53.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1695" for this suite. 04/18/23 04:37:53.8
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":103,"skipped":1657,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.431 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:37:45.539
    Apr 18 04:37:45.539: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 04:37:45.54
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:37:45.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:37:45.677
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 04/18/23 04:37:45.69
    Apr 18 04:37:45.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 create -f -'
    Apr 18 04:37:47.274: INFO: stderr: ""
    Apr 18 04:37:47.274: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 04:37:47.274
    Apr 18 04:37:47.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 04:37:47.445: INFO: stderr: ""
    Apr 18 04:37:47.445: INFO: stdout: "update-demo-nautilus-km57g update-demo-nautilus-qfklk "
    Apr 18 04:37:47.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods update-demo-nautilus-km57g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 04:37:47.552: INFO: stderr: ""
    Apr 18 04:37:47.552: INFO: stdout: ""
    Apr 18 04:37:47.552: INFO: update-demo-nautilus-km57g is created but not running
    Apr 18 04:37:52.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 04:37:52.691: INFO: stderr: ""
    Apr 18 04:37:52.691: INFO: stdout: "update-demo-nautilus-km57g update-demo-nautilus-qfklk "
    Apr 18 04:37:52.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods update-demo-nautilus-km57g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 04:37:52.765: INFO: stderr: ""
    Apr 18 04:37:52.765: INFO: stdout: "true"
    Apr 18 04:37:52.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods update-demo-nautilus-km57g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 04:37:52.839: INFO: stderr: ""
    Apr 18 04:37:52.839: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 04:37:52.839: INFO: validating pod update-demo-nautilus-km57g
    Apr 18 04:37:52.866: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 04:37:52.866: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 04:37:52.866: INFO: update-demo-nautilus-km57g is verified up and running
    Apr 18 04:37:52.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods update-demo-nautilus-qfklk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 04:37:52.969: INFO: stderr: ""
    Apr 18 04:37:52.969: INFO: stdout: "true"
    Apr 18 04:37:52.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods update-demo-nautilus-qfklk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 04:37:53.069: INFO: stderr: ""
    Apr 18 04:37:53.069: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 04:37:53.069: INFO: validating pod update-demo-nautilus-qfklk
    Apr 18 04:37:53.074: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 04:37:53.074: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 04:37:53.074: INFO: update-demo-nautilus-qfklk is verified up and running
    STEP: using delete to clean up resources 04/18/23 04:37:53.074
    Apr 18 04:37:53.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 delete --grace-period=0 --force -f -'
    Apr 18 04:37:53.170: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 04:37:53.170: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 18 04:37:53.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get rc,svc -l name=update-demo --no-headers'
    Apr 18 04:37:53.379: INFO: stderr: "No resources found in kubectl-1695 namespace.\n"
    Apr 18 04:37:53.379: INFO: stdout: ""
    Apr 18 04:37:53.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1695 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 18 04:37:53.681: INFO: stderr: ""
    Apr 18 04:37:53.682: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 04:37:53.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1695" for this suite. 04/18/23 04:37:53.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:37:53.971
Apr 18 04:37:53.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 04:37:53.972
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:37:54.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:37:54.377
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 04/18/23 04:37:54.401
Apr 18 04:37:54.523: INFO: Waiting up to 5m0s for pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93" in namespace "downward-api-3559" to be "running and ready"
Apr 18 04:37:54.534: INFO: Pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93": Phase="Pending", Reason="", readiness=false. Elapsed: 11.113489ms
Apr 18 04:37:54.534: INFO: The phase of Pod annotationupdate43589c53-6812-440b-b35f-857f2044dd93 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:37:56.539: INFO: Pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015912149s
Apr 18 04:37:56.539: INFO: The phase of Pod annotationupdate43589c53-6812-440b-b35f-857f2044dd93 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:37:58.564: INFO: Pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041315068s
Apr 18 04:37:58.564: INFO: The phase of Pod annotationupdate43589c53-6812-440b-b35f-857f2044dd93 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:38:00.539: INFO: Pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93": Phase="Running", Reason="", readiness=true. Elapsed: 6.01586273s
Apr 18 04:38:00.539: INFO: The phase of Pod annotationupdate43589c53-6812-440b-b35f-857f2044dd93 is Running (Ready = true)
Apr 18 04:38:00.539: INFO: Pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93" satisfied condition "running and ready"
Apr 18 04:38:01.216: INFO: Successfully updated pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 04:38:03.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3559" for this suite. 04/18/23 04:38:03.277
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":104,"skipped":1685,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.392 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:37:53.971
    Apr 18 04:37:53.971: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 04:37:53.972
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:37:54.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:37:54.377
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 04/18/23 04:37:54.401
    Apr 18 04:37:54.523: INFO: Waiting up to 5m0s for pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93" in namespace "downward-api-3559" to be "running and ready"
    Apr 18 04:37:54.534: INFO: Pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93": Phase="Pending", Reason="", readiness=false. Elapsed: 11.113489ms
    Apr 18 04:37:54.534: INFO: The phase of Pod annotationupdate43589c53-6812-440b-b35f-857f2044dd93 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:37:56.539: INFO: Pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015912149s
    Apr 18 04:37:56.539: INFO: The phase of Pod annotationupdate43589c53-6812-440b-b35f-857f2044dd93 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:37:58.564: INFO: Pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041315068s
    Apr 18 04:37:58.564: INFO: The phase of Pod annotationupdate43589c53-6812-440b-b35f-857f2044dd93 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:38:00.539: INFO: Pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93": Phase="Running", Reason="", readiness=true. Elapsed: 6.01586273s
    Apr 18 04:38:00.539: INFO: The phase of Pod annotationupdate43589c53-6812-440b-b35f-857f2044dd93 is Running (Ready = true)
    Apr 18 04:38:00.539: INFO: Pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93" satisfied condition "running and ready"
    Apr 18 04:38:01.216: INFO: Successfully updated pod "annotationupdate43589c53-6812-440b-b35f-857f2044dd93"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 04:38:03.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3559" for this suite. 04/18/23 04:38:03.277
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:38:03.366
Apr 18 04:38:03.366: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:38:03.367
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:38:03.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:38:03.511
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 04/18/23 04:38:03.513
Apr 18 04:38:03.556: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00" in namespace "projected-1287" to be "Succeeded or Failed"
Apr 18 04:38:03.559: INFO: Pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.444671ms
Apr 18 04:38:05.642: INFO: Pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086095782s
Apr 18 04:38:07.563: INFO: Pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006424526s
Apr 18 04:38:09.577: INFO: Pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020911776s
STEP: Saw pod success 04/18/23 04:38:09.577
Apr 18 04:38:09.577: INFO: Pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00" satisfied condition "Succeeded or Failed"
Apr 18 04:38:09.582: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00 container client-container: <nil>
STEP: delete the pod 04/18/23 04:38:09.613
Apr 18 04:38:09.827: INFO: Waiting for pod downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00 to disappear
Apr 18 04:38:09.915: INFO: Pod downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 04:38:09.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1287" for this suite. 04/18/23 04:38:09.946
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":105,"skipped":1710,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.669 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:38:03.366
    Apr 18 04:38:03.366: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:38:03.367
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:38:03.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:38:03.511
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 04/18/23 04:38:03.513
    Apr 18 04:38:03.556: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00" in namespace "projected-1287" to be "Succeeded or Failed"
    Apr 18 04:38:03.559: INFO: Pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.444671ms
    Apr 18 04:38:05.642: INFO: Pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086095782s
    Apr 18 04:38:07.563: INFO: Pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006424526s
    Apr 18 04:38:09.577: INFO: Pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020911776s
    STEP: Saw pod success 04/18/23 04:38:09.577
    Apr 18 04:38:09.577: INFO: Pod "downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00" satisfied condition "Succeeded or Failed"
    Apr 18 04:38:09.582: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00 container client-container: <nil>
    STEP: delete the pod 04/18/23 04:38:09.613
    Apr 18 04:38:09.827: INFO: Waiting for pod downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00 to disappear
    Apr 18 04:38:09.915: INFO: Pod downwardapi-volume-2a2e81c9-23a2-40d1-beeb-c75c057cef00 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 04:38:09.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1287" for this suite. 04/18/23 04:38:09.946
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:38:10.036
Apr 18 04:38:10.036: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 04:38:10.037
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:38:10.126
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:38:10.129
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 04/18/23 04:38:10.131
Apr 18 04:38:10.131: INFO: namespace kubectl-6467
Apr 18 04:38:10.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6467 create -f -'
Apr 18 04:38:11.548: INFO: stderr: ""
Apr 18 04:38:11.548: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/18/23 04:38:11.548
Apr 18 04:38:12.554: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 04:38:12.554: INFO: Found 0 / 1
Apr 18 04:38:13.553: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 04:38:13.553: INFO: Found 0 / 1
Apr 18 04:38:14.556: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 04:38:14.556: INFO: Found 0 / 1
Apr 18 04:38:15.551: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 04:38:15.552: INFO: Found 1 / 1
Apr 18 04:38:15.552: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 18 04:38:15.554: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 04:38:15.554: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 18 04:38:15.554: INFO: wait on agnhost-primary startup in kubectl-6467 
Apr 18 04:38:15.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6467 logs agnhost-primary-vt4w6 agnhost-primary'
Apr 18 04:38:15.668: INFO: stderr: ""
Apr 18 04:38:15.668: INFO: stdout: "Paused\n"
STEP: exposing RC 04/18/23 04:38:15.668
Apr 18 04:38:15.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6467 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Apr 18 04:38:15.890: INFO: stderr: ""
Apr 18 04:38:15.890: INFO: stdout: "service/rm2 exposed\n"
Apr 18 04:38:15.919: INFO: Service rm2 in namespace kubectl-6467 found.
STEP: exposing service 04/18/23 04:38:17.965
Apr 18 04:38:17.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6467 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Apr 18 04:38:18.146: INFO: stderr: ""
Apr 18 04:38:18.146: INFO: stdout: "service/rm3 exposed\n"
Apr 18 04:38:18.215: INFO: Service rm3 in namespace kubectl-6467 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 04:38:20.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6467" for this suite. 04/18/23 04:38:20.226
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":106,"skipped":1715,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.216 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:38:10.036
    Apr 18 04:38:10.036: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 04:38:10.037
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:38:10.126
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:38:10.129
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 04/18/23 04:38:10.131
    Apr 18 04:38:10.131: INFO: namespace kubectl-6467
    Apr 18 04:38:10.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6467 create -f -'
    Apr 18 04:38:11.548: INFO: stderr: ""
    Apr 18 04:38:11.548: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/18/23 04:38:11.548
    Apr 18 04:38:12.554: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 04:38:12.554: INFO: Found 0 / 1
    Apr 18 04:38:13.553: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 04:38:13.553: INFO: Found 0 / 1
    Apr 18 04:38:14.556: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 04:38:14.556: INFO: Found 0 / 1
    Apr 18 04:38:15.551: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 04:38:15.552: INFO: Found 1 / 1
    Apr 18 04:38:15.552: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 18 04:38:15.554: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 04:38:15.554: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 18 04:38:15.554: INFO: wait on agnhost-primary startup in kubectl-6467 
    Apr 18 04:38:15.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6467 logs agnhost-primary-vt4w6 agnhost-primary'
    Apr 18 04:38:15.668: INFO: stderr: ""
    Apr 18 04:38:15.668: INFO: stdout: "Paused\n"
    STEP: exposing RC 04/18/23 04:38:15.668
    Apr 18 04:38:15.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6467 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Apr 18 04:38:15.890: INFO: stderr: ""
    Apr 18 04:38:15.890: INFO: stdout: "service/rm2 exposed\n"
    Apr 18 04:38:15.919: INFO: Service rm2 in namespace kubectl-6467 found.
    STEP: exposing service 04/18/23 04:38:17.965
    Apr 18 04:38:17.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6467 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Apr 18 04:38:18.146: INFO: stderr: ""
    Apr 18 04:38:18.146: INFO: stdout: "service/rm3 exposed\n"
    Apr 18 04:38:18.215: INFO: Service rm3 in namespace kubectl-6467 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 04:38:20.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6467" for this suite. 04/18/23 04:38:20.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:38:20.254
Apr 18 04:38:20.254: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename cronjob 04/18/23 04:38:20.255
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:38:20.293
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:38:20.295
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 04/18/23 04:38:20.297
STEP: Ensuring a job is scheduled 04/18/23 04:38:20.369
STEP: Ensuring exactly one is scheduled 04/18/23 04:39:00.763
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/18/23 04:39:00.766
STEP: Ensuring no more jobs are scheduled 04/18/23 04:39:00.769
STEP: Removing cronjob 04/18/23 04:44:00.776
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 18 04:44:00.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2067" for this suite. 04/18/23 04:44:00.806
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":107,"skipped":1756,"failed":0}
------------------------------
â€¢ [SLOW TEST] [340.562 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:38:20.254
    Apr 18 04:38:20.254: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename cronjob 04/18/23 04:38:20.255
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:38:20.293
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:38:20.295
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 04/18/23 04:38:20.297
    STEP: Ensuring a job is scheduled 04/18/23 04:38:20.369
    STEP: Ensuring exactly one is scheduled 04/18/23 04:39:00.763
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/18/23 04:39:00.766
    STEP: Ensuring no more jobs are scheduled 04/18/23 04:39:00.769
    STEP: Removing cronjob 04/18/23 04:44:00.776
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 18 04:44:00.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2067" for this suite. 04/18/23 04:44:00.806
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:44:00.816
Apr 18 04:44:00.816: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename gc 04/18/23 04:44:00.817
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:01.025
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:01.035
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 04/18/23 04:44:01.038
STEP: delete the rc 04/18/23 04:44:06.134
STEP: wait for all pods to be garbage collected 04/18/23 04:44:06.233
STEP: Gathering metrics 04/18/23 04:44:11.27
Apr 18 04:44:11.335: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
Apr 18 04:44:11.338: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 3.127656ms
Apr 18 04:44:11.338: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
Apr 18 04:44:11.338: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
Apr 18 04:44:11.381: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 04:44:11.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5116" for this suite. 04/18/23 04:44:11.385
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":108,"skipped":1756,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.599 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:44:00.816
    Apr 18 04:44:00.816: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename gc 04/18/23 04:44:00.817
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:01.025
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:01.035
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 04/18/23 04:44:01.038
    STEP: delete the rc 04/18/23 04:44:06.134
    STEP: wait for all pods to be garbage collected 04/18/23 04:44:06.233
    STEP: Gathering metrics 04/18/23 04:44:11.27
    Apr 18 04:44:11.335: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
    Apr 18 04:44:11.338: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 3.127656ms
    Apr 18 04:44:11.338: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
    Apr 18 04:44:11.338: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
    Apr 18 04:44:11.381: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 04:44:11.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5116" for this suite. 04/18/23 04:44:11.385
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:44:11.416
Apr 18 04:44:11.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replicaset 04/18/23 04:44:11.417
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:11.598
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:11.6
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Apr 18 04:44:11.603: INFO: Creating ReplicaSet my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119
Apr 18 04:44:11.658: INFO: Pod name my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119: Found 0 pods out of 1
Apr 18 04:44:16.674: INFO: Pod name my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119: Found 1 pods out of 1
Apr 18 04:44:16.674: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119" is running
Apr 18 04:44:16.674: INFO: Waiting up to 5m0s for pod "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k" in namespace "replicaset-9697" to be "running"
Apr 18 04:44:16.724: INFO: Pod "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k": Phase="Running", Reason="", readiness=true. Elapsed: 50.43724ms
Apr 18 04:44:16.725: INFO: Pod "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k" satisfied condition "running"
Apr 18 04:44:16.725: INFO: Pod "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 04:44:11 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 04:44:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 04:44:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 04:44:11 +0000 UTC Reason: Message:}])
Apr 18 04:44:16.725: INFO: Trying to dial the pod
Apr 18 04:44:21.735: INFO: Controller my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119: Got expected result from replica 1 [my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k]: "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 04:44:21.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9697" for this suite. 04/18/23 04:44:21.74
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":109,"skipped":1772,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.344 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:44:11.416
    Apr 18 04:44:11.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replicaset 04/18/23 04:44:11.417
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:11.598
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:11.6
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Apr 18 04:44:11.603: INFO: Creating ReplicaSet my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119
    Apr 18 04:44:11.658: INFO: Pod name my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119: Found 0 pods out of 1
    Apr 18 04:44:16.674: INFO: Pod name my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119: Found 1 pods out of 1
    Apr 18 04:44:16.674: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119" is running
    Apr 18 04:44:16.674: INFO: Waiting up to 5m0s for pod "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k" in namespace "replicaset-9697" to be "running"
    Apr 18 04:44:16.724: INFO: Pod "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k": Phase="Running", Reason="", readiness=true. Elapsed: 50.43724ms
    Apr 18 04:44:16.725: INFO: Pod "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k" satisfied condition "running"
    Apr 18 04:44:16.725: INFO: Pod "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 04:44:11 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 04:44:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 04:44:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 04:44:11 +0000 UTC Reason: Message:}])
    Apr 18 04:44:16.725: INFO: Trying to dial the pod
    Apr 18 04:44:21.735: INFO: Controller my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119: Got expected result from replica 1 [my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k]: "my-hostname-basic-8d3abd4f-d924-4258-862f-3b990e84b119-8z52k", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 04:44:21.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9697" for this suite. 04/18/23 04:44:21.74
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:44:21.762
Apr 18 04:44:21.762: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename svcaccounts 04/18/23 04:44:21.763
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:21.808
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:21.81
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Apr 18 04:44:21.910: INFO: Waiting up to 5m0s for pod "pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65" in namespace "svcaccounts-9777" to be "running"
Apr 18 04:44:21.913: INFO: Pod "pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.312297ms
Apr 18 04:44:23.918: INFO: Pod "pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007297365s
Apr 18 04:44:25.916: INFO: Pod "pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65": Phase="Running", Reason="", readiness=true. Elapsed: 4.005523512s
Apr 18 04:44:25.916: INFO: Pod "pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65" satisfied condition "running"
STEP: reading a file in the container 04/18/23 04:44:25.916
Apr 18 04:44:25.916: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9777 pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 04/18/23 04:44:26.075
Apr 18 04:44:26.075: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9777 pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 04/18/23 04:44:26.214
Apr 18 04:44:26.214: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9777 pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Apr 18 04:44:26.368: INFO: Got root ca configmap in namespace "svcaccounts-9777"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 04:44:26.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9777" for this suite. 04/18/23 04:44:26.374
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":110,"skipped":1808,"failed":0}
------------------------------
â€¢ [4.632 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:44:21.762
    Apr 18 04:44:21.762: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 04:44:21.763
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:21.808
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:21.81
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Apr 18 04:44:21.910: INFO: Waiting up to 5m0s for pod "pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65" in namespace "svcaccounts-9777" to be "running"
    Apr 18 04:44:21.913: INFO: Pod "pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.312297ms
    Apr 18 04:44:23.918: INFO: Pod "pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007297365s
    Apr 18 04:44:25.916: INFO: Pod "pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65": Phase="Running", Reason="", readiness=true. Elapsed: 4.005523512s
    Apr 18 04:44:25.916: INFO: Pod "pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65" satisfied condition "running"
    STEP: reading a file in the container 04/18/23 04:44:25.916
    Apr 18 04:44:25.916: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9777 pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 04/18/23 04:44:26.075
    Apr 18 04:44:26.075: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9777 pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 04/18/23 04:44:26.214
    Apr 18 04:44:26.214: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9777 pod-service-account-b46fc65f-f452-4c1b-b854-cce6b3406f65 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Apr 18 04:44:26.368: INFO: Got root ca configmap in namespace "svcaccounts-9777"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 04:44:26.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9777" for this suite. 04/18/23 04:44:26.374
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:44:26.396
Apr 18 04:44:26.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename namespaces 04/18/23 04:44:26.397
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:26.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:26.493
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 04/18/23 04:44:26.501
STEP: patching the Namespace 04/18/23 04:44:26.543
STEP: get the Namespace and ensuring it has the label 04/18/23 04:44:26.569
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 18 04:44:26.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1183" for this suite. 04/18/23 04:44:26.575
STEP: Destroying namespace "nspatchtest-1ff1525d-606d-4ff4-b183-5765d856efc8-5437" for this suite. 04/18/23 04:44:27.015
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":111,"skipped":1840,"failed":0}
------------------------------
â€¢ [0.657 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:44:26.396
    Apr 18 04:44:26.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename namespaces 04/18/23 04:44:26.397
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:26.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:26.493
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 04/18/23 04:44:26.501
    STEP: patching the Namespace 04/18/23 04:44:26.543
    STEP: get the Namespace and ensuring it has the label 04/18/23 04:44:26.569
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 04:44:26.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-1183" for this suite. 04/18/23 04:44:26.575
    STEP: Destroying namespace "nspatchtest-1ff1525d-606d-4ff4-b183-5765d856efc8-5437" for this suite. 04/18/23 04:44:27.015
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:44:27.054
Apr 18 04:44:27.054: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename daemonsets 04/18/23 04:44:27.055
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:27.283
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:27.285
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 04/18/23 04:44:27.372
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 04:44:27.433
Apr 18 04:44:27.478: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 04:44:27.478: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:44:28.524: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 04:44:28.524: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:44:29.784: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 04:44:29.784: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:44:30.487: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 04:44:30.487: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:44:31.625: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 04:44:31.625: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 04:44:32.523: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 04:44:32.523: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 04/18/23 04:44:32.586
Apr 18 04:44:32.841: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 04:44:32.841: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:44:33.851: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 04:44:33.851: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:44:34.918: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 04:44:34.918: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:44:35.849: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 04:44:35.849: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:44:36.908: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 04:44:36.908: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:44:37.879: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 04:44:37.879: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 04:44:38.848: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 04:44:38.848: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 04:44:38.851
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5313, will wait for the garbage collector to delete the pods 04/18/23 04:44:38.851
Apr 18 04:44:38.931: INFO: Deleting DaemonSet.extensions daemon-set took: 26.320408ms
Apr 18 04:44:39.232: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.87875ms
Apr 18 04:44:42.436: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 04:44:42.436: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 04:44:42.438: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4093004"},"items":null}

Apr 18 04:44:42.441: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4093004"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 04:44:42.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5313" for this suite. 04/18/23 04:44:42.458
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":112,"skipped":1870,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.474 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:44:27.054
    Apr 18 04:44:27.054: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename daemonsets 04/18/23 04:44:27.055
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:27.283
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:27.285
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 04/18/23 04:44:27.372
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 04:44:27.433
    Apr 18 04:44:27.478: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 04:44:27.478: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:44:28.524: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 04:44:28.524: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:44:29.784: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 04:44:29.784: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:44:30.487: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 04:44:30.487: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:44:31.625: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 04:44:31.625: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 04:44:32.523: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 04:44:32.523: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 04/18/23 04:44:32.586
    Apr 18 04:44:32.841: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 04:44:32.841: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:44:33.851: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 04:44:33.851: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:44:34.918: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 04:44:34.918: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:44:35.849: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 04:44:35.849: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:44:36.908: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 04:44:36.908: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:44:37.879: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 04:44:37.879: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 04:44:38.848: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 04:44:38.848: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 04:44:38.851
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5313, will wait for the garbage collector to delete the pods 04/18/23 04:44:38.851
    Apr 18 04:44:38.931: INFO: Deleting DaemonSet.extensions daemon-set took: 26.320408ms
    Apr 18 04:44:39.232: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.87875ms
    Apr 18 04:44:42.436: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 04:44:42.436: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 04:44:42.438: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4093004"},"items":null}

    Apr 18 04:44:42.441: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4093004"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 04:44:42.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5313" for this suite. 04/18/23 04:44:42.458
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:44:42.529
Apr 18 04:44:42.529: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 04:44:42.53
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:42.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:42.675
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 04/18/23 04:44:42.677
Apr 18 04:44:42.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 18 04:44:42.813: INFO: stderr: ""
Apr 18 04:44:42.813: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 04/18/23 04:44:42.813
Apr 18 04:44:42.813: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 18 04:44:42.813: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-9299" to be "running and ready, or succeeded"
Apr 18 04:44:42.890: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 77.187378ms
Apr 18 04:44:42.890: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'apps-208' to be 'Running' but was 'Pending'
Apr 18 04:44:44.896: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082673923s
Apr 18 04:44:44.896: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'apps-208' to be 'Running' but was 'Pending'
Apr 18 04:44:46.894: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.080567226s
Apr 18 04:44:46.894: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 18 04:44:46.894: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 04/18/23 04:44:46.894
Apr 18 04:44:46.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator'
Apr 18 04:44:47.004: INFO: stderr: ""
Apr 18 04:44:47.004: INFO: stdout: "I0418 04:44:44.911540       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/vs7j 571\nI0418 04:44:45.111981       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/5js 585\nI0418 04:44:45.312282       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/2gkj 518\nI0418 04:44:45.512579       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/9nfn 400\nI0418 04:44:45.711964       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/jfv 522\nI0418 04:44:45.912285       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/t4z5 503\nI0418 04:44:46.112626       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/629z 564\nI0418 04:44:46.312002       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/78h 543\nI0418 04:44:46.512250       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/drlw 221\nI0418 04:44:46.712652       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/457b 498\nI0418 04:44:46.911919       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/fgg6 451\n"
STEP: limiting log lines 04/18/23 04:44:47.004
Apr 18 04:44:47.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator --tail=1'
Apr 18 04:44:47.091: INFO: stderr: ""
Apr 18 04:44:47.091: INFO: stdout: "I0418 04:44:46.911919       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/fgg6 451\n"
Apr 18 04:44:47.091: INFO: got output "I0418 04:44:46.911919       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/fgg6 451\n"
STEP: limiting log bytes 04/18/23 04:44:47.091
Apr 18 04:44:47.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator --limit-bytes=1'
Apr 18 04:44:47.175: INFO: stderr: ""
Apr 18 04:44:47.175: INFO: stdout: "I"
Apr 18 04:44:47.175: INFO: got output "I"
STEP: exposing timestamps 04/18/23 04:44:47.175
Apr 18 04:44:47.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator --tail=1 --timestamps'
Apr 18 04:44:47.255: INFO: stderr: ""
Apr 18 04:44:47.255: INFO: stdout: "2023-04-18T13:44:47.112370410+09:00 I0418 04:44:47.112272       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/bgc 266\n"
Apr 18 04:44:47.255: INFO: got output "2023-04-18T13:44:47.112370410+09:00 I0418 04:44:47.112272       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/bgc 266\n"
STEP: restricting to a time range 04/18/23 04:44:47.255
Apr 18 04:44:49.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator --since=1s'
Apr 18 04:44:49.834: INFO: stderr: ""
Apr 18 04:44:49.834: INFO: stdout: "I0418 04:44:48.912291       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/lq44 446\nI0418 04:44:49.112594       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/bz2 568\nI0418 04:44:49.311959       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/9bll 558\nI0418 04:44:49.512247       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/kube-system/pods/t4tm 422\nI0418 04:44:49.712580       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/w9p9 570\n"
Apr 18 04:44:49.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator --since=24h'
Apr 18 04:44:49.915: INFO: stderr: ""
Apr 18 04:44:49.915: INFO: stdout: "I0418 04:44:44.911540       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/vs7j 571\nI0418 04:44:45.111981       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/5js 585\nI0418 04:44:45.312282       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/2gkj 518\nI0418 04:44:45.512579       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/9nfn 400\nI0418 04:44:45.711964       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/jfv 522\nI0418 04:44:45.912285       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/t4z5 503\nI0418 04:44:46.112626       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/629z 564\nI0418 04:44:46.312002       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/78h 543\nI0418 04:44:46.512250       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/drlw 221\nI0418 04:44:46.712652       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/457b 498\nI0418 04:44:46.911919       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/fgg6 451\nI0418 04:44:47.112272       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/bgc 266\nI0418 04:44:47.312602       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/r4jc 541\nI0418 04:44:47.511910       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/wsm4 376\nI0418 04:44:47.712333       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/q78k 415\nI0418 04:44:47.911622       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/gfq9 402\nI0418 04:44:48.112002       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/7w5 579\nI0418 04:44:48.312291       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/bsnt 545\nI0418 04:44:48.512637       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/7h4v 257\nI0418 04:44:48.712052       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/zrd 396\nI0418 04:44:48.912291       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/lq44 446\nI0418 04:44:49.112594       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/bz2 568\nI0418 04:44:49.311959       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/9bll 558\nI0418 04:44:49.512247       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/kube-system/pods/t4tm 422\nI0418 04:44:49.712580       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/w9p9 570\nI0418 04:44:49.911947       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/kube-system/pods/2zw 409\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Apr 18 04:44:49.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 delete pod logs-generator'
Apr 18 04:44:51.299: INFO: stderr: ""
Apr 18 04:44:51.299: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 04:44:51.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9299" for this suite. 04/18/23 04:44:51.304
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":113,"skipped":1875,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.862 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:44:42.529
    Apr 18 04:44:42.529: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 04:44:42.53
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:42.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:42.675
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 04/18/23 04:44:42.677
    Apr 18 04:44:42.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Apr 18 04:44:42.813: INFO: stderr: ""
    Apr 18 04:44:42.813: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 04/18/23 04:44:42.813
    Apr 18 04:44:42.813: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Apr 18 04:44:42.813: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-9299" to be "running and ready, or succeeded"
    Apr 18 04:44:42.890: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 77.187378ms
    Apr 18 04:44:42.890: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'apps-208' to be 'Running' but was 'Pending'
    Apr 18 04:44:44.896: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082673923s
    Apr 18 04:44:44.896: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'apps-208' to be 'Running' but was 'Pending'
    Apr 18 04:44:46.894: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.080567226s
    Apr 18 04:44:46.894: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Apr 18 04:44:46.894: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 04/18/23 04:44:46.894
    Apr 18 04:44:46.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator'
    Apr 18 04:44:47.004: INFO: stderr: ""
    Apr 18 04:44:47.004: INFO: stdout: "I0418 04:44:44.911540       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/vs7j 571\nI0418 04:44:45.111981       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/5js 585\nI0418 04:44:45.312282       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/2gkj 518\nI0418 04:44:45.512579       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/9nfn 400\nI0418 04:44:45.711964       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/jfv 522\nI0418 04:44:45.912285       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/t4z5 503\nI0418 04:44:46.112626       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/629z 564\nI0418 04:44:46.312002       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/78h 543\nI0418 04:44:46.512250       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/drlw 221\nI0418 04:44:46.712652       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/457b 498\nI0418 04:44:46.911919       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/fgg6 451\n"
    STEP: limiting log lines 04/18/23 04:44:47.004
    Apr 18 04:44:47.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator --tail=1'
    Apr 18 04:44:47.091: INFO: stderr: ""
    Apr 18 04:44:47.091: INFO: stdout: "I0418 04:44:46.911919       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/fgg6 451\n"
    Apr 18 04:44:47.091: INFO: got output "I0418 04:44:46.911919       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/fgg6 451\n"
    STEP: limiting log bytes 04/18/23 04:44:47.091
    Apr 18 04:44:47.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator --limit-bytes=1'
    Apr 18 04:44:47.175: INFO: stderr: ""
    Apr 18 04:44:47.175: INFO: stdout: "I"
    Apr 18 04:44:47.175: INFO: got output "I"
    STEP: exposing timestamps 04/18/23 04:44:47.175
    Apr 18 04:44:47.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator --tail=1 --timestamps'
    Apr 18 04:44:47.255: INFO: stderr: ""
    Apr 18 04:44:47.255: INFO: stdout: "2023-04-18T13:44:47.112370410+09:00 I0418 04:44:47.112272       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/bgc 266\n"
    Apr 18 04:44:47.255: INFO: got output "2023-04-18T13:44:47.112370410+09:00 I0418 04:44:47.112272       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/bgc 266\n"
    STEP: restricting to a time range 04/18/23 04:44:47.255
    Apr 18 04:44:49.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator --since=1s'
    Apr 18 04:44:49.834: INFO: stderr: ""
    Apr 18 04:44:49.834: INFO: stdout: "I0418 04:44:48.912291       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/lq44 446\nI0418 04:44:49.112594       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/bz2 568\nI0418 04:44:49.311959       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/9bll 558\nI0418 04:44:49.512247       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/kube-system/pods/t4tm 422\nI0418 04:44:49.712580       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/w9p9 570\n"
    Apr 18 04:44:49.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 logs logs-generator logs-generator --since=24h'
    Apr 18 04:44:49.915: INFO: stderr: ""
    Apr 18 04:44:49.915: INFO: stdout: "I0418 04:44:44.911540       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/vs7j 571\nI0418 04:44:45.111981       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/5js 585\nI0418 04:44:45.312282       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/2gkj 518\nI0418 04:44:45.512579       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/9nfn 400\nI0418 04:44:45.711964       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/jfv 522\nI0418 04:44:45.912285       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/t4z5 503\nI0418 04:44:46.112626       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/629z 564\nI0418 04:44:46.312002       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/78h 543\nI0418 04:44:46.512250       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/drlw 221\nI0418 04:44:46.712652       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/457b 498\nI0418 04:44:46.911919       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/fgg6 451\nI0418 04:44:47.112272       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/bgc 266\nI0418 04:44:47.312602       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/r4jc 541\nI0418 04:44:47.511910       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/default/pods/wsm4 376\nI0418 04:44:47.712333       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/q78k 415\nI0418 04:44:47.911622       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/gfq9 402\nI0418 04:44:48.112002       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/7w5 579\nI0418 04:44:48.312291       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/bsnt 545\nI0418 04:44:48.512637       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/7h4v 257\nI0418 04:44:48.712052       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/zrd 396\nI0418 04:44:48.912291       1 logs_generator.go:76] 20 POST /api/v1/namespaces/default/pods/lq44 446\nI0418 04:44:49.112594       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/bz2 568\nI0418 04:44:49.311959       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/9bll 558\nI0418 04:44:49.512247       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/kube-system/pods/t4tm 422\nI0418 04:44:49.712580       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/w9p9 570\nI0418 04:44:49.911947       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/kube-system/pods/2zw 409\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Apr 18 04:44:49.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9299 delete pod logs-generator'
    Apr 18 04:44:51.299: INFO: stderr: ""
    Apr 18 04:44:51.299: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 04:44:51.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9299" for this suite. 04/18/23 04:44:51.304
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:44:51.391
Apr 18 04:44:51.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 04:44:51.392
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:51.487
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:51.49
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-5967 04/18/23 04:44:51.492
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5967 to expose endpoints map[] 04/18/23 04:44:51.554
Apr 18 04:44:51.613: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Apr 18 04:44:52.687: INFO: successfully validated that service multi-endpoint-test in namespace services-5967 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5967 04/18/23 04:44:52.687
Apr 18 04:44:52.780: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5967" to be "running and ready"
Apr 18 04:44:52.782: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.398387ms
Apr 18 04:44:52.782: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:44:54.786: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006420331s
Apr 18 04:44:54.786: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:44:56.786: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.006100028s
Apr 18 04:44:56.786: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 18 04:44:56.786: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5967 to expose endpoints map[pod1:[100]] 04/18/23 04:44:56.789
Apr 18 04:44:56.797: INFO: successfully validated that service multi-endpoint-test in namespace services-5967 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-5967 04/18/23 04:44:56.797
Apr 18 04:44:57.051: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5967" to be "running and ready"
Apr 18 04:44:57.458: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 406.60321ms
Apr 18 04:44:57.458: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:44:59.467: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.415779163s
Apr 18 04:44:59.467: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:45:01.463: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.411542604s
Apr 18 04:45:01.463: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 18 04:45:01.463: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5967 to expose endpoints map[pod1:[100] pod2:[101]] 04/18/23 04:45:01.466
Apr 18 04:45:01.478: INFO: successfully validated that service multi-endpoint-test in namespace services-5967 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 04/18/23 04:45:01.478
Apr 18 04:45:01.478: INFO: Creating new exec pod
Apr 18 04:45:01.501: INFO: Waiting up to 5m0s for pod "execpoddkr89" in namespace "services-5967" to be "running"
Apr 18 04:45:01.508: INFO: Pod "execpoddkr89": Phase="Pending", Reason="", readiness=false. Elapsed: 6.785132ms
Apr 18 04:45:03.532: INFO: Pod "execpoddkr89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031254848s
Apr 18 04:45:05.513: INFO: Pod "execpoddkr89": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011625273s
Apr 18 04:45:07.513: INFO: Pod "execpoddkr89": Phase="Running", Reason="", readiness=true. Elapsed: 6.012006803s
Apr 18 04:45:07.513: INFO: Pod "execpoddkr89" satisfied condition "running"
Apr 18 04:45:08.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5967 exec execpoddkr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Apr 18 04:45:08.672: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Apr 18 04:45:08.672: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:45:08.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5967 exec execpoddkr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.9.63 80'
Apr 18 04:45:08.834: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.9.63 80\nConnection to 10.96.9.63 80 port [tcp/http] succeeded!\n"
Apr 18 04:45:08.834: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:45:08.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5967 exec execpoddkr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Apr 18 04:45:09.056: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Apr 18 04:45:09.056: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:45:09.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5967 exec execpoddkr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.9.63 81'
Apr 18 04:45:09.312: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.9.63 81\nConnection to 10.96.9.63 81 port [tcp/*] succeeded!\n"
Apr 18 04:45:09.313: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5967 04/18/23 04:45:09.313
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5967 to expose endpoints map[pod2:[101]] 04/18/23 04:45:09.477
Apr 18 04:45:09.781: INFO: successfully validated that service multi-endpoint-test in namespace services-5967 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-5967 04/18/23 04:45:09.781
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5967 to expose endpoints map[] 04/18/23 04:45:09.927
Apr 18 04:45:10.279: INFO: successfully validated that service multi-endpoint-test in namespace services-5967 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 04:45:10.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5967" for this suite. 04/18/23 04:45:10.496
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":114,"skipped":1876,"failed":0}
------------------------------
â€¢ [SLOW TEST] [19.373 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:44:51.391
    Apr 18 04:44:51.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 04:44:51.392
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:44:51.487
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:44:51.49
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-5967 04/18/23 04:44:51.492
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5967 to expose endpoints map[] 04/18/23 04:44:51.554
    Apr 18 04:44:51.613: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
    Apr 18 04:44:52.687: INFO: successfully validated that service multi-endpoint-test in namespace services-5967 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-5967 04/18/23 04:44:52.687
    Apr 18 04:44:52.780: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5967" to be "running and ready"
    Apr 18 04:44:52.782: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.398387ms
    Apr 18 04:44:52.782: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:44:54.786: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006420331s
    Apr 18 04:44:54.786: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:44:56.786: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.006100028s
    Apr 18 04:44:56.786: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 18 04:44:56.786: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5967 to expose endpoints map[pod1:[100]] 04/18/23 04:44:56.789
    Apr 18 04:44:56.797: INFO: successfully validated that service multi-endpoint-test in namespace services-5967 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-5967 04/18/23 04:44:56.797
    Apr 18 04:44:57.051: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5967" to be "running and ready"
    Apr 18 04:44:57.458: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 406.60321ms
    Apr 18 04:44:57.458: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:44:59.467: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.415779163s
    Apr 18 04:44:59.467: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:45:01.463: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.411542604s
    Apr 18 04:45:01.463: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 18 04:45:01.463: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5967 to expose endpoints map[pod1:[100] pod2:[101]] 04/18/23 04:45:01.466
    Apr 18 04:45:01.478: INFO: successfully validated that service multi-endpoint-test in namespace services-5967 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 04/18/23 04:45:01.478
    Apr 18 04:45:01.478: INFO: Creating new exec pod
    Apr 18 04:45:01.501: INFO: Waiting up to 5m0s for pod "execpoddkr89" in namespace "services-5967" to be "running"
    Apr 18 04:45:01.508: INFO: Pod "execpoddkr89": Phase="Pending", Reason="", readiness=false. Elapsed: 6.785132ms
    Apr 18 04:45:03.532: INFO: Pod "execpoddkr89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031254848s
    Apr 18 04:45:05.513: INFO: Pod "execpoddkr89": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011625273s
    Apr 18 04:45:07.513: INFO: Pod "execpoddkr89": Phase="Running", Reason="", readiness=true. Elapsed: 6.012006803s
    Apr 18 04:45:07.513: INFO: Pod "execpoddkr89" satisfied condition "running"
    Apr 18 04:45:08.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5967 exec execpoddkr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Apr 18 04:45:08.672: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Apr 18 04:45:08.672: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:45:08.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5967 exec execpoddkr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.9.63 80'
    Apr 18 04:45:08.834: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.9.63 80\nConnection to 10.96.9.63 80 port [tcp/http] succeeded!\n"
    Apr 18 04:45:08.834: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:45:08.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5967 exec execpoddkr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Apr 18 04:45:09.056: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Apr 18 04:45:09.056: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:45:09.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5967 exec execpoddkr89 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.9.63 81'
    Apr 18 04:45:09.312: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.9.63 81\nConnection to 10.96.9.63 81 port [tcp/*] succeeded!\n"
    Apr 18 04:45:09.313: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-5967 04/18/23 04:45:09.313
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5967 to expose endpoints map[pod2:[101]] 04/18/23 04:45:09.477
    Apr 18 04:45:09.781: INFO: successfully validated that service multi-endpoint-test in namespace services-5967 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-5967 04/18/23 04:45:09.781
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5967 to expose endpoints map[] 04/18/23 04:45:09.927
    Apr 18 04:45:10.279: INFO: successfully validated that service multi-endpoint-test in namespace services-5967 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 04:45:10.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5967" for this suite. 04/18/23 04:45:10.496
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:45:10.765
Apr 18 04:45:10.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 04:45:10.766
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:10.879
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:10.881
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 04/18/23 04:45:10.934
Apr 18 04:45:10.982: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7" in namespace "downward-api-6939" to be "Succeeded or Failed"
Apr 18 04:45:10.984: INFO: Pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.688111ms
Apr 18 04:45:12.990: INFO: Pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007994648s
Apr 18 04:45:14.990: INFO: Pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008636451s
Apr 18 04:45:16.988: INFO: Pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00638145s
STEP: Saw pod success 04/18/23 04:45:16.988
Apr 18 04:45:16.988: INFO: Pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7" satisfied condition "Succeeded or Failed"
Apr 18 04:45:16.991: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7 container client-container: <nil>
STEP: delete the pod 04/18/23 04:45:17.092
Apr 18 04:45:17.185: INFO: Waiting for pod downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7 to disappear
Apr 18 04:45:17.364: INFO: Pod downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 04:45:17.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6939" for this suite. 04/18/23 04:45:17.369
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":115,"skipped":1882,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.631 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:45:10.765
    Apr 18 04:45:10.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 04:45:10.766
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:10.879
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:10.881
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 04/18/23 04:45:10.934
    Apr 18 04:45:10.982: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7" in namespace "downward-api-6939" to be "Succeeded or Failed"
    Apr 18 04:45:10.984: INFO: Pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.688111ms
    Apr 18 04:45:12.990: INFO: Pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007994648s
    Apr 18 04:45:14.990: INFO: Pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008636451s
    Apr 18 04:45:16.988: INFO: Pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00638145s
    STEP: Saw pod success 04/18/23 04:45:16.988
    Apr 18 04:45:16.988: INFO: Pod "downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7" satisfied condition "Succeeded or Failed"
    Apr 18 04:45:16.991: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7 container client-container: <nil>
    STEP: delete the pod 04/18/23 04:45:17.092
    Apr 18 04:45:17.185: INFO: Waiting for pod downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7 to disappear
    Apr 18 04:45:17.364: INFO: Pod downwardapi-volume-3693932b-936d-4866-8427-8046f569b3e7 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 04:45:17.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6939" for this suite. 04/18/23 04:45:17.369
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:45:17.398
Apr 18 04:45:17.398: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename containers 04/18/23 04:45:17.399
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:17.587
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:17.591
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 04/18/23 04:45:17.594
Apr 18 04:45:17.675: INFO: Waiting up to 5m0s for pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89" in namespace "containers-3949" to be "Succeeded or Failed"
Apr 18 04:45:17.763: INFO: Pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89": Phase="Pending", Reason="", readiness=false. Elapsed: 88.031308ms
Apr 18 04:45:19.767: INFO: Pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09218832s
Apr 18 04:45:21.767: INFO: Pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89": Phase="Pending", Reason="", readiness=false. Elapsed: 4.091801775s
Apr 18 04:45:23.837: INFO: Pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.161754484s
STEP: Saw pod success 04/18/23 04:45:23.837
Apr 18 04:45:23.837: INFO: Pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89" satisfied condition "Succeeded or Failed"
Apr 18 04:45:23.849: INFO: Trying to get logs from node apps-208 pod client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 04:45:23.855
Apr 18 04:45:23.933: INFO: Waiting for pod client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89 to disappear
Apr 18 04:45:23.937: INFO: Pod client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 18 04:45:23.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3949" for this suite. 04/18/23 04:45:23.941
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":116,"skipped":1920,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.613 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:45:17.398
    Apr 18 04:45:17.398: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename containers 04/18/23 04:45:17.399
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:17.587
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:17.591
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 04/18/23 04:45:17.594
    Apr 18 04:45:17.675: INFO: Waiting up to 5m0s for pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89" in namespace "containers-3949" to be "Succeeded or Failed"
    Apr 18 04:45:17.763: INFO: Pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89": Phase="Pending", Reason="", readiness=false. Elapsed: 88.031308ms
    Apr 18 04:45:19.767: INFO: Pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09218832s
    Apr 18 04:45:21.767: INFO: Pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89": Phase="Pending", Reason="", readiness=false. Elapsed: 4.091801775s
    Apr 18 04:45:23.837: INFO: Pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.161754484s
    STEP: Saw pod success 04/18/23 04:45:23.837
    Apr 18 04:45:23.837: INFO: Pod "client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89" satisfied condition "Succeeded or Failed"
    Apr 18 04:45:23.849: INFO: Trying to get logs from node apps-208 pod client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 04:45:23.855
    Apr 18 04:45:23.933: INFO: Waiting for pod client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89 to disappear
    Apr 18 04:45:23.937: INFO: Pod client-containers-c8f2a015-3adc-4af2-9975-590c4c5feb89 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 18 04:45:23.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-3949" for this suite. 04/18/23 04:45:23.941
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:45:24.011
Apr 18 04:45:24.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 04:45:24.012
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:24.099
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:24.102
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/18/23 04:45:24.104
Apr 18 04:45:24.178: INFO: Waiting up to 5m0s for pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7" in namespace "emptydir-6206" to be "Succeeded or Failed"
Apr 18 04:45:24.181: INFO: Pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.946388ms
Apr 18 04:45:26.199: INFO: Pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020594745s
Apr 18 04:45:28.185: INFO: Pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007062829s
Apr 18 04:45:30.232: INFO: Pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05376694s
STEP: Saw pod success 04/18/23 04:45:30.232
Apr 18 04:45:30.232: INFO: Pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7" satisfied condition "Succeeded or Failed"
Apr 18 04:45:30.253: INFO: Trying to get logs from node apps-208 pod pod-b483389e-94e2-43f0-925f-3742f1ed8db7 container test-container: <nil>
STEP: delete the pod 04/18/23 04:45:30.268
Apr 18 04:45:30.407: INFO: Waiting for pod pod-b483389e-94e2-43f0-925f-3742f1ed8db7 to disappear
Apr 18 04:45:30.410: INFO: Pod pod-b483389e-94e2-43f0-925f-3742f1ed8db7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 04:45:30.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6206" for this suite. 04/18/23 04:45:30.414
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":117,"skipped":1921,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.414 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:45:24.011
    Apr 18 04:45:24.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 04:45:24.012
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:24.099
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:24.102
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/18/23 04:45:24.104
    Apr 18 04:45:24.178: INFO: Waiting up to 5m0s for pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7" in namespace "emptydir-6206" to be "Succeeded or Failed"
    Apr 18 04:45:24.181: INFO: Pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.946388ms
    Apr 18 04:45:26.199: INFO: Pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020594745s
    Apr 18 04:45:28.185: INFO: Pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007062829s
    Apr 18 04:45:30.232: INFO: Pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05376694s
    STEP: Saw pod success 04/18/23 04:45:30.232
    Apr 18 04:45:30.232: INFO: Pod "pod-b483389e-94e2-43f0-925f-3742f1ed8db7" satisfied condition "Succeeded or Failed"
    Apr 18 04:45:30.253: INFO: Trying to get logs from node apps-208 pod pod-b483389e-94e2-43f0-925f-3742f1ed8db7 container test-container: <nil>
    STEP: delete the pod 04/18/23 04:45:30.268
    Apr 18 04:45:30.407: INFO: Waiting for pod pod-b483389e-94e2-43f0-925f-3742f1ed8db7 to disappear
    Apr 18 04:45:30.410: INFO: Pod pod-b483389e-94e2-43f0-925f-3742f1ed8db7 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 04:45:30.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6206" for this suite. 04/18/23 04:45:30.414
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:45:30.426
Apr 18 04:45:30.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename init-container 04/18/23 04:45:30.427
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:30.502
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:30.504
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 04/18/23 04:45:30.653
Apr 18 04:45:30.653: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 04:45:37.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5296" for this suite. 04/18/23 04:45:37.141
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":118,"skipped":1926,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.779 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:45:30.426
    Apr 18 04:45:30.426: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename init-container 04/18/23 04:45:30.427
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:30.502
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:30.504
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 04/18/23 04:45:30.653
    Apr 18 04:45:30.653: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 04:45:37.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-5296" for this suite. 04/18/23 04:45:37.141
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:45:37.206
Apr 18 04:45:37.206: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename namespaces 04/18/23 04:45:37.207
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:37.281
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:37.283
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 04/18/23 04:45:37.286
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:37.38
STEP: Creating a service in the namespace 04/18/23 04:45:37.382
STEP: Deleting the namespace 04/18/23 04:45:37.537
STEP: Waiting for the namespace to be removed. 04/18/23 04:45:37.603
STEP: Recreating the namespace 04/18/23 04:45:44.614
STEP: Verifying there is no service in the namespace 04/18/23 04:45:44.715
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 18 04:45:44.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3214" for this suite. 04/18/23 04:45:44.756
STEP: Destroying namespace "nsdeletetest-4667" for this suite. 04/18/23 04:45:44.795
Apr 18 04:45:44.889: INFO: Namespace nsdeletetest-4667 was already deleted
STEP: Destroying namespace "nsdeletetest-1413" for this suite. 04/18/23 04:45:44.889
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":119,"skipped":1937,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.733 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:45:37.206
    Apr 18 04:45:37.206: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename namespaces 04/18/23 04:45:37.207
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:37.281
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:37.283
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 04/18/23 04:45:37.286
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:37.38
    STEP: Creating a service in the namespace 04/18/23 04:45:37.382
    STEP: Deleting the namespace 04/18/23 04:45:37.537
    STEP: Waiting for the namespace to be removed. 04/18/23 04:45:37.603
    STEP: Recreating the namespace 04/18/23 04:45:44.614
    STEP: Verifying there is no service in the namespace 04/18/23 04:45:44.715
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 04:45:44.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-3214" for this suite. 04/18/23 04:45:44.756
    STEP: Destroying namespace "nsdeletetest-4667" for this suite. 04/18/23 04:45:44.795
    Apr 18 04:45:44.889: INFO: Namespace nsdeletetest-4667 was already deleted
    STEP: Destroying namespace "nsdeletetest-1413" for this suite. 04/18/23 04:45:44.889
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:45:44.939
Apr 18 04:45:44.939: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:45:44.94
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:44.964
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:44.966
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-143c1a66-dc48-4538-844e-28bb4d1b940a 04/18/23 04:45:45.065
STEP: Creating a pod to test consume secrets 04/18/23 04:45:45.112
Apr 18 04:45:45.131: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c" in namespace "projected-2546" to be "Succeeded or Failed"
Apr 18 04:45:45.134: INFO: Pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.79039ms
Apr 18 04:45:47.157: INFO: Pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025811264s
Apr 18 04:45:49.139: INFO: Pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008182333s
Apr 18 04:45:51.137: INFO: Pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006174877s
STEP: Saw pod success 04/18/23 04:45:51.137
Apr 18 04:45:51.137: INFO: Pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c" satisfied condition "Succeeded or Failed"
Apr 18 04:45:51.140: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c container projected-secret-volume-test: <nil>
STEP: delete the pod 04/18/23 04:45:51.145
Apr 18 04:45:51.207: INFO: Waiting for pod pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c to disappear
Apr 18 04:45:51.210: INFO: Pod pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 04:45:51.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2546" for this suite. 04/18/23 04:45:51.214
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":120,"skipped":1939,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.284 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:45:44.939
    Apr 18 04:45:44.939: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:45:44.94
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:44.964
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:44.966
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-143c1a66-dc48-4538-844e-28bb4d1b940a 04/18/23 04:45:45.065
    STEP: Creating a pod to test consume secrets 04/18/23 04:45:45.112
    Apr 18 04:45:45.131: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c" in namespace "projected-2546" to be "Succeeded or Failed"
    Apr 18 04:45:45.134: INFO: Pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.79039ms
    Apr 18 04:45:47.157: INFO: Pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025811264s
    Apr 18 04:45:49.139: INFO: Pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008182333s
    Apr 18 04:45:51.137: INFO: Pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.006174877s
    STEP: Saw pod success 04/18/23 04:45:51.137
    Apr 18 04:45:51.137: INFO: Pod "pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c" satisfied condition "Succeeded or Failed"
    Apr 18 04:45:51.140: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 04:45:51.145
    Apr 18 04:45:51.207: INFO: Waiting for pod pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c to disappear
    Apr 18 04:45:51.210: INFO: Pod pod-projected-secrets-70c75b9f-88d1-48b3-9bed-e536229b267c no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 04:45:51.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2546" for this suite. 04/18/23 04:45:51.214
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:45:51.225
Apr 18 04:45:51.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename endpointslicemirroring 04/18/23 04:45:51.226
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:51.365
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:51.367
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 04/18/23 04:45:51.44
Apr 18 04:45:51.511: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 04/18/23 04:45:53.516
Apr 18 04:45:53.548: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint 04/18/23 04:45:55.552
Apr 18 04:45:55.576: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Apr 18 04:45:57.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-6432" for this suite. 04/18/23 04:45:57.718
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":121,"skipped":1977,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.573 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:45:51.225
    Apr 18 04:45:51.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename endpointslicemirroring 04/18/23 04:45:51.226
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:51.365
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:51.367
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 04/18/23 04:45:51.44
    Apr 18 04:45:51.511: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 04/18/23 04:45:53.516
    Apr 18 04:45:53.548: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
    STEP: mirroring deletion of a custom Endpoint 04/18/23 04:45:55.552
    Apr 18 04:45:55.576: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Apr 18 04:45:57.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-6432" for this suite. 04/18/23 04:45:57.718
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:45:57.8
Apr 18 04:45:57.801: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 04:45:57.801
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:57.904
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:57.906
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 04/18/23 04:45:57.939
Apr 18 04:45:57.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: mark a version not serverd 04/18/23 04:46:21.493
STEP: check the unserved version gets removed 04/18/23 04:46:21.569
STEP: check the other version is not changed 04/18/23 04:46:30.129
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:46:45.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3420" for this suite. 04/18/23 04:46:45.414
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":122,"skipped":2018,"failed":0}
------------------------------
â€¢ [SLOW TEST] [47.634 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:45:57.8
    Apr 18 04:45:57.801: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 04:45:57.801
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:45:57.904
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:45:57.906
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 04/18/23 04:45:57.939
    Apr 18 04:45:57.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: mark a version not serverd 04/18/23 04:46:21.493
    STEP: check the unserved version gets removed 04/18/23 04:46:21.569
    STEP: check the other version is not changed 04/18/23 04:46:30.129
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:46:45.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3420" for this suite. 04/18/23 04:46:45.414
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:46:45.435
Apr 18 04:46:45.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 04:46:45.437
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:46:45.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:46:45.487
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 04/18/23 04:46:45.516
Apr 18 04:46:45.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9034 api-versions'
Apr 18 04:46:45.580: INFO: stderr: ""
Apr 18 04:46:45.580: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncore.strimzi.io/v1beta2\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nextensions.istio.io/v1alpha1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\ninstall.istio.io/v1alpha1\nkafka.strimzi.io/v1alpha1\nkafka.strimzi.io/v1beta1\nkafka.strimzi.io/v1beta2\nmetrics.k8s.io/v1beta1\nmonitoring.coreos.com/v1\nmonitoring.coreos.com/v1alpha1\nnetworking.istio.io/v1alpha3\nnetworking.istio.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsecurity.istio.io/v1\nsecurity.istio.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\ntelemetry.istio.io/v1alpha1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 04:46:45.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9034" for this suite. 04/18/23 04:46:45.584
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":123,"skipped":2022,"failed":0}
------------------------------
â€¢ [0.175 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:46:45.435
    Apr 18 04:46:45.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 04:46:45.437
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:46:45.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:46:45.487
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 04/18/23 04:46:45.516
    Apr 18 04:46:45.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9034 api-versions'
    Apr 18 04:46:45.580: INFO: stderr: ""
    Apr 18 04:46:45.580: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncore.strimzi.io/v1beta2\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nextensions.istio.io/v1alpha1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\ninstall.istio.io/v1alpha1\nkafka.strimzi.io/v1alpha1\nkafka.strimzi.io/v1beta1\nkafka.strimzi.io/v1beta2\nmetrics.k8s.io/v1beta1\nmonitoring.coreos.com/v1\nmonitoring.coreos.com/v1alpha1\nnetworking.istio.io/v1alpha3\nnetworking.istio.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsecurity.istio.io/v1\nsecurity.istio.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\ntelemetry.istio.io/v1alpha1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 04:46:45.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9034" for this suite. 04/18/23 04:46:45.584
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:46:45.612
Apr 18 04:46:45.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename podtemplate 04/18/23 04:46:45.613
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:46:45.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:46:45.689
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 04/18/23 04:46:45.723
STEP: Replace a pod template 04/18/23 04:46:45.746
Apr 18 04:46:45.760: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 18 04:46:45.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-7219" for this suite. 04/18/23 04:46:45.765
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":124,"skipped":2066,"failed":0}
------------------------------
â€¢ [0.164 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:46:45.612
    Apr 18 04:46:45.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename podtemplate 04/18/23 04:46:45.613
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:46:45.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:46:45.689
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 04/18/23 04:46:45.723
    STEP: Replace a pod template 04/18/23 04:46:45.746
    Apr 18 04:46:45.760: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 18 04:46:45.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-7219" for this suite. 04/18/23 04:46:45.765
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:46:45.777
Apr 18 04:46:45.777: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename init-container 04/18/23 04:46:45.778
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:46:45.931
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:46:45.934
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 04/18/23 04:46:45.936
Apr 18 04:46:45.936: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 04:46:51.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9076" for this suite. 04/18/23 04:46:51.327
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":125,"skipped":2070,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.662 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:46:45.777
    Apr 18 04:46:45.777: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename init-container 04/18/23 04:46:45.778
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:46:45.931
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:46:45.934
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 04/18/23 04:46:45.936
    Apr 18 04:46:45.936: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 04:46:51.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9076" for this suite. 04/18/23 04:46:51.327
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:46:51.44
Apr 18 04:46:51.440: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:46:51.441
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:46:51.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:46:51.472
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-78362482-c323-413d-8548-b1b908d28282 04/18/23 04:46:51.556
STEP: Creating the pod 04/18/23 04:46:51.607
Apr 18 04:46:51.626: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848" in namespace "projected-850" to be "running and ready"
Apr 18 04:46:51.629: INFO: Pod "pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848": Phase="Pending", Reason="", readiness=false. Elapsed: 2.744794ms
Apr 18 04:46:51.629: INFO: The phase of Pod pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:46:53.647: INFO: Pod "pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020757976s
Apr 18 04:46:53.647: INFO: The phase of Pod pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:46:55.633: INFO: Pod "pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848": Phase="Running", Reason="", readiness=true. Elapsed: 4.007335328s
Apr 18 04:46:55.634: INFO: The phase of Pod pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848 is Running (Ready = true)
Apr 18 04:46:55.634: INFO: Pod "pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-78362482-c323-413d-8548-b1b908d28282 04/18/23 04:46:55.649
STEP: waiting to observe update in volume 04/18/23 04:46:55.67
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 04:48:12.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-850" for this suite. 04/18/23 04:48:12.667
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":126,"skipped":2096,"failed":0}
------------------------------
â€¢ [SLOW TEST] [81.267 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:46:51.44
    Apr 18 04:46:51.440: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:46:51.441
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:46:51.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:46:51.472
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-78362482-c323-413d-8548-b1b908d28282 04/18/23 04:46:51.556
    STEP: Creating the pod 04/18/23 04:46:51.607
    Apr 18 04:46:51.626: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848" in namespace "projected-850" to be "running and ready"
    Apr 18 04:46:51.629: INFO: Pod "pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848": Phase="Pending", Reason="", readiness=false. Elapsed: 2.744794ms
    Apr 18 04:46:51.629: INFO: The phase of Pod pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:46:53.647: INFO: Pod "pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020757976s
    Apr 18 04:46:53.647: INFO: The phase of Pod pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:46:55.633: INFO: Pod "pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848": Phase="Running", Reason="", readiness=true. Elapsed: 4.007335328s
    Apr 18 04:46:55.634: INFO: The phase of Pod pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848 is Running (Ready = true)
    Apr 18 04:46:55.634: INFO: Pod "pod-projected-configmaps-d3b23c6b-75cc-4743-b1e7-75774bb28848" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-78362482-c323-413d-8548-b1b908d28282 04/18/23 04:46:55.649
    STEP: waiting to observe update in volume 04/18/23 04:46:55.67
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 04:48:12.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-850" for this suite. 04/18/23 04:48:12.667
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:48:12.708
Apr 18 04:48:12.708: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 04:48:12.709
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:48:12.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:48:12.735
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/18/23 04:48:12.796
Apr 18 04:48:12.797: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/18/23 04:48:48.278
Apr 18 04:48:48.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 04:49:02.246: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:49:40.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6512" for this suite. 04/18/23 04:49:40.496
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":127,"skipped":2106,"failed":0}
------------------------------
â€¢ [SLOW TEST] [87.808 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:48:12.708
    Apr 18 04:48:12.708: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 04:48:12.709
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:48:12.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:48:12.735
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/18/23 04:48:12.796
    Apr 18 04:48:12.797: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/18/23 04:48:48.278
    Apr 18 04:48:48.279: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 04:49:02.246: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:49:40.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6512" for this suite. 04/18/23 04:49:40.496
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:49:40.516
Apr 18 04:49:40.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 04:49:40.517
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:49:40.665
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:49:40.668
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 04/18/23 04:49:40.67
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 04:49:40.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6817" for this suite. 04/18/23 04:49:40.725
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":128,"skipped":2120,"failed":0}
------------------------------
â€¢ [0.224 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:49:40.516
    Apr 18 04:49:40.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 04:49:40.517
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:49:40.665
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:49:40.668
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 04/18/23 04:49:40.67
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 04:49:40.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6817" for this suite. 04/18/23 04:49:40.725
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:49:40.742
Apr 18 04:49:40.742: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename dns 04/18/23 04:49:40.743
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:49:40.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:49:40.901
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3324.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3324.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 04/18/23 04:49:40.903
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3324.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3324.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 04/18/23 04:49:40.903
STEP: creating a pod to probe /etc/hosts 04/18/23 04:49:40.904
STEP: submitting the pod to kubernetes 04/18/23 04:49:40.904
Apr 18 04:49:40.999: INFO: Waiting up to 15m0s for pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b" in namespace "dns-3324" to be "running"
Apr 18 04:49:41.057: INFO: Pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b": Phase="Pending", Reason="", readiness=false. Elapsed: 57.687614ms
Apr 18 04:49:43.110: INFO: Pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110808157s
Apr 18 04:49:45.062: INFO: Pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063065596s
Apr 18 04:49:47.092: INFO: Pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b": Phase="Running", Reason="", readiness=true. Elapsed: 6.092324254s
Apr 18 04:49:47.092: INFO: Pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b" satisfied condition "running"
STEP: retrieving the pod 04/18/23 04:49:47.092
STEP: looking for the results for each expected name from probers 04/18/23 04:49:47.095
Apr 18 04:49:47.108: INFO: DNS probes using dns-3324/dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b succeeded

STEP: deleting the pod 04/18/23 04:49:47.108
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 04:49:47.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3324" for this suite. 04/18/23 04:49:47.264
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":129,"skipped":2151,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.550 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:49:40.742
    Apr 18 04:49:40.742: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename dns 04/18/23 04:49:40.743
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:49:40.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:49:40.901
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3324.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3324.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     04/18/23 04:49:40.903
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3324.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3324.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     04/18/23 04:49:40.903
    STEP: creating a pod to probe /etc/hosts 04/18/23 04:49:40.904
    STEP: submitting the pod to kubernetes 04/18/23 04:49:40.904
    Apr 18 04:49:40.999: INFO: Waiting up to 15m0s for pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b" in namespace "dns-3324" to be "running"
    Apr 18 04:49:41.057: INFO: Pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b": Phase="Pending", Reason="", readiness=false. Elapsed: 57.687614ms
    Apr 18 04:49:43.110: INFO: Pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110808157s
    Apr 18 04:49:45.062: INFO: Pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063065596s
    Apr 18 04:49:47.092: INFO: Pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b": Phase="Running", Reason="", readiness=true. Elapsed: 6.092324254s
    Apr 18 04:49:47.092: INFO: Pod "dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 04:49:47.092
    STEP: looking for the results for each expected name from probers 04/18/23 04:49:47.095
    Apr 18 04:49:47.108: INFO: DNS probes using dns-3324/dns-test-10810b60-2382-4ccb-acd3-eb6a68aa913b succeeded

    STEP: deleting the pod 04/18/23 04:49:47.108
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 04:49:47.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3324" for this suite. 04/18/23 04:49:47.264
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:49:47.293
Apr 18 04:49:47.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename deployment 04/18/23 04:49:47.294
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:49:47.341
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:49:47.344
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Apr 18 04:49:47.346: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 18 04:49:47.427: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 18 04:49:52.431: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 04:49:52.431
Apr 18 04:49:52.432: INFO: Creating deployment "test-rolling-update-deployment"
Apr 18 04:49:52.451: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 18 04:49:52.463: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 18 04:49:54.533: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 18 04:49:54.536: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 04:49:56.555: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 49, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 04:49:58.593: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 04:49:58.631: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-8716  bf1c68eb-dac6-434c-9c81-813c89b5cdd5 4094610 1 2023-04-18 04:49:52 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-18 04:49:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:49:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b79228 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 04:49:52 +0000 UTC,LastTransitionTime:2023-04-18 04:49:52 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-04-18 04:49:56 +0000 UTC,LastTransitionTime:2023-04-18 04:49:52 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 18 04:49:58.644: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-8716  aa3b5733-48a8-4e46-9da2-e5e756dbfd0b 4094598 1 2023-04-18 04:49:52 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment bf1c68eb-dac6-434c-9c81-813c89b5cdd5 0xc006f6c1f7 0xc006f6c1f8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 04:49:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bf1c68eb-dac6-434c-9c81-813c89b5cdd5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:49:55 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006f6c438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 18 04:49:58.644: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 18 04:49:58.644: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-8716  464333ad-0c0e-4345-8224-c3677fcaadac 4094609 2 2023-04-18 04:49:47 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment bf1c68eb-dac6-434c-9c81-813c89b5cdd5 0xc003b79c47 0xc003b79c48}] [] [{e2e.test Update apps/v1 2023-04-18 04:49:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:49:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bf1c68eb-dac6-434c-9c81-813c89b5cdd5\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:49:56 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003b79ff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 04:49:58.647: INFO: Pod "test-rolling-update-deployment-78f575d8ff-9xd9g" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-9xd9g test-rolling-update-deployment-78f575d8ff- deployment-8716  28987f83-d880-4570-9f23-8329e8a92bf3 4094597 0 2023-04-18 04:49:52 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:52c1411688584f834e6536439783d718285ca97921f3dc111ac6cb247272a893 cni.projectcalico.org/podIP:172.16.125.58/32 cni.projectcalico.org/podIPs:172.16.125.58/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff aa3b5733-48a8-4e46-9da2-e5e756dbfd0b 0xc005e62217 0xc005e62218}] [] [{kube-controller-manager Update v1 2023-04-18 04:49:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa3b5733-48a8-4e46-9da2-e5e756dbfd0b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 04:49:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 04:49:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.58\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6jddl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6jddl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:49:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:49:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:49:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:49:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.58,StartTime:2023-04-18 04:49:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 04:49:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://fa0e130bb48cadd1262e0eb6b3403cd7600d96f582abbd06cb3e8940d35cc0b4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.58,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 04:49:58.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8716" for this suite. 04/18/23 04:49:58.651
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":130,"skipped":2174,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.367 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:49:47.293
    Apr 18 04:49:47.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename deployment 04/18/23 04:49:47.294
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:49:47.341
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:49:47.344
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Apr 18 04:49:47.346: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Apr 18 04:49:47.427: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 18 04:49:52.431: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 04:49:52.431
    Apr 18 04:49:52.432: INFO: Creating deployment "test-rolling-update-deployment"
    Apr 18 04:49:52.451: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Apr 18 04:49:52.463: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Apr 18 04:49:54.533: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Apr 18 04:49:54.536: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 04:49:56.555: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 49, 56, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 49, 52, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-78f575d8ff\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 04:49:58.593: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 04:49:58.631: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-8716  bf1c68eb-dac6-434c-9c81-813c89b5cdd5 4094610 1 2023-04-18 04:49:52 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2023-04-18 04:49:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:49:56 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b79228 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 04:49:52 +0000 UTC,LastTransitionTime:2023-04-18 04:49:52 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2023-04-18 04:49:56 +0000 UTC,LastTransitionTime:2023-04-18 04:49:52 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 18 04:49:58.644: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-8716  aa3b5733-48a8-4e46-9da2-e5e756dbfd0b 4094598 1 2023-04-18 04:49:52 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment bf1c68eb-dac6-434c-9c81-813c89b5cdd5 0xc006f6c1f7 0xc006f6c1f8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 04:49:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bf1c68eb-dac6-434c-9c81-813c89b5cdd5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:49:55 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006f6c438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 04:49:58.644: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Apr 18 04:49:58.644: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-8716  464333ad-0c0e-4345-8224-c3677fcaadac 4094609 2 2023-04-18 04:49:47 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment bf1c68eb-dac6-434c-9c81-813c89b5cdd5 0xc003b79c47 0xc003b79c48}] [] [{e2e.test Update apps/v1 2023-04-18 04:49:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:49:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bf1c68eb-dac6-434c-9c81-813c89b5cdd5\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2023-04-18 04:49:56 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003b79ff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 04:49:58.647: INFO: Pod "test-rolling-update-deployment-78f575d8ff-9xd9g" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-9xd9g test-rolling-update-deployment-78f575d8ff- deployment-8716  28987f83-d880-4570-9f23-8329e8a92bf3 4094597 0 2023-04-18 04:49:52 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:52c1411688584f834e6536439783d718285ca97921f3dc111ac6cb247272a893 cni.projectcalico.org/podIP:172.16.125.58/32 cni.projectcalico.org/podIPs:172.16.125.58/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff aa3b5733-48a8-4e46-9da2-e5e756dbfd0b 0xc005e62217 0xc005e62218}] [] [{kube-controller-manager Update v1 2023-04-18 04:49:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"aa3b5733-48a8-4e46-9da2-e5e756dbfd0b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 04:49:54 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 04:49:55 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.58\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6jddl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6jddl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:49:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:49:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:49:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 04:49:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.58,StartTime:2023-04-18 04:49:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 04:49:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://fa0e130bb48cadd1262e0eb6b3403cd7600d96f582abbd06cb3e8940d35cc0b4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.58,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 04:49:58.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8716" for this suite. 04/18/23 04:49:58.651
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:49:58.662
Apr 18 04:49:58.662: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename cronjob 04/18/23 04:49:58.663
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:49:58.801
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:49:58.803
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 04/18/23 04:49:58.805
STEP: Ensuring a job is scheduled 04/18/23 04:49:58.83
STEP: Ensuring exactly one is scheduled 04/18/23 04:50:00.834
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/18/23 04:50:00.837
STEP: Ensuring the job is replaced with a new one 04/18/23 04:50:00.84
STEP: Removing cronjob 04/18/23 04:51:00.844
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 18 04:51:00.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2126" for this suite. 04/18/23 04:51:00.878
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":131,"skipped":2197,"failed":0}
------------------------------
â€¢ [SLOW TEST] [62.263 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:49:58.662
    Apr 18 04:49:58.662: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename cronjob 04/18/23 04:49:58.663
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:49:58.801
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:49:58.803
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 04/18/23 04:49:58.805
    STEP: Ensuring a job is scheduled 04/18/23 04:49:58.83
    STEP: Ensuring exactly one is scheduled 04/18/23 04:50:00.834
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/18/23 04:50:00.837
    STEP: Ensuring the job is replaced with a new one 04/18/23 04:50:00.84
    STEP: Removing cronjob 04/18/23 04:51:00.844
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 18 04:51:00.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2126" for this suite. 04/18/23 04:51:00.878
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:51:00.926
Apr 18 04:51:00.926: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 04:51:00.927
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:51:01.226
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:51:01.23
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9141 04/18/23 04:51:01.232
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/18/23 04:51:01.59
STEP: creating service externalsvc in namespace services-9141 04/18/23 04:51:01.59
STEP: creating replication controller externalsvc in namespace services-9141 04/18/23 04:51:01.749
I0418 04:51:01.874998      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-9141, replica count: 2
I0418 04:51:04.926326      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 04:51:07.927766      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 04/18/23 04:51:07.934
Apr 18 04:51:08.059: INFO: Creating new exec pod
Apr 18 04:51:08.192: INFO: Waiting up to 5m0s for pod "execpod9kgj8" in namespace "services-9141" to be "running"
Apr 18 04:51:08.195: INFO: Pod "execpod9kgj8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.213862ms
Apr 18 04:51:10.255: INFO: Pod "execpod9kgj8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062576221s
Apr 18 04:51:12.199: INFO: Pod "execpod9kgj8": Phase="Running", Reason="", readiness=true. Elapsed: 4.00747871s
Apr 18 04:51:12.199: INFO: Pod "execpod9kgj8" satisfied condition "running"
Apr 18 04:51:12.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-9141 exec execpod9kgj8 -- /bin/sh -x -c nslookup nodeport-service.services-9141.svc.cluster.local'
Apr 18 04:51:12.392: INFO: stderr: "+ nslookup nodeport-service.services-9141.svc.cluster.local\n"
Apr 18 04:51:12.392: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-9141.svc.cluster.local\tcanonical name = externalsvc.services-9141.svc.cluster.local.\nName:\texternalsvc.services-9141.svc.cluster.local\nAddress: 10.96.13.100\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9141, will wait for the garbage collector to delete the pods 04/18/23 04:51:12.392
Apr 18 04:51:12.491: INFO: Deleting ReplicationController externalsvc took: 23.279067ms
Apr 18 04:51:12.592: INFO: Terminating ReplicationController externalsvc pods took: 100.275024ms
Apr 18 04:51:15.958: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 04:51:16.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9141" for this suite. 04/18/23 04:51:16.086
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":132,"skipped":2216,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.391 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:51:00.926
    Apr 18 04:51:00.926: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 04:51:00.927
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:51:01.226
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:51:01.23
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-9141 04/18/23 04:51:01.232
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/18/23 04:51:01.59
    STEP: creating service externalsvc in namespace services-9141 04/18/23 04:51:01.59
    STEP: creating replication controller externalsvc in namespace services-9141 04/18/23 04:51:01.749
    I0418 04:51:01.874998      22 runners.go:193] Created replication controller with name: externalsvc, namespace: services-9141, replica count: 2
    I0418 04:51:04.926326      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 04:51:07.927766      22 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 04/18/23 04:51:07.934
    Apr 18 04:51:08.059: INFO: Creating new exec pod
    Apr 18 04:51:08.192: INFO: Waiting up to 5m0s for pod "execpod9kgj8" in namespace "services-9141" to be "running"
    Apr 18 04:51:08.195: INFO: Pod "execpod9kgj8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.213862ms
    Apr 18 04:51:10.255: INFO: Pod "execpod9kgj8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062576221s
    Apr 18 04:51:12.199: INFO: Pod "execpod9kgj8": Phase="Running", Reason="", readiness=true. Elapsed: 4.00747871s
    Apr 18 04:51:12.199: INFO: Pod "execpod9kgj8" satisfied condition "running"
    Apr 18 04:51:12.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-9141 exec execpod9kgj8 -- /bin/sh -x -c nslookup nodeport-service.services-9141.svc.cluster.local'
    Apr 18 04:51:12.392: INFO: stderr: "+ nslookup nodeport-service.services-9141.svc.cluster.local\n"
    Apr 18 04:51:12.392: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-9141.svc.cluster.local\tcanonical name = externalsvc.services-9141.svc.cluster.local.\nName:\texternalsvc.services-9141.svc.cluster.local\nAddress: 10.96.13.100\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-9141, will wait for the garbage collector to delete the pods 04/18/23 04:51:12.392
    Apr 18 04:51:12.491: INFO: Deleting ReplicationController externalsvc took: 23.279067ms
    Apr 18 04:51:12.592: INFO: Terminating ReplicationController externalsvc pods took: 100.275024ms
    Apr 18 04:51:15.958: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 04:51:16.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9141" for this suite. 04/18/23 04:51:16.086
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:51:16.318
Apr 18 04:51:16.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 04:51:16.32
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:51:16.376
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:51:16.379
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-6669 04/18/23 04:51:16.381
Apr 18 04:51:16.409: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-6669" to be "running and ready"
Apr 18 04:51:16.515: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 105.578394ms
Apr 18 04:51:16.515: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:51:18.520: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.110665875s
Apr 18 04:51:18.520: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Apr 18 04:51:18.520: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Apr 18 04:51:18.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Apr 18 04:51:18.881: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Apr 18 04:51:18.881: INFO: stdout: "ipvs"
Apr 18 04:51:18.881: INFO: proxyMode: ipvs
Apr 18 04:51:19.091: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Apr 18 04:51:19.106: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-6669 04/18/23 04:51:19.106
STEP: creating replication controller affinity-clusterip-timeout in namespace services-6669 04/18/23 04:51:19.192
I0418 04:51:19.318174      22 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-6669, replica count: 3
I0418 04:51:22.369102      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 04:51:25.371373      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 04:51:25.377: INFO: Creating new exec pod
Apr 18 04:51:25.403: INFO: Waiting up to 5m0s for pod "execpod-affinityzn4p6" in namespace "services-6669" to be "running"
Apr 18 04:51:25.406: INFO: Pod "execpod-affinityzn4p6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.872078ms
Apr 18 04:51:27.411: INFO: Pod "execpod-affinityzn4p6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007919193s
Apr 18 04:51:29.411: INFO: Pod "execpod-affinityzn4p6": Phase="Running", Reason="", readiness=true. Elapsed: 4.007528326s
Apr 18 04:51:29.411: INFO: Pod "execpod-affinityzn4p6" satisfied condition "running"
Apr 18 04:51:30.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec execpod-affinityzn4p6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Apr 18 04:51:30.605: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Apr 18 04:51:30.605: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:51:30.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec execpod-affinityzn4p6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.12.16 80'
Apr 18 04:51:30.841: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.12.16 80\nConnection to 10.96.12.16 80 port [tcp/http] succeeded!\n"
Apr 18 04:51:30.841: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 04:51:30.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec execpod-affinityzn4p6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.12.16:80/ ; done'
Apr 18 04:51:31.134: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n"
Apr 18 04:51:31.134: INFO: stdout: "\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k"
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
Apr 18 04:51:31.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec execpod-affinityzn4p6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.96.12.16:80/'
Apr 18 04:51:31.312: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n"
Apr 18 04:51:31.312: INFO: stdout: "affinity-clusterip-timeout-ckd2k"
Apr 18 04:53:41.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec execpod-affinityzn4p6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.96.12.16:80/'
Apr 18 04:53:41.474: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n"
Apr 18 04:53:41.474: INFO: stdout: "affinity-clusterip-timeout-mskwg"
Apr 18 04:53:41.474: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-6669, will wait for the garbage collector to delete the pods 04/18/23 04:53:41.646
Apr 18 04:53:41.810: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 110.283435ms
Apr 18 04:53:42.110: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 300.693825ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 04:53:45.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6669" for this suite. 04/18/23 04:53:45.607
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":133,"skipped":2221,"failed":0}
------------------------------
â€¢ [SLOW TEST] [149.348 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:51:16.318
    Apr 18 04:51:16.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 04:51:16.32
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:51:16.376
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:51:16.379
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-6669 04/18/23 04:51:16.381
    Apr 18 04:51:16.409: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-6669" to be "running and ready"
    Apr 18 04:51:16.515: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 105.578394ms
    Apr 18 04:51:16.515: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:51:18.520: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.110665875s
    Apr 18 04:51:18.520: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Apr 18 04:51:18.520: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Apr 18 04:51:18.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Apr 18 04:51:18.881: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Apr 18 04:51:18.881: INFO: stdout: "ipvs"
    Apr 18 04:51:18.881: INFO: proxyMode: ipvs
    Apr 18 04:51:19.091: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Apr 18 04:51:19.106: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-6669 04/18/23 04:51:19.106
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-6669 04/18/23 04:51:19.192
    I0418 04:51:19.318174      22 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-6669, replica count: 3
    I0418 04:51:22.369102      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 04:51:25.371373      22 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 04:51:25.377: INFO: Creating new exec pod
    Apr 18 04:51:25.403: INFO: Waiting up to 5m0s for pod "execpod-affinityzn4p6" in namespace "services-6669" to be "running"
    Apr 18 04:51:25.406: INFO: Pod "execpod-affinityzn4p6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.872078ms
    Apr 18 04:51:27.411: INFO: Pod "execpod-affinityzn4p6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007919193s
    Apr 18 04:51:29.411: INFO: Pod "execpod-affinityzn4p6": Phase="Running", Reason="", readiness=true. Elapsed: 4.007528326s
    Apr 18 04:51:29.411: INFO: Pod "execpod-affinityzn4p6" satisfied condition "running"
    Apr 18 04:51:30.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec execpod-affinityzn4p6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Apr 18 04:51:30.605: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Apr 18 04:51:30.605: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:51:30.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec execpod-affinityzn4p6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.12.16 80'
    Apr 18 04:51:30.841: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.12.16 80\nConnection to 10.96.12.16 80 port [tcp/http] succeeded!\n"
    Apr 18 04:51:30.841: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 04:51:30.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec execpod-affinityzn4p6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.12.16:80/ ; done'
    Apr 18 04:51:31.134: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n"
    Apr 18 04:51:31.134: INFO: stdout: "\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k\naffinity-clusterip-timeout-ckd2k"
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Received response from host: affinity-clusterip-timeout-ckd2k
    Apr 18 04:51:31.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec execpod-affinityzn4p6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.96.12.16:80/'
    Apr 18 04:51:31.312: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n"
    Apr 18 04:51:31.312: INFO: stdout: "affinity-clusterip-timeout-ckd2k"
    Apr 18 04:53:41.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-6669 exec execpod-affinityzn4p6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.96.12.16:80/'
    Apr 18 04:53:41.474: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.96.12.16:80/\n"
    Apr 18 04:53:41.474: INFO: stdout: "affinity-clusterip-timeout-mskwg"
    Apr 18 04:53:41.474: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-6669, will wait for the garbage collector to delete the pods 04/18/23 04:53:41.646
    Apr 18 04:53:41.810: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 110.283435ms
    Apr 18 04:53:42.110: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 300.693825ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 04:53:45.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6669" for this suite. 04/18/23 04:53:45.607
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:53:45.668
Apr 18 04:53:45.668: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 04:53:45.669
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:53:45.755
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:53:45.758
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 04/18/23 04:53:45.76
Apr 18 04:53:45.874: INFO: Waiting up to 5m0s for pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9" in namespace "downward-api-2782" to be "Succeeded or Failed"
Apr 18 04:53:45.877: INFO: Pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.151256ms
Apr 18 04:53:47.975: INFO: Pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101872503s
Apr 18 04:53:49.882: INFO: Pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008119721s
Apr 18 04:53:51.881: INFO: Pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007718082s
STEP: Saw pod success 04/18/23 04:53:51.881
Apr 18 04:53:51.881: INFO: Pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9" satisfied condition "Succeeded or Failed"
Apr 18 04:53:51.899: INFO: Trying to get logs from node apps-208 pod downward-api-649dc932-4f07-437e-a495-22997e81e8e9 container dapi-container: <nil>
STEP: delete the pod 04/18/23 04:53:51.971
Apr 18 04:53:52.175: INFO: Waiting for pod downward-api-649dc932-4f07-437e-a495-22997e81e8e9 to disappear
Apr 18 04:53:52.241: INFO: Pod downward-api-649dc932-4f07-437e-a495-22997e81e8e9 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 18 04:53:52.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2782" for this suite. 04/18/23 04:53:52.315
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":134,"skipped":2245,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.757 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:53:45.668
    Apr 18 04:53:45.668: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 04:53:45.669
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:53:45.755
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:53:45.758
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 04/18/23 04:53:45.76
    Apr 18 04:53:45.874: INFO: Waiting up to 5m0s for pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9" in namespace "downward-api-2782" to be "Succeeded or Failed"
    Apr 18 04:53:45.877: INFO: Pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.151256ms
    Apr 18 04:53:47.975: INFO: Pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101872503s
    Apr 18 04:53:49.882: INFO: Pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008119721s
    Apr 18 04:53:51.881: INFO: Pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007718082s
    STEP: Saw pod success 04/18/23 04:53:51.881
    Apr 18 04:53:51.881: INFO: Pod "downward-api-649dc932-4f07-437e-a495-22997e81e8e9" satisfied condition "Succeeded or Failed"
    Apr 18 04:53:51.899: INFO: Trying to get logs from node apps-208 pod downward-api-649dc932-4f07-437e-a495-22997e81e8e9 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 04:53:51.971
    Apr 18 04:53:52.175: INFO: Waiting for pod downward-api-649dc932-4f07-437e-a495-22997e81e8e9 to disappear
    Apr 18 04:53:52.241: INFO: Pod downward-api-649dc932-4f07-437e-a495-22997e81e8e9 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 18 04:53:52.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2782" for this suite. 04/18/23 04:53:52.315
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:53:52.427
Apr 18 04:53:52.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 04:53:52.428
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:53:52.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:53:52.597
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Apr 18 04:53:52.599: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:53:58.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5168" for this suite. 04/18/23 04:53:58.266
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":135,"skipped":2275,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.971 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:53:52.427
    Apr 18 04:53:52.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 04:53:52.428
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:53:52.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:53:52.597
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Apr 18 04:53:52.599: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:53:58.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-5168" for this suite. 04/18/23 04:53:58.266
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:53:58.403
Apr 18 04:53:58.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:53:58.405
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:53:58.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:53:58.512
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 04/18/23 04:53:58.514
Apr 18 04:53:58.559: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272" in namespace "projected-5964" to be "Succeeded or Failed"
Apr 18 04:53:58.611: INFO: Pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272": Phase="Pending", Reason="", readiness=false. Elapsed: 51.878242ms
Apr 18 04:54:00.623: INFO: Pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063570933s
Apr 18 04:54:02.616: INFO: Pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056520486s
Apr 18 04:54:04.911: INFO: Pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.351462389s
STEP: Saw pod success 04/18/23 04:54:04.911
Apr 18 04:54:04.911: INFO: Pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272" satisfied condition "Succeeded or Failed"
Apr 18 04:54:04.961: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272 container client-container: <nil>
STEP: delete the pod 04/18/23 04:54:04.967
Apr 18 04:54:05.124: INFO: Waiting for pod downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272 to disappear
Apr 18 04:54:05.127: INFO: Pod downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 04:54:05.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5964" for this suite. 04/18/23 04:54:05.131
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":136,"skipped":2347,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.878 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:53:58.403
    Apr 18 04:53:58.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:53:58.405
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:53:58.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:53:58.512
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 04/18/23 04:53:58.514
    Apr 18 04:53:58.559: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272" in namespace "projected-5964" to be "Succeeded or Failed"
    Apr 18 04:53:58.611: INFO: Pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272": Phase="Pending", Reason="", readiness=false. Elapsed: 51.878242ms
    Apr 18 04:54:00.623: INFO: Pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063570933s
    Apr 18 04:54:02.616: INFO: Pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056520486s
    Apr 18 04:54:04.911: INFO: Pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.351462389s
    STEP: Saw pod success 04/18/23 04:54:04.911
    Apr 18 04:54:04.911: INFO: Pod "downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272" satisfied condition "Succeeded or Failed"
    Apr 18 04:54:04.961: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272 container client-container: <nil>
    STEP: delete the pod 04/18/23 04:54:04.967
    Apr 18 04:54:05.124: INFO: Waiting for pod downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272 to disappear
    Apr 18 04:54:05.127: INFO: Pod downwardapi-volume-a27fe444-b69e-4ea7-99f6-a6e0a7d22272 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 04:54:05.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5964" for this suite. 04/18/23 04:54:05.131
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:54:05.282
Apr 18 04:54:05.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 04:54:05.283
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:54:05.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:54:05.339
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-9d5b8d30-5e49-4030-b289-e1dc4b0fd348 04/18/23 04:54:05.341
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 18 04:54:05.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4194" for this suite. 04/18/23 04:54:05.347
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":137,"skipped":2363,"failed":0}
------------------------------
â€¢ [0.083 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:54:05.282
    Apr 18 04:54:05.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 04:54:05.283
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:54:05.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:54:05.339
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-9d5b8d30-5e49-4030-b289-e1dc4b0fd348 04/18/23 04:54:05.341
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 04:54:05.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4194" for this suite. 04/18/23 04:54:05.347
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:54:05.367
Apr 18 04:54:05.367: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 04:54:05.368
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:54:05.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:54:05.453
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 04:54:05.512
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 04:54:06.053
STEP: Deploying the webhook pod 04/18/23 04:54:06.095
STEP: Wait for the deployment to be ready 04/18/23 04:54:06.224
Apr 18 04:54:06.328: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 18 04:54:08.340: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 54, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 54, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 54, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 54, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 04:54:10.345
STEP: Verifying the service has paired with the endpoint 04/18/23 04:54:10.433
Apr 18 04:54:11.433: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 04/18/23 04:54:11.437
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/18/23 04:54:11.438
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/18/23 04:54:11.438
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/18/23 04:54:11.438
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/18/23 04:54:11.439
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/18/23 04:54:11.439
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/18/23 04:54:11.44
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 04:54:11.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7402" for this suite. 04/18/23 04:54:11.445
STEP: Destroying namespace "webhook-7402-markers" for this suite. 04/18/23 04:54:11.479
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":138,"skipped":2404,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.416 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:54:05.367
    Apr 18 04:54:05.367: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 04:54:05.368
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:54:05.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:54:05.453
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 04:54:05.512
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 04:54:06.053
    STEP: Deploying the webhook pod 04/18/23 04:54:06.095
    STEP: Wait for the deployment to be ready 04/18/23 04:54:06.224
    Apr 18 04:54:06.328: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 18 04:54:08.340: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 4, 54, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 54, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 4, 54, 7, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 4, 54, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 04:54:10.345
    STEP: Verifying the service has paired with the endpoint 04/18/23 04:54:10.433
    Apr 18 04:54:11.433: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 04/18/23 04:54:11.437
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/18/23 04:54:11.438
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/18/23 04:54:11.438
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/18/23 04:54:11.438
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/18/23 04:54:11.439
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/18/23 04:54:11.439
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/18/23 04:54:11.44
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 04:54:11.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7402" for this suite. 04/18/23 04:54:11.445
    STEP: Destroying namespace "webhook-7402-markers" for this suite. 04/18/23 04:54:11.479
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:54:11.783
Apr 18 04:54:11.783: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 04:54:11.784
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:54:11.91
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:54:11.913
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-96a4fef2-019f-4129-a04c-ecff3ee4d7f3 04/18/23 04:54:11.928
STEP: Creating a pod to test consume configMaps 04/18/23 04:54:11.949
Apr 18 04:54:12.041: INFO: Waiting up to 5m0s for pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189" in namespace "configmap-5178" to be "Succeeded or Failed"
Apr 18 04:54:12.044: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189": Phase="Pending", Reason="", readiness=false. Elapsed: 2.927002ms
Apr 18 04:54:14.049: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007105974s
Apr 18 04:54:16.049: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189": Phase="Running", Reason="", readiness=true. Elapsed: 4.00791776s
Apr 18 04:54:18.048: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189": Phase="Running", Reason="", readiness=false. Elapsed: 6.006243614s
Apr 18 04:54:20.047: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.005993941s
STEP: Saw pod success 04/18/23 04:54:20.047
Apr 18 04:54:20.048: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189" satisfied condition "Succeeded or Failed"
Apr 18 04:54:20.051: INFO: Trying to get logs from node apps-208 pod pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 04:54:20.068
Apr 18 04:54:20.244: INFO: Waiting for pod pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189 to disappear
Apr 18 04:54:20.272: INFO: Pod pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 04:54:20.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5178" for this suite. 04/18/23 04:54:20.276
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":139,"skipped":2409,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.518 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:54:11.783
    Apr 18 04:54:11.783: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 04:54:11.784
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:54:11.91
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:54:11.913
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-96a4fef2-019f-4129-a04c-ecff3ee4d7f3 04/18/23 04:54:11.928
    STEP: Creating a pod to test consume configMaps 04/18/23 04:54:11.949
    Apr 18 04:54:12.041: INFO: Waiting up to 5m0s for pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189" in namespace "configmap-5178" to be "Succeeded or Failed"
    Apr 18 04:54:12.044: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189": Phase="Pending", Reason="", readiness=false. Elapsed: 2.927002ms
    Apr 18 04:54:14.049: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007105974s
    Apr 18 04:54:16.049: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189": Phase="Running", Reason="", readiness=true. Elapsed: 4.00791776s
    Apr 18 04:54:18.048: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189": Phase="Running", Reason="", readiness=false. Elapsed: 6.006243614s
    Apr 18 04:54:20.047: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.005993941s
    STEP: Saw pod success 04/18/23 04:54:20.047
    Apr 18 04:54:20.048: INFO: Pod "pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189" satisfied condition "Succeeded or Failed"
    Apr 18 04:54:20.051: INFO: Trying to get logs from node apps-208 pod pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 04:54:20.068
    Apr 18 04:54:20.244: INFO: Waiting for pod pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189 to disappear
    Apr 18 04:54:20.272: INFO: Pod pod-configmaps-a1b25a36-c531-4c46-a49b-25117ca0f189 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 04:54:20.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5178" for this suite. 04/18/23 04:54:20.276
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:54:20.305
Apr 18 04:54:20.306: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 04:54:20.307
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:54:20.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:54:20.347
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-eebf8932-64fb-4b20-8598-73e5cc664e56 04/18/23 04:54:20.436
STEP: Creating secret with name s-test-opt-upd-7eae80a4-92ee-4c0f-b113-756d4d88c5c0 04/18/23 04:54:20.46
STEP: Creating the pod 04/18/23 04:54:20.479
Apr 18 04:54:20.512: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb" in namespace "projected-1265" to be "running and ready"
Apr 18 04:54:20.515: INFO: Pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.589209ms
Apr 18 04:54:20.515: INFO: The phase of Pod pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:54:22.519: INFO: Pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006638313s
Apr 18 04:54:22.519: INFO: The phase of Pod pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:54:24.520: INFO: Pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007949339s
Apr 18 04:54:24.520: INFO: The phase of Pod pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb is Pending, waiting for it to be Running (with Ready = true)
Apr 18 04:54:26.520: INFO: Pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb": Phase="Running", Reason="", readiness=true. Elapsed: 6.007424843s
Apr 18 04:54:26.520: INFO: The phase of Pod pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb is Running (Ready = true)
Apr 18 04:54:26.520: INFO: Pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-eebf8932-64fb-4b20-8598-73e5cc664e56 04/18/23 04:54:26.54
STEP: Updating secret s-test-opt-upd-7eae80a4-92ee-4c0f-b113-756d4d88c5c0 04/18/23 04:54:26.578
STEP: Creating secret with name s-test-opt-create-f4625e64-8544-4d18-8a0b-3d75a6c9ace3 04/18/23 04:54:26.594
STEP: waiting to observe update in volume 04/18/23 04:54:26.66
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 04:55:47.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1265" for this suite. 04/18/23 04:55:47.856
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":140,"skipped":2436,"failed":0}
------------------------------
â€¢ [SLOW TEST] [87.638 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:54:20.305
    Apr 18 04:54:20.306: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 04:54:20.307
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:54:20.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:54:20.347
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-eebf8932-64fb-4b20-8598-73e5cc664e56 04/18/23 04:54:20.436
    STEP: Creating secret with name s-test-opt-upd-7eae80a4-92ee-4c0f-b113-756d4d88c5c0 04/18/23 04:54:20.46
    STEP: Creating the pod 04/18/23 04:54:20.479
    Apr 18 04:54:20.512: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb" in namespace "projected-1265" to be "running and ready"
    Apr 18 04:54:20.515: INFO: Pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.589209ms
    Apr 18 04:54:20.515: INFO: The phase of Pod pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:54:22.519: INFO: Pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006638313s
    Apr 18 04:54:22.519: INFO: The phase of Pod pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:54:24.520: INFO: Pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007949339s
    Apr 18 04:54:24.520: INFO: The phase of Pod pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 04:54:26.520: INFO: Pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb": Phase="Running", Reason="", readiness=true. Elapsed: 6.007424843s
    Apr 18 04:54:26.520: INFO: The phase of Pod pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb is Running (Ready = true)
    Apr 18 04:54:26.520: INFO: Pod "pod-projected-secrets-7ad25255-8e94-45c1-a56c-14ecaff72abb" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-eebf8932-64fb-4b20-8598-73e5cc664e56 04/18/23 04:54:26.54
    STEP: Updating secret s-test-opt-upd-7eae80a4-92ee-4c0f-b113-756d4d88c5c0 04/18/23 04:54:26.578
    STEP: Creating secret with name s-test-opt-create-f4625e64-8544-4d18-8a0b-3d75a6c9ace3 04/18/23 04:54:26.594
    STEP: waiting to observe update in volume 04/18/23 04:54:26.66
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 04:55:47.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1265" for this suite. 04/18/23 04:55:47.856
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:55:47.944
Apr 18 04:55:47.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename subpath 04/18/23 04:55:47.945
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:55:47.996
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:55:47.999
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/18/23 04:55:48.014
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-9wl6 04/18/23 04:55:48.106
STEP: Creating a pod to test atomic-volume-subpath 04/18/23 04:55:48.106
Apr 18 04:55:48.130: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9wl6" in namespace "subpath-5471" to be "Succeeded or Failed"
Apr 18 04:55:48.132: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.429752ms
Apr 18 04:55:50.136: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006145549s
Apr 18 04:55:52.146: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 4.01589193s
Apr 18 04:55:54.138: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 6.008334931s
Apr 18 04:55:56.138: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 8.00764938s
Apr 18 04:55:58.172: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 10.042467553s
Apr 18 04:56:00.138: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 12.008249426s
Apr 18 04:56:02.136: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 14.006400564s
Apr 18 04:56:04.138: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 16.007796219s
Apr 18 04:56:06.137: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 18.006808596s
Apr 18 04:56:08.136: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 20.006301934s
Apr 18 04:56:10.154: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 22.023871036s
Apr 18 04:56:12.188: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=false. Elapsed: 24.057696583s
Apr 18 04:56:14.137: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.006591265s
STEP: Saw pod success 04/18/23 04:56:14.137
Apr 18 04:56:14.137: INFO: Pod "pod-subpath-test-configmap-9wl6" satisfied condition "Succeeded or Failed"
Apr 18 04:56:14.140: INFO: Trying to get logs from node apps-208 pod pod-subpath-test-configmap-9wl6 container test-container-subpath-configmap-9wl6: <nil>
STEP: delete the pod 04/18/23 04:56:14.146
Apr 18 04:56:14.235: INFO: Waiting for pod pod-subpath-test-configmap-9wl6 to disappear
Apr 18 04:56:14.237: INFO: Pod pod-subpath-test-configmap-9wl6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9wl6 04/18/23 04:56:14.238
Apr 18 04:56:14.238: INFO: Deleting pod "pod-subpath-test-configmap-9wl6" in namespace "subpath-5471"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 18 04:56:14.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5471" for this suite. 04/18/23 04:56:14.266
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":141,"skipped":2444,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.336 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:55:47.944
    Apr 18 04:55:47.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename subpath 04/18/23 04:55:47.945
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:55:47.996
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:55:47.999
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/18/23 04:55:48.014
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-9wl6 04/18/23 04:55:48.106
    STEP: Creating a pod to test atomic-volume-subpath 04/18/23 04:55:48.106
    Apr 18 04:55:48.130: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9wl6" in namespace "subpath-5471" to be "Succeeded or Failed"
    Apr 18 04:55:48.132: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.429752ms
    Apr 18 04:55:50.136: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006145549s
    Apr 18 04:55:52.146: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 4.01589193s
    Apr 18 04:55:54.138: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 6.008334931s
    Apr 18 04:55:56.138: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 8.00764938s
    Apr 18 04:55:58.172: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 10.042467553s
    Apr 18 04:56:00.138: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 12.008249426s
    Apr 18 04:56:02.136: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 14.006400564s
    Apr 18 04:56:04.138: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 16.007796219s
    Apr 18 04:56:06.137: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 18.006808596s
    Apr 18 04:56:08.136: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 20.006301934s
    Apr 18 04:56:10.154: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=true. Elapsed: 22.023871036s
    Apr 18 04:56:12.188: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Running", Reason="", readiness=false. Elapsed: 24.057696583s
    Apr 18 04:56:14.137: INFO: Pod "pod-subpath-test-configmap-9wl6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.006591265s
    STEP: Saw pod success 04/18/23 04:56:14.137
    Apr 18 04:56:14.137: INFO: Pod "pod-subpath-test-configmap-9wl6" satisfied condition "Succeeded or Failed"
    Apr 18 04:56:14.140: INFO: Trying to get logs from node apps-208 pod pod-subpath-test-configmap-9wl6 container test-container-subpath-configmap-9wl6: <nil>
    STEP: delete the pod 04/18/23 04:56:14.146
    Apr 18 04:56:14.235: INFO: Waiting for pod pod-subpath-test-configmap-9wl6 to disappear
    Apr 18 04:56:14.237: INFO: Pod pod-subpath-test-configmap-9wl6 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-9wl6 04/18/23 04:56:14.238
    Apr 18 04:56:14.238: INFO: Deleting pod "pod-subpath-test-configmap-9wl6" in namespace "subpath-5471"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 18 04:56:14.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5471" for this suite. 04/18/23 04:56:14.266
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:56:14.281
Apr 18 04:56:14.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename runtimeclass 04/18/23 04:56:14.282
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:56:14.391
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:56:14.394
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 18 04:56:14.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6963" for this suite. 04/18/23 04:56:14.407
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":142,"skipped":2467,"failed":0}
------------------------------
â€¢ [0.145 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:56:14.281
    Apr 18 04:56:14.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename runtimeclass 04/18/23 04:56:14.282
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:56:14.391
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:56:14.394
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 18 04:56:14.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6963" for this suite. 04/18/23 04:56:14.407
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 04:56:14.427
Apr 18 04:56:14.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-probe 04/18/23 04:56:14.428
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:56:14.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:56:14.54
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-21696b56-9ca9-4bed-8295-47220708a09f in namespace container-probe-8742 04/18/23 04:56:14.542
Apr 18 04:56:14.581: INFO: Waiting up to 5m0s for pod "busybox-21696b56-9ca9-4bed-8295-47220708a09f" in namespace "container-probe-8742" to be "not pending"
Apr 18 04:56:14.590: INFO: Pod "busybox-21696b56-9ca9-4bed-8295-47220708a09f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.189541ms
Apr 18 04:56:16.669: INFO: Pod "busybox-21696b56-9ca9-4bed-8295-47220708a09f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088172637s
Apr 18 04:56:18.594: INFO: Pod "busybox-21696b56-9ca9-4bed-8295-47220708a09f": Phase="Running", Reason="", readiness=true. Elapsed: 4.013430255s
Apr 18 04:56:18.594: INFO: Pod "busybox-21696b56-9ca9-4bed-8295-47220708a09f" satisfied condition "not pending"
Apr 18 04:56:18.594: INFO: Started pod busybox-21696b56-9ca9-4bed-8295-47220708a09f in namespace container-probe-8742
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 04:56:18.594
Apr 18 04:56:18.597: INFO: Initial restart count of pod busybox-21696b56-9ca9-4bed-8295-47220708a09f is 0
STEP: deleting the pod 04/18/23 05:00:19.942
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 05:00:20.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8742" for this suite. 04/18/23 05:00:20.082
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":143,"skipped":2478,"failed":0}
------------------------------
â€¢ [SLOW TEST] [245.730 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 04:56:14.427
    Apr 18 04:56:14.427: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-probe 04/18/23 04:56:14.428
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 04:56:14.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 04:56:14.54
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-21696b56-9ca9-4bed-8295-47220708a09f in namespace container-probe-8742 04/18/23 04:56:14.542
    Apr 18 04:56:14.581: INFO: Waiting up to 5m0s for pod "busybox-21696b56-9ca9-4bed-8295-47220708a09f" in namespace "container-probe-8742" to be "not pending"
    Apr 18 04:56:14.590: INFO: Pod "busybox-21696b56-9ca9-4bed-8295-47220708a09f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.189541ms
    Apr 18 04:56:16.669: INFO: Pod "busybox-21696b56-9ca9-4bed-8295-47220708a09f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088172637s
    Apr 18 04:56:18.594: INFO: Pod "busybox-21696b56-9ca9-4bed-8295-47220708a09f": Phase="Running", Reason="", readiness=true. Elapsed: 4.013430255s
    Apr 18 04:56:18.594: INFO: Pod "busybox-21696b56-9ca9-4bed-8295-47220708a09f" satisfied condition "not pending"
    Apr 18 04:56:18.594: INFO: Started pod busybox-21696b56-9ca9-4bed-8295-47220708a09f in namespace container-probe-8742
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 04:56:18.594
    Apr 18 04:56:18.597: INFO: Initial restart count of pod busybox-21696b56-9ca9-4bed-8295-47220708a09f is 0
    STEP: deleting the pod 04/18/23 05:00:19.942
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 05:00:20.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8742" for this suite. 04/18/23 05:00:20.082
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:00:20.159
Apr 18 05:00:20.159: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename runtimeclass 04/18/23 05:00:20.16
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:00:20.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:00:20.293
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 04/18/23 05:00:20.314
STEP: getting /apis/node.k8s.io 04/18/23 05:00:20.316
STEP: getting /apis/node.k8s.io/v1 04/18/23 05:00:20.317
STEP: creating 04/18/23 05:00:20.318
STEP: watching 04/18/23 05:00:20.471
Apr 18 05:00:20.471: INFO: starting watch
STEP: getting 04/18/23 05:00:20.492
STEP: listing 04/18/23 05:00:20.494
STEP: patching 04/18/23 05:00:20.497
STEP: updating 04/18/23 05:00:20.55
Apr 18 05:00:20.581: INFO: waiting for watch events with expected annotations
STEP: deleting 04/18/23 05:00:20.581
STEP: deleting a collection 04/18/23 05:00:20.65
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 18 05:00:20.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1536" for this suite. 04/18/23 05:00:20.787
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":144,"skipped":2501,"failed":0}
------------------------------
â€¢ [0.653 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:00:20.159
    Apr 18 05:00:20.159: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename runtimeclass 04/18/23 05:00:20.16
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:00:20.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:00:20.293
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 04/18/23 05:00:20.314
    STEP: getting /apis/node.k8s.io 04/18/23 05:00:20.316
    STEP: getting /apis/node.k8s.io/v1 04/18/23 05:00:20.317
    STEP: creating 04/18/23 05:00:20.318
    STEP: watching 04/18/23 05:00:20.471
    Apr 18 05:00:20.471: INFO: starting watch
    STEP: getting 04/18/23 05:00:20.492
    STEP: listing 04/18/23 05:00:20.494
    STEP: patching 04/18/23 05:00:20.497
    STEP: updating 04/18/23 05:00:20.55
    Apr 18 05:00:20.581: INFO: waiting for watch events with expected annotations
    STEP: deleting 04/18/23 05:00:20.581
    STEP: deleting a collection 04/18/23 05:00:20.65
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 18 05:00:20.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1536" for this suite. 04/18/23 05:00:20.787
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:00:20.813
Apr 18 05:00:20.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename tables 04/18/23 05:00:20.814
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:00:20.928
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:00:20.931
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Apr 18 05:00:20.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-8726" for this suite. 04/18/23 05:00:20.939
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":145,"skipped":2519,"failed":0}
------------------------------
â€¢ [0.146 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:00:20.813
    Apr 18 05:00:20.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename tables 04/18/23 05:00:20.814
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:00:20.928
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:00:20.931
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Apr 18 05:00:20.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-8726" for this suite. 04/18/23 05:00:20.939
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:00:20.962
Apr 18 05:00:20.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename disruption 04/18/23 05:00:20.963
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:00:21.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:00:21.103
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:00:21.106
Apr 18 05:00:21.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename disruption-2 04/18/23 05:00:21.107
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:00:21.125
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:00:21.127
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 04/18/23 05:00:21.217
STEP: Waiting for the pdb to be processed 04/18/23 05:00:23.282
STEP: Waiting for the pdb to be processed 04/18/23 05:00:25.343
STEP: listing a collection of PDBs across all namespaces 04/18/23 05:00:27.374
STEP: listing a collection of PDBs in namespace disruption-5407 04/18/23 05:00:27.377
STEP: deleting a collection of PDBs 04/18/23 05:00:27.379
STEP: Waiting for the PDB collection to be deleted 04/18/23 05:00:27.468
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Apr 18 05:00:27.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-9013" for this suite. 04/18/23 05:00:27.474
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 18 05:00:27.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5407" for this suite. 04/18/23 05:00:27.488
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":146,"skipped":2598,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.539 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:00:20.962
    Apr 18 05:00:20.962: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename disruption 04/18/23 05:00:20.963
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:00:21.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:00:21.103
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:00:21.106
    Apr 18 05:00:21.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename disruption-2 04/18/23 05:00:21.107
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:00:21.125
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:00:21.127
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 04/18/23 05:00:21.217
    STEP: Waiting for the pdb to be processed 04/18/23 05:00:23.282
    STEP: Waiting for the pdb to be processed 04/18/23 05:00:25.343
    STEP: listing a collection of PDBs across all namespaces 04/18/23 05:00:27.374
    STEP: listing a collection of PDBs in namespace disruption-5407 04/18/23 05:00:27.377
    STEP: deleting a collection of PDBs 04/18/23 05:00:27.379
    STEP: Waiting for the PDB collection to be deleted 04/18/23 05:00:27.468
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Apr 18 05:00:27.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-9013" for this suite. 04/18/23 05:00:27.474
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 18 05:00:27.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-5407" for this suite. 04/18/23 05:00:27.488
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:00:27.502
Apr 18 05:00:27.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename cronjob 04/18/23 05:00:27.503
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:00:27.599
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:00:27.602
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 04/18/23 05:00:27.604
STEP: Ensuring no jobs are scheduled 04/18/23 05:00:27.626
STEP: Ensuring no job exists by listing jobs explicitly 04/18/23 05:05:27.633
STEP: Removing cronjob 04/18/23 05:05:27.723
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 18 05:05:27.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-846" for this suite. 04/18/23 05:05:27.754
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":147,"skipped":2618,"failed":0}
------------------------------
â€¢ [SLOW TEST] [300.272 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:00:27.502
    Apr 18 05:00:27.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename cronjob 04/18/23 05:00:27.503
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:00:27.599
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:00:27.602
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 04/18/23 05:00:27.604
    STEP: Ensuring no jobs are scheduled 04/18/23 05:00:27.626
    STEP: Ensuring no job exists by listing jobs explicitly 04/18/23 05:05:27.633
    STEP: Removing cronjob 04/18/23 05:05:27.723
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 18 05:05:27.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-846" for this suite. 04/18/23 05:05:27.754
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:05:27.775
Apr 18 05:05:27.775: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename gc 04/18/23 05:05:27.776
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:05:27.914
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:05:27.917
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 04/18/23 05:05:27.931
STEP: create the rc2 04/18/23 05:05:28.008
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/18/23 05:05:38.385
STEP: delete the rc simpletest-rc-to-be-deleted 04/18/23 05:05:56.023
STEP: wait for the rc to be deleted 04/18/23 05:05:56.288
Apr 18 05:06:02.663: INFO: 75 pods remaining
Apr 18 05:06:02.663: INFO: 73 pods has nil DeletionTimestamp
Apr 18 05:06:02.663: INFO: 
Apr 18 05:06:06.678: INFO: 50 pods remaining
Apr 18 05:06:06.678: INFO: 50 pods has nil DeletionTimestamp
Apr 18 05:06:06.678: INFO: 
STEP: Gathering metrics 04/18/23 05:06:11.37
Apr 18 05:06:11.792: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
Apr 18 05:06:12.218: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 425.830184ms
Apr 18 05:06:12.218: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
Apr 18 05:06:12.218: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
Apr 18 05:06:12.265: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 18 05:06:12.265: INFO: Deleting pod "simpletest-rc-to-be-deleted-244nj" in namespace "gc-1905"
Apr 18 05:06:12.623: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hz9n" in namespace "gc-1905"
Apr 18 05:06:13.087: INFO: Deleting pod "simpletest-rc-to-be-deleted-2pmzl" in namespace "gc-1905"
Apr 18 05:06:13.362: INFO: Deleting pod "simpletest-rc-to-be-deleted-4c4s4" in namespace "gc-1905"
Apr 18 05:06:14.520: INFO: Deleting pod "simpletest-rc-to-be-deleted-4jm6q" in namespace "gc-1905"
Apr 18 05:06:15.140: INFO: Deleting pod "simpletest-rc-to-be-deleted-544x5" in namespace "gc-1905"
Apr 18 05:06:16.366: INFO: Deleting pod "simpletest-rc-to-be-deleted-5v5ft" in namespace "gc-1905"
Apr 18 05:06:16.457: INFO: Deleting pod "simpletest-rc-to-be-deleted-5wvks" in namespace "gc-1905"
Apr 18 05:06:16.896: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hsts" in namespace "gc-1905"
Apr 18 05:06:17.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-6lsv6" in namespace "gc-1905"
Apr 18 05:06:18.238: INFO: Deleting pod "simpletest-rc-to-be-deleted-6n2fl" in namespace "gc-1905"
Apr 18 05:06:18.493: INFO: Deleting pod "simpletest-rc-to-be-deleted-6tlws" in namespace "gc-1905"
Apr 18 05:06:18.696: INFO: Deleting pod "simpletest-rc-to-be-deleted-79ct4" in namespace "gc-1905"
Apr 18 05:06:19.114: INFO: Deleting pod "simpletest-rc-to-be-deleted-7gp24" in namespace "gc-1905"
Apr 18 05:06:19.813: INFO: Deleting pod "simpletest-rc-to-be-deleted-7hhfs" in namespace "gc-1905"
Apr 18 05:06:20.315: INFO: Deleting pod "simpletest-rc-to-be-deleted-7v9fc" in namespace "gc-1905"
Apr 18 05:06:20.521: INFO: Deleting pod "simpletest-rc-to-be-deleted-8b44x" in namespace "gc-1905"
Apr 18 05:06:20.652: INFO: Deleting pod "simpletest-rc-to-be-deleted-8fs46" in namespace "gc-1905"
Apr 18 05:06:20.852: INFO: Deleting pod "simpletest-rc-to-be-deleted-8mbkp" in namespace "gc-1905"
Apr 18 05:06:21.036: INFO: Deleting pod "simpletest-rc-to-be-deleted-8rs24" in namespace "gc-1905"
Apr 18 05:06:21.194: INFO: Deleting pod "simpletest-rc-to-be-deleted-92jl6" in namespace "gc-1905"
Apr 18 05:06:21.411: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dsxm" in namespace "gc-1905"
Apr 18 05:06:21.804: INFO: Deleting pod "simpletest-rc-to-be-deleted-9gq7b" in namespace "gc-1905"
Apr 18 05:06:22.151: INFO: Deleting pod "simpletest-rc-to-be-deleted-9pn5h" in namespace "gc-1905"
Apr 18 05:06:22.677: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqnj5" in namespace "gc-1905"
Apr 18 05:06:23.106: INFO: Deleting pod "simpletest-rc-to-be-deleted-brnpr" in namespace "gc-1905"
Apr 18 05:06:24.065: INFO: Deleting pod "simpletest-rc-to-be-deleted-c47vl" in namespace "gc-1905"
Apr 18 05:06:24.729: INFO: Deleting pod "simpletest-rc-to-be-deleted-c866z" in namespace "gc-1905"
Apr 18 05:06:24.988: INFO: Deleting pod "simpletest-rc-to-be-deleted-ccjpm" in namespace "gc-1905"
Apr 18 05:06:25.308: INFO: Deleting pod "simpletest-rc-to-be-deleted-ckst2" in namespace "gc-1905"
Apr 18 05:06:25.600: INFO: Deleting pod "simpletest-rc-to-be-deleted-cn7gw" in namespace "gc-1905"
Apr 18 05:06:25.816: INFO: Deleting pod "simpletest-rc-to-be-deleted-cntwh" in namespace "gc-1905"
Apr 18 05:06:26.054: INFO: Deleting pod "simpletest-rc-to-be-deleted-ctq2c" in namespace "gc-1905"
Apr 18 05:06:26.454: INFO: Deleting pod "simpletest-rc-to-be-deleted-ctsfw" in namespace "gc-1905"
Apr 18 05:06:26.937: INFO: Deleting pod "simpletest-rc-to-be-deleted-czf89" in namespace "gc-1905"
Apr 18 05:06:27.430: INFO: Deleting pod "simpletest-rc-to-be-deleted-czpzp" in namespace "gc-1905"
Apr 18 05:06:27.597: INFO: Deleting pod "simpletest-rc-to-be-deleted-dc28m" in namespace "gc-1905"
Apr 18 05:06:27.915: INFO: Deleting pod "simpletest-rc-to-be-deleted-df2bp" in namespace "gc-1905"
Apr 18 05:06:28.180: INFO: Deleting pod "simpletest-rc-to-be-deleted-djzmw" in namespace "gc-1905"
Apr 18 05:06:28.730: INFO: Deleting pod "simpletest-rc-to-be-deleted-drbrg" in namespace "gc-1905"
Apr 18 05:06:29.144: INFO: Deleting pod "simpletest-rc-to-be-deleted-dx6sh" in namespace "gc-1905"
Apr 18 05:06:29.619: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7qnt" in namespace "gc-1905"
Apr 18 05:06:29.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7zd8" in namespace "gc-1905"
Apr 18 05:06:30.514: INFO: Deleting pod "simpletest-rc-to-be-deleted-f8q4g" in namespace "gc-1905"
Apr 18 05:06:30.798: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjczj" in namespace "gc-1905"
Apr 18 05:06:31.131: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjl6s" in namespace "gc-1905"
Apr 18 05:06:31.373: INFO: Deleting pod "simpletest-rc-to-be-deleted-ftbpw" in namespace "gc-1905"
Apr 18 05:06:31.686: INFO: Deleting pod "simpletest-rc-to-be-deleted-fxt2t" in namespace "gc-1905"
Apr 18 05:06:32.108: INFO: Deleting pod "simpletest-rc-to-be-deleted-ghpjn" in namespace "gc-1905"
Apr 18 05:06:32.581: INFO: Deleting pod "simpletest-rc-to-be-deleted-gv6bc" in namespace "gc-1905"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 05:06:32.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1905" for this suite. 04/18/23 05:06:32.949
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":148,"skipped":2624,"failed":0}
------------------------------
â€¢ [SLOW TEST] [65.393 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:05:27.775
    Apr 18 05:05:27.775: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename gc 04/18/23 05:05:27.776
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:05:27.914
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:05:27.917
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 04/18/23 05:05:27.931
    STEP: create the rc2 04/18/23 05:05:28.008
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/18/23 05:05:38.385
    STEP: delete the rc simpletest-rc-to-be-deleted 04/18/23 05:05:56.023
    STEP: wait for the rc to be deleted 04/18/23 05:05:56.288
    Apr 18 05:06:02.663: INFO: 75 pods remaining
    Apr 18 05:06:02.663: INFO: 73 pods has nil DeletionTimestamp
    Apr 18 05:06:02.663: INFO: 
    Apr 18 05:06:06.678: INFO: 50 pods remaining
    Apr 18 05:06:06.678: INFO: 50 pods has nil DeletionTimestamp
    Apr 18 05:06:06.678: INFO: 
    STEP: Gathering metrics 04/18/23 05:06:11.37
    Apr 18 05:06:11.792: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
    Apr 18 05:06:12.218: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 425.830184ms
    Apr 18 05:06:12.218: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
    Apr 18 05:06:12.218: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
    Apr 18 05:06:12.265: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 18 05:06:12.265: INFO: Deleting pod "simpletest-rc-to-be-deleted-244nj" in namespace "gc-1905"
    Apr 18 05:06:12.623: INFO: Deleting pod "simpletest-rc-to-be-deleted-2hz9n" in namespace "gc-1905"
    Apr 18 05:06:13.087: INFO: Deleting pod "simpletest-rc-to-be-deleted-2pmzl" in namespace "gc-1905"
    Apr 18 05:06:13.362: INFO: Deleting pod "simpletest-rc-to-be-deleted-4c4s4" in namespace "gc-1905"
    Apr 18 05:06:14.520: INFO: Deleting pod "simpletest-rc-to-be-deleted-4jm6q" in namespace "gc-1905"
    Apr 18 05:06:15.140: INFO: Deleting pod "simpletest-rc-to-be-deleted-544x5" in namespace "gc-1905"
    Apr 18 05:06:16.366: INFO: Deleting pod "simpletest-rc-to-be-deleted-5v5ft" in namespace "gc-1905"
    Apr 18 05:06:16.457: INFO: Deleting pod "simpletest-rc-to-be-deleted-5wvks" in namespace "gc-1905"
    Apr 18 05:06:16.896: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hsts" in namespace "gc-1905"
    Apr 18 05:06:17.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-6lsv6" in namespace "gc-1905"
    Apr 18 05:06:18.238: INFO: Deleting pod "simpletest-rc-to-be-deleted-6n2fl" in namespace "gc-1905"
    Apr 18 05:06:18.493: INFO: Deleting pod "simpletest-rc-to-be-deleted-6tlws" in namespace "gc-1905"
    Apr 18 05:06:18.696: INFO: Deleting pod "simpletest-rc-to-be-deleted-79ct4" in namespace "gc-1905"
    Apr 18 05:06:19.114: INFO: Deleting pod "simpletest-rc-to-be-deleted-7gp24" in namespace "gc-1905"
    Apr 18 05:06:19.813: INFO: Deleting pod "simpletest-rc-to-be-deleted-7hhfs" in namespace "gc-1905"
    Apr 18 05:06:20.315: INFO: Deleting pod "simpletest-rc-to-be-deleted-7v9fc" in namespace "gc-1905"
    Apr 18 05:06:20.521: INFO: Deleting pod "simpletest-rc-to-be-deleted-8b44x" in namespace "gc-1905"
    Apr 18 05:06:20.652: INFO: Deleting pod "simpletest-rc-to-be-deleted-8fs46" in namespace "gc-1905"
    Apr 18 05:06:20.852: INFO: Deleting pod "simpletest-rc-to-be-deleted-8mbkp" in namespace "gc-1905"
    Apr 18 05:06:21.036: INFO: Deleting pod "simpletest-rc-to-be-deleted-8rs24" in namespace "gc-1905"
    Apr 18 05:06:21.194: INFO: Deleting pod "simpletest-rc-to-be-deleted-92jl6" in namespace "gc-1905"
    Apr 18 05:06:21.411: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dsxm" in namespace "gc-1905"
    Apr 18 05:06:21.804: INFO: Deleting pod "simpletest-rc-to-be-deleted-9gq7b" in namespace "gc-1905"
    Apr 18 05:06:22.151: INFO: Deleting pod "simpletest-rc-to-be-deleted-9pn5h" in namespace "gc-1905"
    Apr 18 05:06:22.677: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqnj5" in namespace "gc-1905"
    Apr 18 05:06:23.106: INFO: Deleting pod "simpletest-rc-to-be-deleted-brnpr" in namespace "gc-1905"
    Apr 18 05:06:24.065: INFO: Deleting pod "simpletest-rc-to-be-deleted-c47vl" in namespace "gc-1905"
    Apr 18 05:06:24.729: INFO: Deleting pod "simpletest-rc-to-be-deleted-c866z" in namespace "gc-1905"
    Apr 18 05:06:24.988: INFO: Deleting pod "simpletest-rc-to-be-deleted-ccjpm" in namespace "gc-1905"
    Apr 18 05:06:25.308: INFO: Deleting pod "simpletest-rc-to-be-deleted-ckst2" in namespace "gc-1905"
    Apr 18 05:06:25.600: INFO: Deleting pod "simpletest-rc-to-be-deleted-cn7gw" in namespace "gc-1905"
    Apr 18 05:06:25.816: INFO: Deleting pod "simpletest-rc-to-be-deleted-cntwh" in namespace "gc-1905"
    Apr 18 05:06:26.054: INFO: Deleting pod "simpletest-rc-to-be-deleted-ctq2c" in namespace "gc-1905"
    Apr 18 05:06:26.454: INFO: Deleting pod "simpletest-rc-to-be-deleted-ctsfw" in namespace "gc-1905"
    Apr 18 05:06:26.937: INFO: Deleting pod "simpletest-rc-to-be-deleted-czf89" in namespace "gc-1905"
    Apr 18 05:06:27.430: INFO: Deleting pod "simpletest-rc-to-be-deleted-czpzp" in namespace "gc-1905"
    Apr 18 05:06:27.597: INFO: Deleting pod "simpletest-rc-to-be-deleted-dc28m" in namespace "gc-1905"
    Apr 18 05:06:27.915: INFO: Deleting pod "simpletest-rc-to-be-deleted-df2bp" in namespace "gc-1905"
    Apr 18 05:06:28.180: INFO: Deleting pod "simpletest-rc-to-be-deleted-djzmw" in namespace "gc-1905"
    Apr 18 05:06:28.730: INFO: Deleting pod "simpletest-rc-to-be-deleted-drbrg" in namespace "gc-1905"
    Apr 18 05:06:29.144: INFO: Deleting pod "simpletest-rc-to-be-deleted-dx6sh" in namespace "gc-1905"
    Apr 18 05:06:29.619: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7qnt" in namespace "gc-1905"
    Apr 18 05:06:29.969: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7zd8" in namespace "gc-1905"
    Apr 18 05:06:30.514: INFO: Deleting pod "simpletest-rc-to-be-deleted-f8q4g" in namespace "gc-1905"
    Apr 18 05:06:30.798: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjczj" in namespace "gc-1905"
    Apr 18 05:06:31.131: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjl6s" in namespace "gc-1905"
    Apr 18 05:06:31.373: INFO: Deleting pod "simpletest-rc-to-be-deleted-ftbpw" in namespace "gc-1905"
    Apr 18 05:06:31.686: INFO: Deleting pod "simpletest-rc-to-be-deleted-fxt2t" in namespace "gc-1905"
    Apr 18 05:06:32.108: INFO: Deleting pod "simpletest-rc-to-be-deleted-ghpjn" in namespace "gc-1905"
    Apr 18 05:06:32.581: INFO: Deleting pod "simpletest-rc-to-be-deleted-gv6bc" in namespace "gc-1905"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 05:06:32.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1905" for this suite. 04/18/23 05:06:32.949
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:06:33.169
Apr 18 05:06:33.170: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 05:06:33.171
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:06:33.421
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:06:33.424
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 04/18/23 05:06:33.427
Apr 18 05:06:33.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd" in namespace "downward-api-9333" to be "Succeeded or Failed"
Apr 18 05:06:33.716: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 84.705588ms
Apr 18 05:06:35.732: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100964902s
Apr 18 05:06:37.758: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126708833s
Apr 18 05:06:39.720: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.088511025s
Apr 18 05:06:41.760: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.129040991s
Apr 18 05:06:43.729: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.098167886s
Apr 18 05:06:45.905: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.274238653s
Apr 18 05:06:47.796: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.164911607s
Apr 18 05:06:49.825: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.194270778s
Apr 18 05:06:51.728: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.096958004s
Apr 18 05:06:53.721: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 20.089703468s
Apr 18 05:06:55.719: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.088102218s
STEP: Saw pod success 04/18/23 05:06:55.719
Apr 18 05:06:55.719: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd" satisfied condition "Succeeded or Failed"
Apr 18 05:06:55.823: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd container client-container: <nil>
STEP: delete the pod 04/18/23 05:06:55.875
Apr 18 05:06:56.259: INFO: Waiting for pod downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd to disappear
Apr 18 05:06:56.268: INFO: Pod downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 05:06:56.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9333" for this suite. 04/18/23 05:06:56.272
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":149,"skipped":2638,"failed":0}
------------------------------
â€¢ [SLOW TEST] [23.185 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:06:33.169
    Apr 18 05:06:33.170: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 05:06:33.171
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:06:33.421
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:06:33.424
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 04/18/23 05:06:33.427
    Apr 18 05:06:33.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd" in namespace "downward-api-9333" to be "Succeeded or Failed"
    Apr 18 05:06:33.716: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 84.705588ms
    Apr 18 05:06:35.732: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100964902s
    Apr 18 05:06:37.758: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126708833s
    Apr 18 05:06:39.720: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.088511025s
    Apr 18 05:06:41.760: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.129040991s
    Apr 18 05:06:43.729: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.098167886s
    Apr 18 05:06:45.905: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.274238653s
    Apr 18 05:06:47.796: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.164911607s
    Apr 18 05:06:49.825: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.194270778s
    Apr 18 05:06:51.728: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.096958004s
    Apr 18 05:06:53.721: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Pending", Reason="", readiness=false. Elapsed: 20.089703468s
    Apr 18 05:06:55.719: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.088102218s
    STEP: Saw pod success 04/18/23 05:06:55.719
    Apr 18 05:06:55.719: INFO: Pod "downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd" satisfied condition "Succeeded or Failed"
    Apr 18 05:06:55.823: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd container client-container: <nil>
    STEP: delete the pod 04/18/23 05:06:55.875
    Apr 18 05:06:56.259: INFO: Waiting for pod downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd to disappear
    Apr 18 05:06:56.268: INFO: Pod downwardapi-volume-6e89f72d-39bc-41f2-a418-d9ddd23c20fd no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 05:06:56.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9333" for this suite. 04/18/23 05:06:56.272
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:06:56.355
Apr 18 05:06:56.355: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sched-pred 04/18/23 05:06:56.356
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:06:56.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:06:56.756
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 18 05:06:56.758: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 18 05:06:56.798: INFO: Waiting for terminating namespaces to be deleted...
Apr 18 05:06:56.801: INFO: 
Logging pods the apiserver thinks is on node apps-207 before test
Apr 18 05:06:57.055: INFO: addon-manager-5d75c94878-q9nwx from cocktail-addon started at 2023-04-14 07:23:24 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container addon-manager ready: true, restart count 1
Apr 18 05:06:57.055: INFO: agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w from cocktail-addon started at 2023-04-14 07:27:45 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container alarm-agent ready: true, restart count 0
Apr 18 05:06:57.055: INFO: alertmanager-monitoring-kube-prometheus-alertmanager-0 from cocktail-addon started at 2023-04-14 07:24:51 +0000 UTC (2 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container alertmanager ready: true, restart count 1
Apr 18 05:06:57.055: INFO: 	Container config-reloader ready: true, restart count 0
Apr 18 05:06:57.055: INFO: monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container kube-prometheus-stack ready: true, restart count 0
Apr 18 05:06:57.055: INFO: monitoring-kube-state-metrics-7dddf6695f-l8mlh from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container kube-state-metrics ready: true, restart count 0
Apr 18 05:06:57.055: INFO: monitoring-prometheus-node-exporter-d9xr5 from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 05:06:57.055: INFO: prometheus-monitoring-kube-prometheus-prometheus-0 from cocktail-addon started at 2023-04-14 11:20:12 +0000 UTC (2 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container config-reloader ready: true, restart count 0
Apr 18 05:06:57.055: INFO: 	Container prometheus ready: true, restart count 0
Apr 18 05:06:57.055: INFO: promtail-fjjqt from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container promtail ready: true, restart count 0
Apr 18 05:06:57.055: INFO: cocktail-api-gateway-648577694-g7lzt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container gateway ready: true, restart count 4
Apr 18 05:06:57.055: INFO: cocktail-batch-server-5895cd6748-x5qsz from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container batch ready: true, restart count 0
Apr 18 05:06:57.055: INFO: cocktail-build-api-5d65b8dd6-8tb9g from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container build-api ready: true, restart count 0
Apr 18 05:06:57.055: INFO: cocktail-build-queue-7855f6f4dd-vsc6p from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container nats-streaming ready: true, restart count 0
Apr 18 05:06:57.055: INFO: cocktail-cluster-api-6b5df5884f-4nbvz from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container cluster-api ready: true, restart count 2
Apr 18 05:06:57.055: INFO: cocktail-dashboard-86844bcfbd-wbnzx from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container dashboard ready: true, restart count 0
Apr 18 05:06:57.055: INFO: cocktail-dashboard-proxy-5476f6847-ptzhj from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container dashboard-proxy ready: true, restart count 0
Apr 18 05:06:57.055: INFO: cocktail-dashboard-queue-5745c9f74c-2gks8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container dashboard-queue ready: true, restart count 0
Apr 18 05:06:57.055: INFO: cocktail-dashboard-session-9d746547b-gk8d5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container dashboard-session ready: true, restart count 0
Apr 18 05:06:57.055: INFO: cocktail-monitoring-metric-collector-5695cb8669-mktvm from cocktail-system started at 2023-04-14 11:19:55 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container collector ready: true, restart count 4
Apr 18 05:06:57.055: INFO: calico-kube-controllers-74677b4c5f-rjqrf from kube-system started at 2023-04-11 08:28:10 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 18 05:06:57.055: INFO: calico-node-nmmjb from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 05:06:57.055: INFO: coredns-7ffbbc99d-5xc7c from kube-system started at 2023-04-11 08:28:13 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container coredns ready: true, restart count 0
Apr 18 05:06:57.055: INFO: csi-nfs-node-w5rjr from kube-system started at 2023-04-11 08:28:52 +0000 UTC (4 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:06:57.055: INFO: 	Container metrics ready: true, restart count 0
Apr 18 05:06:57.055: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:06:57.055: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 05:06:57.055: INFO: kube-apiserver-apps-207 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 05:06:57.055: INFO: kube-controller-manager-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container kube-controller-manager ready: true, restart count 1
Apr 18 05:06:57.055: INFO: kube-proxy-clw95 from kube-system started at 2023-04-11 08:28:27 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 05:06:57.055: INFO: kube-scheduler-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 18 05:06:57.055: INFO: metrics-server-7b879bf57b-vfp7l from kube-system started at 2023-04-13 06:15:39 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container metrics-server ready: true, restart count 0
Apr 18 05:06:57.055: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:06:57.055: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:06:57.055: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 05:06:57.055: INFO: 
Logging pods the apiserver thinks is on node apps-208 before test
Apr 18 05:06:57.083: INFO: monitoring-prometheus-node-exporter-x99mx from cocktail-addon started at 2023-04-18 04:30:51 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 05:06:57.083: INFO: nginx-ingress-nginx-controller-865cbc698d-sqwlm from cocktail-addon started at 2023-04-18 04:30:49 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container controller ready: true, restart count 0
Apr 18 05:06:57.083: INFO: nginx-ingress-nginx-defaultbackend-649fd8955b-wk6kv from cocktail-addon started at 2023-04-18 04:30:48 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container ingress-nginx-default-backend ready: true, restart count 0
Apr 18 05:06:57.083: INFO: promtail-c9qhr from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container promtail ready: true, restart count 0
Apr 18 05:06:57.083: INFO: calico-node-jstls from kube-system started at 2023-04-11 08:28:11 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 05:06:57.083: INFO: csi-nfs-node-t4zm5 from kube-system started at 2023-04-11 08:28:48 +0000 UTC (4 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:06:57.083: INFO: 	Container metrics ready: true, restart count 0
Apr 18 05:06:57.083: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:06:57.083: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 05:06:57.083: INFO: kube-apiserver-apps-208 from kube-system started at 2023-04-11 08:26:44 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 05:06:57.083: INFO: kube-controller-manager-apps-208 from kube-system started at 2023-04-05 06:51:47 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 18 05:06:57.083: INFO: kube-proxy-vb944 from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 05:06:57.083: INFO: kube-scheduler-apps-208 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 18 05:06:57.083: INFO: sonobuoy from sonobuoy started at 2023-04-18 04:01:18 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 18 05:06:57.083: INFO: sonobuoy-e2e-job-5f413cbb3b804c34 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container e2e ready: true, restart count 0
Apr 18 05:06:57.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:06:57.083: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-lzt9z from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:06:57.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:06:57.083: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 05:06:57.083: INFO: 
Logging pods the apiserver thinks is on node apps-209 before test
Apr 18 05:06:57.470: INFO: agent-mdi1zj-1-event-agent-757455b86f-jzfp7 from cocktail-addon started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container event-agent ready: true, restart count 0
Apr 18 05:06:57.470: INFO: agent-mdi1zj-1-metric-agent-0 from cocktail-addon started at 2023-04-14 07:27:47 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container metric-agent ready: true, restart count 6
Apr 18 05:06:57.470: INFO: monitoring-extension-event-exporter-57bc857b7b-d2kgh from cocktail-addon started at 2023-04-14 07:26:55 +0000 UTC (2 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container caddy ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container event-exporter ready: true, restart count 0
Apr 18 05:06:57.470: INFO: monitoring-prometheus-node-exporter-tx7km from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 05:06:57.470: INFO: promtail-bgwzf from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container promtail ready: true, restart count 0
Apr 18 05:06:57.470: INFO: cocktail-api-cmdb-0 from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container api-cmdb ready: true, restart count 0
Apr 18 05:06:57.470: INFO: cocktail-api-server-5d47cb7fdd-5ptrt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container api-server ready: true, restart count 1
Apr 18 05:06:57.470: INFO: cocktail-log-api-6c69c456db-j8gr8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container api ready: true, restart count 0
Apr 18 05:06:57.470: INFO: cocktail-log-loki-0 from cocktail-system started at 2023-04-14 07:04:56 +0000 UTC (2 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container loki ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container tls-proxy ready: true, restart count 0
Apr 18 05:06:57.470: INFO: cocktail-monitoring-76bdf6974f-p5hs8 from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container monitoring ready: true, restart count 3
Apr 18 05:06:57.470: INFO: cocktail-monitoring-alarm-collector-78448f5d-gbmcs from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container collector ready: true, restart count 6
Apr 18 05:06:57.470: INFO: cocktail-monitoring-event-collector-7fd78d476d-9pw9f from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container collector ready: true, restart count 7
Apr 18 05:06:57.470: INFO: cocktail-monitoring-monitoring-db-0 from cocktail-system started at 2023-04-14 11:20:11 +0000 UTC (2 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container db ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container log-lotate ready: true, restart count 0
Apr 18 05:06:57.470: INFO: cocktail-monitoring-proxy-648c665797-jd2fs from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container monitoring-proxy ready: true, restart count 0
Apr 18 05:06:57.470: INFO: cocktail-mq-entity-operator-7964999574-5zzkb from cocktail-system started at 2023-04-14 07:07:37 +0000 UTC (3 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container tls-sidecar ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container topic-operator ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container user-operator ready: true, restart count 0
Apr 18 05:06:57.470: INFO: cocktail-mq-kafka-0 from cocktail-system started at 2023-04-14 07:08:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container kafka ready: true, restart count 0
Apr 18 05:06:57.470: INFO: cocktail-mq-zookeeper-0 from cocktail-system started at 2023-04-14 07:05:54 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container zookeeper ready: true, restart count 0
Apr 18 05:06:57.470: INFO: cocktail-package-5f59d96bd8-d2nj5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container package ready: true, restart count 1
Apr 18 05:06:57.470: INFO: strimzi-cluster-operator-668f4bff5c-zqqjr from cocktail-system started at 2023-04-14 11:05:05 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container strimzi-cluster-operator ready: true, restart count 0
Apr 18 05:06:57.470: INFO: calico-node-q6mxd from kube-system started at 2023-04-11 08:28:12 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 05:06:57.470: INFO: coredns-7ffbbc99d-mkf8k from kube-system started at 2023-04-14 11:05:04 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container coredns ready: true, restart count 0
Apr 18 05:06:57.470: INFO: csi-nfs-controller-7ccd7c4947-dw42l from kube-system started at 2023-04-14 11:05:06 +0000 UTC (3 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container csi-provisioner ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:06:57.470: INFO: csi-nfs-node-nh5wf from kube-system started at 2023-04-11 08:28:49 +0000 UTC (4 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container metrics ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 05:06:57.470: INFO: kube-apiserver-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 05:06:57.470: INFO: kube-controller-manager-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container kube-controller-manager ready: true, restart count 1
Apr 18 05:06:57.470: INFO: kube-proxy-vmwrf from kube-system started at 2023-04-11 08:28:28 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 05:06:57.470: INFO: kube-scheduler-apps-209 from kube-system started at 2023-04-07 08:18:47 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container kube-scheduler ready: true, restart count 1
Apr 18 05:06:57.470: INFO: metrics-server-7b879bf57b-6vnbg from kube-system started at 2023-04-13 06:15:03 +0000 UTC (1 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container metrics-server ready: true, restart count 0
Apr 18 05:06:57.470: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-j4n44 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:06:57.470: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:06:57.470: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 04/18/23 05:06:57.47
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1756ef1cd4445b6d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 04/18/23 05:06:58.166
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:06:58.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8512" for this suite. 04/18/23 05:06:58.968
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":150,"skipped":2641,"failed":0}
------------------------------
â€¢ [2.649 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:06:56.355
    Apr 18 05:06:56.355: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sched-pred 04/18/23 05:06:56.356
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:06:56.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:06:56.756
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 18 05:06:56.758: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 18 05:06:56.798: INFO: Waiting for terminating namespaces to be deleted...
    Apr 18 05:06:56.801: INFO: 
    Logging pods the apiserver thinks is on node apps-207 before test
    Apr 18 05:06:57.055: INFO: addon-manager-5d75c94878-q9nwx from cocktail-addon started at 2023-04-14 07:23:24 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container addon-manager ready: true, restart count 1
    Apr 18 05:06:57.055: INFO: agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w from cocktail-addon started at 2023-04-14 07:27:45 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container alarm-agent ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: alertmanager-monitoring-kube-prometheus-alertmanager-0 from cocktail-addon started at 2023-04-14 07:24:51 +0000 UTC (2 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container alertmanager ready: true, restart count 1
    Apr 18 05:06:57.055: INFO: 	Container config-reloader ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container kube-prometheus-stack ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: monitoring-kube-state-metrics-7dddf6695f-l8mlh from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: monitoring-prometheus-node-exporter-d9xr5 from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: prometheus-monitoring-kube-prometheus-prometheus-0 from cocktail-addon started at 2023-04-14 11:20:12 +0000 UTC (2 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container config-reloader ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: 	Container prometheus ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: promtail-fjjqt from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: cocktail-api-gateway-648577694-g7lzt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container gateway ready: true, restart count 4
    Apr 18 05:06:57.055: INFO: cocktail-batch-server-5895cd6748-x5qsz from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container batch ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: cocktail-build-api-5d65b8dd6-8tb9g from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container build-api ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: cocktail-build-queue-7855f6f4dd-vsc6p from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container nats-streaming ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: cocktail-cluster-api-6b5df5884f-4nbvz from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container cluster-api ready: true, restart count 2
    Apr 18 05:06:57.055: INFO: cocktail-dashboard-86844bcfbd-wbnzx from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container dashboard ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: cocktail-dashboard-proxy-5476f6847-ptzhj from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container dashboard-proxy ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: cocktail-dashboard-queue-5745c9f74c-2gks8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container dashboard-queue ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: cocktail-dashboard-session-9d746547b-gk8d5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container dashboard-session ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: cocktail-monitoring-metric-collector-5695cb8669-mktvm from cocktail-system started at 2023-04-14 11:19:55 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container collector ready: true, restart count 4
    Apr 18 05:06:57.055: INFO: calico-kube-controllers-74677b4c5f-rjqrf from kube-system started at 2023-04-11 08:28:10 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: calico-node-nmmjb from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: coredns-7ffbbc99d-5xc7c from kube-system started at 2023-04-11 08:28:13 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: csi-nfs-node-w5rjr from kube-system started at 2023-04-11 08:28:52 +0000 UTC (4 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: kube-apiserver-apps-207 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: kube-controller-manager-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Apr 18 05:06:57.055: INFO: kube-proxy-clw95 from kube-system started at 2023-04-11 08:28:27 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: kube-scheduler-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: metrics-server-7b879bf57b-vfp7l from kube-system started at 2023-04-13 06:15:39 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:06:57.055: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 05:06:57.055: INFO: 
    Logging pods the apiserver thinks is on node apps-208 before test
    Apr 18 05:06:57.083: INFO: monitoring-prometheus-node-exporter-x99mx from cocktail-addon started at 2023-04-18 04:30:51 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: nginx-ingress-nginx-controller-865cbc698d-sqwlm from cocktail-addon started at 2023-04-18 04:30:49 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container controller ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: nginx-ingress-nginx-defaultbackend-649fd8955b-wk6kv from cocktail-addon started at 2023-04-18 04:30:48 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container ingress-nginx-default-backend ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: promtail-c9qhr from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: calico-node-jstls from kube-system started at 2023-04-11 08:28:11 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: csi-nfs-node-t4zm5 from kube-system started at 2023-04-11 08:28:48 +0000 UTC (4 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: kube-apiserver-apps-208 from kube-system started at 2023-04-11 08:26:44 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: kube-controller-manager-apps-208 from kube-system started at 2023-04-05 06:51:47 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: kube-proxy-vb944 from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: kube-scheduler-apps-208 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: sonobuoy from sonobuoy started at 2023-04-18 04:01:18 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: sonobuoy-e2e-job-5f413cbb3b804c34 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container e2e ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-lzt9z from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:06:57.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 05:06:57.083: INFO: 
    Logging pods the apiserver thinks is on node apps-209 before test
    Apr 18 05:06:57.470: INFO: agent-mdi1zj-1-event-agent-757455b86f-jzfp7 from cocktail-addon started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container event-agent ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: agent-mdi1zj-1-metric-agent-0 from cocktail-addon started at 2023-04-14 07:27:47 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container metric-agent ready: true, restart count 6
    Apr 18 05:06:57.470: INFO: monitoring-extension-event-exporter-57bc857b7b-d2kgh from cocktail-addon started at 2023-04-14 07:26:55 +0000 UTC (2 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container caddy ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container event-exporter ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: monitoring-prometheus-node-exporter-tx7km from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: promtail-bgwzf from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: cocktail-api-cmdb-0 from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container api-cmdb ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: cocktail-api-server-5d47cb7fdd-5ptrt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container api-server ready: true, restart count 1
    Apr 18 05:06:57.470: INFO: cocktail-log-api-6c69c456db-j8gr8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container api ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: cocktail-log-loki-0 from cocktail-system started at 2023-04-14 07:04:56 +0000 UTC (2 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container loki ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container tls-proxy ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: cocktail-monitoring-76bdf6974f-p5hs8 from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container monitoring ready: true, restart count 3
    Apr 18 05:06:57.470: INFO: cocktail-monitoring-alarm-collector-78448f5d-gbmcs from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container collector ready: true, restart count 6
    Apr 18 05:06:57.470: INFO: cocktail-monitoring-event-collector-7fd78d476d-9pw9f from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container collector ready: true, restart count 7
    Apr 18 05:06:57.470: INFO: cocktail-monitoring-monitoring-db-0 from cocktail-system started at 2023-04-14 11:20:11 +0000 UTC (2 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container db ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container log-lotate ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: cocktail-monitoring-proxy-648c665797-jd2fs from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container monitoring-proxy ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: cocktail-mq-entity-operator-7964999574-5zzkb from cocktail-system started at 2023-04-14 07:07:37 +0000 UTC (3 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container tls-sidecar ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container topic-operator ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container user-operator ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: cocktail-mq-kafka-0 from cocktail-system started at 2023-04-14 07:08:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container kafka ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: cocktail-mq-zookeeper-0 from cocktail-system started at 2023-04-14 07:05:54 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container zookeeper ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: cocktail-package-5f59d96bd8-d2nj5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container package ready: true, restart count 1
    Apr 18 05:06:57.470: INFO: strimzi-cluster-operator-668f4bff5c-zqqjr from cocktail-system started at 2023-04-14 11:05:05 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container strimzi-cluster-operator ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: calico-node-q6mxd from kube-system started at 2023-04-11 08:28:12 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: coredns-7ffbbc99d-mkf8k from kube-system started at 2023-04-14 11:05:04 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: csi-nfs-controller-7ccd7c4947-dw42l from kube-system started at 2023-04-14 11:05:06 +0000 UTC (3 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container csi-provisioner ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: csi-nfs-node-nh5wf from kube-system started at 2023-04-11 08:28:49 +0000 UTC (4 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: kube-apiserver-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: kube-controller-manager-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Apr 18 05:06:57.470: INFO: kube-proxy-vmwrf from kube-system started at 2023-04-11 08:28:28 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: kube-scheduler-apps-209 from kube-system started at 2023-04-07 08:18:47 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container kube-scheduler ready: true, restart count 1
    Apr 18 05:06:57.470: INFO: metrics-server-7b879bf57b-6vnbg from kube-system started at 2023-04-13 06:15:03 +0000 UTC (1 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-j4n44 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:06:57.470: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:06:57.470: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 04/18/23 05:06:57.47
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.1756ef1cd4445b6d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.] 04/18/23 05:06:58.166
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:06:58.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8512" for this suite. 04/18/23 05:06:58.968
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:06:59.006
Apr 18 05:06:59.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 05:06:59.007
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:06:59.242
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:06:59.245
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 04/18/23 05:06:59.306
STEP: Ensuring ResourceQuota status is calculated 04/18/23 05:06:59.459
STEP: Creating a ResourceQuota with not best effort scope 04/18/23 05:07:01.644
STEP: Ensuring ResourceQuota status is calculated 04/18/23 05:07:01.772
STEP: Creating a best-effort pod 04/18/23 05:07:03.803
STEP: Ensuring resource quota with best effort scope captures the pod usage 04/18/23 05:07:03.996
STEP: Ensuring resource quota with not best effort ignored the pod usage 04/18/23 05:07:06.713
STEP: Deleting the pod 04/18/23 05:07:08.731
STEP: Ensuring resource quota status released the pod usage 04/18/23 05:07:08.907
STEP: Creating a not best-effort pod 04/18/23 05:07:10.937
STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/18/23 05:07:11.061
STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/18/23 05:07:13.08
STEP: Deleting the pod 04/18/23 05:07:15.119
STEP: Ensuring resource quota status released the pod usage 04/18/23 05:07:15.314
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 05:07:17.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5469" for this suite. 04/18/23 05:07:17.341
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":151,"skipped":2657,"failed":0}
------------------------------
â€¢ [SLOW TEST] [18.364 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:06:59.006
    Apr 18 05:06:59.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 05:06:59.007
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:06:59.242
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:06:59.245
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 04/18/23 05:06:59.306
    STEP: Ensuring ResourceQuota status is calculated 04/18/23 05:06:59.459
    STEP: Creating a ResourceQuota with not best effort scope 04/18/23 05:07:01.644
    STEP: Ensuring ResourceQuota status is calculated 04/18/23 05:07:01.772
    STEP: Creating a best-effort pod 04/18/23 05:07:03.803
    STEP: Ensuring resource quota with best effort scope captures the pod usage 04/18/23 05:07:03.996
    STEP: Ensuring resource quota with not best effort ignored the pod usage 04/18/23 05:07:06.713
    STEP: Deleting the pod 04/18/23 05:07:08.731
    STEP: Ensuring resource quota status released the pod usage 04/18/23 05:07:08.907
    STEP: Creating a not best-effort pod 04/18/23 05:07:10.937
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/18/23 05:07:11.061
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/18/23 05:07:13.08
    STEP: Deleting the pod 04/18/23 05:07:15.119
    STEP: Ensuring resource quota status released the pod usage 04/18/23 05:07:15.314
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 05:07:17.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5469" for this suite. 04/18/23 05:07:17.341
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:07:17.371
Apr 18 05:07:17.371: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 05:07:17.372
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:07:17.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:07:17.493
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Apr 18 05:07:17.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:07:23.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4353" for this suite. 04/18/23 05:07:23.665
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":152,"skipped":2699,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.394 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:07:17.371
    Apr 18 05:07:17.371: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 05:07:17.372
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:07:17.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:07:17.493
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Apr 18 05:07:17.495: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:07:23.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-4353" for this suite. 04/18/23 05:07:23.665
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:07:23.765
Apr 18 05:07:23.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:07:23.767
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:07:23.875
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:07:23.877
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-28967fbd-2fb7-4b45-a199-880790dca42b 04/18/23 05:07:23.88
STEP: Creating a pod to test consume configMaps 04/18/23 05:07:23.944
Apr 18 05:07:23.995: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df" in namespace "projected-2200" to be "Succeeded or Failed"
Apr 18 05:07:24.043: INFO: Pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df": Phase="Pending", Reason="", readiness=false. Elapsed: 48.501828ms
Apr 18 05:07:26.090: INFO: Pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095710729s
Apr 18 05:07:28.047: INFO: Pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df": Phase="Running", Reason="", readiness=false. Elapsed: 4.052234775s
Apr 18 05:07:30.049: INFO: Pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.053849151s
STEP: Saw pod success 04/18/23 05:07:30.049
Apr 18 05:07:30.049: INFO: Pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df" satisfied condition "Succeeded or Failed"
Apr 18 05:07:30.052: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:07:30.058
Apr 18 05:07:30.112: INFO: Waiting for pod pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df to disappear
Apr 18 05:07:30.118: INFO: Pod pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 05:07:30.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2200" for this suite. 04/18/23 05:07:30.189
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":153,"skipped":2700,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.441 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:07:23.765
    Apr 18 05:07:23.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:07:23.767
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:07:23.875
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:07:23.877
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-28967fbd-2fb7-4b45-a199-880790dca42b 04/18/23 05:07:23.88
    STEP: Creating a pod to test consume configMaps 04/18/23 05:07:23.944
    Apr 18 05:07:23.995: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df" in namespace "projected-2200" to be "Succeeded or Failed"
    Apr 18 05:07:24.043: INFO: Pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df": Phase="Pending", Reason="", readiness=false. Elapsed: 48.501828ms
    Apr 18 05:07:26.090: INFO: Pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095710729s
    Apr 18 05:07:28.047: INFO: Pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df": Phase="Running", Reason="", readiness=false. Elapsed: 4.052234775s
    Apr 18 05:07:30.049: INFO: Pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.053849151s
    STEP: Saw pod success 04/18/23 05:07:30.049
    Apr 18 05:07:30.049: INFO: Pod "pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df" satisfied condition "Succeeded or Failed"
    Apr 18 05:07:30.052: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:07:30.058
    Apr 18 05:07:30.112: INFO: Waiting for pod pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df to disappear
    Apr 18 05:07:30.118: INFO: Pod pod-projected-configmaps-4b38435a-f3e2-4079-8ee7-d667b0d2c9df no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 05:07:30.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2200" for this suite. 04/18/23 05:07:30.189
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:07:30.208
Apr 18 05:07:30.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename deployment 04/18/23 05:07:30.209
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:07:30.254
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:07:30.257
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Apr 18 05:07:30.265: INFO: Creating deployment "webserver-deployment"
Apr 18 05:07:30.281: INFO: Waiting for observed generation 1
Apr 18 05:07:32.472: INFO: Waiting for all required pods to come up
Apr 18 05:07:32.734: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 04/18/23 05:07:32.734
Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zmcgx" in namespace "deployment-5324" to be "running"
Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-6lf42" in namespace "deployment-5324" to be "running"
Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-kwc57" in namespace "deployment-5324" to be "running"
Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-4bxg9" in namespace "deployment-5324" to be "running"
Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-p7mrn" in namespace "deployment-5324" to be "running"
Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-9lxbg" in namespace "deployment-5324" to be "running"
Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-kgdhc" in namespace "deployment-5324" to be "running"
Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-6nf7k" in namespace "deployment-5324" to be "running"
Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-wf52f" in namespace "deployment-5324" to be "running"
Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-md2kq" in namespace "deployment-5324" to be "running"
Apr 18 05:07:32.764: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Pending", Reason="", readiness=false. Elapsed: 30.098513ms
Apr 18 05:07:32.764: INFO: Pod "webserver-deployment-845c8977d9-9lxbg": Phase="Pending", Reason="", readiness=false. Elapsed: 30.004689ms
Apr 18 05:07:32.764: INFO: Pod "webserver-deployment-845c8977d9-p7mrn": Phase="Pending", Reason="", readiness=false. Elapsed: 30.112776ms
Apr 18 05:07:32.764: INFO: Pod "webserver-deployment-845c8977d9-wf52f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.095283ms
Apr 18 05:07:32.764: INFO: Pod "webserver-deployment-845c8977d9-md2kq": Phase="Pending", Reason="", readiness=false. Elapsed: 30.192697ms
Apr 18 05:07:32.765: INFO: Pod "webserver-deployment-845c8977d9-6nf7k": Phase="Pending", Reason="", readiness=false. Elapsed: 30.473733ms
Apr 18 05:07:32.765: INFO: Pod "webserver-deployment-845c8977d9-kwc57": Phase="Pending", Reason="", readiness=false. Elapsed: 30.578918ms
Apr 18 05:07:33.106: INFO: Pod "webserver-deployment-845c8977d9-kgdhc": Phase="Pending", Reason="", readiness=false. Elapsed: 371.747393ms
Apr 18 05:07:33.106: INFO: Pod "webserver-deployment-845c8977d9-4bxg9": Phase="Pending", Reason="", readiness=false. Elapsed: 371.804839ms
Apr 18 05:07:33.106: INFO: Pod "webserver-deployment-845c8977d9-6lf42": Phase="Pending", Reason="", readiness=false. Elapsed: 371.842426ms
Apr 18 05:07:34.956: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.221837819s
Apr 18 05:07:34.988: INFO: Pod "webserver-deployment-845c8977d9-6nf7k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.25343323s
Apr 18 05:07:34.988: INFO: Pod "webserver-deployment-845c8977d9-wf52f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.253457217s
Apr 18 05:07:35.051: INFO: Pod "webserver-deployment-845c8977d9-9lxbg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.3169358s
Apr 18 05:07:35.051: INFO: Pod "webserver-deployment-845c8977d9-md2kq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.316925141s
Apr 18 05:07:35.080: INFO: Pod "webserver-deployment-845c8977d9-p7mrn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.345502241s
Apr 18 05:07:35.080: INFO: Pod "webserver-deployment-845c8977d9-kwc57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.345630571s
Apr 18 05:07:35.248: INFO: Pod "webserver-deployment-845c8977d9-4bxg9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.513594771s
Apr 18 05:07:35.254: INFO: Pod "webserver-deployment-845c8977d9-6lf42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.520410497s
Apr 18 05:07:35.268: INFO: Pod "webserver-deployment-845c8977d9-kgdhc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.533846862s
Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Pending", Reason="", readiness=false. Elapsed: 4.176594563s
Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-6nf7k": Phase="Running", Reason="", readiness=true. Elapsed: 4.176625879s
Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-6nf7k" satisfied condition "running"
Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-p7mrn": Phase="Running", Reason="", readiness=true. Elapsed: 4.176739324s
Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-p7mrn" satisfied condition "running"
Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-wf52f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.176769906s
Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-md2kq": Phase="Running", Reason="", readiness=true. Elapsed: 4.176737936s
Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-md2kq" satisfied condition "running"
Apr 18 05:07:36.938: INFO: Pod "webserver-deployment-845c8977d9-kwc57": Phase="Pending", Reason="", readiness=false. Elapsed: 4.204271631s
Apr 18 05:07:36.938: INFO: Pod "webserver-deployment-845c8977d9-9lxbg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.204304525s
Apr 18 05:07:37.181: INFO: Pod "webserver-deployment-845c8977d9-kgdhc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.447305151s
Apr 18 05:07:37.230: INFO: Pod "webserver-deployment-845c8977d9-6lf42": Phase="Running", Reason="", readiness=true. Elapsed: 4.496246754s
Apr 18 05:07:37.230: INFO: Pod "webserver-deployment-845c8977d9-6lf42" satisfied condition "running"
Apr 18 05:07:37.237: INFO: Pod "webserver-deployment-845c8977d9-4bxg9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.502702267s
Apr 18 05:07:38.941: INFO: Pod "webserver-deployment-845c8977d9-9lxbg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.206851223s
Apr 18 05:07:38.941: INFO: Pod "webserver-deployment-845c8977d9-wf52f": Phase="Running", Reason="", readiness=true. Elapsed: 6.206832557s
Apr 18 05:07:38.941: INFO: Pod "webserver-deployment-845c8977d9-wf52f" satisfied condition "running"
Apr 18 05:07:38.941: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.207335808s
Apr 18 05:07:39.066: INFO: Pod "webserver-deployment-845c8977d9-kwc57": Phase="Pending", Reason="", readiness=false. Elapsed: 6.331777865s
Apr 18 05:07:39.124: INFO: Pod "webserver-deployment-845c8977d9-kgdhc": Phase="Running", Reason="", readiness=true. Elapsed: 6.389767078s
Apr 18 05:07:39.124: INFO: Pod "webserver-deployment-845c8977d9-kgdhc" satisfied condition "running"
Apr 18 05:07:39.130: INFO: Pod "webserver-deployment-845c8977d9-4bxg9": Phase="Running", Reason="", readiness=true. Elapsed: 6.395808351s
Apr 18 05:07:39.130: INFO: Pod "webserver-deployment-845c8977d9-4bxg9" satisfied condition "running"
Apr 18 05:07:40.832: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.097656844s
Apr 18 05:07:40.832: INFO: Pod "webserver-deployment-845c8977d9-kwc57": Phase="Running", Reason="", readiness=true. Elapsed: 8.09762891s
Apr 18 05:07:40.832: INFO: Pod "webserver-deployment-845c8977d9-kwc57" satisfied condition "running"
Apr 18 05:07:40.842: INFO: Pod "webserver-deployment-845c8977d9-9lxbg": Phase="Running", Reason="", readiness=true. Elapsed: 8.108201993s
Apr 18 05:07:40.842: INFO: Pod "webserver-deployment-845c8977d9-9lxbg" satisfied condition "running"
Apr 18 05:07:42.774: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Running", Reason="", readiness=true. Elapsed: 10.039520269s
Apr 18 05:07:42.774: INFO: Pod "webserver-deployment-845c8977d9-zmcgx" satisfied condition "running"
Apr 18 05:07:42.774: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 18 05:07:42.779: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 18 05:07:42.830: INFO: Updating deployment webserver-deployment
Apr 18 05:07:42.830: INFO: Waiting for observed generation 2
Apr 18 05:07:45.280: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 18 05:07:45.446: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 18 05:07:45.466: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 18 05:07:45.489: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 18 05:07:45.489: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 18 05:07:45.491: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 18 05:07:45.502: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 18 05:07:45.502: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 18 05:07:45.656: INFO: Updating deployment webserver-deployment
Apr 18 05:07:45.656: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 18 05:07:45.662: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 18 05:07:45.974: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 05:07:47.236: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-5324  d00fee9c-f7b4-4416-9a94-8893734b50c2 4100799 3 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006e67538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-04-18 05:07:45 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-18 05:07:45 +0000 UTC,LastTransitionTime:2023-04-18 05:07:45 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 18 05:07:47.765: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-5324  e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 4100856 3 2023-04-18 05:07:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment d00fee9c-f7b4-4416-9a94-8893734b50c2 0xc005cbf787 0xc005cbf788}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d00fee9c-f7b4-4416-9a94-8893734b50c2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005cbf838 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 05:07:47.765: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 18 05:07:47.765: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-5324  fb90255f-c72f-42be-8fe9-58c8e289811e 4100860 3 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment d00fee9c-f7b4-4416-9a94-8893734b50c2 0xc005cbf897 0xc005cbf898}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d00fee9c-f7b4-4416-9a94-8893734b50c2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005cbf928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 18 05:07:48.228: INFO: Pod "webserver-deployment-69b7448995-268v2" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-268v2 webserver-deployment-69b7448995- deployment-5324  7a9e1789-7775-4b28-8da5-92e086583200 4100850 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc005cbfe27 0xc005cbfe28}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dphcd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dphcd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.228: INFO: Pod "webserver-deployment-69b7448995-68q2c" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-68q2c webserver-deployment-69b7448995- deployment-5324  7adb2d88-2989-42e0-815b-879c6f8d0d07 4100822 0 2023-04-18 05:07:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc005cbffa7 0xc005cbffa8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fzhx2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fzhx2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.228: INFO: Pod "webserver-deployment-69b7448995-6bl2n" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-6bl2n webserver-deployment-69b7448995- deployment-5324  2824617b-7364-46fb-91e1-0448b65ecd1a 4100882 0 2023-04-18 05:07:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ccfe49b8a0171d887c36ae948ce0a06057d423f36819775c1f5393046359d0df cni.projectcalico.org/podIP:172.16.100.158/32 cni.projectcalico.org/podIPs:172.16.100.158/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539a117 0xc00539a118}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qbcjs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qbcjs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:07:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.228: INFO: Pod "webserver-deployment-69b7448995-7qqm6" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-7qqm6 webserver-deployment-69b7448995- deployment-5324  ec2a56e9-1ae0-4606-94fc-f8936c1b46c1 4100848 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539a327 0xc00539a328}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hc5jj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hc5jj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-87s6m" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-87s6m webserver-deployment-69b7448995- deployment-5324  6f0bc070-b4cf-4899-b8a8-953fc4eaf041 4100785 0 2023-04-18 05:07:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:372282c27c5260cdaf46cc588d656fe311db138f9cfb6befc3be8f9bb85a6a63 cni.projectcalico.org/podIP:172.16.144.27/32 cni.projectcalico.org/podIPs:172.16.144.27/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539a547 0xc00539a548}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v6nlp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v6nlp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:,StartTime:2023-04-18 05:07:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-8z4dx" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-8z4dx webserver-deployment-69b7448995- deployment-5324  6b92c6ee-bd3b-4db8-bfa2-fa6a88a9e4be 4100832 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539a757 0xc00539a758}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-956pn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-956pn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-dthwr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-dthwr webserver-deployment-69b7448995- deployment-5324  f569d0b5-5103-46dd-a881-1112924a1f41 4100817 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539a947 0xc00539a948}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gxscq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gxscq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-fgprh" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fgprh webserver-deployment-69b7448995- deployment-5324  828a78ea-3072-4555-af12-69bad0d60510 4100859 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539aac7 0xc00539aac8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6d56b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6d56b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-lbk2l" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lbk2l webserver-deployment-69b7448995- deployment-5324  3cdb93b7-c75a-4c98-9f05-2abf70ba41a9 4100869 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539acc7 0xc00539acc8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fk2f8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fk2f8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-mctsq" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-mctsq webserver-deployment-69b7448995- deployment-5324  a24a3f39-50ed-4f74-8254-ba15cb021af5 4100736 0 2023-04-18 05:07:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539aeb7 0xc00539aeb8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7wrlp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7wrlp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:,StartTime:2023-04-18 05:07:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-69b7448995-tt97q" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-tt97q webserver-deployment-69b7448995- deployment-5324  b101f651-c18d-4315-99f9-9493a9c6310b 4100771 0 2023-04-18 05:07:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539b0a7 0xc00539b0a8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dcv4f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dcv4f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:,StartTime:2023-04-18 05:07:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-69b7448995-vqsgc" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-vqsgc webserver-deployment-69b7448995- deployment-5324  17d8eaf6-1b78-4877-a7c7-cd3208ff4ca0 4100775 0 2023-04-18 05:07:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539b2a7 0xc00539b2a8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p47mr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p47mr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:,StartTime:2023-04-18 05:07:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-69b7448995-wg6n6" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-wg6n6 webserver-deployment-69b7448995- deployment-5324  637af549-7de1-4cb5-8a37-2831aa9b1dbc 4100876 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539b497 0xc00539b498}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dktnd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dktnd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-845c8977d9-24tp2" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-24tp2 webserver-deployment-845c8977d9- deployment-5324  e6016bc9-1349-4b02-8d67-16c2f747149a 4100825 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539b697 0xc00539b698}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l4m4t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l4m4t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-845c8977d9-4bxg9" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4bxg9 webserver-deployment-845c8977d9- deployment-5324  6c8657f5-2d05-4ad6-9add-00c6db536382 4100653 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:5efb84e7aeb0af79867c8cded4d3fe6b67122b755044f91dd3f8694222a45931 cni.projectcalico.org/podIP:172.16.100.144/32 cni.projectcalico.org/podIPs:172.16.100.144/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539b817 0xc00539b818}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.100.144\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4h4bl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4h4bl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:172.16.100.144,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1a6cca93b1d12459bc38545b0e78fb131c43dcb106956230671792a262cb936e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.100.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-845c8977d9-5p5wx" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-5p5wx webserver-deployment-845c8977d9- deployment-5324  023e69f5-c0d1-4f5d-b610-ac96e5a87f10 4100810 0 2023-04-18 05:07:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539ba37 0xc00539ba38}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q9nnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q9nnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.231: INFO: Pod "webserver-deployment-845c8977d9-6lf42" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-6lf42 webserver-deployment-845c8977d9- deployment-5324  d187aba6-5731-40e2-8c05-45edfefc8ec6 4100647 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:57b35cb2ddf6ad472c136f8a43e25b7aeef04d09ebacb8ea1a17c86d9feb0ae3 cni.projectcalico.org/podIP:172.16.100.153/32 cni.projectcalico.org/podIPs:172.16.100.153/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539bba7 0xc00539bba8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.100.153\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8kwwd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8kwwd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:172.16.100.153,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://15fdb588ee8f45e38ec8084f887e28b6bb6df501d536a258a179809a3df02b20,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.100.153,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.231: INFO: Pod "webserver-deployment-845c8977d9-6nf7k" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-6nf7k webserver-deployment-845c8977d9- deployment-5324  2849edab-cf1f-462a-ad3a-76bbb1ea1a40 4100636 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ccfda70f94c5216bcfef065d93cc86bf98ec8df4b7402dd3a8319ab955a4404f cni.projectcalico.org/podIP:172.16.125.41/32 cni.projectcalico.org/podIPs:172.16.125.41/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539bdd7 0xc00539bdd8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7cwrr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7cwrr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.41,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://4f8fe119485c3b4825189a6be93c1a12e801327f62f5d70d1c48971942f93471,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.231: INFO: Pod "webserver-deployment-845c8977d9-d62xq" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-d62xq webserver-deployment-845c8977d9- deployment-5324  8eca132f-8a40-47bf-98c2-80feed3a7184 4100878 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539bfe7 0xc00539bfe8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lbjmz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lbjmz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:,StartTime:2023-04-18 05:07:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.231: INFO: Pod "webserver-deployment-845c8977d9-gsf2l" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gsf2l webserver-deployment-845c8977d9- deployment-5324  2f08649e-5cb7-42f5-abeb-55ddfb35eaad 4100835 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e061b7 0xc005e061b8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d4nt4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d4nt4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.231: INFO: Pod "webserver-deployment-845c8977d9-kgdhc" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kgdhc webserver-deployment-845c8977d9- deployment-5324  ab434917-6ad5-4799-a6bc-18863cd92f5f 4100669 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ebd800ce8f14e575c29484ce4547efe3915544418dc666e9a542bc6cfa8ca9f2 cni.projectcalico.org/podIP:172.16.125.43/32 cni.projectcalico.org/podIPs:172.16.125.43/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06347 0xc005e06348}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.43\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-glvgm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-glvgm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.43,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://099c8c0e1b875d385ec8f3bc4bae59cca76f23f01d2a5d51c7f80ee5ca09c4ea,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.232: INFO: Pod "webserver-deployment-845c8977d9-kwc57" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-kwc57 webserver-deployment-845c8977d9- deployment-5324  09b96e72-c795-41bd-a227-4b7f36fe2c1c 4100700 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:839ec9568d49d0e49538fddcec6e52c1d8d4fe765ff51aedd0f28323e9fb36f0 cni.projectcalico.org/podIP:172.16.144.52/32 cni.projectcalico.org/podIPs:172.16.144.52/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06577 0xc005e06578}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.144.52\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6l698,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6l698,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:172.16.144.52,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://53250ea70e860989eeda397df27fe92c65396463149beccd1974b264c4a2f7ad,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.144.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.232: INFO: Pod "webserver-deployment-845c8977d9-md2kq" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-md2kq webserver-deployment-845c8977d9- deployment-5324  d6afc010-d397-4564-9eee-42bcaa1b799b 4100631 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:c4606f01751469a70379b26ddebfb627ab940affbed9801d551458925bdf16db cni.projectcalico.org/podIP:172.16.100.185/32 cni.projectcalico.org/podIPs:172.16.100.185/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06797 0xc005e06798}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.100.185\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g49n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g49n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:172.16.100.185,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a8fa08fdbecc1876295c44acd5accb4c126286483161d300d59bcd2bf933b08f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.100.185,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.232: INFO: Pod "webserver-deployment-845c8977d9-p7mrn" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-p7mrn webserver-deployment-845c8977d9- deployment-5324  55504a86-747d-4434-882e-ab9c6471990a 4100642 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:92802fb8562985fe4cd2b33b88524290a72fa6d16223ff483b2e67477a8f1127 cni.projectcalico.org/podIP:172.16.144.53/32 cni.projectcalico.org/podIPs:172.16.144.53/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e069e7 0xc005e069e8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.144.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mxgg5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mxgg5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:172.16.144.53,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8c35181acd8a6359f0dfc4c8ad40f2046ea25ec7c168e93582ecafbd54c702c1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.144.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.232: INFO: Pod "webserver-deployment-845c8977d9-qsg78" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qsg78 webserver-deployment-845c8977d9- deployment-5324  4be80af8-8719-4071-8095-6ad8ec108f83 4100834 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06c07 0xc005e06c08}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cmfzg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cmfzg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.232: INFO: Pod "webserver-deployment-845c8977d9-rgwql" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-rgwql webserver-deployment-845c8977d9- deployment-5324  3ae293f4-9f8d-4146-9e01-6b048565ab22 4100879 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06d87 0xc005e06d88}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-skfbv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-skfbv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:07:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-sghq9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-sghq9 webserver-deployment-845c8977d9- deployment-5324  18814efd-9e8c-451e-97c7-f90225e089d6 4100854 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06f77 0xc005e06f78}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-shbpf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-shbpf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-tcfg4" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tcfg4 webserver-deployment-845c8977d9- deployment-5324  738edb66-c5e4-4b65-9e18-c40279db4f24 4100853 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e070f7 0xc005e070f8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-78jlm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-78jlm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-tqnp4" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tqnp4 webserver-deployment-845c8977d9- deployment-5324  e3720927-b06e-4a8d-be11-6e83a2693ef3 4100833 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e07287 0xc005e07288}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qvbgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qvbgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-v8lrr" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-v8lrr webserver-deployment-845c8977d9- deployment-5324  6692c27e-04ee-48d1-b0a8-81f6abacffab 4100855 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e073f7 0xc005e073f8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xlll5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xlll5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-vv5h8" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vv5h8 webserver-deployment-845c8977d9- deployment-5324  040bc0bd-023d-455d-8f73-f5b796bd8686 4100862 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e07567 0xc005e07568}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8qk6m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8qk6m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-wf52f" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wf52f webserver-deployment-845c8977d9- deployment-5324  6b262b03-3d01-4a87-97b9-14798e8796bb 4100670 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:553fd1a1e2eaebf257850186ede9c1a1e59182910451ba44ca3526d72ab44e6a cni.projectcalico.org/podIP:172.16.144.48/32 cni.projectcalico.org/podIPs:172.16.144.48/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e076f7 0xc005e076f8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.144.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwl8k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwl8k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:172.16.144.48,StartTime:2023-04-18 05:07:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://dd51a5373aad77f99a47a8dae6d774b080304a1acdfb731ce8d8018c53adce01,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.144.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-zrh2k" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zrh2k webserver-deployment-845c8977d9- deployment-5324  6782bf1f-0bbc-46bf-b79a-9d8859ee124f 4100857 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e07907 0xc005e07908}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8hn6l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8hn6l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 05:07:48.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5324" for this suite. 04/18/23 05:07:48.705
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":154,"skipped":2717,"failed":0}
------------------------------
â€¢ [SLOW TEST] [19.145 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:07:30.208
    Apr 18 05:07:30.208: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename deployment 04/18/23 05:07:30.209
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:07:30.254
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:07:30.257
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Apr 18 05:07:30.265: INFO: Creating deployment "webserver-deployment"
    Apr 18 05:07:30.281: INFO: Waiting for observed generation 1
    Apr 18 05:07:32.472: INFO: Waiting for all required pods to come up
    Apr 18 05:07:32.734: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 04/18/23 05:07:32.734
    Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-zmcgx" in namespace "deployment-5324" to be "running"
    Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-6lf42" in namespace "deployment-5324" to be "running"
    Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-kwc57" in namespace "deployment-5324" to be "running"
    Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-4bxg9" in namespace "deployment-5324" to be "running"
    Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-p7mrn" in namespace "deployment-5324" to be "running"
    Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-9lxbg" in namespace "deployment-5324" to be "running"
    Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-kgdhc" in namespace "deployment-5324" to be "running"
    Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-6nf7k" in namespace "deployment-5324" to be "running"
    Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-wf52f" in namespace "deployment-5324" to be "running"
    Apr 18 05:07:32.734: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-md2kq" in namespace "deployment-5324" to be "running"
    Apr 18 05:07:32.764: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Pending", Reason="", readiness=false. Elapsed: 30.098513ms
    Apr 18 05:07:32.764: INFO: Pod "webserver-deployment-845c8977d9-9lxbg": Phase="Pending", Reason="", readiness=false. Elapsed: 30.004689ms
    Apr 18 05:07:32.764: INFO: Pod "webserver-deployment-845c8977d9-p7mrn": Phase="Pending", Reason="", readiness=false. Elapsed: 30.112776ms
    Apr 18 05:07:32.764: INFO: Pod "webserver-deployment-845c8977d9-wf52f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.095283ms
    Apr 18 05:07:32.764: INFO: Pod "webserver-deployment-845c8977d9-md2kq": Phase="Pending", Reason="", readiness=false. Elapsed: 30.192697ms
    Apr 18 05:07:32.765: INFO: Pod "webserver-deployment-845c8977d9-6nf7k": Phase="Pending", Reason="", readiness=false. Elapsed: 30.473733ms
    Apr 18 05:07:32.765: INFO: Pod "webserver-deployment-845c8977d9-kwc57": Phase="Pending", Reason="", readiness=false. Elapsed: 30.578918ms
    Apr 18 05:07:33.106: INFO: Pod "webserver-deployment-845c8977d9-kgdhc": Phase="Pending", Reason="", readiness=false. Elapsed: 371.747393ms
    Apr 18 05:07:33.106: INFO: Pod "webserver-deployment-845c8977d9-4bxg9": Phase="Pending", Reason="", readiness=false. Elapsed: 371.804839ms
    Apr 18 05:07:33.106: INFO: Pod "webserver-deployment-845c8977d9-6lf42": Phase="Pending", Reason="", readiness=false. Elapsed: 371.842426ms
    Apr 18 05:07:34.956: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.221837819s
    Apr 18 05:07:34.988: INFO: Pod "webserver-deployment-845c8977d9-6nf7k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.25343323s
    Apr 18 05:07:34.988: INFO: Pod "webserver-deployment-845c8977d9-wf52f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.253457217s
    Apr 18 05:07:35.051: INFO: Pod "webserver-deployment-845c8977d9-9lxbg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.3169358s
    Apr 18 05:07:35.051: INFO: Pod "webserver-deployment-845c8977d9-md2kq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.316925141s
    Apr 18 05:07:35.080: INFO: Pod "webserver-deployment-845c8977d9-p7mrn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.345502241s
    Apr 18 05:07:35.080: INFO: Pod "webserver-deployment-845c8977d9-kwc57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.345630571s
    Apr 18 05:07:35.248: INFO: Pod "webserver-deployment-845c8977d9-4bxg9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.513594771s
    Apr 18 05:07:35.254: INFO: Pod "webserver-deployment-845c8977d9-6lf42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.520410497s
    Apr 18 05:07:35.268: INFO: Pod "webserver-deployment-845c8977d9-kgdhc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.533846862s
    Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Pending", Reason="", readiness=false. Elapsed: 4.176594563s
    Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-6nf7k": Phase="Running", Reason="", readiness=true. Elapsed: 4.176625879s
    Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-6nf7k" satisfied condition "running"
    Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-p7mrn": Phase="Running", Reason="", readiness=true. Elapsed: 4.176739324s
    Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-p7mrn" satisfied condition "running"
    Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-wf52f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.176769906s
    Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-md2kq": Phase="Running", Reason="", readiness=true. Elapsed: 4.176737936s
    Apr 18 05:07:36.911: INFO: Pod "webserver-deployment-845c8977d9-md2kq" satisfied condition "running"
    Apr 18 05:07:36.938: INFO: Pod "webserver-deployment-845c8977d9-kwc57": Phase="Pending", Reason="", readiness=false. Elapsed: 4.204271631s
    Apr 18 05:07:36.938: INFO: Pod "webserver-deployment-845c8977d9-9lxbg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.204304525s
    Apr 18 05:07:37.181: INFO: Pod "webserver-deployment-845c8977d9-kgdhc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.447305151s
    Apr 18 05:07:37.230: INFO: Pod "webserver-deployment-845c8977d9-6lf42": Phase="Running", Reason="", readiness=true. Elapsed: 4.496246754s
    Apr 18 05:07:37.230: INFO: Pod "webserver-deployment-845c8977d9-6lf42" satisfied condition "running"
    Apr 18 05:07:37.237: INFO: Pod "webserver-deployment-845c8977d9-4bxg9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.502702267s
    Apr 18 05:07:38.941: INFO: Pod "webserver-deployment-845c8977d9-9lxbg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.206851223s
    Apr 18 05:07:38.941: INFO: Pod "webserver-deployment-845c8977d9-wf52f": Phase="Running", Reason="", readiness=true. Elapsed: 6.206832557s
    Apr 18 05:07:38.941: INFO: Pod "webserver-deployment-845c8977d9-wf52f" satisfied condition "running"
    Apr 18 05:07:38.941: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.207335808s
    Apr 18 05:07:39.066: INFO: Pod "webserver-deployment-845c8977d9-kwc57": Phase="Pending", Reason="", readiness=false. Elapsed: 6.331777865s
    Apr 18 05:07:39.124: INFO: Pod "webserver-deployment-845c8977d9-kgdhc": Phase="Running", Reason="", readiness=true. Elapsed: 6.389767078s
    Apr 18 05:07:39.124: INFO: Pod "webserver-deployment-845c8977d9-kgdhc" satisfied condition "running"
    Apr 18 05:07:39.130: INFO: Pod "webserver-deployment-845c8977d9-4bxg9": Phase="Running", Reason="", readiness=true. Elapsed: 6.395808351s
    Apr 18 05:07:39.130: INFO: Pod "webserver-deployment-845c8977d9-4bxg9" satisfied condition "running"
    Apr 18 05:07:40.832: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.097656844s
    Apr 18 05:07:40.832: INFO: Pod "webserver-deployment-845c8977d9-kwc57": Phase="Running", Reason="", readiness=true. Elapsed: 8.09762891s
    Apr 18 05:07:40.832: INFO: Pod "webserver-deployment-845c8977d9-kwc57" satisfied condition "running"
    Apr 18 05:07:40.842: INFO: Pod "webserver-deployment-845c8977d9-9lxbg": Phase="Running", Reason="", readiness=true. Elapsed: 8.108201993s
    Apr 18 05:07:40.842: INFO: Pod "webserver-deployment-845c8977d9-9lxbg" satisfied condition "running"
    Apr 18 05:07:42.774: INFO: Pod "webserver-deployment-845c8977d9-zmcgx": Phase="Running", Reason="", readiness=true. Elapsed: 10.039520269s
    Apr 18 05:07:42.774: INFO: Pod "webserver-deployment-845c8977d9-zmcgx" satisfied condition "running"
    Apr 18 05:07:42.774: INFO: Waiting for deployment "webserver-deployment" to complete
    Apr 18 05:07:42.779: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Apr 18 05:07:42.830: INFO: Updating deployment webserver-deployment
    Apr 18 05:07:42.830: INFO: Waiting for observed generation 2
    Apr 18 05:07:45.280: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Apr 18 05:07:45.446: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Apr 18 05:07:45.466: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 18 05:07:45.489: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Apr 18 05:07:45.489: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Apr 18 05:07:45.491: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 18 05:07:45.502: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Apr 18 05:07:45.502: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Apr 18 05:07:45.656: INFO: Updating deployment webserver-deployment
    Apr 18 05:07:45.656: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Apr 18 05:07:45.662: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Apr 18 05:07:45.974: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 05:07:47.236: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-5324  d00fee9c-f7b4-4416-9a94-8893734b50c2 4100799 3 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006e67538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2023-04-18 05:07:45 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-18 05:07:45 +0000 UTC,LastTransitionTime:2023-04-18 05:07:45 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Apr 18 05:07:47.765: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-5324  e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 4100856 3 2023-04-18 05:07:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment d00fee9c-f7b4-4416-9a94-8893734b50c2 0xc005cbf787 0xc005cbf788}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d00fee9c-f7b4-4416-9a94-8893734b50c2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005cbf838 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 05:07:47.765: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Apr 18 05:07:47.765: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-5324  fb90255f-c72f-42be-8fe9-58c8e289811e 4100860 3 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment d00fee9c-f7b4-4416-9a94-8893734b50c2 0xc005cbf897 0xc005cbf898}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d00fee9c-f7b4-4416-9a94-8893734b50c2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005cbf928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 05:07:48.228: INFO: Pod "webserver-deployment-69b7448995-268v2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-268v2 webserver-deployment-69b7448995- deployment-5324  7a9e1789-7775-4b28-8da5-92e086583200 4100850 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc005cbfe27 0xc005cbfe28}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dphcd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dphcd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.228: INFO: Pod "webserver-deployment-69b7448995-68q2c" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-68q2c webserver-deployment-69b7448995- deployment-5324  7adb2d88-2989-42e0-815b-879c6f8d0d07 4100822 0 2023-04-18 05:07:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc005cbffa7 0xc005cbffa8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fzhx2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fzhx2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.228: INFO: Pod "webserver-deployment-69b7448995-6bl2n" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-6bl2n webserver-deployment-69b7448995- deployment-5324  2824617b-7364-46fb-91e1-0448b65ecd1a 4100882 0 2023-04-18 05:07:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:ccfe49b8a0171d887c36ae948ce0a06057d423f36819775c1f5393046359d0df cni.projectcalico.org/podIP:172.16.100.158/32 cni.projectcalico.org/podIPs:172.16.100.158/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539a117 0xc00539a118}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qbcjs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qbcjs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:07:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.228: INFO: Pod "webserver-deployment-69b7448995-7qqm6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-7qqm6 webserver-deployment-69b7448995- deployment-5324  ec2a56e9-1ae0-4606-94fc-f8936c1b46c1 4100848 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539a327 0xc00539a328}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hc5jj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hc5jj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-87s6m" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-87s6m webserver-deployment-69b7448995- deployment-5324  6f0bc070-b4cf-4899-b8a8-953fc4eaf041 4100785 0 2023-04-18 05:07:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:372282c27c5260cdaf46cc588d656fe311db138f9cfb6befc3be8f9bb85a6a63 cni.projectcalico.org/podIP:172.16.144.27/32 cni.projectcalico.org/podIPs:172.16.144.27/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539a547 0xc00539a548}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-v6nlp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-v6nlp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:,StartTime:2023-04-18 05:07:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-8z4dx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-8z4dx webserver-deployment-69b7448995- deployment-5324  6b92c6ee-bd3b-4db8-bfa2-fa6a88a9e4be 4100832 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539a757 0xc00539a758}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-956pn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-956pn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-dthwr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-dthwr webserver-deployment-69b7448995- deployment-5324  f569d0b5-5103-46dd-a881-1112924a1f41 4100817 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539a947 0xc00539a948}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gxscq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gxscq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-fgprh" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fgprh webserver-deployment-69b7448995- deployment-5324  828a78ea-3072-4555-af12-69bad0d60510 4100859 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539aac7 0xc00539aac8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6d56b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6d56b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-lbk2l" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lbk2l webserver-deployment-69b7448995- deployment-5324  3cdb93b7-c75a-4c98-9f05-2abf70ba41a9 4100869 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539acc7 0xc00539acc8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fk2f8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fk2f8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.229: INFO: Pod "webserver-deployment-69b7448995-mctsq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-mctsq webserver-deployment-69b7448995- deployment-5324  a24a3f39-50ed-4f74-8254-ba15cb021af5 4100736 0 2023-04-18 05:07:42 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539aeb7 0xc00539aeb8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7wrlp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7wrlp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:,StartTime:2023-04-18 05:07:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-69b7448995-tt97q" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-tt97q webserver-deployment-69b7448995- deployment-5324  b101f651-c18d-4315-99f9-9493a9c6310b 4100771 0 2023-04-18 05:07:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539b0a7 0xc00539b0a8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:44 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dcv4f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dcv4f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:,StartTime:2023-04-18 05:07:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-69b7448995-vqsgc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-vqsgc webserver-deployment-69b7448995- deployment-5324  17d8eaf6-1b78-4877-a7c7-cd3208ff4ca0 4100775 0 2023-04-18 05:07:44 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539b2a7 0xc00539b2a8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:44 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p47mr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p47mr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:,StartTime:2023-04-18 05:07:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-69b7448995-wg6n6" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-wg6n6 webserver-deployment-69b7448995- deployment-5324  637af549-7de1-4cb5-8a37-2831aa9b1dbc 4100876 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e 0xc00539b497 0xc00539b498}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e8afc5f8-5d04-46c4-9e3a-50a8cbd40f7e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dktnd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dktnd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:07:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-845c8977d9-24tp2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-24tp2 webserver-deployment-845c8977d9- deployment-5324  e6016bc9-1349-4b02-8d67-16c2f747149a 4100825 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539b697 0xc00539b698}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-l4m4t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-l4m4t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-845c8977d9-4bxg9" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4bxg9 webserver-deployment-845c8977d9- deployment-5324  6c8657f5-2d05-4ad6-9add-00c6db536382 4100653 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:5efb84e7aeb0af79867c8cded4d3fe6b67122b755044f91dd3f8694222a45931 cni.projectcalico.org/podIP:172.16.100.144/32 cni.projectcalico.org/podIPs:172.16.100.144/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539b817 0xc00539b818}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.100.144\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4h4bl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4h4bl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:172.16.100.144,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1a6cca93b1d12459bc38545b0e78fb131c43dcb106956230671792a262cb936e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.100.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.230: INFO: Pod "webserver-deployment-845c8977d9-5p5wx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-5p5wx webserver-deployment-845c8977d9- deployment-5324  023e69f5-c0d1-4f5d-b610-ac96e5a87f10 4100810 0 2023-04-18 05:07:45 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539ba37 0xc00539ba38}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:45 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q9nnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q9nnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.231: INFO: Pod "webserver-deployment-845c8977d9-6lf42" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-6lf42 webserver-deployment-845c8977d9- deployment-5324  d187aba6-5731-40e2-8c05-45edfefc8ec6 4100647 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:57b35cb2ddf6ad472c136f8a43e25b7aeef04d09ebacb8ea1a17c86d9feb0ae3 cni.projectcalico.org/podIP:172.16.100.153/32 cni.projectcalico.org/podIPs:172.16.100.153/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539bba7 0xc00539bba8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.100.153\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8kwwd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8kwwd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:172.16.100.153,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://15fdb588ee8f45e38ec8084f887e28b6bb6df501d536a258a179809a3df02b20,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.100.153,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.231: INFO: Pod "webserver-deployment-845c8977d9-6nf7k" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-6nf7k webserver-deployment-845c8977d9- deployment-5324  2849edab-cf1f-462a-ad3a-76bbb1ea1a40 4100636 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ccfda70f94c5216bcfef065d93cc86bf98ec8df4b7402dd3a8319ab955a4404f cni.projectcalico.org/podIP:172.16.125.41/32 cni.projectcalico.org/podIPs:172.16.125.41/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539bdd7 0xc00539bdd8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7cwrr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7cwrr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.41,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://4f8fe119485c3b4825189a6be93c1a12e801327f62f5d70d1c48971942f93471,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.231: INFO: Pod "webserver-deployment-845c8977d9-d62xq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-d62xq webserver-deployment-845c8977d9- deployment-5324  8eca132f-8a40-47bf-98c2-80feed3a7184 4100878 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc00539bfe7 0xc00539bfe8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lbjmz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lbjmz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:,StartTime:2023-04-18 05:07:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.231: INFO: Pod "webserver-deployment-845c8977d9-gsf2l" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gsf2l webserver-deployment-845c8977d9- deployment-5324  2f08649e-5cb7-42f5-abeb-55ddfb35eaad 4100835 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e061b7 0xc005e061b8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d4nt4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d4nt4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.231: INFO: Pod "webserver-deployment-845c8977d9-kgdhc" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kgdhc webserver-deployment-845c8977d9- deployment-5324  ab434917-6ad5-4799-a6bc-18863cd92f5f 4100669 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ebd800ce8f14e575c29484ce4547efe3915544418dc666e9a542bc6cfa8ca9f2 cni.projectcalico.org/podIP:172.16.125.43/32 cni.projectcalico.org/podIPs:172.16.125.43/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06347 0xc005e06348}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.43\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-glvgm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-glvgm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.43,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://099c8c0e1b875d385ec8f3bc4bae59cca76f23f01d2a5d51c7f80ee5ca09c4ea,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.232: INFO: Pod "webserver-deployment-845c8977d9-kwc57" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-kwc57 webserver-deployment-845c8977d9- deployment-5324  09b96e72-c795-41bd-a227-4b7f36fe2c1c 4100700 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:839ec9568d49d0e49538fddcec6e52c1d8d4fe765ff51aedd0f28323e9fb36f0 cni.projectcalico.org/podIP:172.16.144.52/32 cni.projectcalico.org/podIPs:172.16.144.52/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06577 0xc005e06578}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.144.52\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6l698,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6l698,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:172.16.144.52,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://53250ea70e860989eeda397df27fe92c65396463149beccd1974b264c4a2f7ad,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.144.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.232: INFO: Pod "webserver-deployment-845c8977d9-md2kq" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-md2kq webserver-deployment-845c8977d9- deployment-5324  d6afc010-d397-4564-9eee-42bcaa1b799b 4100631 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:c4606f01751469a70379b26ddebfb627ab940affbed9801d551458925bdf16db cni.projectcalico.org/podIP:172.16.100.185/32 cni.projectcalico.org/podIPs:172.16.100.185/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06797 0xc005e06798}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:35 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.100.185\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g49n4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g49n4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:172.16.100.185,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a8fa08fdbecc1876295c44acd5accb4c126286483161d300d59bcd2bf933b08f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.100.185,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.232: INFO: Pod "webserver-deployment-845c8977d9-p7mrn" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-p7mrn webserver-deployment-845c8977d9- deployment-5324  55504a86-747d-4434-882e-ab9c6471990a 4100642 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:92802fb8562985fe4cd2b33b88524290a72fa6d16223ff483b2e67477a8f1127 cni.projectcalico.org/podIP:172.16.144.53/32 cni.projectcalico.org/podIPs:172.16.144.53/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e069e7 0xc005e069e8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.144.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mxgg5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mxgg5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:172.16.144.53,StartTime:2023-04-18 05:07:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8c35181acd8a6359f0dfc4c8ad40f2046ea25ec7c168e93582ecafbd54c702c1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.144.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.232: INFO: Pod "webserver-deployment-845c8977d9-qsg78" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qsg78 webserver-deployment-845c8977d9- deployment-5324  4be80af8-8719-4071-8095-6ad8ec108f83 4100834 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06c07 0xc005e06c08}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cmfzg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cmfzg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.232: INFO: Pod "webserver-deployment-845c8977d9-rgwql" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-rgwql webserver-deployment-845c8977d9- deployment-5324  3ae293f4-9f8d-4146-9e01-6b048565ab22 4100879 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06d87 0xc005e06d88}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:07:47 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-skfbv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-skfbv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:07:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-sghq9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-sghq9 webserver-deployment-845c8977d9- deployment-5324  18814efd-9e8c-451e-97c7-f90225e089d6 4100854 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e06f77 0xc005e06f78}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-shbpf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-shbpf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-tcfg4" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tcfg4 webserver-deployment-845c8977d9- deployment-5324  738edb66-c5e4-4b65-9e18-c40279db4f24 4100853 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e070f7 0xc005e070f8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-78jlm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-78jlm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-tqnp4" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tqnp4 webserver-deployment-845c8977d9- deployment-5324  e3720927-b06e-4a8d-be11-6e83a2693ef3 4100833 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e07287 0xc005e07288}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qvbgh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qvbgh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-v8lrr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-v8lrr webserver-deployment-845c8977d9- deployment-5324  6692c27e-04ee-48d1-b0a8-81f6abacffab 4100855 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e073f7 0xc005e073f8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xlll5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xlll5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-vv5h8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vv5h8 webserver-deployment-845c8977d9- deployment-5324  040bc0bd-023d-455d-8f73-f5b796bd8686 4100862 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e07567 0xc005e07568}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8qk6m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8qk6m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-wf52f" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wf52f webserver-deployment-845c8977d9- deployment-5324  6b262b03-3d01-4a87-97b9-14798e8796bb 4100670 0 2023-04-18 05:07:30 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:553fd1a1e2eaebf257850186ede9c1a1e59182910451ba44ca3526d72ab44e6a cni.projectcalico.org/podIP:172.16.144.48/32 cni.projectcalico.org/podIPs:172.16.144.48/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e076f7 0xc005e076f8}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:07:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:07:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.144.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zwl8k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zwl8k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.109,PodIP:172.16.144.48,StartTime:2023-04-18 05:07:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:07:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://dd51a5373aad77f99a47a8dae6d774b080304a1acdfb731ce8d8018c53adce01,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.144.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:07:48.233: INFO: Pod "webserver-deployment-845c8977d9-zrh2k" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zrh2k webserver-deployment-845c8977d9- deployment-5324  6782bf1f-0bbc-46bf-b79a-9d8859ee124f 4100857 0 2023-04-18 05:07:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 fb90255f-c72f-42be-8fe9-58c8e289811e 0xc005e07907 0xc005e07908}] [] [{kube-controller-manager Update v1 2023-04-18 05:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb90255f-c72f-42be-8fe9-58c8e289811e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8hn6l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8hn6l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-209,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:07:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 05:07:48.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-5324" for this suite. 04/18/23 05:07:48.705
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:07:49.353
Apr 18 05:07:49.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename runtimeclass 04/18/23 05:07:49.354
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:07:51.025
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:07:51.027
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Apr 18 05:07:51.427: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-2927 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 18 05:07:52.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2927" for this suite. 04/18/23 05:07:52.383
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":155,"skipped":2718,"failed":0}
------------------------------
â€¢ [3.236 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:07:49.353
    Apr 18 05:07:49.353: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename runtimeclass 04/18/23 05:07:49.354
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:07:51.025
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:07:51.027
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Apr 18 05:07:51.427: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-2927 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 18 05:07:52.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-2927" for this suite. 04/18/23 05:07:52.383
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:07:52.591
Apr 18 05:07:52.591: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-probe 04/18/23 05:07:52.592
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:07:53.092
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:07:53.095
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Apr 18 05:07:53.269: INFO: Waiting up to 5m0s for pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9" in namespace "container-probe-9927" to be "running and ready"
Apr 18 05:07:54.110: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 841.145631ms
Apr 18 05:07:54.110: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:07:56.115: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.845441897s
Apr 18 05:07:56.115: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:07:58.185: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.916111319s
Apr 18 05:07:58.185: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:08:00.221: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.952151019s
Apr 18 05:08:00.221: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:08:02.220: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.950757841s
Apr 18 05:08:02.220: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:08:04.326: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.057242144s
Apr 18 05:08:04.326: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:08:06.188: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 12.919166393s
Apr 18 05:08:06.188: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
Apr 18 05:08:08.271: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 15.002104364s
Apr 18 05:08:08.271: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
Apr 18 05:08:10.115: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 16.846172298s
Apr 18 05:08:10.115: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
Apr 18 05:08:12.155: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 18.88598103s
Apr 18 05:08:12.155: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
Apr 18 05:08:14.179: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 20.909477893s
Apr 18 05:08:14.179: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
Apr 18 05:08:16.125: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 22.855444131s
Apr 18 05:08:16.125: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
Apr 18 05:08:18.507: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 25.237544022s
Apr 18 05:08:18.507: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
Apr 18 05:08:20.279: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 27.010017741s
Apr 18 05:08:20.279: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
Apr 18 05:08:22.115: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 28.845367122s
Apr 18 05:08:22.115: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
Apr 18 05:08:24.167: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 30.898197355s
Apr 18 05:08:24.167: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
Apr 18 05:08:26.115: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=true. Elapsed: 32.845480421s
Apr 18 05:08:26.115: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = true)
Apr 18 05:08:26.115: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9" satisfied condition "running and ready"
Apr 18 05:08:26.118: INFO: Container started at 2023-04-18 05:08:04 +0000 UTC, pod became ready at 2023-04-18 05:08:24 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 05:08:26.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9927" for this suite. 04/18/23 05:08:26.122
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":156,"skipped":2741,"failed":0}
------------------------------
â€¢ [SLOW TEST] [33.555 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:07:52.591
    Apr 18 05:07:52.591: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-probe 04/18/23 05:07:52.592
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:07:53.092
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:07:53.095
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Apr 18 05:07:53.269: INFO: Waiting up to 5m0s for pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9" in namespace "container-probe-9927" to be "running and ready"
    Apr 18 05:07:54.110: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 841.145631ms
    Apr 18 05:07:54.110: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:07:56.115: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.845441897s
    Apr 18 05:07:56.115: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:07:58.185: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.916111319s
    Apr 18 05:07:58.185: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:08:00.221: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.952151019s
    Apr 18 05:08:00.221: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:08:02.220: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.950757841s
    Apr 18 05:08:02.220: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:08:04.326: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.057242144s
    Apr 18 05:08:04.326: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:08:06.188: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 12.919166393s
    Apr 18 05:08:06.188: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
    Apr 18 05:08:08.271: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 15.002104364s
    Apr 18 05:08:08.271: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
    Apr 18 05:08:10.115: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 16.846172298s
    Apr 18 05:08:10.115: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
    Apr 18 05:08:12.155: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 18.88598103s
    Apr 18 05:08:12.155: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
    Apr 18 05:08:14.179: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 20.909477893s
    Apr 18 05:08:14.179: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
    Apr 18 05:08:16.125: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 22.855444131s
    Apr 18 05:08:16.125: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
    Apr 18 05:08:18.507: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 25.237544022s
    Apr 18 05:08:18.507: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
    Apr 18 05:08:20.279: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 27.010017741s
    Apr 18 05:08:20.279: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
    Apr 18 05:08:22.115: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 28.845367122s
    Apr 18 05:08:22.115: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
    Apr 18 05:08:24.167: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=false. Elapsed: 30.898197355s
    Apr 18 05:08:24.167: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = false)
    Apr 18 05:08:26.115: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9": Phase="Running", Reason="", readiness=true. Elapsed: 32.845480421s
    Apr 18 05:08:26.115: INFO: The phase of Pod test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9 is Running (Ready = true)
    Apr 18 05:08:26.115: INFO: Pod "test-webserver-74590efe-905b-4a52-ac51-985d5b1cd8c9" satisfied condition "running and ready"
    Apr 18 05:08:26.118: INFO: Container started at 2023-04-18 05:08:04 +0000 UTC, pod became ready at 2023-04-18 05:08:24 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 05:08:26.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9927" for this suite. 04/18/23 05:08:26.122
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:08:26.147
Apr 18 05:08:26.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename deployment 04/18/23 05:08:26.148
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:08:26.282
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:08:26.285
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 04/18/23 05:08:26.294
STEP: waiting for Deployment to be created 04/18/23 05:08:26.317
STEP: waiting for all Replicas to be Ready 04/18/23 05:08:26.318
Apr 18 05:08:26.319: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 05:08:26.319: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 05:08:26.480: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 05:08:26.480: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 05:08:26.607: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 05:08:26.607: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 05:08:26.792: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 05:08:26.793: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 18 05:08:29.288: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 18 05:08:29.288: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 18 05:08:30.120: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 04/18/23 05:08:30.12
W0418 05:08:30.184628      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 18 05:08:30.186: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 04/18/23 05:08:30.186
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:30.299: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:30.300: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:30.491: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:30.491: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:30.801: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:30.801: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:30.968: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:30.968: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:33.481: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:33.481: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:34.067: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
STEP: listing Deployments 04/18/23 05:08:34.067
Apr 18 05:08:34.078: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 04/18/23 05:08:34.078
Apr 18 05:08:34.121: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 04/18/23 05:08:34.121
Apr 18 05:08:34.126: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 05:08:34.309: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 05:08:34.498: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 05:08:34.686: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 05:08:34.952: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 05:08:35.143: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 05:08:38.447: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 05:08:38.828: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 05:08:39.104: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 05:08:39.228: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 18 05:08:42.559: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 04/18/23 05:08:43.642
STEP: fetching the DeploymentStatus 04/18/23 05:08:43.828
Apr 18 05:08:43.833: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 3
STEP: deleting the Deployment 04/18/23 05:08:43.834
Apr 18 05:08:43.924: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
Apr 18 05:08:43.925: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 05:08:43.928: INFO: Log out all the ReplicaSets if there is no deployment created
Apr 18 05:08:43.931: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-8379  0b4597d4-bc81-44ab-95a7-b522114580cb 4101707 4 2023-04-18 05:08:30 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 36490aea-1cce-443e-a192-defec8bc570e 0xc00321c4a7 0xc00321c4a8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:08:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36490aea-1cce-443e-a192-defec8bc570e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:08:43 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00321c690 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Apr 18 05:08:44.055: INFO: pod: "test-deployment-54cc775c4b-fvfj9":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-fvfj9 test-deployment-54cc775c4b- deployment-8379  1326ef2a-ac58-46fe-aeec-ab821825f592 4101702 0 2023-04-18 05:08:30 +0000 UTC 2023-04-18 05:08:43 +0000 UTC 0xc005c01898 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:dcb36f1b092a3323f2eaf2e0910562c6bf6656a00bc7775caa19d9cd8b9805ec cni.projectcalico.org/podIP:172.16.125.46/32 cni.projectcalico.org/podIPs:172.16.125.46/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 0b4597d4-bc81-44ab-95a7-b522114580cb 0xc005c018e7 0xc005c018e8}] [] [{kube-controller-manager Update v1 2023-04-18 05:08:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0b4597d4-bc81-44ab-95a7-b522114580cb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:08:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:08:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.46\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rpsdp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rpsdp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.46,StartTime:2023-04-18 05:08:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:08:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://bb60b97b9f3fb58d6b85746845a34143510670155d7b91a3e4515a8d2d6e94b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.46,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 18 05:08:44.056: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-8379  4e6b4292-cb55-4be9-8ec6-1f35e1632c69 4101697 2 2023-04-18 05:08:34 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 36490aea-1cce-443e-a192-defec8bc570e 0xc00321cdb7 0xc00321cdb8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:08:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36490aea-1cce-443e-a192-defec8bc570e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:08:42 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00321d3d0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Apr 18 05:08:44.068: INFO: pod: "test-deployment-7c7d8d58c8-7s9c9":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-7s9c9 test-deployment-7c7d8d58c8- deployment-8379  6e4d6e36-8db4-46db-834f-bd027fec80f2 4101646 0 2023-04-18 05:08:34 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:db21758605ad7c5a0fa260f579487f57ce6f117faf37b64be6546d6f9372b574 cni.projectcalico.org/podIP:172.16.125.32/32 cni.projectcalico.org/podIPs:172.16.125.32/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 4e6b4292-cb55-4be9-8ec6-1f35e1632c69 0xc003a4b2c7 0xc003a4b2c8}] [] [{kube-controller-manager Update v1 2023-04-18 05:08:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4e6b4292-cb55-4be9-8ec6-1f35e1632c69\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:08:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:08:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.32\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gn6vv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gn6vv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.32,StartTime:2023-04-18 05:08:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:08:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://933709cb66046b31ef3774bda78b009c87312d32eb4405e40a5c72b3655248b1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.32,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 18 05:08:44.068: INFO: pod: "test-deployment-7c7d8d58c8-gqvjm":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-gqvjm test-deployment-7c7d8d58c8- deployment-8379  7e822ac2-453f-4dbd-b932-76a30a3ee0ed 4101696 0 2023-04-18 05:08:38 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:17ec7630755f495da2e4b97f55fdb5a6deb0eb60ea75f90aeca65692440ac8db cni.projectcalico.org/podIP:172.16.100.131/32 cni.projectcalico.org/podIPs:172.16.100.131/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 4e6b4292-cb55-4be9-8ec6-1f35e1632c69 0xc003a4b4f7 0xc003a4b4f8}] [] [{kube-controller-manager Update v1 2023-04-18 05:08:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4e6b4292-cb55-4be9-8ec6-1f35e1632c69\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:08:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:08:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.100.131\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wsct4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wsct4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:172.16.100.131,StartTime:2023-04-18 05:08:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:08:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f8c8befc1c4492af9678c3ae5bc4fe266c9b97b611a4ecbf7a9404352b555807,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.100.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Apr 18 05:08:44.068: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-8379  1958b374-caae-4645-8516-22ce990f2982 4101580 3 2023-04-18 05:08:26 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 36490aea-1cce-443e-a192-defec8bc570e 0xc00321d497 0xc00321d498}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:08:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36490aea-1cce-443e-a192-defec8bc570e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:08:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00321d690 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 05:08:44.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8379" for this suite. 04/18/23 05:08:44.198
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":157,"skipped":2766,"failed":0}
------------------------------
â€¢ [SLOW TEST] [18.104 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:08:26.147
    Apr 18 05:08:26.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename deployment 04/18/23 05:08:26.148
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:08:26.282
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:08:26.285
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 04/18/23 05:08:26.294
    STEP: waiting for Deployment to be created 04/18/23 05:08:26.317
    STEP: waiting for all Replicas to be Ready 04/18/23 05:08:26.318
    Apr 18 05:08:26.319: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 05:08:26.319: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 05:08:26.480: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 05:08:26.480: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 05:08:26.607: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 05:08:26.607: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 05:08:26.792: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 05:08:26.793: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 18 05:08:29.288: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 18 05:08:29.288: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 18 05:08:30.120: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 04/18/23 05:08:30.12
    W0418 05:08:30.184628      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 18 05:08:30.186: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 04/18/23 05:08:30.186
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 0
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:30.187: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:30.299: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:30.300: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:30.491: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:30.491: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:30.801: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:30.801: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:30.968: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:30.968: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:33.481: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:33.481: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:34.067: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    STEP: listing Deployments 04/18/23 05:08:34.067
    Apr 18 05:08:34.078: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 04/18/23 05:08:34.078
    Apr 18 05:08:34.121: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 04/18/23 05:08:34.121
    Apr 18 05:08:34.126: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 05:08:34.309: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 05:08:34.498: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 05:08:34.686: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 05:08:34.952: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 05:08:35.143: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 05:08:38.447: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 05:08:38.828: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 05:08:39.104: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 05:08:39.228: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 18 05:08:42.559: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 04/18/23 05:08:43.642
    STEP: fetching the DeploymentStatus 04/18/23 05:08:43.828
    Apr 18 05:08:43.833: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 1
    Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 2
    Apr 18 05:08:43.834: INFO: observed Deployment test-deployment in namespace deployment-8379 with ReadyReplicas 3
    STEP: deleting the Deployment 04/18/23 05:08:43.834
    Apr 18 05:08:43.924: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    Apr 18 05:08:43.925: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 05:08:43.928: INFO: Log out all the ReplicaSets if there is no deployment created
    Apr 18 05:08:43.931: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-8379  0b4597d4-bc81-44ab-95a7-b522114580cb 4101707 4 2023-04-18 05:08:30 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 36490aea-1cce-443e-a192-defec8bc570e 0xc00321c4a7 0xc00321c4a8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:08:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36490aea-1cce-443e-a192-defec8bc570e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:08:43 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00321c690 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Apr 18 05:08:44.055: INFO: pod: "test-deployment-54cc775c4b-fvfj9":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-fvfj9 test-deployment-54cc775c4b- deployment-8379  1326ef2a-ac58-46fe-aeec-ab821825f592 4101702 0 2023-04-18 05:08:30 +0000 UTC 2023-04-18 05:08:43 +0000 UTC 0xc005c01898 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[cni.projectcalico.org/containerID:dcb36f1b092a3323f2eaf2e0910562c6bf6656a00bc7775caa19d9cd8b9805ec cni.projectcalico.org/podIP:172.16.125.46/32 cni.projectcalico.org/podIPs:172.16.125.46/32] [{apps/v1 ReplicaSet test-deployment-54cc775c4b 0b4597d4-bc81-44ab-95a7-b522114580cb 0xc005c018e7 0xc005c018e8}] [] [{kube-controller-manager Update v1 2023-04-18 05:08:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0b4597d4-bc81-44ab-95a7-b522114580cb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:08:31 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:08:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.46\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rpsdp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rpsdp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.46,StartTime:2023-04-18 05:08:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:08:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://bb60b97b9f3fb58d6b85746845a34143510670155d7b91a3e4515a8d2d6e94b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.46,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 18 05:08:44.056: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-8379  4e6b4292-cb55-4be9-8ec6-1f35e1632c69 4101697 2 2023-04-18 05:08:34 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 36490aea-1cce-443e-a192-defec8bc570e 0xc00321cdb7 0xc00321cdb8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:08:38 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36490aea-1cce-443e-a192-defec8bc570e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:08:42 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00321d3d0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Apr 18 05:08:44.068: INFO: pod: "test-deployment-7c7d8d58c8-7s9c9":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-7s9c9 test-deployment-7c7d8d58c8- deployment-8379  6e4d6e36-8db4-46db-834f-bd027fec80f2 4101646 0 2023-04-18 05:08:34 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:db21758605ad7c5a0fa260f579487f57ce6f117faf37b64be6546d6f9372b574 cni.projectcalico.org/podIP:172.16.125.32/32 cni.projectcalico.org/podIPs:172.16.125.32/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 4e6b4292-cb55-4be9-8ec6-1f35e1632c69 0xc003a4b2c7 0xc003a4b2c8}] [] [{kube-controller-manager Update v1 2023-04-18 05:08:34 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4e6b4292-cb55-4be9-8ec6-1f35e1632c69\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:08:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:08:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.32\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gn6vv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gn6vv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.32,StartTime:2023-04-18 05:08:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:08:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://933709cb66046b31ef3774bda78b009c87312d32eb4405e40a5c72b3655248b1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.32,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 18 05:08:44.068: INFO: pod: "test-deployment-7c7d8d58c8-gqvjm":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-gqvjm test-deployment-7c7d8d58c8- deployment-8379  7e822ac2-453f-4dbd-b932-76a30a3ee0ed 4101696 0 2023-04-18 05:08:38 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[cni.projectcalico.org/containerID:17ec7630755f495da2e4b97f55fdb5a6deb0eb60ea75f90aeca65692440ac8db cni.projectcalico.org/podIP:172.16.100.131/32 cni.projectcalico.org/podIPs:172.16.100.131/32] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 4e6b4292-cb55-4be9-8ec6-1f35e1632c69 0xc003a4b4f7 0xc003a4b4f8}] [] [{kube-controller-manager Update v1 2023-04-18 05:08:38 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4e6b4292-cb55-4be9-8ec6-1f35e1632c69\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:08:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:08:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.100.131\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wsct4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wsct4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:08:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:172.16.100.131,StartTime:2023-04-18 05:08:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:08:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f8c8befc1c4492af9678c3ae5bc4fe266c9b97b611a4ecbf7a9404352b555807,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.100.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Apr 18 05:08:44.068: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-8379  1958b374-caae-4645-8516-22ce990f2982 4101580 3 2023-04-18 05:08:26 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 36490aea-1cce-443e-a192-defec8bc570e 0xc00321d497 0xc00321d498}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:08:33 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36490aea-1cce-443e-a192-defec8bc570e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:08:33 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00321d690 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 05:08:44.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8379" for this suite. 04/18/23 05:08:44.198
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:08:44.252
Apr 18 05:08:44.253: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 05:08:44.254
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:08:44.534
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:08:44.536
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/18/23 05:08:44.648
Apr 18 05:08:44.687: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5244" to be "running and ready"
Apr 18 05:08:44.700: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 13.689632ms
Apr 18 05:08:44.701: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:08:46.743: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05578833s
Apr 18 05:08:46.743: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:08:48.720: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.032768492s
Apr 18 05:08:48.720: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 18 05:08:48.720: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 04/18/23 05:08:48.722
Apr 18 05:08:48.753: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-5244" to be "running and ready"
Apr 18 05:08:48.779: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 26.546817ms
Apr 18 05:08:48.779: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:08:50.801: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048453709s
Apr 18 05:08:50.801: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:08:52.835: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.082183274s
Apr 18 05:08:52.835: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Apr 18 05:08:52.835: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/18/23 05:08:52.869
Apr 18 05:08:52.919: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 18 05:08:52.958: INFO: Pod pod-with-prestop-http-hook still exists
Apr 18 05:08:54.959: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 18 05:08:54.984: INFO: Pod pod-with-prestop-http-hook still exists
Apr 18 05:08:56.959: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 18 05:08:56.969: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 04/18/23 05:08:56.969
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 18 05:08:57.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5244" for this suite. 04/18/23 05:08:57.006
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":158,"skipped":2770,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.767 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:08:44.252
    Apr 18 05:08:44.253: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 05:08:44.254
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:08:44.534
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:08:44.536
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/18/23 05:08:44.648
    Apr 18 05:08:44.687: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5244" to be "running and ready"
    Apr 18 05:08:44.700: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 13.689632ms
    Apr 18 05:08:44.701: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:08:46.743: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05578833s
    Apr 18 05:08:46.743: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:08:48.720: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.032768492s
    Apr 18 05:08:48.720: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 18 05:08:48.720: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 04/18/23 05:08:48.722
    Apr 18 05:08:48.753: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-5244" to be "running and ready"
    Apr 18 05:08:48.779: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 26.546817ms
    Apr 18 05:08:48.779: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:08:50.801: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048453709s
    Apr 18 05:08:50.801: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:08:52.835: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.082183274s
    Apr 18 05:08:52.835: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Apr 18 05:08:52.835: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/18/23 05:08:52.869
    Apr 18 05:08:52.919: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 18 05:08:52.958: INFO: Pod pod-with-prestop-http-hook still exists
    Apr 18 05:08:54.959: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 18 05:08:54.984: INFO: Pod pod-with-prestop-http-hook still exists
    Apr 18 05:08:56.959: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 18 05:08:56.969: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 04/18/23 05:08:56.969
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 18 05:08:57.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-5244" for this suite. 04/18/23 05:08:57.006
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:08:57.019
Apr 18 05:08:57.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 05:08:57.02
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:08:57.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:08:57.137
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/18/23 05:08:57.143
Apr 18 05:08:57.181: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-295" to be "running and ready"
Apr 18 05:08:57.183: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.85638ms
Apr 18 05:08:57.183: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:08:59.187: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006302342s
Apr 18 05:08:59.187: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:09:01.188: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.007006645s
Apr 18 05:09:01.188: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 18 05:09:01.188: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 04/18/23 05:09:01.191
Apr 18 05:09:01.239: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-295" to be "running and ready"
Apr 18 05:09:01.242: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.439424ms
Apr 18 05:09:01.242: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:09:03.246: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006809002s
Apr 18 05:09:03.246: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:09:05.247: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.007199833s
Apr 18 05:09:05.247: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Apr 18 05:09:05.247: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/18/23 05:09:05.25
STEP: delete the pod with lifecycle hook 04/18/23 05:09:05.265
Apr 18 05:09:05.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 18 05:09:05.339: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 18 05:09:07.340: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 18 05:09:07.426: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 18 05:09:09.340: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 18 05:09:09.344: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 18 05:09:09.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-295" for this suite. 04/18/23 05:09:09.348
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":159,"skipped":2773,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.352 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:08:57.019
    Apr 18 05:08:57.019: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 05:08:57.02
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:08:57.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:08:57.137
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/18/23 05:08:57.143
    Apr 18 05:08:57.181: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-295" to be "running and ready"
    Apr 18 05:08:57.183: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.85638ms
    Apr 18 05:08:57.183: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:08:59.187: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006302342s
    Apr 18 05:08:59.187: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:09:01.188: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.007006645s
    Apr 18 05:09:01.188: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 18 05:09:01.188: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 04/18/23 05:09:01.191
    Apr 18 05:09:01.239: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-295" to be "running and ready"
    Apr 18 05:09:01.242: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.439424ms
    Apr 18 05:09:01.242: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:09:03.246: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006809002s
    Apr 18 05:09:03.246: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:09:05.247: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.007199833s
    Apr 18 05:09:05.247: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Apr 18 05:09:05.247: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/18/23 05:09:05.25
    STEP: delete the pod with lifecycle hook 04/18/23 05:09:05.265
    Apr 18 05:09:05.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 18 05:09:05.339: INFO: Pod pod-with-poststart-exec-hook still exists
    Apr 18 05:09:07.340: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 18 05:09:07.426: INFO: Pod pod-with-poststart-exec-hook still exists
    Apr 18 05:09:09.340: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 18 05:09:09.344: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 18 05:09:09.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-295" for this suite. 04/18/23 05:09:09.348
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:09:09.372
Apr 18 05:09:09.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename deployment 04/18/23 05:09:09.373
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:09:09.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:09:09.431
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Apr 18 05:09:09.433: INFO: Creating simple deployment test-new-deployment
Apr 18 05:09:09.583: INFO: deployment "test-new-deployment" doesn't have the required revision set
Apr 18 05:09:11.685: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 9, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 9, 9, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 9, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 9, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: getting scale subresource 04/18/23 05:09:13.816
STEP: updating a scale subresource 04/18/23 05:09:13.818
STEP: verifying the deployment Spec.Replicas was modified 04/18/23 05:09:13.934
STEP: Patch a scale subresource 04/18/23 05:09:14.077
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 05:09:14.447: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-8812  598d3813-0023-47d9-bb47-4f7562fe5dda 4102013 3 2023-04-18 05:09:09 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-18 05:09:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b790e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-04-18 05:09:12 +0000 UTC,LastTransitionTime:2023-04-18 05:09:09 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-18 05:09:14 +0000 UTC,LastTransitionTime:2023-04-18 05:09:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 18 05:09:14.450: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-8812  cc926f2d-4ead-4e4a-a559-0ac8ab60f78b 4102017 3 2023-04-18 05:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 598d3813-0023-47d9-bb47-4f7562fe5dda 0xc0037b7b87 0xc0037b7b88}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"598d3813-0023-47d9-bb47-4f7562fe5dda\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037b7c28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 18 05:09:14.455: INFO: Pod "test-new-deployment-845c8977d9-4jfqh" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-4jfqh test-new-deployment-845c8977d9- deployment-8812  06c7fdd2-49be-44b7-965c-0e7eb3086730 4102019 0 2023-04-18 05:09:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 cc926f2d-4ead-4e4a-a559-0ac8ab60f78b 0xc004223ba7 0xc004223ba8}] [] [{kube-controller-manager Update v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc926f2d-4ead-4e4a-a559-0ac8ab60f78b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mbvvq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mbvvq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:09:14.455: INFO: Pod "test-new-deployment-845c8977d9-4zqn6" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-4zqn6 test-new-deployment-845c8977d9- deployment-8812  311b52f4-cc0e-4d9c-9db5-44b9e78c975b 4101998 0 2023-04-18 05:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:1c18f77b216ab58eaf2ae902de8c0fed1c86b5450136e7fa556852c9040337fc cni.projectcalico.org/podIP:172.16.125.49/32 cni.projectcalico.org/podIPs:172.16.125.49/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 cc926f2d-4ead-4e4a-a559-0ac8ab60f78b 0xc004223d10 0xc004223d11}] [] [{kube-controller-manager Update v1 2023-04-18 05:09:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc926f2d-4ead-4e4a-a559-0ac8ab60f78b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:09:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:09:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.49\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vgrqb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vgrqb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.49,StartTime:2023-04-18 05:09:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:09:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3ff6479a1681a995bd5123d31cadaf230f4e3f97f43aa16341efd26a8f1aa5ae,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.49,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:09:14.455: INFO: Pod "test-new-deployment-845c8977d9-thzvh" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-thzvh test-new-deployment-845c8977d9- deployment-8812  0b58e5a3-2a47-4d15-b8bb-7f42c7a0f578 4102016 0 2023-04-18 05:09:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 cc926f2d-4ead-4e4a-a559-0ac8ab60f78b 0xc004223f17 0xc004223f18}] [] [{kube-controller-manager Update v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc926f2d-4ead-4e4a-a559-0ac8ab60f78b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ccbkb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ccbkb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:09:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 05:09:14.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8812" for this suite. 04/18/23 05:09:14.46
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":160,"skipped":2804,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.216 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:09:09.372
    Apr 18 05:09:09.372: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename deployment 04/18/23 05:09:09.373
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:09:09.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:09:09.431
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Apr 18 05:09:09.433: INFO: Creating simple deployment test-new-deployment
    Apr 18 05:09:09.583: INFO: deployment "test-new-deployment" doesn't have the required revision set
    Apr 18 05:09:11.685: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 9, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 9, 9, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 9, 9, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 9, 9, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-new-deployment-845c8977d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: getting scale subresource 04/18/23 05:09:13.816
    STEP: updating a scale subresource 04/18/23 05:09:13.818
    STEP: verifying the deployment Spec.Replicas was modified 04/18/23 05:09:13.934
    STEP: Patch a scale subresource 04/18/23 05:09:14.077
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 05:09:14.447: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-8812  598d3813-0023-47d9-bb47-4f7562fe5dda 4102013 3 2023-04-18 05:09:09 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2023-04-18 05:09:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b790e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2023-04-18 05:09:12 +0000 UTC,LastTransitionTime:2023-04-18 05:09:09 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-18 05:09:14 +0000 UTC,LastTransitionTime:2023-04-18 05:09:14 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 18 05:09:14.450: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-8812  cc926f2d-4ead-4e4a-a559-0ac8ab60f78b 4102017 3 2023-04-18 05:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 598d3813-0023-47d9-bb47-4f7562fe5dda 0xc0037b7b87 0xc0037b7b88}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"598d3813-0023-47d9-bb47-4f7562fe5dda\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037b7c28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 05:09:14.455: INFO: Pod "test-new-deployment-845c8977d9-4jfqh" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-4jfqh test-new-deployment-845c8977d9- deployment-8812  06c7fdd2-49be-44b7-965c-0e7eb3086730 4102019 0 2023-04-18 05:09:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 cc926f2d-4ead-4e4a-a559-0ac8ab60f78b 0xc004223ba7 0xc004223ba8}] [] [{kube-controller-manager Update v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc926f2d-4ead-4e4a-a559-0ac8ab60f78b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mbvvq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mbvvq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:09:14.455: INFO: Pod "test-new-deployment-845c8977d9-4zqn6" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-4zqn6 test-new-deployment-845c8977d9- deployment-8812  311b52f4-cc0e-4d9c-9db5-44b9e78c975b 4101998 0 2023-04-18 05:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:1c18f77b216ab58eaf2ae902de8c0fed1c86b5450136e7fa556852c9040337fc cni.projectcalico.org/podIP:172.16.125.49/32 cni.projectcalico.org/podIPs:172.16.125.49/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 cc926f2d-4ead-4e4a-a559-0ac8ab60f78b 0xc004223d10 0xc004223d11}] [] [{kube-controller-manager Update v1 2023-04-18 05:09:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc926f2d-4ead-4e4a-a559-0ac8ab60f78b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:09:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:09:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.49\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vgrqb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vgrqb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.49,StartTime:2023-04-18 05:09:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:09:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3ff6479a1681a995bd5123d31cadaf230f4e3f97f43aa16341efd26a8f1aa5ae,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.49,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:09:14.455: INFO: Pod "test-new-deployment-845c8977d9-thzvh" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-thzvh test-new-deployment-845c8977d9- deployment-8812  0b58e5a3-2a47-4d15-b8bb-7f42c7a0f578 4102016 0 2023-04-18 05:09:14 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 cc926f2d-4ead-4e4a-a559-0ac8ab60f78b 0xc004223f17 0xc004223f18}] [] [{kube-controller-manager Update v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"cc926f2d-4ead-4e4a-a559-0ac8ab60f78b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:09:14 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ccbkb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ccbkb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-207,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:14 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:09:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.107,PodIP:,StartTime:2023-04-18 05:09:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 05:09:14.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8812" for this suite. 04/18/23 05:09:14.46
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:09:14.589
Apr 18 05:09:14.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 05:09:14.59
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:09:14.825
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:09:14.828
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 05:09:15.022
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:09:15.592
STEP: Deploying the webhook pod 04/18/23 05:09:15.622
STEP: Wait for the deployment to be ready 04/18/23 05:09:16.392
Apr 18 05:09:16.581: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 18 05:09:18.590: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 9, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 9, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 9, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 9, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 05:09:20.628
STEP: Verifying the service has paired with the endpoint 04/18/23 05:09:20.964
Apr 18 05:09:21.965: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/18/23 05:09:21.969
STEP: create a configmap that should be updated by the webhook 04/18/23 05:09:22.391
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:09:22.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9357" for this suite. 04/18/23 05:09:22.892
STEP: Destroying namespace "webhook-9357-markers" for this suite. 04/18/23 05:09:23.061
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":161,"skipped":2804,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.443 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:09:14.589
    Apr 18 05:09:14.589: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 05:09:14.59
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:09:14.825
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:09:14.828
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 05:09:15.022
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:09:15.592
    STEP: Deploying the webhook pod 04/18/23 05:09:15.622
    STEP: Wait for the deployment to be ready 04/18/23 05:09:16.392
    Apr 18 05:09:16.581: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 18 05:09:18.590: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 9, 16, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 9, 16, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 9, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 9, 16, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 05:09:20.628
    STEP: Verifying the service has paired with the endpoint 04/18/23 05:09:20.964
    Apr 18 05:09:21.965: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/18/23 05:09:21.969
    STEP: create a configmap that should be updated by the webhook 04/18/23 05:09:22.391
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:09:22.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9357" for this suite. 04/18/23 05:09:22.892
    STEP: Destroying namespace "webhook-9357-markers" for this suite. 04/18/23 05:09:23.061
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:09:24.033
Apr 18 05:09:24.033: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 05:09:24.034
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:09:24.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:09:24.473
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-3596 04/18/23 05:09:24.475
STEP: creating service affinity-clusterip-transition in namespace services-3596 04/18/23 05:09:24.475
STEP: creating replication controller affinity-clusterip-transition in namespace services-3596 04/18/23 05:09:24.832
I0418 05:09:25.065101      22 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3596, replica count: 3
I0418 05:09:28.116337      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 05:09:31.117079      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 05:09:34.117599      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 05:09:34.161: INFO: Creating new exec pod
Apr 18 05:09:34.217: INFO: Waiting up to 5m0s for pod "execpod-affinityktlhb" in namespace "services-3596" to be "running"
Apr 18 05:09:34.274: INFO: Pod "execpod-affinityktlhb": Phase="Pending", Reason="", readiness=false. Elapsed: 56.905532ms
Apr 18 05:09:36.279: INFO: Pod "execpod-affinityktlhb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061848106s
Apr 18 05:09:38.291: INFO: Pod "execpod-affinityktlhb": Phase="Running", Reason="", readiness=true. Elapsed: 4.073674531s
Apr 18 05:09:38.291: INFO: Pod "execpod-affinityktlhb" satisfied condition "running"
Apr 18 05:09:39.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-3596 exec execpod-affinityktlhb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Apr 18 05:09:39.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Apr 18 05:09:39.455: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:09:39.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-3596 exec execpod-affinityktlhb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.11.38 80'
Apr 18 05:09:39.617: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.11.38 80\nConnection to 10.96.11.38 80 port [tcp/http] succeeded!\n"
Apr 18 05:09:39.617: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:09:39.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-3596 exec execpod-affinityktlhb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.11.38:80/ ; done'
Apr 18 05:09:39.985: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n"
Apr 18 05:09:39.985: INFO: stdout: "\naffinity-clusterip-transition-swjlj\naffinity-clusterip-transition-5x7zm\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-swjlj\naffinity-clusterip-transition-5x7zm\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-swjlj\naffinity-clusterip-transition-5x7zm\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-swjlj\naffinity-clusterip-transition-5x7zm\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-swjlj\naffinity-clusterip-transition-5x7zm\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-swjlj"
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-5x7zm
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-5x7zm
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-5x7zm
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-5x7zm
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-5x7zm
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
Apr 18 05:09:40.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-3596 exec execpod-affinityktlhb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.11.38:80/ ; done'
Apr 18 05:09:40.239: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n"
Apr 18 05:09:40.239: INFO: stdout: "\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz"
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
Apr 18 05:09:40.239: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3596, will wait for the garbage collector to delete the pods 04/18/23 05:09:40.671
Apr 18 05:09:40.796: INFO: Deleting ReplicationController affinity-clusterip-transition took: 69.407407ms
Apr 18 05:09:40.996: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 200.225302ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 05:09:45.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3596" for this suite. 04/18/23 05:09:45.062
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":162,"skipped":2809,"failed":0}
------------------------------
â€¢ [SLOW TEST] [21.078 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:09:24.033
    Apr 18 05:09:24.033: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 05:09:24.034
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:09:24.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:09:24.473
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-3596 04/18/23 05:09:24.475
    STEP: creating service affinity-clusterip-transition in namespace services-3596 04/18/23 05:09:24.475
    STEP: creating replication controller affinity-clusterip-transition in namespace services-3596 04/18/23 05:09:24.832
    I0418 05:09:25.065101      22 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-3596, replica count: 3
    I0418 05:09:28.116337      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 05:09:31.117079      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 05:09:34.117599      22 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 05:09:34.161: INFO: Creating new exec pod
    Apr 18 05:09:34.217: INFO: Waiting up to 5m0s for pod "execpod-affinityktlhb" in namespace "services-3596" to be "running"
    Apr 18 05:09:34.274: INFO: Pod "execpod-affinityktlhb": Phase="Pending", Reason="", readiness=false. Elapsed: 56.905532ms
    Apr 18 05:09:36.279: INFO: Pod "execpod-affinityktlhb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061848106s
    Apr 18 05:09:38.291: INFO: Pod "execpod-affinityktlhb": Phase="Running", Reason="", readiness=true. Elapsed: 4.073674531s
    Apr 18 05:09:38.291: INFO: Pod "execpod-affinityktlhb" satisfied condition "running"
    Apr 18 05:09:39.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-3596 exec execpod-affinityktlhb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Apr 18 05:09:39.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Apr 18 05:09:39.455: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:09:39.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-3596 exec execpod-affinityktlhb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.11.38 80'
    Apr 18 05:09:39.617: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.11.38 80\nConnection to 10.96.11.38 80 port [tcp/http] succeeded!\n"
    Apr 18 05:09:39.617: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:09:39.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-3596 exec execpod-affinityktlhb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.11.38:80/ ; done'
    Apr 18 05:09:39.985: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n"
    Apr 18 05:09:39.985: INFO: stdout: "\naffinity-clusterip-transition-swjlj\naffinity-clusterip-transition-5x7zm\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-swjlj\naffinity-clusterip-transition-5x7zm\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-swjlj\naffinity-clusterip-transition-5x7zm\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-swjlj\naffinity-clusterip-transition-5x7zm\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-swjlj\naffinity-clusterip-transition-5x7zm\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-swjlj"
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-5x7zm
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-5x7zm
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-5x7zm
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-5x7zm
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-5x7zm
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:39.985: INFO: Received response from host: affinity-clusterip-transition-swjlj
    Apr 18 05:09:40.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-3596 exec execpod-affinityktlhb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.11.38:80/ ; done'
    Apr 18 05:09:40.239: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.11.38:80/\n"
    Apr 18 05:09:40.239: INFO: stdout: "\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz\naffinity-clusterip-transition-rw2zz"
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Received response from host: affinity-clusterip-transition-rw2zz
    Apr 18 05:09:40.239: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-3596, will wait for the garbage collector to delete the pods 04/18/23 05:09:40.671
    Apr 18 05:09:40.796: INFO: Deleting ReplicationController affinity-clusterip-transition took: 69.407407ms
    Apr 18 05:09:40.996: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 200.225302ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 05:09:45.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3596" for this suite. 04/18/23 05:09:45.062
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:09:45.112
Apr 18 05:09:45.112: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename security-context-test 04/18/23 05:09:45.113
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:09:45.21
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:09:45.212
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Apr 18 05:09:45.268: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799" in namespace "security-context-test-290" to be "Succeeded or Failed"
Apr 18 05:09:45.309: INFO: Pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799": Phase="Pending", Reason="", readiness=false. Elapsed: 40.005525ms
Apr 18 05:09:47.313: INFO: Pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044647898s
Apr 18 05:09:49.314: INFO: Pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045158594s
Apr 18 05:09:51.312: INFO: Pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043661232s
Apr 18 05:09:51.312: INFO: Pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 05:09:51.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-290" for this suite. 04/18/23 05:09:51.359
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":163,"skipped":2822,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.266 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:09:45.112
    Apr 18 05:09:45.112: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename security-context-test 04/18/23 05:09:45.113
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:09:45.21
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:09:45.212
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Apr 18 05:09:45.268: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799" in namespace "security-context-test-290" to be "Succeeded or Failed"
    Apr 18 05:09:45.309: INFO: Pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799": Phase="Pending", Reason="", readiness=false. Elapsed: 40.005525ms
    Apr 18 05:09:47.313: INFO: Pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044647898s
    Apr 18 05:09:49.314: INFO: Pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045158594s
    Apr 18 05:09:51.312: INFO: Pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043661232s
    Apr 18 05:09:51.312: INFO: Pod "alpine-nnp-false-5a6b3f9c-48a3-4553-ac24-9dddb0b70799" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 05:09:51.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-290" for this suite. 04/18/23 05:09:51.359
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:09:51.379
Apr 18 05:09:51.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename daemonsets 04/18/23 05:09:51.38
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:09:51.545
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:09:51.548
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 04/18/23 05:09:51.71
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 05:09:51.773
Apr 18 05:09:51.794: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:09:51.794: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:09:52.802: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:09:52.802: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:09:53.872: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:09:53.872: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:09:55.034: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:09:55.034: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:09:55.803: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 05:09:55.803: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/18/23 05:09:55.806
Apr 18 05:09:55.989: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 05:09:55.989: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 04/18/23 05:09:55.989
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 05:09:57.03
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9432, will wait for the garbage collector to delete the pods 04/18/23 05:09:57.03
Apr 18 05:09:57.236: INFO: Deleting DaemonSet.extensions daemon-set took: 152.658425ms
Apr 18 05:09:58.036: INFO: Terminating DaemonSet.extensions daemon-set pods took: 800.756839ms
Apr 18 05:10:02.882: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:10:02.882: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 05:10:02.885: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4102587"},"items":null}

Apr 18 05:10:02.887: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4102587"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:10:02.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9432" for this suite. 04/18/23 05:10:02.905
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":164,"skipped":2842,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.544 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:09:51.379
    Apr 18 05:09:51.379: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename daemonsets 04/18/23 05:09:51.38
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:09:51.545
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:09:51.548
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 04/18/23 05:09:51.71
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 05:09:51.773
    Apr 18 05:09:51.794: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:09:51.794: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:09:52.802: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:09:52.802: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:09:53.872: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:09:53.872: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:09:55.034: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:09:55.034: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:09:55.803: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 05:09:55.803: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/18/23 05:09:55.806
    Apr 18 05:09:55.989: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 05:09:55.989: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 04/18/23 05:09:55.989
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 05:09:57.03
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9432, will wait for the garbage collector to delete the pods 04/18/23 05:09:57.03
    Apr 18 05:09:57.236: INFO: Deleting DaemonSet.extensions daemon-set took: 152.658425ms
    Apr 18 05:09:58.036: INFO: Terminating DaemonSet.extensions daemon-set pods took: 800.756839ms
    Apr 18 05:10:02.882: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:10:02.882: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 05:10:02.885: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4102587"},"items":null}

    Apr 18 05:10:02.887: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4102587"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:10:02.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9432" for this suite. 04/18/23 05:10:02.905
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:10:02.925
Apr 18 05:10:02.925: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename gc 04/18/23 05:10:02.926
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:10:03.056
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:10:03.058
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 04/18/23 05:10:03.064
STEP: delete the rc 04/18/23 05:10:13.277
STEP: wait for the rc to be deleted 04/18/23 05:10:14.561
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/18/23 05:10:19.924
STEP: Gathering metrics 04/18/23 05:10:50.477
Apr 18 05:10:50.899: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
Apr 18 05:10:50.903: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 3.699147ms
Apr 18 05:10:50.903: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
Apr 18 05:10:50.903: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
Apr 18 05:10:50.973: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 18 05:10:50.973: INFO: Deleting pod "simpletest.rc-2668b" in namespace "gc-4066"
Apr 18 05:10:51.738: INFO: Deleting pod "simpletest.rc-2dgqb" in namespace "gc-4066"
Apr 18 05:10:53.118: INFO: Deleting pod "simpletest.rc-2f4nb" in namespace "gc-4066"
Apr 18 05:10:53.661: INFO: Deleting pod "simpletest.rc-2p5bw" in namespace "gc-4066"
Apr 18 05:10:54.352: INFO: Deleting pod "simpletest.rc-2rqsp" in namespace "gc-4066"
Apr 18 05:10:55.551: INFO: Deleting pod "simpletest.rc-2tskh" in namespace "gc-4066"
Apr 18 05:10:56.225: INFO: Deleting pod "simpletest.rc-4z98j" in namespace "gc-4066"
Apr 18 05:10:56.798: INFO: Deleting pod "simpletest.rc-569nd" in namespace "gc-4066"
Apr 18 05:10:57.986: INFO: Deleting pod "simpletest.rc-5c482" in namespace "gc-4066"
Apr 18 05:10:58.550: INFO: Deleting pod "simpletest.rc-5dwjn" in namespace "gc-4066"
Apr 18 05:10:59.345: INFO: Deleting pod "simpletest.rc-5mksl" in namespace "gc-4066"
Apr 18 05:10:59.861: INFO: Deleting pod "simpletest.rc-5ngfx" in namespace "gc-4066"
Apr 18 05:11:00.323: INFO: Deleting pod "simpletest.rc-5wf4r" in namespace "gc-4066"
Apr 18 05:11:00.649: INFO: Deleting pod "simpletest.rc-6mxdn" in namespace "gc-4066"
Apr 18 05:11:01.457: INFO: Deleting pod "simpletest.rc-6vnsz" in namespace "gc-4066"
Apr 18 05:11:02.129: INFO: Deleting pod "simpletest.rc-6zbvq" in namespace "gc-4066"
Apr 18 05:11:03.091: INFO: Deleting pod "simpletest.rc-7sfv7" in namespace "gc-4066"
Apr 18 05:11:03.690: INFO: Deleting pod "simpletest.rc-7w9b9" in namespace "gc-4066"
Apr 18 05:11:04.188: INFO: Deleting pod "simpletest.rc-8ltl9" in namespace "gc-4066"
Apr 18 05:11:04.918: INFO: Deleting pod "simpletest.rc-8qr5h" in namespace "gc-4066"
Apr 18 05:11:05.535: INFO: Deleting pod "simpletest.rc-8wq6d" in namespace "gc-4066"
Apr 18 05:11:06.622: INFO: Deleting pod "simpletest.rc-94ct8" in namespace "gc-4066"
Apr 18 05:11:07.289: INFO: Deleting pod "simpletest.rc-95x7t" in namespace "gc-4066"
Apr 18 05:11:08.703: INFO: Deleting pod "simpletest.rc-9gtqf" in namespace "gc-4066"
Apr 18 05:11:09.440: INFO: Deleting pod "simpletest.rc-9szsk" in namespace "gc-4066"
Apr 18 05:11:09.859: INFO: Deleting pod "simpletest.rc-b4mfd" in namespace "gc-4066"
Apr 18 05:11:10.327: INFO: Deleting pod "simpletest.rc-bfjzf" in namespace "gc-4066"
Apr 18 05:11:10.877: INFO: Deleting pod "simpletest.rc-bmr45" in namespace "gc-4066"
Apr 18 05:11:11.383: INFO: Deleting pod "simpletest.rc-bnpfg" in namespace "gc-4066"
Apr 18 05:11:12.880: INFO: Deleting pod "simpletest.rc-c4mw2" in namespace "gc-4066"
Apr 18 05:11:13.813: INFO: Deleting pod "simpletest.rc-cgkd9" in namespace "gc-4066"
Apr 18 05:11:15.114: INFO: Deleting pod "simpletest.rc-crsl6" in namespace "gc-4066"
Apr 18 05:11:15.447: INFO: Deleting pod "simpletest.rc-d6s6m" in namespace "gc-4066"
Apr 18 05:11:15.850: INFO: Deleting pod "simpletest.rc-d8cgf" in namespace "gc-4066"
Apr 18 05:11:16.342: INFO: Deleting pod "simpletest.rc-drj7h" in namespace "gc-4066"
Apr 18 05:11:16.759: INFO: Deleting pod "simpletest.rc-dstqc" in namespace "gc-4066"
Apr 18 05:11:17.524: INFO: Deleting pod "simpletest.rc-f282v" in namespace "gc-4066"
Apr 18 05:11:17.976: INFO: Deleting pod "simpletest.rc-f2gkk" in namespace "gc-4066"
Apr 18 05:11:18.537: INFO: Deleting pod "simpletest.rc-f857p" in namespace "gc-4066"
Apr 18 05:11:18.798: INFO: Deleting pod "simpletest.rc-f9cmn" in namespace "gc-4066"
Apr 18 05:11:19.669: INFO: Deleting pod "simpletest.rc-g2xxw" in namespace "gc-4066"
Apr 18 05:11:20.311: INFO: Deleting pod "simpletest.rc-gtxmg" in namespace "gc-4066"
Apr 18 05:11:20.669: INFO: Deleting pod "simpletest.rc-hks2k" in namespace "gc-4066"
Apr 18 05:11:21.042: INFO: Deleting pod "simpletest.rc-hmzm9" in namespace "gc-4066"
Apr 18 05:11:21.369: INFO: Deleting pod "simpletest.rc-hnkxh" in namespace "gc-4066"
Apr 18 05:11:21.951: INFO: Deleting pod "simpletest.rc-ht78c" in namespace "gc-4066"
Apr 18 05:11:22.241: INFO: Deleting pod "simpletest.rc-hth6p" in namespace "gc-4066"
Apr 18 05:11:22.509: INFO: Deleting pod "simpletest.rc-httxm" in namespace "gc-4066"
Apr 18 05:11:22.967: INFO: Deleting pod "simpletest.rc-htz59" in namespace "gc-4066"
Apr 18 05:11:23.430: INFO: Deleting pod "simpletest.rc-k9n6s" in namespace "gc-4066"
Apr 18 05:11:23.756: INFO: Deleting pod "simpletest.rc-kjhkj" in namespace "gc-4066"
Apr 18 05:11:24.013: INFO: Deleting pod "simpletest.rc-kmlk5" in namespace "gc-4066"
Apr 18 05:11:24.438: INFO: Deleting pod "simpletest.rc-ks7rv" in namespace "gc-4066"
Apr 18 05:11:24.786: INFO: Deleting pod "simpletest.rc-kzw9j" in namespace "gc-4066"
Apr 18 05:11:25.423: INFO: Deleting pod "simpletest.rc-ldb7c" in namespace "gc-4066"
Apr 18 05:11:25.827: INFO: Deleting pod "simpletest.rc-lhzs2" in namespace "gc-4066"
Apr 18 05:11:26.295: INFO: Deleting pod "simpletest.rc-lq5k7" in namespace "gc-4066"
Apr 18 05:11:26.580: INFO: Deleting pod "simpletest.rc-lrvkn" in namespace "gc-4066"
Apr 18 05:11:26.762: INFO: Deleting pod "simpletest.rc-ltsvd" in namespace "gc-4066"
Apr 18 05:11:27.533: INFO: Deleting pod "simpletest.rc-mjqsf" in namespace "gc-4066"
Apr 18 05:11:28.055: INFO: Deleting pod "simpletest.rc-mvbx2" in namespace "gc-4066"
Apr 18 05:11:28.350: INFO: Deleting pod "simpletest.rc-ngcrh" in namespace "gc-4066"
Apr 18 05:11:28.707: INFO: Deleting pod "simpletest.rc-nklcn" in namespace "gc-4066"
Apr 18 05:11:28.970: INFO: Deleting pod "simpletest.rc-nrgdd" in namespace "gc-4066"
Apr 18 05:11:29.304: INFO: Deleting pod "simpletest.rc-pcgxh" in namespace "gc-4066"
Apr 18 05:11:29.552: INFO: Deleting pod "simpletest.rc-pn99f" in namespace "gc-4066"
Apr 18 05:11:29.831: INFO: Deleting pod "simpletest.rc-pr56x" in namespace "gc-4066"
Apr 18 05:11:30.328: INFO: Deleting pod "simpletest.rc-qj8r4" in namespace "gc-4066"
Apr 18 05:11:30.470: INFO: Deleting pod "simpletest.rc-qmsmb" in namespace "gc-4066"
Apr 18 05:11:30.820: INFO: Deleting pod "simpletest.rc-qw6vm" in namespace "gc-4066"
Apr 18 05:11:31.112: INFO: Deleting pod "simpletest.rc-r4dtf" in namespace "gc-4066"
Apr 18 05:11:31.460: INFO: Deleting pod "simpletest.rc-r8ncf" in namespace "gc-4066"
Apr 18 05:11:31.653: INFO: Deleting pod "simpletest.rc-rnjhf" in namespace "gc-4066"
Apr 18 05:11:32.054: INFO: Deleting pod "simpletest.rc-rp7k7" in namespace "gc-4066"
Apr 18 05:11:32.920: INFO: Deleting pod "simpletest.rc-rqd2h" in namespace "gc-4066"
Apr 18 05:11:33.104: INFO: Deleting pod "simpletest.rc-s6dwx" in namespace "gc-4066"
Apr 18 05:11:33.650: INFO: Deleting pod "simpletest.rc-s6jw7" in namespace "gc-4066"
Apr 18 05:11:33.958: INFO: Deleting pod "simpletest.rc-sknct" in namespace "gc-4066"
Apr 18 05:11:34.313: INFO: Deleting pod "simpletest.rc-sm6q5" in namespace "gc-4066"
Apr 18 05:11:34.710: INFO: Deleting pod "simpletest.rc-smw8q" in namespace "gc-4066"
Apr 18 05:11:35.291: INFO: Deleting pod "simpletest.rc-sq4ng" in namespace "gc-4066"
Apr 18 05:11:35.551: INFO: Deleting pod "simpletest.rc-srxwx" in namespace "gc-4066"
Apr 18 05:11:35.916: INFO: Deleting pod "simpletest.rc-t227q" in namespace "gc-4066"
Apr 18 05:11:36.140: INFO: Deleting pod "simpletest.rc-t6gsh" in namespace "gc-4066"
Apr 18 05:11:36.218: INFO: Deleting pod "simpletest.rc-t7fjw" in namespace "gc-4066"
Apr 18 05:11:36.553: INFO: Deleting pod "simpletest.rc-tmfj4" in namespace "gc-4066"
Apr 18 05:11:37.106: INFO: Deleting pod "simpletest.rc-tp6c7" in namespace "gc-4066"
Apr 18 05:11:37.507: INFO: Deleting pod "simpletest.rc-tqkz7" in namespace "gc-4066"
Apr 18 05:11:37.883: INFO: Deleting pod "simpletest.rc-v2zfv" in namespace "gc-4066"
Apr 18 05:11:38.976: INFO: Deleting pod "simpletest.rc-v49rs" in namespace "gc-4066"
Apr 18 05:11:39.469: INFO: Deleting pod "simpletest.rc-v5grs" in namespace "gc-4066"
Apr 18 05:11:39.718: INFO: Deleting pod "simpletest.rc-vrnnm" in namespace "gc-4066"
Apr 18 05:11:40.175: INFO: Deleting pod "simpletest.rc-w6wt8" in namespace "gc-4066"
Apr 18 05:11:40.407: INFO: Deleting pod "simpletest.rc-wfphd" in namespace "gc-4066"
Apr 18 05:11:41.070: INFO: Deleting pod "simpletest.rc-wkgx5" in namespace "gc-4066"
Apr 18 05:11:41.261: INFO: Deleting pod "simpletest.rc-xfk58" in namespace "gc-4066"
Apr 18 05:11:42.704: INFO: Deleting pod "simpletest.rc-xtk2r" in namespace "gc-4066"
Apr 18 05:11:42.895: INFO: Deleting pod "simpletest.rc-z789s" in namespace "gc-4066"
Apr 18 05:11:43.404: INFO: Deleting pod "simpletest.rc-zbl7t" in namespace "gc-4066"
Apr 18 05:11:43.508: INFO: Deleting pod "simpletest.rc-zg95n" in namespace "gc-4066"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 05:11:43.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4066" for this suite. 04/18/23 05:11:43.855
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":165,"skipped":2884,"failed":0}
------------------------------
â€¢ [SLOW TEST] [100.950 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:10:02.925
    Apr 18 05:10:02.925: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename gc 04/18/23 05:10:02.926
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:10:03.056
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:10:03.058
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 04/18/23 05:10:03.064
    STEP: delete the rc 04/18/23 05:10:13.277
    STEP: wait for the rc to be deleted 04/18/23 05:10:14.561
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/18/23 05:10:19.924
    STEP: Gathering metrics 04/18/23 05:10:50.477
    Apr 18 05:10:50.899: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
    Apr 18 05:10:50.903: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 3.699147ms
    Apr 18 05:10:50.903: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
    Apr 18 05:10:50.903: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
    Apr 18 05:10:50.973: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 18 05:10:50.973: INFO: Deleting pod "simpletest.rc-2668b" in namespace "gc-4066"
    Apr 18 05:10:51.738: INFO: Deleting pod "simpletest.rc-2dgqb" in namespace "gc-4066"
    Apr 18 05:10:53.118: INFO: Deleting pod "simpletest.rc-2f4nb" in namespace "gc-4066"
    Apr 18 05:10:53.661: INFO: Deleting pod "simpletest.rc-2p5bw" in namespace "gc-4066"
    Apr 18 05:10:54.352: INFO: Deleting pod "simpletest.rc-2rqsp" in namespace "gc-4066"
    Apr 18 05:10:55.551: INFO: Deleting pod "simpletest.rc-2tskh" in namespace "gc-4066"
    Apr 18 05:10:56.225: INFO: Deleting pod "simpletest.rc-4z98j" in namespace "gc-4066"
    Apr 18 05:10:56.798: INFO: Deleting pod "simpletest.rc-569nd" in namespace "gc-4066"
    Apr 18 05:10:57.986: INFO: Deleting pod "simpletest.rc-5c482" in namespace "gc-4066"
    Apr 18 05:10:58.550: INFO: Deleting pod "simpletest.rc-5dwjn" in namespace "gc-4066"
    Apr 18 05:10:59.345: INFO: Deleting pod "simpletest.rc-5mksl" in namespace "gc-4066"
    Apr 18 05:10:59.861: INFO: Deleting pod "simpletest.rc-5ngfx" in namespace "gc-4066"
    Apr 18 05:11:00.323: INFO: Deleting pod "simpletest.rc-5wf4r" in namespace "gc-4066"
    Apr 18 05:11:00.649: INFO: Deleting pod "simpletest.rc-6mxdn" in namespace "gc-4066"
    Apr 18 05:11:01.457: INFO: Deleting pod "simpletest.rc-6vnsz" in namespace "gc-4066"
    Apr 18 05:11:02.129: INFO: Deleting pod "simpletest.rc-6zbvq" in namespace "gc-4066"
    Apr 18 05:11:03.091: INFO: Deleting pod "simpletest.rc-7sfv7" in namespace "gc-4066"
    Apr 18 05:11:03.690: INFO: Deleting pod "simpletest.rc-7w9b9" in namespace "gc-4066"
    Apr 18 05:11:04.188: INFO: Deleting pod "simpletest.rc-8ltl9" in namespace "gc-4066"
    Apr 18 05:11:04.918: INFO: Deleting pod "simpletest.rc-8qr5h" in namespace "gc-4066"
    Apr 18 05:11:05.535: INFO: Deleting pod "simpletest.rc-8wq6d" in namespace "gc-4066"
    Apr 18 05:11:06.622: INFO: Deleting pod "simpletest.rc-94ct8" in namespace "gc-4066"
    Apr 18 05:11:07.289: INFO: Deleting pod "simpletest.rc-95x7t" in namespace "gc-4066"
    Apr 18 05:11:08.703: INFO: Deleting pod "simpletest.rc-9gtqf" in namespace "gc-4066"
    Apr 18 05:11:09.440: INFO: Deleting pod "simpletest.rc-9szsk" in namespace "gc-4066"
    Apr 18 05:11:09.859: INFO: Deleting pod "simpletest.rc-b4mfd" in namespace "gc-4066"
    Apr 18 05:11:10.327: INFO: Deleting pod "simpletest.rc-bfjzf" in namespace "gc-4066"
    Apr 18 05:11:10.877: INFO: Deleting pod "simpletest.rc-bmr45" in namespace "gc-4066"
    Apr 18 05:11:11.383: INFO: Deleting pod "simpletest.rc-bnpfg" in namespace "gc-4066"
    Apr 18 05:11:12.880: INFO: Deleting pod "simpletest.rc-c4mw2" in namespace "gc-4066"
    Apr 18 05:11:13.813: INFO: Deleting pod "simpletest.rc-cgkd9" in namespace "gc-4066"
    Apr 18 05:11:15.114: INFO: Deleting pod "simpletest.rc-crsl6" in namespace "gc-4066"
    Apr 18 05:11:15.447: INFO: Deleting pod "simpletest.rc-d6s6m" in namespace "gc-4066"
    Apr 18 05:11:15.850: INFO: Deleting pod "simpletest.rc-d8cgf" in namespace "gc-4066"
    Apr 18 05:11:16.342: INFO: Deleting pod "simpletest.rc-drj7h" in namespace "gc-4066"
    Apr 18 05:11:16.759: INFO: Deleting pod "simpletest.rc-dstqc" in namespace "gc-4066"
    Apr 18 05:11:17.524: INFO: Deleting pod "simpletest.rc-f282v" in namespace "gc-4066"
    Apr 18 05:11:17.976: INFO: Deleting pod "simpletest.rc-f2gkk" in namespace "gc-4066"
    Apr 18 05:11:18.537: INFO: Deleting pod "simpletest.rc-f857p" in namespace "gc-4066"
    Apr 18 05:11:18.798: INFO: Deleting pod "simpletest.rc-f9cmn" in namespace "gc-4066"
    Apr 18 05:11:19.669: INFO: Deleting pod "simpletest.rc-g2xxw" in namespace "gc-4066"
    Apr 18 05:11:20.311: INFO: Deleting pod "simpletest.rc-gtxmg" in namespace "gc-4066"
    Apr 18 05:11:20.669: INFO: Deleting pod "simpletest.rc-hks2k" in namespace "gc-4066"
    Apr 18 05:11:21.042: INFO: Deleting pod "simpletest.rc-hmzm9" in namespace "gc-4066"
    Apr 18 05:11:21.369: INFO: Deleting pod "simpletest.rc-hnkxh" in namespace "gc-4066"
    Apr 18 05:11:21.951: INFO: Deleting pod "simpletest.rc-ht78c" in namespace "gc-4066"
    Apr 18 05:11:22.241: INFO: Deleting pod "simpletest.rc-hth6p" in namespace "gc-4066"
    Apr 18 05:11:22.509: INFO: Deleting pod "simpletest.rc-httxm" in namespace "gc-4066"
    Apr 18 05:11:22.967: INFO: Deleting pod "simpletest.rc-htz59" in namespace "gc-4066"
    Apr 18 05:11:23.430: INFO: Deleting pod "simpletest.rc-k9n6s" in namespace "gc-4066"
    Apr 18 05:11:23.756: INFO: Deleting pod "simpletest.rc-kjhkj" in namespace "gc-4066"
    Apr 18 05:11:24.013: INFO: Deleting pod "simpletest.rc-kmlk5" in namespace "gc-4066"
    Apr 18 05:11:24.438: INFO: Deleting pod "simpletest.rc-ks7rv" in namespace "gc-4066"
    Apr 18 05:11:24.786: INFO: Deleting pod "simpletest.rc-kzw9j" in namespace "gc-4066"
    Apr 18 05:11:25.423: INFO: Deleting pod "simpletest.rc-ldb7c" in namespace "gc-4066"
    Apr 18 05:11:25.827: INFO: Deleting pod "simpletest.rc-lhzs2" in namespace "gc-4066"
    Apr 18 05:11:26.295: INFO: Deleting pod "simpletest.rc-lq5k7" in namespace "gc-4066"
    Apr 18 05:11:26.580: INFO: Deleting pod "simpletest.rc-lrvkn" in namespace "gc-4066"
    Apr 18 05:11:26.762: INFO: Deleting pod "simpletest.rc-ltsvd" in namespace "gc-4066"
    Apr 18 05:11:27.533: INFO: Deleting pod "simpletest.rc-mjqsf" in namespace "gc-4066"
    Apr 18 05:11:28.055: INFO: Deleting pod "simpletest.rc-mvbx2" in namespace "gc-4066"
    Apr 18 05:11:28.350: INFO: Deleting pod "simpletest.rc-ngcrh" in namespace "gc-4066"
    Apr 18 05:11:28.707: INFO: Deleting pod "simpletest.rc-nklcn" in namespace "gc-4066"
    Apr 18 05:11:28.970: INFO: Deleting pod "simpletest.rc-nrgdd" in namespace "gc-4066"
    Apr 18 05:11:29.304: INFO: Deleting pod "simpletest.rc-pcgxh" in namespace "gc-4066"
    Apr 18 05:11:29.552: INFO: Deleting pod "simpletest.rc-pn99f" in namespace "gc-4066"
    Apr 18 05:11:29.831: INFO: Deleting pod "simpletest.rc-pr56x" in namespace "gc-4066"
    Apr 18 05:11:30.328: INFO: Deleting pod "simpletest.rc-qj8r4" in namespace "gc-4066"
    Apr 18 05:11:30.470: INFO: Deleting pod "simpletest.rc-qmsmb" in namespace "gc-4066"
    Apr 18 05:11:30.820: INFO: Deleting pod "simpletest.rc-qw6vm" in namespace "gc-4066"
    Apr 18 05:11:31.112: INFO: Deleting pod "simpletest.rc-r4dtf" in namespace "gc-4066"
    Apr 18 05:11:31.460: INFO: Deleting pod "simpletest.rc-r8ncf" in namespace "gc-4066"
    Apr 18 05:11:31.653: INFO: Deleting pod "simpletest.rc-rnjhf" in namespace "gc-4066"
    Apr 18 05:11:32.054: INFO: Deleting pod "simpletest.rc-rp7k7" in namespace "gc-4066"
    Apr 18 05:11:32.920: INFO: Deleting pod "simpletest.rc-rqd2h" in namespace "gc-4066"
    Apr 18 05:11:33.104: INFO: Deleting pod "simpletest.rc-s6dwx" in namespace "gc-4066"
    Apr 18 05:11:33.650: INFO: Deleting pod "simpletest.rc-s6jw7" in namespace "gc-4066"
    Apr 18 05:11:33.958: INFO: Deleting pod "simpletest.rc-sknct" in namespace "gc-4066"
    Apr 18 05:11:34.313: INFO: Deleting pod "simpletest.rc-sm6q5" in namespace "gc-4066"
    Apr 18 05:11:34.710: INFO: Deleting pod "simpletest.rc-smw8q" in namespace "gc-4066"
    Apr 18 05:11:35.291: INFO: Deleting pod "simpletest.rc-sq4ng" in namespace "gc-4066"
    Apr 18 05:11:35.551: INFO: Deleting pod "simpletest.rc-srxwx" in namespace "gc-4066"
    Apr 18 05:11:35.916: INFO: Deleting pod "simpletest.rc-t227q" in namespace "gc-4066"
    Apr 18 05:11:36.140: INFO: Deleting pod "simpletest.rc-t6gsh" in namespace "gc-4066"
    Apr 18 05:11:36.218: INFO: Deleting pod "simpletest.rc-t7fjw" in namespace "gc-4066"
    Apr 18 05:11:36.553: INFO: Deleting pod "simpletest.rc-tmfj4" in namespace "gc-4066"
    Apr 18 05:11:37.106: INFO: Deleting pod "simpletest.rc-tp6c7" in namespace "gc-4066"
    Apr 18 05:11:37.507: INFO: Deleting pod "simpletest.rc-tqkz7" in namespace "gc-4066"
    Apr 18 05:11:37.883: INFO: Deleting pod "simpletest.rc-v2zfv" in namespace "gc-4066"
    Apr 18 05:11:38.976: INFO: Deleting pod "simpletest.rc-v49rs" in namespace "gc-4066"
    Apr 18 05:11:39.469: INFO: Deleting pod "simpletest.rc-v5grs" in namespace "gc-4066"
    Apr 18 05:11:39.718: INFO: Deleting pod "simpletest.rc-vrnnm" in namespace "gc-4066"
    Apr 18 05:11:40.175: INFO: Deleting pod "simpletest.rc-w6wt8" in namespace "gc-4066"
    Apr 18 05:11:40.407: INFO: Deleting pod "simpletest.rc-wfphd" in namespace "gc-4066"
    Apr 18 05:11:41.070: INFO: Deleting pod "simpletest.rc-wkgx5" in namespace "gc-4066"
    Apr 18 05:11:41.261: INFO: Deleting pod "simpletest.rc-xfk58" in namespace "gc-4066"
    Apr 18 05:11:42.704: INFO: Deleting pod "simpletest.rc-xtk2r" in namespace "gc-4066"
    Apr 18 05:11:42.895: INFO: Deleting pod "simpletest.rc-z789s" in namespace "gc-4066"
    Apr 18 05:11:43.404: INFO: Deleting pod "simpletest.rc-zbl7t" in namespace "gc-4066"
    Apr 18 05:11:43.508: INFO: Deleting pod "simpletest.rc-zg95n" in namespace "gc-4066"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 05:11:43.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-4066" for this suite. 04/18/23 05:11:43.855
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:11:43.876
Apr 18 05:11:43.876: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename subpath 04/18/23 05:11:43.877
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:11:44.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:11:44.807
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/18/23 05:11:44.809
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-wmxg 04/18/23 05:11:44.887
STEP: Creating a pod to test atomic-volume-subpath 04/18/23 05:11:44.888
Apr 18 05:11:44.955: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-wmxg" in namespace "subpath-3358" to be "Succeeded or Failed"
Apr 18 05:11:45.167: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 211.59414ms
Apr 18 05:11:47.251: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.296225805s
Apr 18 05:11:49.288: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.333265892s
Apr 18 05:11:51.242: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.286744985s
Apr 18 05:11:53.203: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 8.248492913s
Apr 18 05:11:55.196: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 10.241308274s
Apr 18 05:11:57.285: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 12.330239002s
Apr 18 05:11:59.208: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 14.252763115s
Apr 18 05:12:01.196: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 16.241537888s
Apr 18 05:12:03.172: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 18.217316116s
Apr 18 05:12:05.171: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 20.215740446s
Apr 18 05:12:07.193: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 22.237965401s
Apr 18 05:12:09.221: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 24.265821387s
Apr 18 05:12:11.207: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 26.252075125s
Apr 18 05:12:13.191: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 28.235592451s
Apr 18 05:12:15.262: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 30.307281757s
Apr 18 05:12:17.187: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=false. Elapsed: 32.232560062s
Apr 18 05:12:19.188: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.23278119s
STEP: Saw pod success 04/18/23 05:12:19.188
Apr 18 05:12:19.188: INFO: Pod "pod-subpath-test-projected-wmxg" satisfied condition "Succeeded or Failed"
Apr 18 05:12:19.191: INFO: Trying to get logs from node apps-208 pod pod-subpath-test-projected-wmxg container test-container-subpath-projected-wmxg: <nil>
STEP: delete the pod 04/18/23 05:12:19.21
Apr 18 05:12:19.357: INFO: Waiting for pod pod-subpath-test-projected-wmxg to disappear
Apr 18 05:12:19.363: INFO: Pod pod-subpath-test-projected-wmxg no longer exists
STEP: Deleting pod pod-subpath-test-projected-wmxg 04/18/23 05:12:19.363
Apr 18 05:12:19.363: INFO: Deleting pod "pod-subpath-test-projected-wmxg" in namespace "subpath-3358"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 18 05:12:19.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3358" for this suite. 04/18/23 05:12:19.425
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":166,"skipped":2905,"failed":0}
------------------------------
â€¢ [SLOW TEST] [35.619 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:11:43.876
    Apr 18 05:11:43.876: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename subpath 04/18/23 05:11:43.877
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:11:44.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:11:44.807
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/18/23 05:11:44.809
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-wmxg 04/18/23 05:11:44.887
    STEP: Creating a pod to test atomic-volume-subpath 04/18/23 05:11:44.888
    Apr 18 05:11:44.955: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-wmxg" in namespace "subpath-3358" to be "Succeeded or Failed"
    Apr 18 05:11:45.167: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 211.59414ms
    Apr 18 05:11:47.251: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.296225805s
    Apr 18 05:11:49.288: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.333265892s
    Apr 18 05:11:51.242: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.286744985s
    Apr 18 05:11:53.203: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 8.248492913s
    Apr 18 05:11:55.196: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Pending", Reason="", readiness=false. Elapsed: 10.241308274s
    Apr 18 05:11:57.285: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 12.330239002s
    Apr 18 05:11:59.208: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 14.252763115s
    Apr 18 05:12:01.196: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 16.241537888s
    Apr 18 05:12:03.172: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 18.217316116s
    Apr 18 05:12:05.171: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 20.215740446s
    Apr 18 05:12:07.193: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 22.237965401s
    Apr 18 05:12:09.221: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 24.265821387s
    Apr 18 05:12:11.207: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 26.252075125s
    Apr 18 05:12:13.191: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 28.235592451s
    Apr 18 05:12:15.262: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=true. Elapsed: 30.307281757s
    Apr 18 05:12:17.187: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Running", Reason="", readiness=false. Elapsed: 32.232560062s
    Apr 18 05:12:19.188: INFO: Pod "pod-subpath-test-projected-wmxg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.23278119s
    STEP: Saw pod success 04/18/23 05:12:19.188
    Apr 18 05:12:19.188: INFO: Pod "pod-subpath-test-projected-wmxg" satisfied condition "Succeeded or Failed"
    Apr 18 05:12:19.191: INFO: Trying to get logs from node apps-208 pod pod-subpath-test-projected-wmxg container test-container-subpath-projected-wmxg: <nil>
    STEP: delete the pod 04/18/23 05:12:19.21
    Apr 18 05:12:19.357: INFO: Waiting for pod pod-subpath-test-projected-wmxg to disappear
    Apr 18 05:12:19.363: INFO: Pod pod-subpath-test-projected-wmxg no longer exists
    STEP: Deleting pod pod-subpath-test-projected-wmxg 04/18/23 05:12:19.363
    Apr 18 05:12:19.363: INFO: Deleting pod "pod-subpath-test-projected-wmxg" in namespace "subpath-3358"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 18 05:12:19.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-3358" for this suite. 04/18/23 05:12:19.425
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:12:19.497
Apr 18 05:12:19.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:12:19.498
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:12:19.631
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:12:19.634
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-853e9380-50c6-4e8e-9354-6ea3dc99c321 04/18/23 05:12:19.676
STEP: Creating configMap with name cm-test-opt-upd-beb2c7a5-abed-410e-a6fe-16778438f0ea 04/18/23 05:12:19.74
STEP: Creating the pod 04/18/23 05:12:19.76
Apr 18 05:12:19.941: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b" in namespace "projected-3201" to be "running and ready"
Apr 18 05:12:20.014: INFO: Pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 72.555082ms
Apr 18 05:12:20.014: INFO: The phase of Pod pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:12:22.057: INFO: Pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.116101879s
Apr 18 05:12:22.057: INFO: The phase of Pod pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:12:24.019: INFO: Pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.077526688s
Apr 18 05:12:24.019: INFO: The phase of Pod pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:12:26.037: INFO: Pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b": Phase="Running", Reason="", readiness=true. Elapsed: 6.096389399s
Apr 18 05:12:26.037: INFO: The phase of Pod pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b is Running (Ready = true)
Apr 18 05:12:26.037: INFO: Pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-853e9380-50c6-4e8e-9354-6ea3dc99c321 04/18/23 05:12:26.078
STEP: Updating configmap cm-test-opt-upd-beb2c7a5-abed-410e-a6fe-16778438f0ea 04/18/23 05:12:26.112
STEP: Creating configMap with name cm-test-opt-create-39a0ab71-8bd8-4686-9b27-9f7d60d17e23 04/18/23 05:12:26.191
STEP: waiting to observe update in volume 04/18/23 05:12:26.229
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 05:13:47.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3201" for this suite. 04/18/23 05:13:47.597
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":167,"skipped":2941,"failed":0}
------------------------------
â€¢ [SLOW TEST] [88.123 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:12:19.497
    Apr 18 05:12:19.497: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:12:19.498
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:12:19.631
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:12:19.634
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-853e9380-50c6-4e8e-9354-6ea3dc99c321 04/18/23 05:12:19.676
    STEP: Creating configMap with name cm-test-opt-upd-beb2c7a5-abed-410e-a6fe-16778438f0ea 04/18/23 05:12:19.74
    STEP: Creating the pod 04/18/23 05:12:19.76
    Apr 18 05:12:19.941: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b" in namespace "projected-3201" to be "running and ready"
    Apr 18 05:12:20.014: INFO: Pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 72.555082ms
    Apr 18 05:12:20.014: INFO: The phase of Pod pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:12:22.057: INFO: Pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.116101879s
    Apr 18 05:12:22.057: INFO: The phase of Pod pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:12:24.019: INFO: Pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.077526688s
    Apr 18 05:12:24.019: INFO: The phase of Pod pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:12:26.037: INFO: Pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b": Phase="Running", Reason="", readiness=true. Elapsed: 6.096389399s
    Apr 18 05:12:26.037: INFO: The phase of Pod pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b is Running (Ready = true)
    Apr 18 05:12:26.037: INFO: Pod "pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-853e9380-50c6-4e8e-9354-6ea3dc99c321 04/18/23 05:12:26.078
    STEP: Updating configmap cm-test-opt-upd-beb2c7a5-abed-410e-a6fe-16778438f0ea 04/18/23 05:12:26.112
    STEP: Creating configMap with name cm-test-opt-create-39a0ab71-8bd8-4686-9b27-9f7d60d17e23 04/18/23 05:12:26.191
    STEP: waiting to observe update in volume 04/18/23 05:12:26.229
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 05:13:47.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3201" for this suite. 04/18/23 05:13:47.597
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:13:47.622
Apr 18 05:13:47.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename limitrange 04/18/23 05:13:47.623
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:13:47.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:13:47.662
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 04/18/23 05:13:47.68
STEP: Setting up watch 04/18/23 05:13:47.68
STEP: Submitting a LimitRange 04/18/23 05:13:47.783
STEP: Verifying LimitRange creation was observed 04/18/23 05:13:47.82
STEP: Fetching the LimitRange to ensure it has proper values 04/18/23 05:13:47.821
Apr 18 05:13:47.824: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 18 05:13:47.824: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 04/18/23 05:13:47.824
STEP: Ensuring Pod has resource requirements applied from LimitRange 04/18/23 05:13:47.846
Apr 18 05:13:47.849: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 18 05:13:47.849: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 04/18/23 05:13:47.849
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/18/23 05:13:47.969
Apr 18 05:13:48.005: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 18 05:13:48.005: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 04/18/23 05:13:48.005
STEP: Failing to create a Pod with more than max resources 04/18/23 05:13:48.007
STEP: Updating a LimitRange 04/18/23 05:13:48.009
STEP: Verifying LimitRange updating is effective 04/18/23 05:13:48.037
STEP: Creating a Pod with less than former min resources 04/18/23 05:13:50.22
STEP: Failing to create a Pod with more than max resources 04/18/23 05:13:50.431
STEP: Deleting a LimitRange 04/18/23 05:13:50.433
STEP: Verifying the LimitRange was deleted 04/18/23 05:13:50.514
Apr 18 05:13:55.527: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 04/18/23 05:13:55.527
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Apr 18 05:13:55.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-7761" for this suite. 04/18/23 05:13:55.687
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":168,"skipped":2968,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.093 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:13:47.622
    Apr 18 05:13:47.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename limitrange 04/18/23 05:13:47.623
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:13:47.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:13:47.662
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 04/18/23 05:13:47.68
    STEP: Setting up watch 04/18/23 05:13:47.68
    STEP: Submitting a LimitRange 04/18/23 05:13:47.783
    STEP: Verifying LimitRange creation was observed 04/18/23 05:13:47.82
    STEP: Fetching the LimitRange to ensure it has proper values 04/18/23 05:13:47.821
    Apr 18 05:13:47.824: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 18 05:13:47.824: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 04/18/23 05:13:47.824
    STEP: Ensuring Pod has resource requirements applied from LimitRange 04/18/23 05:13:47.846
    Apr 18 05:13:47.849: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 18 05:13:47.849: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 04/18/23 05:13:47.849
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/18/23 05:13:47.969
    Apr 18 05:13:48.005: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Apr 18 05:13:48.005: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 04/18/23 05:13:48.005
    STEP: Failing to create a Pod with more than max resources 04/18/23 05:13:48.007
    STEP: Updating a LimitRange 04/18/23 05:13:48.009
    STEP: Verifying LimitRange updating is effective 04/18/23 05:13:48.037
    STEP: Creating a Pod with less than former min resources 04/18/23 05:13:50.22
    STEP: Failing to create a Pod with more than max resources 04/18/23 05:13:50.431
    STEP: Deleting a LimitRange 04/18/23 05:13:50.433
    STEP: Verifying the LimitRange was deleted 04/18/23 05:13:50.514
    Apr 18 05:13:55.527: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 04/18/23 05:13:55.527
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Apr 18 05:13:55.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-7761" for this suite. 04/18/23 05:13:55.687
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:13:55.716
Apr 18 05:13:55.716: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sched-pred 04/18/23 05:13:55.717
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:13:55.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:13:55.842
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 18 05:13:55.844: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 18 05:13:55.870: INFO: Waiting for terminating namespaces to be deleted...
Apr 18 05:13:55.872: INFO: 
Logging pods the apiserver thinks is on node apps-207 before test
Apr 18 05:13:55.893: INFO: addon-manager-5d75c94878-q9nwx from cocktail-addon started at 2023-04-14 07:23:24 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container addon-manager ready: true, restart count 1
Apr 18 05:13:55.893: INFO: agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w from cocktail-addon started at 2023-04-14 07:27:45 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container alarm-agent ready: true, restart count 0
Apr 18 05:13:55.893: INFO: alertmanager-monitoring-kube-prometheus-alertmanager-0 from cocktail-addon started at 2023-04-14 07:24:51 +0000 UTC (2 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container alertmanager ready: true, restart count 1
Apr 18 05:13:55.893: INFO: 	Container config-reloader ready: true, restart count 0
Apr 18 05:13:55.893: INFO: monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container kube-prometheus-stack ready: true, restart count 0
Apr 18 05:13:55.893: INFO: monitoring-kube-state-metrics-7dddf6695f-l8mlh from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container kube-state-metrics ready: true, restart count 0
Apr 18 05:13:55.893: INFO: monitoring-prometheus-node-exporter-d9xr5 from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 05:13:55.893: INFO: prometheus-monitoring-kube-prometheus-prometheus-0 from cocktail-addon started at 2023-04-14 11:20:12 +0000 UTC (2 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container config-reloader ready: true, restart count 0
Apr 18 05:13:55.893: INFO: 	Container prometheus ready: true, restart count 0
Apr 18 05:13:55.893: INFO: promtail-fjjqt from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container promtail ready: true, restart count 0
Apr 18 05:13:55.893: INFO: cocktail-api-gateway-648577694-g7lzt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container gateway ready: true, restart count 4
Apr 18 05:13:55.893: INFO: cocktail-batch-server-5895cd6748-x5qsz from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container batch ready: true, restart count 0
Apr 18 05:13:55.893: INFO: cocktail-build-api-5d65b8dd6-8tb9g from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container build-api ready: true, restart count 0
Apr 18 05:13:55.893: INFO: cocktail-build-queue-7855f6f4dd-vsc6p from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container nats-streaming ready: true, restart count 0
Apr 18 05:13:55.893: INFO: cocktail-cluster-api-6b5df5884f-4nbvz from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container cluster-api ready: true, restart count 2
Apr 18 05:13:55.893: INFO: cocktail-dashboard-86844bcfbd-wbnzx from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container dashboard ready: true, restart count 0
Apr 18 05:13:55.893: INFO: cocktail-dashboard-proxy-5476f6847-ptzhj from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container dashboard-proxy ready: true, restart count 0
Apr 18 05:13:55.893: INFO: cocktail-dashboard-queue-5745c9f74c-2gks8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container dashboard-queue ready: true, restart count 0
Apr 18 05:13:55.893: INFO: cocktail-dashboard-session-9d746547b-gk8d5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container dashboard-session ready: true, restart count 0
Apr 18 05:13:55.893: INFO: cocktail-monitoring-metric-collector-5695cb8669-mktvm from cocktail-system started at 2023-04-14 11:19:55 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container collector ready: true, restart count 4
Apr 18 05:13:55.893: INFO: calico-kube-controllers-74677b4c5f-rjqrf from kube-system started at 2023-04-11 08:28:10 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 18 05:13:55.893: INFO: calico-node-nmmjb from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 05:13:55.893: INFO: coredns-7ffbbc99d-5xc7c from kube-system started at 2023-04-11 08:28:13 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container coredns ready: true, restart count 0
Apr 18 05:13:55.893: INFO: csi-nfs-node-w5rjr from kube-system started at 2023-04-11 08:28:52 +0000 UTC (4 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:13:55.893: INFO: 	Container metrics ready: true, restart count 0
Apr 18 05:13:55.893: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:13:55.893: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 05:13:55.893: INFO: kube-apiserver-apps-207 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 05:13:55.893: INFO: kube-controller-manager-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container kube-controller-manager ready: true, restart count 1
Apr 18 05:13:55.893: INFO: kube-proxy-clw95 from kube-system started at 2023-04-11 08:28:27 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 05:13:55.893: INFO: kube-scheduler-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 18 05:13:55.893: INFO: metrics-server-7b879bf57b-vfp7l from kube-system started at 2023-04-13 06:15:39 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container metrics-server ready: true, restart count 0
Apr 18 05:13:55.893: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:13:55.893: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:13:55.893: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 05:13:55.893: INFO: 
Logging pods the apiserver thinks is on node apps-208 before test
Apr 18 05:13:55.909: INFO: monitoring-prometheus-node-exporter-x99mx from cocktail-addon started at 2023-04-18 04:30:51 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 05:13:55.909: INFO: nginx-ingress-nginx-controller-865cbc698d-sqwlm from cocktail-addon started at 2023-04-18 04:30:49 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container controller ready: true, restart count 0
Apr 18 05:13:55.909: INFO: nginx-ingress-nginx-defaultbackend-649fd8955b-wk6kv from cocktail-addon started at 2023-04-18 04:30:48 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container ingress-nginx-default-backend ready: true, restart count 0
Apr 18 05:13:55.909: INFO: promtail-c9qhr from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container promtail ready: true, restart count 0
Apr 18 05:13:55.909: INFO: calico-node-jstls from kube-system started at 2023-04-11 08:28:11 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 05:13:55.909: INFO: csi-nfs-node-t4zm5 from kube-system started at 2023-04-11 08:28:48 +0000 UTC (4 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:13:55.909: INFO: 	Container metrics ready: true, restart count 0
Apr 18 05:13:55.909: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:13:55.909: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 05:13:55.909: INFO: kube-apiserver-apps-208 from kube-system started at 2023-04-11 08:26:44 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 05:13:55.909: INFO: kube-controller-manager-apps-208 from kube-system started at 2023-04-05 06:51:47 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 18 05:13:55.909: INFO: kube-proxy-vb944 from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 05:13:55.909: INFO: kube-scheduler-apps-208 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 18 05:13:55.909: INFO: pfpod from limitrange-7761 started at 2023-04-18 05:13:50 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container pause ready: true, restart count 0
Apr 18 05:13:55.909: INFO: pod-no-resources from limitrange-7761 started at 2023-04-18 05:13:47 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container pause ready: true, restart count 0
Apr 18 05:13:55.909: INFO: pod-partial-resources from limitrange-7761 started at 2023-04-18 05:13:48 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container pause ready: true, restart count 0
Apr 18 05:13:55.909: INFO: pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b from projected-3201 started at 2023-04-18 05:12:20 +0000 UTC (3 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container createcm-volume-test ready: true, restart count 0
Apr 18 05:13:55.909: INFO: 	Container delcm-volume-test ready: true, restart count 0
Apr 18 05:13:55.909: INFO: 	Container updcm-volume-test ready: true, restart count 0
Apr 18 05:13:55.909: INFO: sonobuoy from sonobuoy started at 2023-04-18 04:01:18 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 18 05:13:55.909: INFO: sonobuoy-e2e-job-5f413cbb3b804c34 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container e2e ready: true, restart count 0
Apr 18 05:13:55.909: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:13:55.909: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-lzt9z from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:13:55.909: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:13:55.909: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 05:13:55.909: INFO: 
Logging pods the apiserver thinks is on node apps-209 before test
Apr 18 05:13:55.933: INFO: agent-mdi1zj-1-event-agent-757455b86f-jzfp7 from cocktail-addon started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container event-agent ready: true, restart count 0
Apr 18 05:13:55.933: INFO: agent-mdi1zj-1-metric-agent-0 from cocktail-addon started at 2023-04-14 07:27:47 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container metric-agent ready: true, restart count 6
Apr 18 05:13:55.933: INFO: monitoring-extension-event-exporter-57bc857b7b-d2kgh from cocktail-addon started at 2023-04-14 07:26:55 +0000 UTC (2 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container caddy ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container event-exporter ready: true, restart count 0
Apr 18 05:13:55.933: INFO: monitoring-prometheus-node-exporter-tx7km from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 05:13:55.933: INFO: promtail-bgwzf from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container promtail ready: true, restart count 0
Apr 18 05:13:55.933: INFO: cocktail-api-cmdb-0 from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container api-cmdb ready: true, restart count 0
Apr 18 05:13:55.933: INFO: cocktail-api-server-5d47cb7fdd-5ptrt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container api-server ready: true, restart count 1
Apr 18 05:13:55.933: INFO: cocktail-log-api-6c69c456db-j8gr8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container api ready: true, restart count 0
Apr 18 05:13:55.933: INFO: cocktail-log-loki-0 from cocktail-system started at 2023-04-14 07:04:56 +0000 UTC (2 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container loki ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container tls-proxy ready: true, restart count 0
Apr 18 05:13:55.933: INFO: cocktail-monitoring-76bdf6974f-p5hs8 from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container monitoring ready: true, restart count 3
Apr 18 05:13:55.933: INFO: cocktail-monitoring-alarm-collector-78448f5d-gbmcs from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container collector ready: true, restart count 6
Apr 18 05:13:55.933: INFO: cocktail-monitoring-event-collector-7fd78d476d-9pw9f from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container collector ready: true, restart count 7
Apr 18 05:13:55.933: INFO: cocktail-monitoring-monitoring-db-0 from cocktail-system started at 2023-04-14 11:20:11 +0000 UTC (2 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container db ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container log-lotate ready: true, restart count 0
Apr 18 05:13:55.933: INFO: cocktail-monitoring-proxy-648c665797-jd2fs from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container monitoring-proxy ready: true, restart count 0
Apr 18 05:13:55.933: INFO: cocktail-mq-entity-operator-7964999574-5zzkb from cocktail-system started at 2023-04-14 07:07:37 +0000 UTC (3 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container tls-sidecar ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container topic-operator ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container user-operator ready: true, restart count 0
Apr 18 05:13:55.933: INFO: cocktail-mq-kafka-0 from cocktail-system started at 2023-04-14 07:08:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container kafka ready: true, restart count 0
Apr 18 05:13:55.933: INFO: cocktail-mq-zookeeper-0 from cocktail-system started at 2023-04-14 07:05:54 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container zookeeper ready: true, restart count 0
Apr 18 05:13:55.933: INFO: cocktail-package-5f59d96bd8-d2nj5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container package ready: true, restart count 1
Apr 18 05:13:55.933: INFO: strimzi-cluster-operator-668f4bff5c-zqqjr from cocktail-system started at 2023-04-14 11:05:05 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container strimzi-cluster-operator ready: true, restart count 0
Apr 18 05:13:55.933: INFO: calico-node-q6mxd from kube-system started at 2023-04-11 08:28:12 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 05:13:55.933: INFO: coredns-7ffbbc99d-mkf8k from kube-system started at 2023-04-14 11:05:04 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container coredns ready: true, restart count 0
Apr 18 05:13:55.933: INFO: csi-nfs-controller-7ccd7c4947-dw42l from kube-system started at 2023-04-14 11:05:06 +0000 UTC (3 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container csi-provisioner ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:13:55.933: INFO: csi-nfs-node-nh5wf from kube-system started at 2023-04-11 08:28:49 +0000 UTC (4 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container metrics ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 05:13:55.933: INFO: kube-apiserver-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 05:13:55.933: INFO: kube-controller-manager-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container kube-controller-manager ready: true, restart count 1
Apr 18 05:13:55.933: INFO: kube-proxy-vmwrf from kube-system started at 2023-04-11 08:28:28 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 05:13:55.933: INFO: kube-scheduler-apps-209 from kube-system started at 2023-04-07 08:18:47 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container kube-scheduler ready: true, restart count 1
Apr 18 05:13:55.933: INFO: metrics-server-7b879bf57b-6vnbg from kube-system started at 2023-04-13 06:15:03 +0000 UTC (1 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container metrics-server ready: true, restart count 0
Apr 18 05:13:55.933: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-j4n44 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:13:55.933: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:13:55.933: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node apps-207 04/18/23 05:14:02.303
STEP: verifying the node has the label node apps-208 04/18/23 05:14:02.397
STEP: verifying the node has the label node apps-209 04/18/23 05:14:02.637
Apr 18 05:14:02.716: INFO: Pod addon-manager-5d75c94878-q9nwx requesting resource cpu=200m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w requesting resource cpu=100m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod agent-mdi1zj-1-event-agent-757455b86f-jzfp7 requesting resource cpu=100m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod agent-mdi1zj-1-metric-agent-0 requesting resource cpu=100m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod alertmanager-monitoring-kube-prometheus-alertmanager-0 requesting resource cpu=200m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod monitoring-extension-event-exporter-57bc857b7b-d2kgh requesting resource cpu=0m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj requesting resource cpu=100m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod monitoring-kube-state-metrics-7dddf6695f-l8mlh requesting resource cpu=100m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod monitoring-prometheus-node-exporter-d9xr5 requesting resource cpu=200m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod monitoring-prometheus-node-exporter-tx7km requesting resource cpu=200m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod monitoring-prometheus-node-exporter-x99mx requesting resource cpu=200m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod nginx-ingress-nginx-controller-865cbc698d-sqwlm requesting resource cpu=300m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod nginx-ingress-nginx-defaultbackend-649fd8955b-wk6kv requesting resource cpu=0m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod prometheus-monitoring-kube-prometheus-prometheus-0 requesting resource cpu=600m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod promtail-bgwzf requesting resource cpu=0m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod promtail-c9qhr requesting resource cpu=0m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod promtail-fjjqt requesting resource cpu=0m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-api-cmdb-0 requesting resource cpu=500m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-api-gateway-648577694-g7lzt requesting resource cpu=500m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-api-server-5d47cb7fdd-5ptrt requesting resource cpu=1000m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-batch-server-5895cd6748-x5qsz requesting resource cpu=100m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-build-api-5d65b8dd6-8tb9g requesting resource cpu=500m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-build-queue-7855f6f4dd-vsc6p requesting resource cpu=500m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-cluster-api-6b5df5884f-4nbvz requesting resource cpu=500m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-dashboard-86844bcfbd-wbnzx requesting resource cpu=300m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-dashboard-proxy-5476f6847-ptzhj requesting resource cpu=500m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-dashboard-queue-5745c9f74c-2gks8 requesting resource cpu=500m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-dashboard-session-9d746547b-gk8d5 requesting resource cpu=100m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-log-api-6c69c456db-j8gr8 requesting resource cpu=100m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-log-loki-0 requesting resource cpu=0m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-76bdf6974f-p5hs8 requesting resource cpu=1000m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-alarm-collector-78448f5d-gbmcs requesting resource cpu=200m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-event-collector-7fd78d476d-9pw9f requesting resource cpu=200m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-metric-collector-5695cb8669-mktvm requesting resource cpu=200m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-monitoring-db-0 requesting resource cpu=600m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-proxy-648c665797-jd2fs requesting resource cpu=100m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-mq-entity-operator-7964999574-5zzkb requesting resource cpu=0m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-mq-kafka-0 requesting resource cpu=500m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-mq-zookeeper-0 requesting resource cpu=0m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod cocktail-package-5f59d96bd8-d2nj5 requesting resource cpu=500m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod strimzi-cluster-operator-668f4bff5c-zqqjr requesting resource cpu=200m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod calico-kube-controllers-74677b4c5f-rjqrf requesting resource cpu=0m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod calico-node-jstls requesting resource cpu=250m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod calico-node-nmmjb requesting resource cpu=250m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod calico-node-q6mxd requesting resource cpu=250m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod coredns-7ffbbc99d-5xc7c requesting resource cpu=100m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod coredns-7ffbbc99d-mkf8k requesting resource cpu=100m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod csi-nfs-controller-7ccd7c4947-dw42l requesting resource cpu=30m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod csi-nfs-node-nh5wf requesting resource cpu=30m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod csi-nfs-node-t4zm5 requesting resource cpu=30m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod csi-nfs-node-w5rjr requesting resource cpu=30m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod kube-apiserver-apps-207 requesting resource cpu=250m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod kube-apiserver-apps-208 requesting resource cpu=250m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod kube-apiserver-apps-209 requesting resource cpu=250m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod kube-controller-manager-apps-207 requesting resource cpu=200m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod kube-controller-manager-apps-208 requesting resource cpu=200m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod kube-controller-manager-apps-209 requesting resource cpu=200m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod kube-proxy-clw95 requesting resource cpu=0m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod kube-proxy-vb944 requesting resource cpu=0m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod kube-proxy-vmwrf requesting resource cpu=0m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod kube-scheduler-apps-207 requesting resource cpu=100m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod kube-scheduler-apps-208 requesting resource cpu=100m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod kube-scheduler-apps-209 requesting resource cpu=100m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod metrics-server-7b879bf57b-6vnbg requesting resource cpu=100m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod metrics-server-7b879bf57b-vfp7l requesting resource cpu=100m on Node apps-207
Apr 18 05:14:02.716: INFO: Pod pfpod requesting resource cpu=10m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod pod-no-resources requesting resource cpu=100m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod pod-partial-resources requesting resource cpu=300m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod sonobuoy requesting resource cpu=0m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod sonobuoy-e2e-job-5f413cbb3b804c34 requesting resource cpu=0m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-j4n44 requesting resource cpu=0m on Node apps-209
Apr 18 05:14:02.716: INFO: Pod sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-lzt9z requesting resource cpu=0m on Node apps-208
Apr 18 05:14:02.716: INFO: Pod sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn requesting resource cpu=0m on Node apps-207
STEP: Starting Pods to consume most of the cluster CPU. 04/18/23 05:14:02.716
Apr 18 05:14:02.716: INFO: Creating a pod which consumes cpu=1239m on Node apps-207
Apr 18 05:14:02.778: INFO: Creating a pod which consumes cpu=4382m on Node apps-208
Apr 18 05:14:02.922: INFO: Creating a pod which consumes cpu=1148m on Node apps-209
Apr 18 05:14:02.939: INFO: Waiting up to 5m0s for pod "filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf" in namespace "sched-pred-8589" to be "running"
Apr 18 05:14:03.237: INFO: Pod "filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf": Phase="Pending", Reason="", readiness=false. Elapsed: 298.27059ms
Apr 18 05:14:05.243: INFO: Pod "filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.30417745s
Apr 18 05:14:07.242: INFO: Pod "filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf": Phase="Running", Reason="", readiness=true. Elapsed: 4.303524279s
Apr 18 05:14:07.242: INFO: Pod "filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf" satisfied condition "running"
Apr 18 05:14:07.242: INFO: Waiting up to 5m0s for pod "filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918" in namespace "sched-pred-8589" to be "running"
Apr 18 05:14:07.245: INFO: Pod "filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918": Phase="Running", Reason="", readiness=true. Elapsed: 2.604499ms
Apr 18 05:14:07.245: INFO: Pod "filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918" satisfied condition "running"
Apr 18 05:14:07.245: INFO: Waiting up to 5m0s for pod "filler-pod-b63ea385-5e38-4509-911b-806984071690" in namespace "sched-pred-8589" to be "running"
Apr 18 05:14:07.248: INFO: Pod "filler-pod-b63ea385-5e38-4509-911b-806984071690": Phase="Running", Reason="", readiness=true. Elapsed: 2.61785ms
Apr 18 05:14:07.248: INFO: Pod "filler-pod-b63ea385-5e38-4509-911b-806984071690" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 04/18/23 05:14:07.248
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf.1756ef7fc6f468ab], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8589/filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf to apps-207] 04/18/23 05:14:07.251
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf.1756ef80420d5dee], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 05:14:07.251
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf.1756ef806dd93ac3], Reason = [Created], Message = [Created container filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf] 04/18/23 05:14:07.251
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf.1756ef807ac36f05], Reason = [Started], Message = [Started container filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf] 04/18/23 05:14:07.251
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b63ea385-5e38-4509-911b-806984071690.1756ef7fca65e710], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8589/filler-pod-b63ea385-5e38-4509-911b-806984071690 to apps-209] 04/18/23 05:14:07.251
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b63ea385-5e38-4509-911b-806984071690.1756ef8057c59532], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 05:14:07.251
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b63ea385-5e38-4509-911b-806984071690.1756ef8083c2b077], Reason = [Created], Message = [Created container filler-pod-b63ea385-5e38-4509-911b-806984071690] 04/18/23 05:14:07.251
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b63ea385-5e38-4509-911b-806984071690.1756ef808f2f6951], Reason = [Started], Message = [Started container filler-pod-b63ea385-5e38-4509-911b-806984071690] 04/18/23 05:14:07.252
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918.1756ef7fc8fd1327], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8589/filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918 to apps-208] 04/18/23 05:14:07.252
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918.1756ef80605cbaef], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 05:14:07.252
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918.1756ef8093211ad3], Reason = [Created], Message = [Created container filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918] 04/18/23 05:14:07.252
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918.1756ef809e12281d], Reason = [Started], Message = [Started container filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918] 04/18/23 05:14:07.252
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1756ef80ca64a4db], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 04/18/23 05:14:07.371
STEP: removing the label node off the node apps-207 04/18/23 05:14:08.305
STEP: verifying the node doesn't have the label node 04/18/23 05:14:08.378
STEP: removing the label node off the node apps-208 04/18/23 05:14:08.41
STEP: verifying the node doesn't have the label node 04/18/23 05:14:08.45
STEP: removing the label node off the node apps-209 04/18/23 05:14:08.458
STEP: verifying the node doesn't have the label node 04/18/23 05:14:08.537
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:14:08.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8589" for this suite. 04/18/23 05:14:08.562
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":169,"skipped":2999,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.874 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:13:55.716
    Apr 18 05:13:55.716: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sched-pred 04/18/23 05:13:55.717
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:13:55.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:13:55.842
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 18 05:13:55.844: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 18 05:13:55.870: INFO: Waiting for terminating namespaces to be deleted...
    Apr 18 05:13:55.872: INFO: 
    Logging pods the apiserver thinks is on node apps-207 before test
    Apr 18 05:13:55.893: INFO: addon-manager-5d75c94878-q9nwx from cocktail-addon started at 2023-04-14 07:23:24 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container addon-manager ready: true, restart count 1
    Apr 18 05:13:55.893: INFO: agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w from cocktail-addon started at 2023-04-14 07:27:45 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container alarm-agent ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: alertmanager-monitoring-kube-prometheus-alertmanager-0 from cocktail-addon started at 2023-04-14 07:24:51 +0000 UTC (2 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container alertmanager ready: true, restart count 1
    Apr 18 05:13:55.893: INFO: 	Container config-reloader ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container kube-prometheus-stack ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: monitoring-kube-state-metrics-7dddf6695f-l8mlh from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: monitoring-prometheus-node-exporter-d9xr5 from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: prometheus-monitoring-kube-prometheus-prometheus-0 from cocktail-addon started at 2023-04-14 11:20:12 +0000 UTC (2 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container config-reloader ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: 	Container prometheus ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: promtail-fjjqt from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: cocktail-api-gateway-648577694-g7lzt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container gateway ready: true, restart count 4
    Apr 18 05:13:55.893: INFO: cocktail-batch-server-5895cd6748-x5qsz from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container batch ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: cocktail-build-api-5d65b8dd6-8tb9g from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container build-api ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: cocktail-build-queue-7855f6f4dd-vsc6p from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container nats-streaming ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: cocktail-cluster-api-6b5df5884f-4nbvz from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container cluster-api ready: true, restart count 2
    Apr 18 05:13:55.893: INFO: cocktail-dashboard-86844bcfbd-wbnzx from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container dashboard ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: cocktail-dashboard-proxy-5476f6847-ptzhj from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container dashboard-proxy ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: cocktail-dashboard-queue-5745c9f74c-2gks8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container dashboard-queue ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: cocktail-dashboard-session-9d746547b-gk8d5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container dashboard-session ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: cocktail-monitoring-metric-collector-5695cb8669-mktvm from cocktail-system started at 2023-04-14 11:19:55 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container collector ready: true, restart count 4
    Apr 18 05:13:55.893: INFO: calico-kube-controllers-74677b4c5f-rjqrf from kube-system started at 2023-04-11 08:28:10 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: calico-node-nmmjb from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: coredns-7ffbbc99d-5xc7c from kube-system started at 2023-04-11 08:28:13 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: csi-nfs-node-w5rjr from kube-system started at 2023-04-11 08:28:52 +0000 UTC (4 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: kube-apiserver-apps-207 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: kube-controller-manager-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Apr 18 05:13:55.893: INFO: kube-proxy-clw95 from kube-system started at 2023-04-11 08:28:27 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: kube-scheduler-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: metrics-server-7b879bf57b-vfp7l from kube-system started at 2023-04-13 06:15:39 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:13:55.893: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 05:13:55.893: INFO: 
    Logging pods the apiserver thinks is on node apps-208 before test
    Apr 18 05:13:55.909: INFO: monitoring-prometheus-node-exporter-x99mx from cocktail-addon started at 2023-04-18 04:30:51 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: nginx-ingress-nginx-controller-865cbc698d-sqwlm from cocktail-addon started at 2023-04-18 04:30:49 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container controller ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: nginx-ingress-nginx-defaultbackend-649fd8955b-wk6kv from cocktail-addon started at 2023-04-18 04:30:48 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container ingress-nginx-default-backend ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: promtail-c9qhr from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: calico-node-jstls from kube-system started at 2023-04-11 08:28:11 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: csi-nfs-node-t4zm5 from kube-system started at 2023-04-11 08:28:48 +0000 UTC (4 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: kube-apiserver-apps-208 from kube-system started at 2023-04-11 08:26:44 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: kube-controller-manager-apps-208 from kube-system started at 2023-04-05 06:51:47 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: kube-proxy-vb944 from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: kube-scheduler-apps-208 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: pfpod from limitrange-7761 started at 2023-04-18 05:13:50 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container pause ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: pod-no-resources from limitrange-7761 started at 2023-04-18 05:13:47 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container pause ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: pod-partial-resources from limitrange-7761 started at 2023-04-18 05:13:48 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container pause ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: pod-projected-configmaps-21f166d9-1de0-4c58-b833-b1e2f9f64f7b from projected-3201 started at 2023-04-18 05:12:20 +0000 UTC (3 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container createcm-volume-test ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: 	Container delcm-volume-test ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: 	Container updcm-volume-test ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: sonobuoy from sonobuoy started at 2023-04-18 04:01:18 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: sonobuoy-e2e-job-5f413cbb3b804c34 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container e2e ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-lzt9z from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:13:55.909: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 05:13:55.909: INFO: 
    Logging pods the apiserver thinks is on node apps-209 before test
    Apr 18 05:13:55.933: INFO: agent-mdi1zj-1-event-agent-757455b86f-jzfp7 from cocktail-addon started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container event-agent ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: agent-mdi1zj-1-metric-agent-0 from cocktail-addon started at 2023-04-14 07:27:47 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container metric-agent ready: true, restart count 6
    Apr 18 05:13:55.933: INFO: monitoring-extension-event-exporter-57bc857b7b-d2kgh from cocktail-addon started at 2023-04-14 07:26:55 +0000 UTC (2 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container caddy ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container event-exporter ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: monitoring-prometheus-node-exporter-tx7km from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: promtail-bgwzf from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: cocktail-api-cmdb-0 from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container api-cmdb ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: cocktail-api-server-5d47cb7fdd-5ptrt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container api-server ready: true, restart count 1
    Apr 18 05:13:55.933: INFO: cocktail-log-api-6c69c456db-j8gr8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container api ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: cocktail-log-loki-0 from cocktail-system started at 2023-04-14 07:04:56 +0000 UTC (2 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container loki ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container tls-proxy ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: cocktail-monitoring-76bdf6974f-p5hs8 from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container monitoring ready: true, restart count 3
    Apr 18 05:13:55.933: INFO: cocktail-monitoring-alarm-collector-78448f5d-gbmcs from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container collector ready: true, restart count 6
    Apr 18 05:13:55.933: INFO: cocktail-monitoring-event-collector-7fd78d476d-9pw9f from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container collector ready: true, restart count 7
    Apr 18 05:13:55.933: INFO: cocktail-monitoring-monitoring-db-0 from cocktail-system started at 2023-04-14 11:20:11 +0000 UTC (2 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container db ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container log-lotate ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: cocktail-monitoring-proxy-648c665797-jd2fs from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container monitoring-proxy ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: cocktail-mq-entity-operator-7964999574-5zzkb from cocktail-system started at 2023-04-14 07:07:37 +0000 UTC (3 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container tls-sidecar ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container topic-operator ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container user-operator ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: cocktail-mq-kafka-0 from cocktail-system started at 2023-04-14 07:08:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container kafka ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: cocktail-mq-zookeeper-0 from cocktail-system started at 2023-04-14 07:05:54 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container zookeeper ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: cocktail-package-5f59d96bd8-d2nj5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container package ready: true, restart count 1
    Apr 18 05:13:55.933: INFO: strimzi-cluster-operator-668f4bff5c-zqqjr from cocktail-system started at 2023-04-14 11:05:05 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container strimzi-cluster-operator ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: calico-node-q6mxd from kube-system started at 2023-04-11 08:28:12 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: coredns-7ffbbc99d-mkf8k from kube-system started at 2023-04-14 11:05:04 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: csi-nfs-controller-7ccd7c4947-dw42l from kube-system started at 2023-04-14 11:05:06 +0000 UTC (3 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container csi-provisioner ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: csi-nfs-node-nh5wf from kube-system started at 2023-04-11 08:28:49 +0000 UTC (4 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: kube-apiserver-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: kube-controller-manager-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Apr 18 05:13:55.933: INFO: kube-proxy-vmwrf from kube-system started at 2023-04-11 08:28:28 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: kube-scheduler-apps-209 from kube-system started at 2023-04-07 08:18:47 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container kube-scheduler ready: true, restart count 1
    Apr 18 05:13:55.933: INFO: metrics-server-7b879bf57b-6vnbg from kube-system started at 2023-04-13 06:15:03 +0000 UTC (1 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-j4n44 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:13:55.933: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:13:55.933: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node apps-207 04/18/23 05:14:02.303
    STEP: verifying the node has the label node apps-208 04/18/23 05:14:02.397
    STEP: verifying the node has the label node apps-209 04/18/23 05:14:02.637
    Apr 18 05:14:02.716: INFO: Pod addon-manager-5d75c94878-q9nwx requesting resource cpu=200m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w requesting resource cpu=100m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod agent-mdi1zj-1-event-agent-757455b86f-jzfp7 requesting resource cpu=100m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod agent-mdi1zj-1-metric-agent-0 requesting resource cpu=100m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod alertmanager-monitoring-kube-prometheus-alertmanager-0 requesting resource cpu=200m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod monitoring-extension-event-exporter-57bc857b7b-d2kgh requesting resource cpu=0m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj requesting resource cpu=100m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod monitoring-kube-state-metrics-7dddf6695f-l8mlh requesting resource cpu=100m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod monitoring-prometheus-node-exporter-d9xr5 requesting resource cpu=200m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod monitoring-prometheus-node-exporter-tx7km requesting resource cpu=200m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod monitoring-prometheus-node-exporter-x99mx requesting resource cpu=200m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod nginx-ingress-nginx-controller-865cbc698d-sqwlm requesting resource cpu=300m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod nginx-ingress-nginx-defaultbackend-649fd8955b-wk6kv requesting resource cpu=0m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod prometheus-monitoring-kube-prometheus-prometheus-0 requesting resource cpu=600m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod promtail-bgwzf requesting resource cpu=0m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod promtail-c9qhr requesting resource cpu=0m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod promtail-fjjqt requesting resource cpu=0m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-api-cmdb-0 requesting resource cpu=500m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-api-gateway-648577694-g7lzt requesting resource cpu=500m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-api-server-5d47cb7fdd-5ptrt requesting resource cpu=1000m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-batch-server-5895cd6748-x5qsz requesting resource cpu=100m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-build-api-5d65b8dd6-8tb9g requesting resource cpu=500m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-build-queue-7855f6f4dd-vsc6p requesting resource cpu=500m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-cluster-api-6b5df5884f-4nbvz requesting resource cpu=500m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-dashboard-86844bcfbd-wbnzx requesting resource cpu=300m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-dashboard-proxy-5476f6847-ptzhj requesting resource cpu=500m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-dashboard-queue-5745c9f74c-2gks8 requesting resource cpu=500m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-dashboard-session-9d746547b-gk8d5 requesting resource cpu=100m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-log-api-6c69c456db-j8gr8 requesting resource cpu=100m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-log-loki-0 requesting resource cpu=0m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-76bdf6974f-p5hs8 requesting resource cpu=1000m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-alarm-collector-78448f5d-gbmcs requesting resource cpu=200m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-event-collector-7fd78d476d-9pw9f requesting resource cpu=200m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-metric-collector-5695cb8669-mktvm requesting resource cpu=200m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-monitoring-db-0 requesting resource cpu=600m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-monitoring-proxy-648c665797-jd2fs requesting resource cpu=100m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-mq-entity-operator-7964999574-5zzkb requesting resource cpu=0m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-mq-kafka-0 requesting resource cpu=500m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-mq-zookeeper-0 requesting resource cpu=0m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod cocktail-package-5f59d96bd8-d2nj5 requesting resource cpu=500m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod strimzi-cluster-operator-668f4bff5c-zqqjr requesting resource cpu=200m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod calico-kube-controllers-74677b4c5f-rjqrf requesting resource cpu=0m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod calico-node-jstls requesting resource cpu=250m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod calico-node-nmmjb requesting resource cpu=250m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod calico-node-q6mxd requesting resource cpu=250m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod coredns-7ffbbc99d-5xc7c requesting resource cpu=100m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod coredns-7ffbbc99d-mkf8k requesting resource cpu=100m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod csi-nfs-controller-7ccd7c4947-dw42l requesting resource cpu=30m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod csi-nfs-node-nh5wf requesting resource cpu=30m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod csi-nfs-node-t4zm5 requesting resource cpu=30m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod csi-nfs-node-w5rjr requesting resource cpu=30m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod kube-apiserver-apps-207 requesting resource cpu=250m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod kube-apiserver-apps-208 requesting resource cpu=250m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod kube-apiserver-apps-209 requesting resource cpu=250m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod kube-controller-manager-apps-207 requesting resource cpu=200m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod kube-controller-manager-apps-208 requesting resource cpu=200m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod kube-controller-manager-apps-209 requesting resource cpu=200m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod kube-proxy-clw95 requesting resource cpu=0m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod kube-proxy-vb944 requesting resource cpu=0m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod kube-proxy-vmwrf requesting resource cpu=0m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod kube-scheduler-apps-207 requesting resource cpu=100m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod kube-scheduler-apps-208 requesting resource cpu=100m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod kube-scheduler-apps-209 requesting resource cpu=100m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod metrics-server-7b879bf57b-6vnbg requesting resource cpu=100m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod metrics-server-7b879bf57b-vfp7l requesting resource cpu=100m on Node apps-207
    Apr 18 05:14:02.716: INFO: Pod pfpod requesting resource cpu=10m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod pod-no-resources requesting resource cpu=100m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod pod-partial-resources requesting resource cpu=300m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod sonobuoy requesting resource cpu=0m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod sonobuoy-e2e-job-5f413cbb3b804c34 requesting resource cpu=0m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-j4n44 requesting resource cpu=0m on Node apps-209
    Apr 18 05:14:02.716: INFO: Pod sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-lzt9z requesting resource cpu=0m on Node apps-208
    Apr 18 05:14:02.716: INFO: Pod sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn requesting resource cpu=0m on Node apps-207
    STEP: Starting Pods to consume most of the cluster CPU. 04/18/23 05:14:02.716
    Apr 18 05:14:02.716: INFO: Creating a pod which consumes cpu=1239m on Node apps-207
    Apr 18 05:14:02.778: INFO: Creating a pod which consumes cpu=4382m on Node apps-208
    Apr 18 05:14:02.922: INFO: Creating a pod which consumes cpu=1148m on Node apps-209
    Apr 18 05:14:02.939: INFO: Waiting up to 5m0s for pod "filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf" in namespace "sched-pred-8589" to be "running"
    Apr 18 05:14:03.237: INFO: Pod "filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf": Phase="Pending", Reason="", readiness=false. Elapsed: 298.27059ms
    Apr 18 05:14:05.243: INFO: Pod "filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.30417745s
    Apr 18 05:14:07.242: INFO: Pod "filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf": Phase="Running", Reason="", readiness=true. Elapsed: 4.303524279s
    Apr 18 05:14:07.242: INFO: Pod "filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf" satisfied condition "running"
    Apr 18 05:14:07.242: INFO: Waiting up to 5m0s for pod "filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918" in namespace "sched-pred-8589" to be "running"
    Apr 18 05:14:07.245: INFO: Pod "filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918": Phase="Running", Reason="", readiness=true. Elapsed: 2.604499ms
    Apr 18 05:14:07.245: INFO: Pod "filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918" satisfied condition "running"
    Apr 18 05:14:07.245: INFO: Waiting up to 5m0s for pod "filler-pod-b63ea385-5e38-4509-911b-806984071690" in namespace "sched-pred-8589" to be "running"
    Apr 18 05:14:07.248: INFO: Pod "filler-pod-b63ea385-5e38-4509-911b-806984071690": Phase="Running", Reason="", readiness=true. Elapsed: 2.61785ms
    Apr 18 05:14:07.248: INFO: Pod "filler-pod-b63ea385-5e38-4509-911b-806984071690" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 04/18/23 05:14:07.248
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf.1756ef7fc6f468ab], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8589/filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf to apps-207] 04/18/23 05:14:07.251
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf.1756ef80420d5dee], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 05:14:07.251
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf.1756ef806dd93ac3], Reason = [Created], Message = [Created container filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf] 04/18/23 05:14:07.251
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf.1756ef807ac36f05], Reason = [Started], Message = [Started container filler-pod-61fdd15e-3e93-49c7-b77f-cb51a5adcaaf] 04/18/23 05:14:07.251
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-b63ea385-5e38-4509-911b-806984071690.1756ef7fca65e710], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8589/filler-pod-b63ea385-5e38-4509-911b-806984071690 to apps-209] 04/18/23 05:14:07.251
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-b63ea385-5e38-4509-911b-806984071690.1756ef8057c59532], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 05:14:07.251
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-b63ea385-5e38-4509-911b-806984071690.1756ef8083c2b077], Reason = [Created], Message = [Created container filler-pod-b63ea385-5e38-4509-911b-806984071690] 04/18/23 05:14:07.251
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-b63ea385-5e38-4509-911b-806984071690.1756ef808f2f6951], Reason = [Started], Message = [Started container filler-pod-b63ea385-5e38-4509-911b-806984071690] 04/18/23 05:14:07.252
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918.1756ef7fc8fd1327], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8589/filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918 to apps-208] 04/18/23 05:14:07.252
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918.1756ef80605cbaef], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/18/23 05:14:07.252
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918.1756ef8093211ad3], Reason = [Created], Message = [Created container filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918] 04/18/23 05:14:07.252
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918.1756ef809e12281d], Reason = [Started], Message = [Started container filler-pod-d91c323a-50dc-4e7b-8c4c-14e01851e918] 04/18/23 05:14:07.252
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.1756ef80ca64a4db], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.] 04/18/23 05:14:07.371
    STEP: removing the label node off the node apps-207 04/18/23 05:14:08.305
    STEP: verifying the node doesn't have the label node 04/18/23 05:14:08.378
    STEP: removing the label node off the node apps-208 04/18/23 05:14:08.41
    STEP: verifying the node doesn't have the label node 04/18/23 05:14:08.45
    STEP: removing the label node off the node apps-209 04/18/23 05:14:08.458
    STEP: verifying the node doesn't have the label node 04/18/23 05:14:08.537
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:14:08.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8589" for this suite. 04/18/23 05:14:08.562
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:14:08.591
Apr 18 05:14:08.591: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 05:14:08.592
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:14:08.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:14:08.7
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 04/18/23 05:14:08.702
Apr 18 05:14:08.734: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1" in namespace "downward-api-4875" to be "Succeeded or Failed"
Apr 18 05:14:08.759: INFO: Pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.970101ms
Apr 18 05:14:10.779: INFO: Pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045060857s
Apr 18 05:14:12.763: INFO: Pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1": Phase="Running", Reason="", readiness=false. Elapsed: 4.028687605s
Apr 18 05:14:14.763: INFO: Pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029172132s
STEP: Saw pod success 04/18/23 05:14:14.763
Apr 18 05:14:14.763: INFO: Pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1" satisfied condition "Succeeded or Failed"
Apr 18 05:14:15.416: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1 container client-container: <nil>
STEP: delete the pod 04/18/23 05:14:15.558
Apr 18 05:14:15.693: INFO: Waiting for pod downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1 to disappear
Apr 18 05:14:15.768: INFO: Pod downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 05:14:15.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4875" for this suite. 04/18/23 05:14:15.774
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":170,"skipped":3024,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.335 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:14:08.591
    Apr 18 05:14:08.591: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 05:14:08.592
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:14:08.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:14:08.7
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 04/18/23 05:14:08.702
    Apr 18 05:14:08.734: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1" in namespace "downward-api-4875" to be "Succeeded or Failed"
    Apr 18 05:14:08.759: INFO: Pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.970101ms
    Apr 18 05:14:10.779: INFO: Pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045060857s
    Apr 18 05:14:12.763: INFO: Pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1": Phase="Running", Reason="", readiness=false. Elapsed: 4.028687605s
    Apr 18 05:14:14.763: INFO: Pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029172132s
    STEP: Saw pod success 04/18/23 05:14:14.763
    Apr 18 05:14:14.763: INFO: Pod "downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1" satisfied condition "Succeeded or Failed"
    Apr 18 05:14:15.416: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1 container client-container: <nil>
    STEP: delete the pod 04/18/23 05:14:15.558
    Apr 18 05:14:15.693: INFO: Waiting for pod downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1 to disappear
    Apr 18 05:14:15.768: INFO: Pod downwardapi-volume-5ab1855f-536b-4f06-a178-45ac451cf6f1 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 05:14:15.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4875" for this suite. 04/18/23 05:14:15.774
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:14:15.928
Apr 18 05:14:15.928: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 05:14:15.929
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:14:16.132
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:14:16.135
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Apr 18 05:14:16.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/18/23 05:14:30.203
Apr 18 05:14:30.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 create -f -'
Apr 18 05:14:31.831: INFO: stderr: ""
Apr 18 05:14:31.831: INFO: stdout: "e2e-test-crd-publish-openapi-3266-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 18 05:14:31.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 delete e2e-test-crd-publish-openapi-3266-crds test-foo'
Apr 18 05:14:32.000: INFO: stderr: ""
Apr 18 05:14:32.000: INFO: stdout: "e2e-test-crd-publish-openapi-3266-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 18 05:14:32.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 apply -f -'
Apr 18 05:14:33.398: INFO: stderr: ""
Apr 18 05:14:33.398: INFO: stdout: "e2e-test-crd-publish-openapi-3266-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 18 05:14:33.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 delete e2e-test-crd-publish-openapi-3266-crds test-foo'
Apr 18 05:14:33.519: INFO: stderr: ""
Apr 18 05:14:33.519: INFO: stdout: "e2e-test-crd-publish-openapi-3266-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/18/23 05:14:33.519
Apr 18 05:14:33.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 create -f -'
Apr 18 05:14:34.946: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/18/23 05:14:34.946
Apr 18 05:14:34.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 create -f -'
Apr 18 05:14:35.328: INFO: rc: 1
Apr 18 05:14:35.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 apply -f -'
Apr 18 05:14:35.723: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/18/23 05:14:35.723
Apr 18 05:14:35.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 create -f -'
Apr 18 05:14:36.099: INFO: rc: 1
Apr 18 05:14:36.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 apply -f -'
Apr 18 05:14:36.495: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 04/18/23 05:14:36.495
Apr 18 05:14:36.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 explain e2e-test-crd-publish-openapi-3266-crds'
Apr 18 05:14:36.863: INFO: stderr: ""
Apr 18 05:14:36.863: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3266-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 04/18/23 05:14:36.864
Apr 18 05:14:36.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 explain e2e-test-crd-publish-openapi-3266-crds.metadata'
Apr 18 05:14:37.245: INFO: stderr: ""
Apr 18 05:14:37.245: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3266-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 18 05:14:37.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 explain e2e-test-crd-publish-openapi-3266-crds.spec'
Apr 18 05:14:37.628: INFO: stderr: ""
Apr 18 05:14:37.628: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3266-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 18 05:14:37.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 explain e2e-test-crd-publish-openapi-3266-crds.spec.bars'
Apr 18 05:14:38.002: INFO: stderr: ""
Apr 18 05:14:38.002: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3266-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/18/23 05:14:38.002
Apr 18 05:14:38.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 explain e2e-test-crd-publish-openapi-3266-crds.spec.bars2'
Apr 18 05:14:38.382: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:14:47.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9603" for this suite. 04/18/23 05:14:47.39
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":171,"skipped":3050,"failed":0}
------------------------------
â€¢ [SLOW TEST] [31.485 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:14:15.928
    Apr 18 05:14:15.928: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 05:14:15.929
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:14:16.132
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:14:16.135
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Apr 18 05:14:16.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/18/23 05:14:30.203
    Apr 18 05:14:30.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 create -f -'
    Apr 18 05:14:31.831: INFO: stderr: ""
    Apr 18 05:14:31.831: INFO: stdout: "e2e-test-crd-publish-openapi-3266-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 18 05:14:31.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 delete e2e-test-crd-publish-openapi-3266-crds test-foo'
    Apr 18 05:14:32.000: INFO: stderr: ""
    Apr 18 05:14:32.000: INFO: stdout: "e2e-test-crd-publish-openapi-3266-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Apr 18 05:14:32.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 apply -f -'
    Apr 18 05:14:33.398: INFO: stderr: ""
    Apr 18 05:14:33.398: INFO: stdout: "e2e-test-crd-publish-openapi-3266-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 18 05:14:33.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 delete e2e-test-crd-publish-openapi-3266-crds test-foo'
    Apr 18 05:14:33.519: INFO: stderr: ""
    Apr 18 05:14:33.519: INFO: stdout: "e2e-test-crd-publish-openapi-3266-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/18/23 05:14:33.519
    Apr 18 05:14:33.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 create -f -'
    Apr 18 05:14:34.946: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/18/23 05:14:34.946
    Apr 18 05:14:34.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 create -f -'
    Apr 18 05:14:35.328: INFO: rc: 1
    Apr 18 05:14:35.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 apply -f -'
    Apr 18 05:14:35.723: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/18/23 05:14:35.723
    Apr 18 05:14:35.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 create -f -'
    Apr 18 05:14:36.099: INFO: rc: 1
    Apr 18 05:14:36.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 --namespace=crd-publish-openapi-9603 apply -f -'
    Apr 18 05:14:36.495: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 04/18/23 05:14:36.495
    Apr 18 05:14:36.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 explain e2e-test-crd-publish-openapi-3266-crds'
    Apr 18 05:14:36.863: INFO: stderr: ""
    Apr 18 05:14:36.863: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3266-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 04/18/23 05:14:36.864
    Apr 18 05:14:36.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 explain e2e-test-crd-publish-openapi-3266-crds.metadata'
    Apr 18 05:14:37.245: INFO: stderr: ""
    Apr 18 05:14:37.245: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3266-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Apr 18 05:14:37.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 explain e2e-test-crd-publish-openapi-3266-crds.spec'
    Apr 18 05:14:37.628: INFO: stderr: ""
    Apr 18 05:14:37.628: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3266-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Apr 18 05:14:37.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 explain e2e-test-crd-publish-openapi-3266-crds.spec.bars'
    Apr 18 05:14:38.002: INFO: stderr: ""
    Apr 18 05:14:38.002: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3266-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/18/23 05:14:38.002
    Apr 18 05:14:38.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-9603 explain e2e-test-crd-publish-openapi-3266-crds.spec.bars2'
    Apr 18 05:14:38.382: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:14:47.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9603" for this suite. 04/18/23 05:14:47.39
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:14:47.413
Apr 18 05:14:47.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 05:14:47.414
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:14:47.504
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:14:47.507
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 04/18/23 05:14:47.51
Apr 18 05:14:47.579: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34" in namespace "downward-api-120" to be "Succeeded or Failed"
Apr 18 05:14:47.582: INFO: Pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34": Phase="Pending", Reason="", readiness=false. Elapsed: 2.963962ms
Apr 18 05:14:49.586: INFO: Pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007632804s
Apr 18 05:14:51.587: INFO: Pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008374722s
Apr 18 05:14:53.610: INFO: Pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030995716s
STEP: Saw pod success 04/18/23 05:14:53.61
Apr 18 05:14:53.610: INFO: Pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34" satisfied condition "Succeeded or Failed"
Apr 18 05:14:53.613: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34 container client-container: <nil>
STEP: delete the pod 04/18/23 05:14:53.671
Apr 18 05:14:53.823: INFO: Waiting for pod downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34 to disappear
Apr 18 05:14:53.844: INFO: Pod downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 05:14:53.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-120" for this suite. 04/18/23 05:14:53.849
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":172,"skipped":3055,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.533 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:14:47.413
    Apr 18 05:14:47.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 05:14:47.414
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:14:47.504
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:14:47.507
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 04/18/23 05:14:47.51
    Apr 18 05:14:47.579: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34" in namespace "downward-api-120" to be "Succeeded or Failed"
    Apr 18 05:14:47.582: INFO: Pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34": Phase="Pending", Reason="", readiness=false. Elapsed: 2.963962ms
    Apr 18 05:14:49.586: INFO: Pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007632804s
    Apr 18 05:14:51.587: INFO: Pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008374722s
    Apr 18 05:14:53.610: INFO: Pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.030995716s
    STEP: Saw pod success 04/18/23 05:14:53.61
    Apr 18 05:14:53.610: INFO: Pod "downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34" satisfied condition "Succeeded or Failed"
    Apr 18 05:14:53.613: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34 container client-container: <nil>
    STEP: delete the pod 04/18/23 05:14:53.671
    Apr 18 05:14:53.823: INFO: Waiting for pod downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34 to disappear
    Apr 18 05:14:53.844: INFO: Pod downwardapi-volume-7a68e4a1-4b94-4b40-bc0d-0fe6b388fc34 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 05:14:53.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-120" for this suite. 04/18/23 05:14:53.849
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:14:53.947
Apr 18 05:14:53.947: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 05:14:53.948
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:14:54.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:14:54.014
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 04/18/23 05:14:54.017
Apr 18 05:14:54.155: INFO: Waiting up to 5m0s for pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23" in namespace "downward-api-3388" to be "Succeeded or Failed"
Apr 18 05:14:54.185: INFO: Pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23": Phase="Pending", Reason="", readiness=false. Elapsed: 30.309276ms
Apr 18 05:14:56.189: INFO: Pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034371981s
Apr 18 05:14:58.189: INFO: Pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034168224s
Apr 18 05:15:00.190: INFO: Pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03572254s
STEP: Saw pod success 04/18/23 05:15:00.191
Apr 18 05:15:00.191: INFO: Pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23" satisfied condition "Succeeded or Failed"
Apr 18 05:15:00.194: INFO: Trying to get logs from node apps-208 pod downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23 container dapi-container: <nil>
STEP: delete the pod 04/18/23 05:15:00.229
Apr 18 05:15:00.318: INFO: Waiting for pod downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23 to disappear
Apr 18 05:15:00.340: INFO: Pod downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 18 05:15:00.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3388" for this suite. 04/18/23 05:15:00.345
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":173,"skipped":3064,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.443 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:14:53.947
    Apr 18 05:14:53.947: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 05:14:53.948
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:14:54.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:14:54.014
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 04/18/23 05:14:54.017
    Apr 18 05:14:54.155: INFO: Waiting up to 5m0s for pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23" in namespace "downward-api-3388" to be "Succeeded or Failed"
    Apr 18 05:14:54.185: INFO: Pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23": Phase="Pending", Reason="", readiness=false. Elapsed: 30.309276ms
    Apr 18 05:14:56.189: INFO: Pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034371981s
    Apr 18 05:14:58.189: INFO: Pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034168224s
    Apr 18 05:15:00.190: INFO: Pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03572254s
    STEP: Saw pod success 04/18/23 05:15:00.191
    Apr 18 05:15:00.191: INFO: Pod "downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23" satisfied condition "Succeeded or Failed"
    Apr 18 05:15:00.194: INFO: Trying to get logs from node apps-208 pod downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 05:15:00.229
    Apr 18 05:15:00.318: INFO: Waiting for pod downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23 to disappear
    Apr 18 05:15:00.340: INFO: Pod downward-api-4b96b995-beb6-4f5e-90ea-b53301bbec23 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 18 05:15:00.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3388" for this suite. 04/18/23 05:15:00.345
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:15:00.39
Apr 18 05:15:00.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:15:00.391
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:00.511
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:00.513
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-68aeeab8-3cfe-444d-beea-2bdb47f06e99 04/18/23 05:15:00.534
STEP: Creating a pod to test consume configMaps 04/18/23 05:15:00.593
Apr 18 05:15:00.638: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d" in namespace "projected-4331" to be "Succeeded or Failed"
Apr 18 05:15:00.676: INFO: Pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d": Phase="Pending", Reason="", readiness=false. Elapsed: 37.683643ms
Apr 18 05:15:02.755: INFO: Pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.117449231s
Apr 18 05:15:04.709: INFO: Pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d": Phase="Running", Reason="", readiness=false. Elapsed: 4.071013321s
Apr 18 05:15:06.679: INFO: Pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.041613469s
STEP: Saw pod success 04/18/23 05:15:06.68
Apr 18 05:15:06.680: INFO: Pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d" satisfied condition "Succeeded or Failed"
Apr 18 05:15:06.715: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:15:06.721
Apr 18 05:15:06.816: INFO: Waiting for pod pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d to disappear
Apr 18 05:15:06.819: INFO: Pod pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 05:15:06.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4331" for this suite. 04/18/23 05:15:06.823
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":174,"skipped":3069,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.457 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:15:00.39
    Apr 18 05:15:00.390: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:15:00.391
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:00.511
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:00.513
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-68aeeab8-3cfe-444d-beea-2bdb47f06e99 04/18/23 05:15:00.534
    STEP: Creating a pod to test consume configMaps 04/18/23 05:15:00.593
    Apr 18 05:15:00.638: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d" in namespace "projected-4331" to be "Succeeded or Failed"
    Apr 18 05:15:00.676: INFO: Pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d": Phase="Pending", Reason="", readiness=false. Elapsed: 37.683643ms
    Apr 18 05:15:02.755: INFO: Pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.117449231s
    Apr 18 05:15:04.709: INFO: Pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d": Phase="Running", Reason="", readiness=false. Elapsed: 4.071013321s
    Apr 18 05:15:06.679: INFO: Pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.041613469s
    STEP: Saw pod success 04/18/23 05:15:06.68
    Apr 18 05:15:06.680: INFO: Pod "pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d" satisfied condition "Succeeded or Failed"
    Apr 18 05:15:06.715: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:15:06.721
    Apr 18 05:15:06.816: INFO: Waiting for pod pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d to disappear
    Apr 18 05:15:06.819: INFO: Pod pod-projected-configmaps-00bb581a-cdd5-4310-85c8-8f443382133d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 05:15:06.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4331" for this suite. 04/18/23 05:15:06.823
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:15:06.849
Apr 18 05:15:06.849: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename watch 04/18/23 05:15:06.85
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:06.928
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:06.931
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 04/18/23 05:15:06.933
STEP: starting a background goroutine to produce watch events 04/18/23 05:15:06.982
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/18/23 05:15:06.982
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 18 05:15:11.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9682" for this suite. 04/18/23 05:15:11.492
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":175,"skipped":3098,"failed":0}
------------------------------
â€¢ [4.667 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:15:06.849
    Apr 18 05:15:06.849: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename watch 04/18/23 05:15:06.85
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:06.928
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:06.931
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 04/18/23 05:15:06.933
    STEP: starting a background goroutine to produce watch events 04/18/23 05:15:06.982
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/18/23 05:15:06.982
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 18 05:15:11.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-9682" for this suite. 04/18/23 05:15:11.492
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:15:11.519
Apr 18 05:15:11.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-runtime 04/18/23 05:15:11.52
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:11.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:11.66
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 04/18/23 05:15:11.664
STEP: wait for the container to reach Succeeded 04/18/23 05:15:11.793
STEP: get the container status 04/18/23 05:15:17.951
STEP: the container should be terminated 04/18/23 05:15:17.958
STEP: the termination message should be set 04/18/23 05:15:17.958
Apr 18 05:15:17.958: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 04/18/23 05:15:17.958
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 18 05:15:18.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5137" for this suite. 04/18/23 05:15:18.127
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":176,"skipped":3127,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.622 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:15:11.519
    Apr 18 05:15:11.519: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-runtime 04/18/23 05:15:11.52
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:11.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:11.66
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 04/18/23 05:15:11.664
    STEP: wait for the container to reach Succeeded 04/18/23 05:15:11.793
    STEP: get the container status 04/18/23 05:15:17.951
    STEP: the container should be terminated 04/18/23 05:15:17.958
    STEP: the termination message should be set 04/18/23 05:15:17.958
    Apr 18 05:15:17.958: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 04/18/23 05:15:17.958
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 18 05:15:18.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5137" for this suite. 04/18/23 05:15:18.127
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:15:18.14
Apr 18 05:15:18.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 05:15:18.141
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:18.166
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:18.169
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-c38c828b-d31a-4330-ab29-f5fe4981f1a8 04/18/23 05:15:18.189
STEP: Creating a pod to test consume secrets 04/18/23 05:15:18.292
Apr 18 05:15:18.417: INFO: Waiting up to 5m0s for pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79" in namespace "secrets-652" to be "Succeeded or Failed"
Apr 18 05:15:18.467: INFO: Pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79": Phase="Pending", Reason="", readiness=false. Elapsed: 50.062847ms
Apr 18 05:15:20.472: INFO: Pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054793778s
Apr 18 05:15:22.492: INFO: Pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075335075s
Apr 18 05:15:24.472: INFO: Pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05488043s
STEP: Saw pod success 04/18/23 05:15:24.472
Apr 18 05:15:24.472: INFO: Pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79" satisfied condition "Succeeded or Failed"
Apr 18 05:15:24.475: INFO: Trying to get logs from node apps-208 pod pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 05:15:24.482
Apr 18 05:15:24.551: INFO: Waiting for pod pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79 to disappear
Apr 18 05:15:24.586: INFO: Pod pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 05:15:24.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-652" for this suite. 04/18/23 05:15:24.591
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":177,"skipped":3127,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.542 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:15:18.14
    Apr 18 05:15:18.141: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 05:15:18.141
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:18.166
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:18.169
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-c38c828b-d31a-4330-ab29-f5fe4981f1a8 04/18/23 05:15:18.189
    STEP: Creating a pod to test consume secrets 04/18/23 05:15:18.292
    Apr 18 05:15:18.417: INFO: Waiting up to 5m0s for pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79" in namespace "secrets-652" to be "Succeeded or Failed"
    Apr 18 05:15:18.467: INFO: Pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79": Phase="Pending", Reason="", readiness=false. Elapsed: 50.062847ms
    Apr 18 05:15:20.472: INFO: Pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054793778s
    Apr 18 05:15:22.492: INFO: Pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075335075s
    Apr 18 05:15:24.472: INFO: Pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05488043s
    STEP: Saw pod success 04/18/23 05:15:24.472
    Apr 18 05:15:24.472: INFO: Pod "pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79" satisfied condition "Succeeded or Failed"
    Apr 18 05:15:24.475: INFO: Trying to get logs from node apps-208 pod pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 05:15:24.482
    Apr 18 05:15:24.551: INFO: Waiting for pod pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79 to disappear
    Apr 18 05:15:24.586: INFO: Pod pod-secrets-841e39e9-dc3d-4458-9155-f7fcb1417f79 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 05:15:24.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-652" for this suite. 04/18/23 05:15:24.591
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:15:24.683
Apr 18 05:15:24.683: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename security-context-test 04/18/23 05:15:24.684
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:24.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:24.77
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Apr 18 05:15:24.877: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7" in namespace "security-context-test-7328" to be "Succeeded or Failed"
Apr 18 05:15:24.880: INFO: Pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.983582ms
Apr 18 05:15:26.992: INFO: Pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.115283083s
Apr 18 05:15:28.910: INFO: Pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033681174s
Apr 18 05:15:30.883: INFO: Pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0068004s
Apr 18 05:15:30.883: INFO: Pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7" satisfied condition "Succeeded or Failed"
Apr 18 05:15:30.889: INFO: Got logs for pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 05:15:30.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7328" for this suite. 04/18/23 05:15:30.894
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":178,"skipped":3134,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.236 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:15:24.683
    Apr 18 05:15:24.683: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename security-context-test 04/18/23 05:15:24.684
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:24.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:24.77
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Apr 18 05:15:24.877: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7" in namespace "security-context-test-7328" to be "Succeeded or Failed"
    Apr 18 05:15:24.880: INFO: Pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.983582ms
    Apr 18 05:15:26.992: INFO: Pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.115283083s
    Apr 18 05:15:28.910: INFO: Pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033681174s
    Apr 18 05:15:30.883: INFO: Pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0068004s
    Apr 18 05:15:30.883: INFO: Pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7" satisfied condition "Succeeded or Failed"
    Apr 18 05:15:30.889: INFO: Got logs for pod "busybox-privileged-false-0a89ac63-0c46-434e-9eec-daff9f242cc7": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 05:15:30.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-7328" for this suite. 04/18/23 05:15:30.894
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:15:30.919
Apr 18 05:15:30.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/18/23 05:15:30.92
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:31.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:31.166
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 04/18/23 05:15:31.21
STEP: Creating hostNetwork=false pod 04/18/23 05:15:31.21
Apr 18 05:15:31.278: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-8915" to be "running and ready"
Apr 18 05:15:31.281: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.032566ms
Apr 18 05:15:31.281: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:15:33.285: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00635772s
Apr 18 05:15:33.285: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:15:35.320: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041334184s
Apr 18 05:15:35.320: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:15:37.303: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.02425037s
Apr 18 05:15:37.303: INFO: The phase of Pod test-pod is Running (Ready = true)
Apr 18 05:15:37.303: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 04/18/23 05:15:37.305
Apr 18 05:15:37.364: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-8915" to be "running and ready"
Apr 18 05:15:37.396: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 32.313564ms
Apr 18 05:15:37.396: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:15:39.451: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086971184s
Apr 18 05:15:39.451: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:15:41.414: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.049925709s
Apr 18 05:15:41.414: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Apr 18 05:15:41.414: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 04/18/23 05:15:41.417
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/18/23 05:15:41.417
Apr 18 05:15:41.417: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:15:41.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:15:41.418: INFO: ExecWithOptions: Clientset creation
Apr 18 05:15:41.418: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 18 05:15:41.502: INFO: Exec stderr: ""
Apr 18 05:15:41.502: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:15:41.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:15:41.503: INFO: ExecWithOptions: Clientset creation
Apr 18 05:15:41.503: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 18 05:15:41.596: INFO: Exec stderr: ""
Apr 18 05:15:41.596: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:15:41.596: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:15:41.597: INFO: ExecWithOptions: Clientset creation
Apr 18 05:15:41.597: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 18 05:15:41.669: INFO: Exec stderr: ""
Apr 18 05:15:41.669: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:15:41.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:15:41.669: INFO: ExecWithOptions: Clientset creation
Apr 18 05:15:41.669: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 18 05:15:41.736: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/18/23 05:15:41.736
Apr 18 05:15:41.736: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:15:41.736: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:15:41.737: INFO: ExecWithOptions: Clientset creation
Apr 18 05:15:41.737: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 18 05:15:41.824: INFO: Exec stderr: ""
Apr 18 05:15:41.824: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:15:41.824: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:15:41.824: INFO: ExecWithOptions: Clientset creation
Apr 18 05:15:41.825: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 18 05:15:41.897: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/18/23 05:15:41.897
Apr 18 05:15:41.897: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:15:41.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:15:41.898: INFO: ExecWithOptions: Clientset creation
Apr 18 05:15:41.898: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 18 05:15:41.963: INFO: Exec stderr: ""
Apr 18 05:15:41.963: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:15:41.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:15:41.964: INFO: ExecWithOptions: Clientset creation
Apr 18 05:15:41.964: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 18 05:15:42.038: INFO: Exec stderr: ""
Apr 18 05:15:42.038: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:15:42.038: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:15:42.038: INFO: ExecWithOptions: Clientset creation
Apr 18 05:15:42.039: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 18 05:15:42.115: INFO: Exec stderr: ""
Apr 18 05:15:42.115: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:15:42.115: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:15:42.115: INFO: ExecWithOptions: Clientset creation
Apr 18 05:15:42.115: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 18 05:15:42.183: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Apr 18 05:15:42.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8915" for this suite. 04/18/23 05:15:42.188
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":179,"skipped":3145,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.292 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:15:30.919
    Apr 18 05:15:30.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/18/23 05:15:30.92
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:31.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:31.166
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 04/18/23 05:15:31.21
    STEP: Creating hostNetwork=false pod 04/18/23 05:15:31.21
    Apr 18 05:15:31.278: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-8915" to be "running and ready"
    Apr 18 05:15:31.281: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.032566ms
    Apr 18 05:15:31.281: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:15:33.285: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00635772s
    Apr 18 05:15:33.285: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:15:35.320: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041334184s
    Apr 18 05:15:35.320: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:15:37.303: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.02425037s
    Apr 18 05:15:37.303: INFO: The phase of Pod test-pod is Running (Ready = true)
    Apr 18 05:15:37.303: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 04/18/23 05:15:37.305
    Apr 18 05:15:37.364: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-8915" to be "running and ready"
    Apr 18 05:15:37.396: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 32.313564ms
    Apr 18 05:15:37.396: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:15:39.451: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086971184s
    Apr 18 05:15:39.451: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:15:41.414: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.049925709s
    Apr 18 05:15:41.414: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Apr 18 05:15:41.414: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 04/18/23 05:15:41.417
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/18/23 05:15:41.417
    Apr 18 05:15:41.417: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:15:41.417: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:15:41.418: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:15:41.418: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 18 05:15:41.502: INFO: Exec stderr: ""
    Apr 18 05:15:41.502: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:15:41.502: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:15:41.503: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:15:41.503: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 18 05:15:41.596: INFO: Exec stderr: ""
    Apr 18 05:15:41.596: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:15:41.596: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:15:41.597: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:15:41.597: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 18 05:15:41.669: INFO: Exec stderr: ""
    Apr 18 05:15:41.669: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:15:41.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:15:41.669: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:15:41.669: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 18 05:15:41.736: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/18/23 05:15:41.736
    Apr 18 05:15:41.736: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:15:41.736: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:15:41.737: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:15:41.737: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 18 05:15:41.824: INFO: Exec stderr: ""
    Apr 18 05:15:41.824: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:15:41.824: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:15:41.824: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:15:41.825: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 18 05:15:41.897: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/18/23 05:15:41.897
    Apr 18 05:15:41.897: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:15:41.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:15:41.898: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:15:41.898: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 18 05:15:41.963: INFO: Exec stderr: ""
    Apr 18 05:15:41.963: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:15:41.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:15:41.964: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:15:41.964: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 18 05:15:42.038: INFO: Exec stderr: ""
    Apr 18 05:15:42.038: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:15:42.038: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:15:42.038: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:15:42.039: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 18 05:15:42.115: INFO: Exec stderr: ""
    Apr 18 05:15:42.115: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8915 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:15:42.115: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:15:42.115: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:15:42.115: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-8915/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 18 05:15:42.183: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Apr 18 05:15:42.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-8915" for this suite. 04/18/23 05:15:42.188
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:15:42.212
Apr 18 05:15:42.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename dns 04/18/23 05:15:42.213
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:42.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:42.408
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 04/18/23 05:15:42.411
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5280 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5280;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5280 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5280;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5280.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5280.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5280.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5280.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5280.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5280.svc;check="$$(dig +notcp +noall +answer +search 178.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.178_udp@PTR;check="$$(dig +tcp +noall +answer +search 178.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.178_tcp@PTR;sleep 1; done
 04/18/23 05:15:42.544
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5280 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5280;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5280 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5280;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5280.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5280.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5280.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5280.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5280.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5280.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5280.svc;check="$$(dig +notcp +noall +answer +search 178.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.178_udp@PTR;check="$$(dig +tcp +noall +answer +search 178.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.178_tcp@PTR;sleep 1; done
 04/18/23 05:15:42.545
STEP: creating a pod to probe DNS 04/18/23 05:15:42.545
STEP: submitting the pod to kubernetes 04/18/23 05:15:42.545
Apr 18 05:15:42.781: INFO: Waiting up to 15m0s for pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808" in namespace "dns-5280" to be "running"
Apr 18 05:15:42.787: INFO: Pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808": Phase="Pending", Reason="", readiness=false. Elapsed: 5.769607ms
Apr 18 05:15:44.791: INFO: Pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009973291s
Apr 18 05:15:46.803: INFO: Pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021908082s
Apr 18 05:15:48.791: INFO: Pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808": Phase="Running", Reason="", readiness=true. Elapsed: 6.009751958s
Apr 18 05:15:48.791: INFO: Pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808" satisfied condition "running"
STEP: retrieving the pod 04/18/23 05:15:48.791
STEP: looking for the results for each expected name from probers 04/18/23 05:15:48.794
Apr 18 05:15:48.880: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:48.884: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:48.949: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:48.982: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.017: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.080: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.090: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.111: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.182: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.186: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.189: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.220: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.286: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.356: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.390: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.421: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:49.482: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

Apr 18 05:15:54.489: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.492: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.496: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.500: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.503: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.507: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.517: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.521: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.537: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.540: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.544: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.547: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.550: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.553: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.557: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.560: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:54.573: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

Apr 18 05:15:59.491: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.494: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.498: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.501: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.504: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.508: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.511: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.514: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.531: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.534: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.537: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.541: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.544: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.547: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.551: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.554: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:15:59.567: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

Apr 18 05:16:04.501: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.550: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.553: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.557: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.560: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.563: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.567: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.570: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.586: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.589: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.593: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.596: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.615: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.624: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.628: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.631: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:04.644: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

Apr 18 05:16:09.490: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.494: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.498: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.501: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.504: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.508: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.511: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.514: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.531: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.535: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.538: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.541: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.544: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.548: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.562: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.566: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:09.580: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

Apr 18 05:16:14.489: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.493: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.496: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.500: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.503: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.506: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.509: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.512: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.529: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.533: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.536: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.539: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.542: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.545: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.548: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.551: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
Apr 18 05:16:14.565: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

Apr 18 05:16:19.564: INFO: DNS probes using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 succeeded

STEP: deleting the pod 04/18/23 05:16:19.564
STEP: deleting the test service 04/18/23 05:16:19.867
STEP: deleting the test headless service 04/18/23 05:16:20.048
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 05:16:20.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5280" for this suite. 04/18/23 05:16:20.188
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":180,"skipped":3161,"failed":0}
------------------------------
â€¢ [SLOW TEST] [38.003 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:15:42.212
    Apr 18 05:15:42.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename dns 04/18/23 05:15:42.213
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:15:42.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:15:42.408
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 04/18/23 05:15:42.411
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5280 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5280;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5280 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5280;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5280.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5280.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5280.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5280.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5280.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5280.svc;check="$$(dig +notcp +noall +answer +search 178.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.178_udp@PTR;check="$$(dig +tcp +noall +answer +search 178.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.178_tcp@PTR;sleep 1; done
     04/18/23 05:15:42.544
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5280 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5280;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5280 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5280;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5280.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5280.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5280.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5280.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5280.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5280.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5280.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5280.svc;check="$$(dig +notcp +noall +answer +search 178.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.178_udp@PTR;check="$$(dig +tcp +noall +answer +search 178.2.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.2.178_tcp@PTR;sleep 1; done
     04/18/23 05:15:42.545
    STEP: creating a pod to probe DNS 04/18/23 05:15:42.545
    STEP: submitting the pod to kubernetes 04/18/23 05:15:42.545
    Apr 18 05:15:42.781: INFO: Waiting up to 15m0s for pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808" in namespace "dns-5280" to be "running"
    Apr 18 05:15:42.787: INFO: Pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808": Phase="Pending", Reason="", readiness=false. Elapsed: 5.769607ms
    Apr 18 05:15:44.791: INFO: Pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009973291s
    Apr 18 05:15:46.803: INFO: Pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021908082s
    Apr 18 05:15:48.791: INFO: Pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808": Phase="Running", Reason="", readiness=true. Elapsed: 6.009751958s
    Apr 18 05:15:48.791: INFO: Pod "dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 05:15:48.791
    STEP: looking for the results for each expected name from probers 04/18/23 05:15:48.794
    Apr 18 05:15:48.880: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:48.884: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:48.949: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:48.982: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.017: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.080: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.090: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.111: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.182: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.186: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.189: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.220: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.286: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.356: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.390: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.421: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:49.482: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

    Apr 18 05:15:54.489: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.492: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.496: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.500: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.503: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.507: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.517: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.521: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.537: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.540: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.544: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.547: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.550: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.553: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.557: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.560: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:54.573: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

    Apr 18 05:15:59.491: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.494: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.498: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.501: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.504: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.508: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.511: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.514: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.531: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.534: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.537: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.541: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.544: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.547: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.551: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.554: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:15:59.567: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

    Apr 18 05:16:04.501: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.550: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.553: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.557: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.560: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.563: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.567: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.570: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.586: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.589: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.593: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.596: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.615: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.624: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.628: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.631: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:04.644: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

    Apr 18 05:16:09.490: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.494: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.498: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.501: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.504: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.508: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.511: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.514: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.531: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.535: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.538: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.541: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.544: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.548: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.562: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.566: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:09.580: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

    Apr 18 05:16:14.489: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.493: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.496: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.500: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.503: INFO: Unable to read wheezy_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.506: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.509: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.512: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.529: INFO: Unable to read jessie_udp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.533: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.536: INFO: Unable to read jessie_udp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.539: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280 from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.542: INFO: Unable to read jessie_udp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.545: INFO: Unable to read jessie_tcp@dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.548: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.551: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc from pod dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808: the server could not find the requested resource (get pods dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808)
    Apr 18 05:16:14.565: INFO: Lookups using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-5280 wheezy_tcp@dns-test-service.dns-5280 wheezy_udp@dns-test-service.dns-5280.svc wheezy_tcp@dns-test-service.dns-5280.svc wheezy_udp@_http._tcp.dns-test-service.dns-5280.svc wheezy_tcp@_http._tcp.dns-test-service.dns-5280.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-5280 jessie_tcp@dns-test-service.dns-5280 jessie_udp@dns-test-service.dns-5280.svc jessie_tcp@dns-test-service.dns-5280.svc jessie_udp@_http._tcp.dns-test-service.dns-5280.svc jessie_tcp@_http._tcp.dns-test-service.dns-5280.svc]

    Apr 18 05:16:19.564: INFO: DNS probes using dns-5280/dns-test-a9ee83ca-8014-44ee-9068-9610cc00f808 succeeded

    STEP: deleting the pod 04/18/23 05:16:19.564
    STEP: deleting the test service 04/18/23 05:16:19.867
    STEP: deleting the test headless service 04/18/23 05:16:20.048
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 05:16:20.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5280" for this suite. 04/18/23 05:16:20.188
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:16:20.216
Apr 18 05:16:20.216: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:16:20.217
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:16:20.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:16:20.266
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-f878edfe-1acd-46d5-bea1-d087090594a7 04/18/23 05:16:20.269
STEP: Creating a pod to test consume secrets 04/18/23 05:16:20.341
Apr 18 05:16:20.365: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906" in namespace "projected-3211" to be "Succeeded or Failed"
Apr 18 05:16:20.390: INFO: Pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906": Phase="Pending", Reason="", readiness=false. Elapsed: 25.032537ms
Apr 18 05:16:22.407: INFO: Pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042520969s
Apr 18 05:16:24.395: INFO: Pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029792279s
Apr 18 05:16:26.450: INFO: Pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.085636863s
STEP: Saw pod success 04/18/23 05:16:26.45
Apr 18 05:16:26.451: INFO: Pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906" satisfied condition "Succeeded or Failed"
Apr 18 05:16:26.454: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/18/23 05:16:26.46
Apr 18 05:16:26.586: INFO: Waiting for pod pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906 to disappear
Apr 18 05:16:26.589: INFO: Pod pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 05:16:26.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3211" for this suite. 04/18/23 05:16:26.593
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":181,"skipped":3167,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.408 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:16:20.216
    Apr 18 05:16:20.216: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:16:20.217
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:16:20.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:16:20.266
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-f878edfe-1acd-46d5-bea1-d087090594a7 04/18/23 05:16:20.269
    STEP: Creating a pod to test consume secrets 04/18/23 05:16:20.341
    Apr 18 05:16:20.365: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906" in namespace "projected-3211" to be "Succeeded or Failed"
    Apr 18 05:16:20.390: INFO: Pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906": Phase="Pending", Reason="", readiness=false. Elapsed: 25.032537ms
    Apr 18 05:16:22.407: INFO: Pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042520969s
    Apr 18 05:16:24.395: INFO: Pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029792279s
    Apr 18 05:16:26.450: INFO: Pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.085636863s
    STEP: Saw pod success 04/18/23 05:16:26.45
    Apr 18 05:16:26.451: INFO: Pod "pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906" satisfied condition "Succeeded or Failed"
    Apr 18 05:16:26.454: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 05:16:26.46
    Apr 18 05:16:26.586: INFO: Waiting for pod pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906 to disappear
    Apr 18 05:16:26.589: INFO: Pod pod-projected-secrets-d9b41db7-8a6a-4a4e-ae58-8a8965215906 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 05:16:26.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3211" for this suite. 04/18/23 05:16:26.593
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:16:26.624
Apr 18 05:16:26.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename svc-latency 04/18/23 05:16:26.626
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:16:26.791
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:16:26.794
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Apr 18 05:16:26.796: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5492 04/18/23 05:16:26.797
I0418 05:16:26.840037      22 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5492, replica count: 1
I0418 05:16:27.891556      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 05:16:28.891809      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 05:16:29.892241      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 05:16:30.157: INFO: Created: latency-svc-hkvhk
Apr 18 05:16:30.191: INFO: Got endpoints: latency-svc-hkvhk [198.973997ms]
Apr 18 05:16:30.318: INFO: Created: latency-svc-gj6k7
Apr 18 05:16:30.641: INFO: Got endpoints: latency-svc-gj6k7 [449.996502ms]
Apr 18 05:16:30.700: INFO: Created: latency-svc-h895b
Apr 18 05:16:30.801: INFO: Created: latency-svc-xf6qf
Apr 18 05:16:30.935: INFO: Got endpoints: latency-svc-xf6qf [742.987128ms]
Apr 18 05:16:30.935: INFO: Got endpoints: latency-svc-h895b [743.208254ms]
Apr 18 05:16:30.976: INFO: Created: latency-svc-hs6tw
Apr 18 05:16:31.200: INFO: Got endpoints: latency-svc-hs6tw [1.008415328s]
Apr 18 05:16:31.200: INFO: Created: latency-svc-p6bdg
Apr 18 05:16:31.324: INFO: Got endpoints: latency-svc-p6bdg [1.131980762s]
Apr 18 05:16:31.333: INFO: Created: latency-svc-xlgkj
Apr 18 05:16:31.516: INFO: Got endpoints: latency-svc-xlgkj [1.324093269s]
Apr 18 05:16:31.627: INFO: Created: latency-svc-m4xp4
Apr 18 05:16:31.658: INFO: Created: latency-svc-bgw7f
Apr 18 05:16:31.909: INFO: Got endpoints: latency-svc-m4xp4 [1.717289347s]
Apr 18 05:16:31.942: INFO: Got endpoints: latency-svc-bgw7f [1.749598295s]
Apr 18 05:16:31.994: INFO: Created: latency-svc-lb9tz
Apr 18 05:16:32.019: INFO: Created: latency-svc-cl8vp
Apr 18 05:16:32.215: INFO: Got endpoints: latency-svc-lb9tz [2.023114061s]
Apr 18 05:16:32.229: INFO: Got endpoints: latency-svc-cl8vp [2.036998955s]
Apr 18 05:16:32.367: INFO: Created: latency-svc-88nvz
Apr 18 05:16:32.383: INFO: Got endpoints: latency-svc-88nvz [2.19051822s]
Apr 18 05:16:32.409: INFO: Created: latency-svc-gqkcn
Apr 18 05:16:32.541: INFO: Got endpoints: latency-svc-gqkcn [2.348954783s]
Apr 18 05:16:32.557: INFO: Created: latency-svc-mjl58
Apr 18 05:16:32.641: INFO: Got endpoints: latency-svc-mjl58 [2.448896237s]
Apr 18 05:16:32.842: INFO: Created: latency-svc-flxqh
Apr 18 05:16:32.866: INFO: Created: latency-svc-hw44b
Apr 18 05:16:32.952: INFO: Created: latency-svc-mmr47
Apr 18 05:16:32.958: INFO: Got endpoints: latency-svc-flxqh [2.765459284s]
Apr 18 05:16:32.975: INFO: Got endpoints: latency-svc-hw44b [2.7826164s]
Apr 18 05:16:33.167: INFO: Got endpoints: latency-svc-mmr47 [2.525605295s]
Apr 18 05:16:33.351: INFO: Created: latency-svc-njm5b
Apr 18 05:16:33.367: INFO: Got endpoints: latency-svc-njm5b [2.431651834s]
Apr 18 05:16:33.409: INFO: Created: latency-svc-4zd94
Apr 18 05:16:33.509: INFO: Got endpoints: latency-svc-4zd94 [2.574519891s]
Apr 18 05:16:33.532: INFO: Created: latency-svc-nl2hh
Apr 18 05:16:33.680: INFO: Created: latency-svc-cfxlr
Apr 18 05:16:33.734: INFO: Got endpoints: latency-svc-nl2hh [2.533718533s]
Apr 18 05:16:33.759: INFO: Got endpoints: latency-svc-cfxlr [2.434677566s]
Apr 18 05:16:33.919: INFO: Created: latency-svc-grz4t
Apr 18 05:16:33.984: INFO: Created: latency-svc-znrn2
Apr 18 05:16:34.050: INFO: Got endpoints: latency-svc-znrn2 [2.534410081s]
Apr 18 05:16:34.200: INFO: Got endpoints: latency-svc-grz4t [2.291265704s]
Apr 18 05:16:34.310: INFO: Created: latency-svc-28ttj
Apr 18 05:16:34.475: INFO: Got endpoints: latency-svc-28ttj [2.533089417s]
Apr 18 05:16:34.619: INFO: Created: latency-svc-lkjrl
Apr 18 05:16:34.626: INFO: Created: latency-svc-2cvsm
Apr 18 05:16:34.701: INFO: Got endpoints: latency-svc-2cvsm [2.485262568s]
Apr 18 05:16:34.942: INFO: Got endpoints: latency-svc-lkjrl [2.71310809s]
Apr 18 05:16:35.043: INFO: Created: latency-svc-nwz82
Apr 18 05:16:35.116: INFO: Created: latency-svc-bvz6k
Apr 18 05:16:35.226: INFO: Got endpoints: latency-svc-nwz82 [2.843402936s]
Apr 18 05:16:35.226: INFO: Got endpoints: latency-svc-bvz6k [2.684963385s]
Apr 18 05:16:35.293: INFO: Created: latency-svc-j7km7
Apr 18 05:16:35.399: INFO: Got endpoints: latency-svc-j7km7 [2.757668159s]
Apr 18 05:16:35.417: INFO: Created: latency-svc-gkmb5
Apr 18 05:16:35.534: INFO: Got endpoints: latency-svc-gkmb5 [2.575695455s]
Apr 18 05:16:35.597: INFO: Created: latency-svc-r6rjj
Apr 18 05:16:35.618: INFO: Got endpoints: latency-svc-r6rjj [2.643121238s]
Apr 18 05:16:35.701: INFO: Created: latency-svc-9m7l9
Apr 18 05:16:35.726: INFO: Created: latency-svc-qcbhf
Apr 18 05:16:35.751: INFO: Got endpoints: latency-svc-9m7l9 [2.584428174s]
Apr 18 05:16:35.952: INFO: Got endpoints: latency-svc-qcbhf [2.585186307s]
Apr 18 05:16:36.072: INFO: Created: latency-svc-2gklh
Apr 18 05:16:36.126: INFO: Got endpoints: latency-svc-2gklh [2.61680309s]
Apr 18 05:16:36.285: INFO: Created: latency-svc-zmbwc
Apr 18 05:16:36.318: INFO: Got endpoints: latency-svc-zmbwc [2.583676329s]
Apr 18 05:16:36.359: INFO: Created: latency-svc-tfff8
Apr 18 05:16:36.445: INFO: Got endpoints: latency-svc-tfff8 [2.686417666s]
Apr 18 05:16:36.462: INFO: Created: latency-svc-dg2fc
Apr 18 05:16:36.526: INFO: Got endpoints: latency-svc-dg2fc [2.475202267s]
Apr 18 05:16:36.643: INFO: Created: latency-svc-nfvwr
Apr 18 05:16:36.749: INFO: Created: latency-svc-vbzlj
Apr 18 05:16:36.785: INFO: Got endpoints: latency-svc-nfvwr [2.584256603s]
Apr 18 05:16:36.809: INFO: Got endpoints: latency-svc-vbzlj [2.334534356s]
Apr 18 05:16:36.909: INFO: Created: latency-svc-sd49z
Apr 18 05:16:36.968: INFO: Got endpoints: latency-svc-sd49z [2.267548404s]
Apr 18 05:16:36.969: INFO: Created: latency-svc-xpjcn
Apr 18 05:16:37.039: INFO: Got endpoints: latency-svc-xpjcn [2.096414066s]
Apr 18 05:16:37.055: INFO: Created: latency-svc-kckt7
Apr 18 05:16:37.251: INFO: Got endpoints: latency-svc-kckt7 [2.025082689s]
Apr 18 05:16:37.412: INFO: Created: latency-svc-wtk92
Apr 18 05:16:37.426: INFO: Created: latency-svc-6qppj
Apr 18 05:16:37.449: INFO: Got endpoints: latency-svc-wtk92 [2.223017394s]
Apr 18 05:16:37.469: INFO: Got endpoints: latency-svc-6qppj [2.069304928s]
Apr 18 05:16:37.567: INFO: Created: latency-svc-28sjv
Apr 18 05:16:37.618: INFO: Got endpoints: latency-svc-28sjv [2.084475185s]
Apr 18 05:16:37.619: INFO: Created: latency-svc-thbjl
Apr 18 05:16:37.709: INFO: Got endpoints: latency-svc-thbjl [2.090876568s]
Apr 18 05:16:37.751: INFO: Created: latency-svc-mlx84
Apr 18 05:16:37.793: INFO: Got endpoints: latency-svc-mlx84 [2.041637977s]
Apr 18 05:16:37.861: INFO: Created: latency-svc-cftl7
Apr 18 05:16:37.952: INFO: Got endpoints: latency-svc-cftl7 [2.000347697s]
Apr 18 05:16:37.974: INFO: Created: latency-svc-trqdf
Apr 18 05:16:38.118: INFO: Got endpoints: latency-svc-trqdf [1.991842249s]
Apr 18 05:16:38.160: INFO: Created: latency-svc-2vdf8
Apr 18 05:16:38.375: INFO: Got endpoints: latency-svc-2vdf8 [2.056917175s]
Apr 18 05:16:38.380: INFO: Created: latency-svc-c6hct
Apr 18 05:16:38.460: INFO: Got endpoints: latency-svc-c6hct [2.014716056s]
Apr 18 05:16:38.536: INFO: Created: latency-svc-4wzjm
Apr 18 05:16:38.635: INFO: Created: latency-svc-pc8hr
Apr 18 05:16:38.791: INFO: Got endpoints: latency-svc-4wzjm [2.26481327s]
Apr 18 05:16:38.818: INFO: Got endpoints: latency-svc-pc8hr [2.033859097s]
Apr 18 05:16:38.870: INFO: Created: latency-svc-qlt26
Apr 18 05:16:38.991: INFO: Got endpoints: latency-svc-qlt26 [2.181514095s]
Apr 18 05:16:39.026: INFO: Created: latency-svc-5xhwc
Apr 18 05:16:39.183: INFO: Got endpoints: latency-svc-5xhwc [2.214921066s]
Apr 18 05:16:39.274: INFO: Created: latency-svc-6qsxd
Apr 18 05:16:39.308: INFO: Got endpoints: latency-svc-6qsxd [2.269358215s]
Apr 18 05:16:39.437: INFO: Created: latency-svc-7gw2g
Apr 18 05:16:39.478: INFO: Got endpoints: latency-svc-7gw2g [2.226679274s]
Apr 18 05:16:39.603: INFO: Created: latency-svc-dlczt
Apr 18 05:16:39.634: INFO: Got endpoints: latency-svc-dlczt [2.184560371s]
Apr 18 05:16:39.663: INFO: Created: latency-svc-5qd26
Apr 18 05:16:39.778: INFO: Created: latency-svc-xtkpv
Apr 18 05:16:39.802: INFO: Got endpoints: latency-svc-5qd26 [2.333460083s]
Apr 18 05:16:39.819: INFO: Got endpoints: latency-svc-xtkpv [2.200588237s]
Apr 18 05:16:40.159: INFO: Created: latency-svc-x7sj9
Apr 18 05:16:40.211: INFO: Got endpoints: latency-svc-x7sj9 [2.50147262s]
Apr 18 05:16:40.227: INFO: Created: latency-svc-rgh8j
Apr 18 05:16:40.375: INFO: Got endpoints: latency-svc-rgh8j [2.581833532s]
Apr 18 05:16:40.440: INFO: Created: latency-svc-j2lbv
Apr 18 05:16:40.477: INFO: Got endpoints: latency-svc-j2lbv [2.524992497s]
Apr 18 05:16:40.620: INFO: Created: latency-svc-dd4wg
Apr 18 05:16:40.646: INFO: Got endpoints: latency-svc-dd4wg [2.527789696s]
Apr 18 05:16:40.647: INFO: Created: latency-svc-x82zf
Apr 18 05:16:40.706: INFO: Got endpoints: latency-svc-x82zf [2.331643568s]
Apr 18 05:16:40.778: INFO: Created: latency-svc-zpsfk
Apr 18 05:16:40.834: INFO: Created: latency-svc-sv5rb
Apr 18 05:16:40.852: INFO: Got endpoints: latency-svc-zpsfk [2.39172029s]
Apr 18 05:16:40.924: INFO: Got endpoints: latency-svc-sv5rb [2.133795405s]
Apr 18 05:16:40.976: INFO: Created: latency-svc-j9txk
Apr 18 05:16:41.011: INFO: Got endpoints: latency-svc-j9txk [2.192407812s]
Apr 18 05:16:41.096: INFO: Created: latency-svc-sbf9g
Apr 18 05:16:41.152: INFO: Got endpoints: latency-svc-sbf9g [2.161252497s]
Apr 18 05:16:41.153: INFO: Created: latency-svc-rmt5h
Apr 18 05:16:41.249: INFO: Created: latency-svc-x7vld
Apr 18 05:16:41.252: INFO: Got endpoints: latency-svc-rmt5h [2.069099113s]
Apr 18 05:16:41.320: INFO: Created: latency-svc-kp5fs
Apr 18 05:16:41.321: INFO: Got endpoints: latency-svc-x7vld [2.012371718s]
Apr 18 05:16:41.461: INFO: Got endpoints: latency-svc-kp5fs [1.982980437s]
Apr 18 05:16:41.462: INFO: Created: latency-svc-gp86w
Apr 18 05:16:41.523: INFO: Created: latency-svc-dnp4z
Apr 18 05:16:41.595: INFO: Got endpoints: latency-svc-gp86w [1.961292518s]
Apr 18 05:16:41.636: INFO: Got endpoints: latency-svc-dnp4z [1.834092295s]
Apr 18 05:16:41.732: INFO: Created: latency-svc-4n7pj
Apr 18 05:16:41.825: INFO: Got endpoints: latency-svc-4n7pj [2.00626932s]
Apr 18 05:16:41.844: INFO: Created: latency-svc-5dfcp
Apr 18 05:16:41.969: INFO: Got endpoints: latency-svc-5dfcp [1.758646786s]
Apr 18 05:16:41.969: INFO: Created: latency-svc-d8987
Apr 18 05:16:42.061: INFO: Got endpoints: latency-svc-d8987 [1.686362987s]
Apr 18 05:16:42.186: INFO: Created: latency-svc-rjrjk
Apr 18 05:16:42.253: INFO: Created: latency-svc-dcbms
Apr 18 05:16:42.369: INFO: Created: latency-svc-j8qrv
Apr 18 05:16:42.403: INFO: Got endpoints: latency-svc-dcbms [1.756954957s]
Apr 18 05:16:42.404: INFO: Got endpoints: latency-svc-rjrjk [1.926263475s]
Apr 18 05:16:42.444: INFO: Got endpoints: latency-svc-j8qrv [1.737200465s]
Apr 18 05:16:42.571: INFO: Created: latency-svc-cp669
Apr 18 05:16:42.619: INFO: Got endpoints: latency-svc-cp669 [1.767383009s]
Apr 18 05:16:42.620: INFO: Created: latency-svc-xvxn2
Apr 18 05:16:42.838: INFO: Created: latency-svc-qp6xs
Apr 18 05:16:42.853: INFO: Got endpoints: latency-svc-xvxn2 [1.92889006s]
Apr 18 05:16:42.910: INFO: Got endpoints: latency-svc-qp6xs [1.899523053s]
Apr 18 05:16:43.022: INFO: Created: latency-svc-6sd8c
Apr 18 05:16:43.061: INFO: Got endpoints: latency-svc-6sd8c [1.909098394s]
Apr 18 05:16:43.079: INFO: Created: latency-svc-w76w8
Apr 18 05:16:43.193: INFO: Got endpoints: latency-svc-w76w8 [1.940538282s]
Apr 18 05:16:43.238: INFO: Created: latency-svc-w9c97
Apr 18 05:16:43.270: INFO: Got endpoints: latency-svc-w9c97 [1.949500247s]
Apr 18 05:16:43.305: INFO: Created: latency-svc-8jglf
Apr 18 05:16:43.403: INFO: Got endpoints: latency-svc-8jglf [1.9421656s]
Apr 18 05:16:43.413: INFO: Created: latency-svc-75hwh
Apr 18 05:16:43.442: INFO: Got endpoints: latency-svc-75hwh [1.846324344s]
Apr 18 05:16:43.462: INFO: Created: latency-svc-756h5
Apr 18 05:16:43.626: INFO: Created: latency-svc-2288f
Apr 18 05:16:43.626: INFO: Got endpoints: latency-svc-756h5 [1.989988043s]
Apr 18 05:16:43.745: INFO: Created: latency-svc-b7sw5
Apr 18 05:16:43.745: INFO: Got endpoints: latency-svc-2288f [1.919737865s]
Apr 18 05:16:43.776: INFO: Got endpoints: latency-svc-b7sw5 [1.806127904s]
Apr 18 05:16:43.796: INFO: Created: latency-svc-2bksw
Apr 18 05:16:43.879: INFO: Got endpoints: latency-svc-2bksw [1.817338083s]
Apr 18 05:16:44.555: INFO: Created: latency-svc-wtpx4
Apr 18 05:16:44.695: INFO: Got endpoints: latency-svc-wtpx4 [2.29188937s]
Apr 18 05:16:44.696: INFO: Created: latency-svc-gr5ff
Apr 18 05:16:44.755: INFO: Got endpoints: latency-svc-gr5ff [2.351888914s]
Apr 18 05:16:44.764: INFO: Created: latency-svc-vdd8n
Apr 18 05:16:44.845: INFO: Got endpoints: latency-svc-vdd8n [2.401818812s]
Apr 18 05:16:44.860: INFO: Created: latency-svc-sfffm
Apr 18 05:16:45.029: INFO: Got endpoints: latency-svc-sfffm [2.409485006s]
Apr 18 05:16:45.029: INFO: Created: latency-svc-gwjgs
Apr 18 05:16:45.087: INFO: Created: latency-svc-tkq9c
Apr 18 05:16:45.117: INFO: Got endpoints: latency-svc-gwjgs [2.263625956s]
Apr 18 05:16:45.118: INFO: Got endpoints: latency-svc-tkq9c [2.207317834s]
Apr 18 05:16:45.228: INFO: Created: latency-svc-vttfj
Apr 18 05:16:45.362: INFO: Got endpoints: latency-svc-vttfj [2.300426124s]
Apr 18 05:16:45.371: INFO: Created: latency-svc-bgg24
Apr 18 05:16:45.459: INFO: Created: latency-svc-cr876
Apr 18 05:16:45.512: INFO: Got endpoints: latency-svc-bgg24 [2.319336817s]
Apr 18 05:16:45.545: INFO: Got endpoints: latency-svc-cr876 [2.274938316s]
Apr 18 05:16:45.629: INFO: Created: latency-svc-l8dmv
Apr 18 05:16:45.684: INFO: Got endpoints: latency-svc-l8dmv [2.28019601s]
Apr 18 05:16:45.695: INFO: Created: latency-svc-pmbsr
Apr 18 05:16:45.821: INFO: Got endpoints: latency-svc-pmbsr [2.379267179s]
Apr 18 05:16:45.834: INFO: Created: latency-svc-vnmfn
Apr 18 05:16:45.904: INFO: Got endpoints: latency-svc-vnmfn [2.276736126s]
Apr 18 05:16:46.047: INFO: Created: latency-svc-2kpb2
Apr 18 05:16:46.579: INFO: Got endpoints: latency-svc-2kpb2 [2.833814806s]
Apr 18 05:16:46.628: INFO: Created: latency-svc-tgh5w
Apr 18 05:16:46.667: INFO: Got endpoints: latency-svc-tgh5w [2.891556983s]
Apr 18 05:16:46.741: INFO: Created: latency-svc-zjjhn
Apr 18 05:16:46.762: INFO: Got endpoints: latency-svc-zjjhn [2.882785996s]
Apr 18 05:16:46.803: INFO: Created: latency-svc-wjrzm
Apr 18 05:16:46.871: INFO: Got endpoints: latency-svc-wjrzm [2.176002546s]
Apr 18 05:16:46.912: INFO: Created: latency-svc-82f5n
Apr 18 05:16:46.984: INFO: Created: latency-svc-j8jgp
Apr 18 05:16:47.021: INFO: Got endpoints: latency-svc-82f5n [2.265426684s]
Apr 18 05:16:47.037: INFO: Got endpoints: latency-svc-j8jgp [2.191737276s]
Apr 18 05:16:47.188: INFO: Created: latency-svc-vcj6v
Apr 18 05:16:47.203: INFO: Got endpoints: latency-svc-vcj6v [2.174709521s]
Apr 18 05:16:47.318: INFO: Created: latency-svc-8vsnh
Apr 18 05:16:47.401: INFO: Got endpoints: latency-svc-8vsnh [2.283858536s]
Apr 18 05:16:47.480: INFO: Created: latency-svc-7tlr7
Apr 18 05:16:47.571: INFO: Got endpoints: latency-svc-7tlr7 [2.453056007s]
Apr 18 05:16:47.596: INFO: Created: latency-svc-t6qlm
Apr 18 05:16:47.596: INFO: Got endpoints: latency-svc-t6qlm [2.234076609s]
Apr 18 05:16:47.668: INFO: Created: latency-svc-jbwpn
Apr 18 05:16:47.723: INFO: Created: latency-svc-mf64n
Apr 18 05:16:47.746: INFO: Got endpoints: latency-svc-jbwpn [2.23350446s]
Apr 18 05:16:47.779: INFO: Got endpoints: latency-svc-mf64n [2.234172065s]
Apr 18 05:16:47.921: INFO: Created: latency-svc-mj86c
Apr 18 05:16:47.921: INFO: Got endpoints: latency-svc-mj86c [2.237301235s]
Apr 18 05:16:47.939: INFO: Created: latency-svc-jwg6x
Apr 18 05:16:48.081: INFO: Created: latency-svc-4rwgk
Apr 18 05:16:48.088: INFO: Got endpoints: latency-svc-jwg6x [2.266940573s]
Apr 18 05:16:48.112: INFO: Got endpoints: latency-svc-4rwgk [2.208029608s]
Apr 18 05:16:48.163: INFO: Created: latency-svc-lwjlb
Apr 18 05:16:48.288: INFO: Got endpoints: latency-svc-lwjlb [1.708845014s]
Apr 18 05:16:48.288: INFO: Created: latency-svc-5b8gz
Apr 18 05:16:48.446: INFO: Got endpoints: latency-svc-5b8gz [1.778404055s]
Apr 18 05:16:48.493: INFO: Created: latency-svc-kv5l2
Apr 18 05:16:48.544: INFO: Created: latency-svc-f4hw7
Apr 18 05:16:48.629: INFO: Got endpoints: latency-svc-f4hw7 [1.867775493s]
Apr 18 05:16:48.645: INFO: Got endpoints: latency-svc-kv5l2 [1.774065496s]
Apr 18 05:16:48.646: INFO: Created: latency-svc-5s55p
Apr 18 05:16:48.779: INFO: Got endpoints: latency-svc-5s55p [1.758021383s]
Apr 18 05:16:48.873: INFO: Created: latency-svc-hxxxh
Apr 18 05:16:48.971: INFO: Got endpoints: latency-svc-hxxxh [1.934029878s]
Apr 18 05:16:49.033: INFO: Created: latency-svc-ktwzw
Apr 18 05:16:49.230: INFO: Got endpoints: latency-svc-ktwzw [2.026593314s]
Apr 18 05:16:49.247: INFO: Created: latency-svc-7lk5p
Apr 18 05:16:49.392: INFO: Created: latency-svc-s8jqp
Apr 18 05:16:49.396: INFO: Got endpoints: latency-svc-7lk5p [1.994710145s]
Apr 18 05:16:49.428: INFO: Got endpoints: latency-svc-s8jqp [1.857257442s]
Apr 18 05:16:49.554: INFO: Created: latency-svc-6rk77
Apr 18 05:16:49.580: INFO: Got endpoints: latency-svc-6rk77 [1.983574726s]
Apr 18 05:16:49.671: INFO: Created: latency-svc-zkwq6
Apr 18 05:16:49.721: INFO: Created: latency-svc-56nj2
Apr 18 05:16:49.746: INFO: Got endpoints: latency-svc-zkwq6 [2.000578443s]
Apr 18 05:16:49.872: INFO: Created: latency-svc-8j79l
Apr 18 05:16:49.879: INFO: Got endpoints: latency-svc-56nj2 [2.099277654s]
Apr 18 05:16:49.888: INFO: Got endpoints: latency-svc-8j79l [1.966719713s]
Apr 18 05:16:49.937: INFO: Created: latency-svc-c9x5t
Apr 18 05:16:50.041: INFO: Got endpoints: latency-svc-c9x5t [1.953069216s]
Apr 18 05:16:50.139: INFO: Created: latency-svc-rlsv6
Apr 18 05:16:50.185: INFO: Created: latency-svc-hlk6l
Apr 18 05:16:50.293: INFO: Created: latency-svc-fcb6x
Apr 18 05:16:50.355: INFO: Got endpoints: latency-svc-hlk6l [2.242975868s]
Apr 18 05:16:50.355: INFO: Got endpoints: latency-svc-rlsv6 [2.067598119s]
Apr 18 05:16:50.413: INFO: Got endpoints: latency-svc-fcb6x [1.967800189s]
Apr 18 05:16:50.485: INFO: Created: latency-svc-sh7l5
Apr 18 05:16:50.538: INFO: Got endpoints: latency-svc-sh7l5 [1.908246393s]
Apr 18 05:16:50.597: INFO: Created: latency-svc-l9pxt
Apr 18 05:16:50.691: INFO: Got endpoints: latency-svc-l9pxt [2.046073815s]
Apr 18 05:16:50.776: INFO: Created: latency-svc-fghjd
Apr 18 05:16:50.831: INFO: Created: latency-svc-5klt6
Apr 18 05:16:50.862: INFO: Got endpoints: latency-svc-fghjd [2.083296574s]
Apr 18 05:16:50.872: INFO: Got endpoints: latency-svc-5klt6 [1.900834966s]
Apr 18 05:16:51.039: INFO: Created: latency-svc-f6tx4
Apr 18 05:16:51.107: INFO: Created: latency-svc-2vksw
Apr 18 05:16:51.184: INFO: Created: latency-svc-vwsp7
Apr 18 05:16:51.188: INFO: Got endpoints: latency-svc-f6tx4 [1.957654995s]
Apr 18 05:16:51.217: INFO: Got endpoints: latency-svc-2vksw [1.821725497s]
Apr 18 05:16:51.218: INFO: Got endpoints: latency-svc-vwsp7 [1.789298574s]
Apr 18 05:16:51.352: INFO: Created: latency-svc-q4g7d
Apr 18 05:16:51.379: INFO: Got endpoints: latency-svc-q4g7d [1.799523872s]
Apr 18 05:16:51.441: INFO: Created: latency-svc-dwkcf
Apr 18 05:16:51.509: INFO: Created: latency-svc-ht79h
Apr 18 05:16:51.547: INFO: Got endpoints: latency-svc-dwkcf [1.80094015s]
Apr 18 05:16:51.563: INFO: Got endpoints: latency-svc-ht79h [1.684321948s]
Apr 18 05:16:51.666: INFO: Created: latency-svc-spxht
Apr 18 05:16:51.721: INFO: Got endpoints: latency-svc-spxht [1.833366178s]
Apr 18 05:16:51.774: INFO: Created: latency-svc-4k82t
Apr 18 05:16:51.843: INFO: Created: latency-svc-n9n9n
Apr 18 05:16:51.888: INFO: Got endpoints: latency-svc-n9n9n [1.533187508s]
Apr 18 05:16:51.932: INFO: Got endpoints: latency-svc-4k82t [1.891247848s]
Apr 18 05:16:52.040: INFO: Created: latency-svc-kkwb5
Apr 18 05:16:52.164: INFO: Got endpoints: latency-svc-kkwb5 [1.808270172s]
Apr 18 05:16:52.164: INFO: Created: latency-svc-j7pwt
Apr 18 05:16:52.205: INFO: Got endpoints: latency-svc-j7pwt [1.791804832s]
Apr 18 05:16:52.286: INFO: Created: latency-svc-gv295
Apr 18 05:16:52.331: INFO: Got endpoints: latency-svc-gv295 [1.792753088s]
Apr 18 05:16:52.348: INFO: Created: latency-svc-nnpgs
Apr 18 05:16:52.481: INFO: Got endpoints: latency-svc-nnpgs [1.789756982s]
Apr 18 05:16:52.490: INFO: Created: latency-svc-9wjhg
Apr 18 05:16:52.514: INFO: Got endpoints: latency-svc-9wjhg [1.651470944s]
Apr 18 05:16:52.607: INFO: Created: latency-svc-6wc9x
Apr 18 05:16:52.688: INFO: Got endpoints: latency-svc-6wc9x [1.816136797s]
Apr 18 05:16:52.714: INFO: Created: latency-svc-knnnx
Apr 18 05:16:52.800: INFO: Created: latency-svc-6nzhp
Apr 18 05:16:52.878: INFO: Got endpoints: latency-svc-knnnx [1.690141014s]
Apr 18 05:16:52.878: INFO: Got endpoints: latency-svc-6nzhp [1.660379322s]
Apr 18 05:16:52.951: INFO: Created: latency-svc-z7lhw
Apr 18 05:16:52.993: INFO: Created: latency-svc-d4lnw
Apr 18 05:16:53.014: INFO: Got endpoints: latency-svc-z7lhw [1.796534967s]
Apr 18 05:16:53.030: INFO: Got endpoints: latency-svc-d4lnw [1.650433926s]
Apr 18 05:16:53.141: INFO: Created: latency-svc-658jw
Apr 18 05:16:53.186: INFO: Got endpoints: latency-svc-658jw [1.63826961s]
Apr 18 05:16:53.198: INFO: Created: latency-svc-7px5t
Apr 18 05:16:53.316: INFO: Got endpoints: latency-svc-7px5t [1.75272446s]
Apr 18 05:16:53.316: INFO: Created: latency-svc-8wfds
Apr 18 05:16:53.338: INFO: Got endpoints: latency-svc-8wfds [1.61713808s]
Apr 18 05:16:53.381: INFO: Created: latency-svc-dgsp5
Apr 18 05:16:53.397: INFO: Got endpoints: latency-svc-dgsp5 [1.508821226s]
Apr 18 05:16:53.515: INFO: Created: latency-svc-f5kk8
Apr 18 05:16:53.515: INFO: Created: latency-svc-crr9t
Apr 18 05:16:53.548: INFO: Got endpoints: latency-svc-f5kk8 [1.384722148s]
Apr 18 05:16:53.573: INFO: Created: latency-svc-j98f4
Apr 18 05:16:53.656: INFO: Got endpoints: latency-svc-crr9t [1.723471041s]
Apr 18 05:16:53.710: INFO: Created: latency-svc-rt8kn
Apr 18 05:16:53.713: INFO: Got endpoints: latency-svc-j98f4 [1.507900445s]
Apr 18 05:16:53.814: INFO: Got endpoints: latency-svc-rt8kn [1.48387942s]
Apr 18 05:16:53.815: INFO: Created: latency-svc-ktnj7
Apr 18 05:16:53.902: INFO: Got endpoints: latency-svc-ktnj7 [1.420732831s]
Apr 18 05:16:53.916: INFO: Created: latency-svc-mzndx
Apr 18 05:16:54.141: INFO: Got endpoints: latency-svc-mzndx [1.627244954s]
Apr 18 05:16:54.149: INFO: Created: latency-svc-bcvrs
Apr 18 05:16:54.181: INFO: Got endpoints: latency-svc-bcvrs [1.493150659s]
Apr 18 05:16:54.349: INFO: Created: latency-svc-jxjx2
Apr 18 05:16:54.385: INFO: Got endpoints: latency-svc-jxjx2 [1.506758267s]
Apr 18 05:16:54.449: INFO: Created: latency-svc-j755s
Apr 18 05:16:54.481: INFO: Got endpoints: latency-svc-j755s [1.602799867s]
Apr 18 05:16:54.524: INFO: Created: latency-svc-rxpds
Apr 18 05:16:54.636: INFO: Got endpoints: latency-svc-rxpds [1.622275629s]
Apr 18 05:16:54.637: INFO: Created: latency-svc-fv6fp
Apr 18 05:16:54.680: INFO: Got endpoints: latency-svc-fv6fp [1.650354091s]
Apr 18 05:16:54.699: INFO: Created: latency-svc-2hksm
Apr 18 05:16:54.781: INFO: Got endpoints: latency-svc-2hksm [1.595346363s]
Apr 18 05:16:54.848: INFO: Created: latency-svc-wz8fq
Apr 18 05:16:54.851: INFO: Created: latency-svc-pc2q8
Apr 18 05:16:54.877: INFO: Got endpoints: latency-svc-wz8fq [1.538670119s]
Apr 18 05:16:54.948: INFO: Got endpoints: latency-svc-pc2q8 [1.632039604s]
Apr 18 05:16:54.991: INFO: Created: latency-svc-m5cvq
Apr 18 05:16:54.999: INFO: Got endpoints: latency-svc-m5cvq [1.601390836s]
Apr 18 05:16:55.144: INFO: Created: latency-svc-lh9pj
Apr 18 05:16:55.198: INFO: Got endpoints: latency-svc-lh9pj [1.64961921s]
Apr 18 05:16:55.199: INFO: Created: latency-svc-cmt2q
Apr 18 05:16:55.256: INFO: Got endpoints: latency-svc-cmt2q [1.600211181s]
Apr 18 05:16:55.332: INFO: Created: latency-svc-qtgmw
Apr 18 05:16:55.348: INFO: Got endpoints: latency-svc-qtgmw [1.634637356s]
Apr 18 05:16:55.388: INFO: Created: latency-svc-slhjx
Apr 18 05:16:55.456: INFO: Got endpoints: latency-svc-slhjx [1.641672193s]
Apr 18 05:16:55.599: INFO: Created: latency-svc-smmzw
Apr 18 05:16:55.630: INFO: Got endpoints: latency-svc-smmzw [1.728269583s]
Apr 18 05:16:55.674: INFO: Created: latency-svc-6bdk4
Apr 18 05:16:55.724: INFO: Created: latency-svc-5rzbc
Apr 18 05:16:55.901: INFO: Got endpoints: latency-svc-5rzbc [1.719215753s]
Apr 18 05:16:55.901: INFO: Got endpoints: latency-svc-6bdk4 [1.759442058s]
Apr 18 05:16:56.058: INFO: Created: latency-svc-pmn2t
Apr 18 05:16:56.065: INFO: Got endpoints: latency-svc-pmn2t [1.679884325s]
Apr 18 05:16:56.183: INFO: Created: latency-svc-58cfx
Apr 18 05:16:56.215: INFO: Got endpoints: latency-svc-58cfx [1.734619396s]
Apr 18 05:16:56.286: INFO: Created: latency-svc-8gq2j
Apr 18 05:16:56.382: INFO: Got endpoints: latency-svc-8gq2j [1.745627409s]
Apr 18 05:16:56.398: INFO: Created: latency-svc-gkhbt
Apr 18 05:16:56.507: INFO: Got endpoints: latency-svc-gkhbt [1.826619274s]
Apr 18 05:16:56.532: INFO: Created: latency-svc-j2cp6
Apr 18 05:16:56.691: INFO: Created: latency-svc-pz6nl
Apr 18 05:16:56.739: INFO: Got endpoints: latency-svc-j2cp6 [1.958235008s]
Apr 18 05:16:56.807: INFO: Got endpoints: latency-svc-pz6nl [1.930341431s]
Apr 18 05:16:56.892: INFO: Created: latency-svc-hvp7b
Apr 18 05:16:56.950: INFO: Created: latency-svc-gpmp8
Apr 18 05:16:57.011: INFO: Created: latency-svc-gv6n6
Apr 18 05:16:57.014: INFO: Got endpoints: latency-svc-hvp7b [2.015590961s]
Apr 18 05:16:57.014: INFO: Got endpoints: latency-svc-gpmp8 [2.06640385s]
Apr 18 05:16:57.115: INFO: Got endpoints: latency-svc-gv6n6 [1.916917043s]
Apr 18 05:16:57.132: INFO: Created: latency-svc-cfl9t
Apr 18 05:16:57.149: INFO: Got endpoints: latency-svc-cfl9t [1.892723134s]
Apr 18 05:16:57.311: INFO: Created: latency-svc-bmsl8
Apr 18 05:16:57.316: INFO: Created: latency-svc-pfmxc
Apr 18 05:16:57.348: INFO: Got endpoints: latency-svc-bmsl8 [2.000317999s]
Apr 18 05:16:57.424: INFO: Got endpoints: latency-svc-pfmxc [1.967763237s]
Apr 18 05:16:57.457: INFO: Created: latency-svc-kxbm7
Apr 18 05:16:57.503: INFO: Got endpoints: latency-svc-kxbm7 [1.872770663s]
Apr 18 05:16:57.516: INFO: Created: latency-svc-m4cj7
Apr 18 05:16:57.616: INFO: Got endpoints: latency-svc-m4cj7 [1.715147605s]
Apr 18 05:16:57.641: INFO: Created: latency-svc-99kx2
Apr 18 05:16:57.677: INFO: Created: latency-svc-5s278
Apr 18 05:16:57.699: INFO: Got endpoints: latency-svc-99kx2 [1.797809287s]
Apr 18 05:16:57.706: INFO: Got endpoints: latency-svc-5s278 [1.64152025s]
Apr 18 05:16:57.706: INFO: Latencies: [449.996502ms 742.987128ms 743.208254ms 1.008415328s 1.131980762s 1.324093269s 1.384722148s 1.420732831s 1.48387942s 1.493150659s 1.506758267s 1.507900445s 1.508821226s 1.533187508s 1.538670119s 1.595346363s 1.600211181s 1.601390836s 1.602799867s 1.61713808s 1.622275629s 1.627244954s 1.632039604s 1.634637356s 1.63826961s 1.64152025s 1.641672193s 1.64961921s 1.650354091s 1.650433926s 1.651470944s 1.660379322s 1.679884325s 1.684321948s 1.686362987s 1.690141014s 1.708845014s 1.715147605s 1.717289347s 1.719215753s 1.723471041s 1.728269583s 1.734619396s 1.737200465s 1.745627409s 1.749598295s 1.75272446s 1.756954957s 1.758021383s 1.758646786s 1.759442058s 1.767383009s 1.774065496s 1.778404055s 1.789298574s 1.789756982s 1.791804832s 1.792753088s 1.796534967s 1.797809287s 1.799523872s 1.80094015s 1.806127904s 1.808270172s 1.816136797s 1.817338083s 1.821725497s 1.826619274s 1.833366178s 1.834092295s 1.846324344s 1.857257442s 1.867775493s 1.872770663s 1.891247848s 1.892723134s 1.899523053s 1.900834966s 1.908246393s 1.909098394s 1.916917043s 1.919737865s 1.926263475s 1.92889006s 1.930341431s 1.934029878s 1.940538282s 1.9421656s 1.949500247s 1.953069216s 1.957654995s 1.958235008s 1.961292518s 1.966719713s 1.967763237s 1.967800189s 1.982980437s 1.983574726s 1.989988043s 1.991842249s 1.994710145s 2.000317999s 2.000347697s 2.000578443s 2.00626932s 2.012371718s 2.014716056s 2.015590961s 2.023114061s 2.025082689s 2.026593314s 2.033859097s 2.036998955s 2.041637977s 2.046073815s 2.056917175s 2.06640385s 2.067598119s 2.069099113s 2.069304928s 2.083296574s 2.084475185s 2.090876568s 2.096414066s 2.099277654s 2.133795405s 2.161252497s 2.174709521s 2.176002546s 2.181514095s 2.184560371s 2.19051822s 2.191737276s 2.192407812s 2.200588237s 2.207317834s 2.208029608s 2.214921066s 2.223017394s 2.226679274s 2.23350446s 2.234076609s 2.234172065s 2.237301235s 2.242975868s 2.263625956s 2.26481327s 2.265426684s 2.266940573s 2.267548404s 2.269358215s 2.274938316s 2.276736126s 2.28019601s 2.283858536s 2.291265704s 2.29188937s 2.300426124s 2.319336817s 2.331643568s 2.333460083s 2.334534356s 2.348954783s 2.351888914s 2.379267179s 2.39172029s 2.401818812s 2.409485006s 2.431651834s 2.434677566s 2.448896237s 2.453056007s 2.475202267s 2.485262568s 2.50147262s 2.524992497s 2.525605295s 2.527789696s 2.533089417s 2.533718533s 2.534410081s 2.574519891s 2.575695455s 2.581833532s 2.583676329s 2.584256603s 2.584428174s 2.585186307s 2.61680309s 2.643121238s 2.684963385s 2.686417666s 2.71310809s 2.757668159s 2.765459284s 2.7826164s 2.833814806s 2.843402936s 2.882785996s 2.891556983s]
Apr 18 05:16:57.706: INFO: 50 %ile: 1.994710145s
Apr 18 05:16:57.706: INFO: 90 %ile: 2.534410081s
Apr 18 05:16:57.706: INFO: 99 %ile: 2.882785996s
Apr 18 05:16:57.706: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Apr 18 05:16:57.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5492" for this suite. 04/18/23 05:16:57.77
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":182,"skipped":3170,"failed":0}
------------------------------
â€¢ [SLOW TEST] [31.174 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:16:26.624
    Apr 18 05:16:26.625: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename svc-latency 04/18/23 05:16:26.626
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:16:26.791
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:16:26.794
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Apr 18 05:16:26.796: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-5492 04/18/23 05:16:26.797
    I0418 05:16:26.840037      22 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5492, replica count: 1
    I0418 05:16:27.891556      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 05:16:28.891809      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 05:16:29.892241      22 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 05:16:30.157: INFO: Created: latency-svc-hkvhk
    Apr 18 05:16:30.191: INFO: Got endpoints: latency-svc-hkvhk [198.973997ms]
    Apr 18 05:16:30.318: INFO: Created: latency-svc-gj6k7
    Apr 18 05:16:30.641: INFO: Got endpoints: latency-svc-gj6k7 [449.996502ms]
    Apr 18 05:16:30.700: INFO: Created: latency-svc-h895b
    Apr 18 05:16:30.801: INFO: Created: latency-svc-xf6qf
    Apr 18 05:16:30.935: INFO: Got endpoints: latency-svc-xf6qf [742.987128ms]
    Apr 18 05:16:30.935: INFO: Got endpoints: latency-svc-h895b [743.208254ms]
    Apr 18 05:16:30.976: INFO: Created: latency-svc-hs6tw
    Apr 18 05:16:31.200: INFO: Got endpoints: latency-svc-hs6tw [1.008415328s]
    Apr 18 05:16:31.200: INFO: Created: latency-svc-p6bdg
    Apr 18 05:16:31.324: INFO: Got endpoints: latency-svc-p6bdg [1.131980762s]
    Apr 18 05:16:31.333: INFO: Created: latency-svc-xlgkj
    Apr 18 05:16:31.516: INFO: Got endpoints: latency-svc-xlgkj [1.324093269s]
    Apr 18 05:16:31.627: INFO: Created: latency-svc-m4xp4
    Apr 18 05:16:31.658: INFO: Created: latency-svc-bgw7f
    Apr 18 05:16:31.909: INFO: Got endpoints: latency-svc-m4xp4 [1.717289347s]
    Apr 18 05:16:31.942: INFO: Got endpoints: latency-svc-bgw7f [1.749598295s]
    Apr 18 05:16:31.994: INFO: Created: latency-svc-lb9tz
    Apr 18 05:16:32.019: INFO: Created: latency-svc-cl8vp
    Apr 18 05:16:32.215: INFO: Got endpoints: latency-svc-lb9tz [2.023114061s]
    Apr 18 05:16:32.229: INFO: Got endpoints: latency-svc-cl8vp [2.036998955s]
    Apr 18 05:16:32.367: INFO: Created: latency-svc-88nvz
    Apr 18 05:16:32.383: INFO: Got endpoints: latency-svc-88nvz [2.19051822s]
    Apr 18 05:16:32.409: INFO: Created: latency-svc-gqkcn
    Apr 18 05:16:32.541: INFO: Got endpoints: latency-svc-gqkcn [2.348954783s]
    Apr 18 05:16:32.557: INFO: Created: latency-svc-mjl58
    Apr 18 05:16:32.641: INFO: Got endpoints: latency-svc-mjl58 [2.448896237s]
    Apr 18 05:16:32.842: INFO: Created: latency-svc-flxqh
    Apr 18 05:16:32.866: INFO: Created: latency-svc-hw44b
    Apr 18 05:16:32.952: INFO: Created: latency-svc-mmr47
    Apr 18 05:16:32.958: INFO: Got endpoints: latency-svc-flxqh [2.765459284s]
    Apr 18 05:16:32.975: INFO: Got endpoints: latency-svc-hw44b [2.7826164s]
    Apr 18 05:16:33.167: INFO: Got endpoints: latency-svc-mmr47 [2.525605295s]
    Apr 18 05:16:33.351: INFO: Created: latency-svc-njm5b
    Apr 18 05:16:33.367: INFO: Got endpoints: latency-svc-njm5b [2.431651834s]
    Apr 18 05:16:33.409: INFO: Created: latency-svc-4zd94
    Apr 18 05:16:33.509: INFO: Got endpoints: latency-svc-4zd94 [2.574519891s]
    Apr 18 05:16:33.532: INFO: Created: latency-svc-nl2hh
    Apr 18 05:16:33.680: INFO: Created: latency-svc-cfxlr
    Apr 18 05:16:33.734: INFO: Got endpoints: latency-svc-nl2hh [2.533718533s]
    Apr 18 05:16:33.759: INFO: Got endpoints: latency-svc-cfxlr [2.434677566s]
    Apr 18 05:16:33.919: INFO: Created: latency-svc-grz4t
    Apr 18 05:16:33.984: INFO: Created: latency-svc-znrn2
    Apr 18 05:16:34.050: INFO: Got endpoints: latency-svc-znrn2 [2.534410081s]
    Apr 18 05:16:34.200: INFO: Got endpoints: latency-svc-grz4t [2.291265704s]
    Apr 18 05:16:34.310: INFO: Created: latency-svc-28ttj
    Apr 18 05:16:34.475: INFO: Got endpoints: latency-svc-28ttj [2.533089417s]
    Apr 18 05:16:34.619: INFO: Created: latency-svc-lkjrl
    Apr 18 05:16:34.626: INFO: Created: latency-svc-2cvsm
    Apr 18 05:16:34.701: INFO: Got endpoints: latency-svc-2cvsm [2.485262568s]
    Apr 18 05:16:34.942: INFO: Got endpoints: latency-svc-lkjrl [2.71310809s]
    Apr 18 05:16:35.043: INFO: Created: latency-svc-nwz82
    Apr 18 05:16:35.116: INFO: Created: latency-svc-bvz6k
    Apr 18 05:16:35.226: INFO: Got endpoints: latency-svc-nwz82 [2.843402936s]
    Apr 18 05:16:35.226: INFO: Got endpoints: latency-svc-bvz6k [2.684963385s]
    Apr 18 05:16:35.293: INFO: Created: latency-svc-j7km7
    Apr 18 05:16:35.399: INFO: Got endpoints: latency-svc-j7km7 [2.757668159s]
    Apr 18 05:16:35.417: INFO: Created: latency-svc-gkmb5
    Apr 18 05:16:35.534: INFO: Got endpoints: latency-svc-gkmb5 [2.575695455s]
    Apr 18 05:16:35.597: INFO: Created: latency-svc-r6rjj
    Apr 18 05:16:35.618: INFO: Got endpoints: latency-svc-r6rjj [2.643121238s]
    Apr 18 05:16:35.701: INFO: Created: latency-svc-9m7l9
    Apr 18 05:16:35.726: INFO: Created: latency-svc-qcbhf
    Apr 18 05:16:35.751: INFO: Got endpoints: latency-svc-9m7l9 [2.584428174s]
    Apr 18 05:16:35.952: INFO: Got endpoints: latency-svc-qcbhf [2.585186307s]
    Apr 18 05:16:36.072: INFO: Created: latency-svc-2gklh
    Apr 18 05:16:36.126: INFO: Got endpoints: latency-svc-2gklh [2.61680309s]
    Apr 18 05:16:36.285: INFO: Created: latency-svc-zmbwc
    Apr 18 05:16:36.318: INFO: Got endpoints: latency-svc-zmbwc [2.583676329s]
    Apr 18 05:16:36.359: INFO: Created: latency-svc-tfff8
    Apr 18 05:16:36.445: INFO: Got endpoints: latency-svc-tfff8 [2.686417666s]
    Apr 18 05:16:36.462: INFO: Created: latency-svc-dg2fc
    Apr 18 05:16:36.526: INFO: Got endpoints: latency-svc-dg2fc [2.475202267s]
    Apr 18 05:16:36.643: INFO: Created: latency-svc-nfvwr
    Apr 18 05:16:36.749: INFO: Created: latency-svc-vbzlj
    Apr 18 05:16:36.785: INFO: Got endpoints: latency-svc-nfvwr [2.584256603s]
    Apr 18 05:16:36.809: INFO: Got endpoints: latency-svc-vbzlj [2.334534356s]
    Apr 18 05:16:36.909: INFO: Created: latency-svc-sd49z
    Apr 18 05:16:36.968: INFO: Got endpoints: latency-svc-sd49z [2.267548404s]
    Apr 18 05:16:36.969: INFO: Created: latency-svc-xpjcn
    Apr 18 05:16:37.039: INFO: Got endpoints: latency-svc-xpjcn [2.096414066s]
    Apr 18 05:16:37.055: INFO: Created: latency-svc-kckt7
    Apr 18 05:16:37.251: INFO: Got endpoints: latency-svc-kckt7 [2.025082689s]
    Apr 18 05:16:37.412: INFO: Created: latency-svc-wtk92
    Apr 18 05:16:37.426: INFO: Created: latency-svc-6qppj
    Apr 18 05:16:37.449: INFO: Got endpoints: latency-svc-wtk92 [2.223017394s]
    Apr 18 05:16:37.469: INFO: Got endpoints: latency-svc-6qppj [2.069304928s]
    Apr 18 05:16:37.567: INFO: Created: latency-svc-28sjv
    Apr 18 05:16:37.618: INFO: Got endpoints: latency-svc-28sjv [2.084475185s]
    Apr 18 05:16:37.619: INFO: Created: latency-svc-thbjl
    Apr 18 05:16:37.709: INFO: Got endpoints: latency-svc-thbjl [2.090876568s]
    Apr 18 05:16:37.751: INFO: Created: latency-svc-mlx84
    Apr 18 05:16:37.793: INFO: Got endpoints: latency-svc-mlx84 [2.041637977s]
    Apr 18 05:16:37.861: INFO: Created: latency-svc-cftl7
    Apr 18 05:16:37.952: INFO: Got endpoints: latency-svc-cftl7 [2.000347697s]
    Apr 18 05:16:37.974: INFO: Created: latency-svc-trqdf
    Apr 18 05:16:38.118: INFO: Got endpoints: latency-svc-trqdf [1.991842249s]
    Apr 18 05:16:38.160: INFO: Created: latency-svc-2vdf8
    Apr 18 05:16:38.375: INFO: Got endpoints: latency-svc-2vdf8 [2.056917175s]
    Apr 18 05:16:38.380: INFO: Created: latency-svc-c6hct
    Apr 18 05:16:38.460: INFO: Got endpoints: latency-svc-c6hct [2.014716056s]
    Apr 18 05:16:38.536: INFO: Created: latency-svc-4wzjm
    Apr 18 05:16:38.635: INFO: Created: latency-svc-pc8hr
    Apr 18 05:16:38.791: INFO: Got endpoints: latency-svc-4wzjm [2.26481327s]
    Apr 18 05:16:38.818: INFO: Got endpoints: latency-svc-pc8hr [2.033859097s]
    Apr 18 05:16:38.870: INFO: Created: latency-svc-qlt26
    Apr 18 05:16:38.991: INFO: Got endpoints: latency-svc-qlt26 [2.181514095s]
    Apr 18 05:16:39.026: INFO: Created: latency-svc-5xhwc
    Apr 18 05:16:39.183: INFO: Got endpoints: latency-svc-5xhwc [2.214921066s]
    Apr 18 05:16:39.274: INFO: Created: latency-svc-6qsxd
    Apr 18 05:16:39.308: INFO: Got endpoints: latency-svc-6qsxd [2.269358215s]
    Apr 18 05:16:39.437: INFO: Created: latency-svc-7gw2g
    Apr 18 05:16:39.478: INFO: Got endpoints: latency-svc-7gw2g [2.226679274s]
    Apr 18 05:16:39.603: INFO: Created: latency-svc-dlczt
    Apr 18 05:16:39.634: INFO: Got endpoints: latency-svc-dlczt [2.184560371s]
    Apr 18 05:16:39.663: INFO: Created: latency-svc-5qd26
    Apr 18 05:16:39.778: INFO: Created: latency-svc-xtkpv
    Apr 18 05:16:39.802: INFO: Got endpoints: latency-svc-5qd26 [2.333460083s]
    Apr 18 05:16:39.819: INFO: Got endpoints: latency-svc-xtkpv [2.200588237s]
    Apr 18 05:16:40.159: INFO: Created: latency-svc-x7sj9
    Apr 18 05:16:40.211: INFO: Got endpoints: latency-svc-x7sj9 [2.50147262s]
    Apr 18 05:16:40.227: INFO: Created: latency-svc-rgh8j
    Apr 18 05:16:40.375: INFO: Got endpoints: latency-svc-rgh8j [2.581833532s]
    Apr 18 05:16:40.440: INFO: Created: latency-svc-j2lbv
    Apr 18 05:16:40.477: INFO: Got endpoints: latency-svc-j2lbv [2.524992497s]
    Apr 18 05:16:40.620: INFO: Created: latency-svc-dd4wg
    Apr 18 05:16:40.646: INFO: Got endpoints: latency-svc-dd4wg [2.527789696s]
    Apr 18 05:16:40.647: INFO: Created: latency-svc-x82zf
    Apr 18 05:16:40.706: INFO: Got endpoints: latency-svc-x82zf [2.331643568s]
    Apr 18 05:16:40.778: INFO: Created: latency-svc-zpsfk
    Apr 18 05:16:40.834: INFO: Created: latency-svc-sv5rb
    Apr 18 05:16:40.852: INFO: Got endpoints: latency-svc-zpsfk [2.39172029s]
    Apr 18 05:16:40.924: INFO: Got endpoints: latency-svc-sv5rb [2.133795405s]
    Apr 18 05:16:40.976: INFO: Created: latency-svc-j9txk
    Apr 18 05:16:41.011: INFO: Got endpoints: latency-svc-j9txk [2.192407812s]
    Apr 18 05:16:41.096: INFO: Created: latency-svc-sbf9g
    Apr 18 05:16:41.152: INFO: Got endpoints: latency-svc-sbf9g [2.161252497s]
    Apr 18 05:16:41.153: INFO: Created: latency-svc-rmt5h
    Apr 18 05:16:41.249: INFO: Created: latency-svc-x7vld
    Apr 18 05:16:41.252: INFO: Got endpoints: latency-svc-rmt5h [2.069099113s]
    Apr 18 05:16:41.320: INFO: Created: latency-svc-kp5fs
    Apr 18 05:16:41.321: INFO: Got endpoints: latency-svc-x7vld [2.012371718s]
    Apr 18 05:16:41.461: INFO: Got endpoints: latency-svc-kp5fs [1.982980437s]
    Apr 18 05:16:41.462: INFO: Created: latency-svc-gp86w
    Apr 18 05:16:41.523: INFO: Created: latency-svc-dnp4z
    Apr 18 05:16:41.595: INFO: Got endpoints: latency-svc-gp86w [1.961292518s]
    Apr 18 05:16:41.636: INFO: Got endpoints: latency-svc-dnp4z [1.834092295s]
    Apr 18 05:16:41.732: INFO: Created: latency-svc-4n7pj
    Apr 18 05:16:41.825: INFO: Got endpoints: latency-svc-4n7pj [2.00626932s]
    Apr 18 05:16:41.844: INFO: Created: latency-svc-5dfcp
    Apr 18 05:16:41.969: INFO: Got endpoints: latency-svc-5dfcp [1.758646786s]
    Apr 18 05:16:41.969: INFO: Created: latency-svc-d8987
    Apr 18 05:16:42.061: INFO: Got endpoints: latency-svc-d8987 [1.686362987s]
    Apr 18 05:16:42.186: INFO: Created: latency-svc-rjrjk
    Apr 18 05:16:42.253: INFO: Created: latency-svc-dcbms
    Apr 18 05:16:42.369: INFO: Created: latency-svc-j8qrv
    Apr 18 05:16:42.403: INFO: Got endpoints: latency-svc-dcbms [1.756954957s]
    Apr 18 05:16:42.404: INFO: Got endpoints: latency-svc-rjrjk [1.926263475s]
    Apr 18 05:16:42.444: INFO: Got endpoints: latency-svc-j8qrv [1.737200465s]
    Apr 18 05:16:42.571: INFO: Created: latency-svc-cp669
    Apr 18 05:16:42.619: INFO: Got endpoints: latency-svc-cp669 [1.767383009s]
    Apr 18 05:16:42.620: INFO: Created: latency-svc-xvxn2
    Apr 18 05:16:42.838: INFO: Created: latency-svc-qp6xs
    Apr 18 05:16:42.853: INFO: Got endpoints: latency-svc-xvxn2 [1.92889006s]
    Apr 18 05:16:42.910: INFO: Got endpoints: latency-svc-qp6xs [1.899523053s]
    Apr 18 05:16:43.022: INFO: Created: latency-svc-6sd8c
    Apr 18 05:16:43.061: INFO: Got endpoints: latency-svc-6sd8c [1.909098394s]
    Apr 18 05:16:43.079: INFO: Created: latency-svc-w76w8
    Apr 18 05:16:43.193: INFO: Got endpoints: latency-svc-w76w8 [1.940538282s]
    Apr 18 05:16:43.238: INFO: Created: latency-svc-w9c97
    Apr 18 05:16:43.270: INFO: Got endpoints: latency-svc-w9c97 [1.949500247s]
    Apr 18 05:16:43.305: INFO: Created: latency-svc-8jglf
    Apr 18 05:16:43.403: INFO: Got endpoints: latency-svc-8jglf [1.9421656s]
    Apr 18 05:16:43.413: INFO: Created: latency-svc-75hwh
    Apr 18 05:16:43.442: INFO: Got endpoints: latency-svc-75hwh [1.846324344s]
    Apr 18 05:16:43.462: INFO: Created: latency-svc-756h5
    Apr 18 05:16:43.626: INFO: Created: latency-svc-2288f
    Apr 18 05:16:43.626: INFO: Got endpoints: latency-svc-756h5 [1.989988043s]
    Apr 18 05:16:43.745: INFO: Created: latency-svc-b7sw5
    Apr 18 05:16:43.745: INFO: Got endpoints: latency-svc-2288f [1.919737865s]
    Apr 18 05:16:43.776: INFO: Got endpoints: latency-svc-b7sw5 [1.806127904s]
    Apr 18 05:16:43.796: INFO: Created: latency-svc-2bksw
    Apr 18 05:16:43.879: INFO: Got endpoints: latency-svc-2bksw [1.817338083s]
    Apr 18 05:16:44.555: INFO: Created: latency-svc-wtpx4
    Apr 18 05:16:44.695: INFO: Got endpoints: latency-svc-wtpx4 [2.29188937s]
    Apr 18 05:16:44.696: INFO: Created: latency-svc-gr5ff
    Apr 18 05:16:44.755: INFO: Got endpoints: latency-svc-gr5ff [2.351888914s]
    Apr 18 05:16:44.764: INFO: Created: latency-svc-vdd8n
    Apr 18 05:16:44.845: INFO: Got endpoints: latency-svc-vdd8n [2.401818812s]
    Apr 18 05:16:44.860: INFO: Created: latency-svc-sfffm
    Apr 18 05:16:45.029: INFO: Got endpoints: latency-svc-sfffm [2.409485006s]
    Apr 18 05:16:45.029: INFO: Created: latency-svc-gwjgs
    Apr 18 05:16:45.087: INFO: Created: latency-svc-tkq9c
    Apr 18 05:16:45.117: INFO: Got endpoints: latency-svc-gwjgs [2.263625956s]
    Apr 18 05:16:45.118: INFO: Got endpoints: latency-svc-tkq9c [2.207317834s]
    Apr 18 05:16:45.228: INFO: Created: latency-svc-vttfj
    Apr 18 05:16:45.362: INFO: Got endpoints: latency-svc-vttfj [2.300426124s]
    Apr 18 05:16:45.371: INFO: Created: latency-svc-bgg24
    Apr 18 05:16:45.459: INFO: Created: latency-svc-cr876
    Apr 18 05:16:45.512: INFO: Got endpoints: latency-svc-bgg24 [2.319336817s]
    Apr 18 05:16:45.545: INFO: Got endpoints: latency-svc-cr876 [2.274938316s]
    Apr 18 05:16:45.629: INFO: Created: latency-svc-l8dmv
    Apr 18 05:16:45.684: INFO: Got endpoints: latency-svc-l8dmv [2.28019601s]
    Apr 18 05:16:45.695: INFO: Created: latency-svc-pmbsr
    Apr 18 05:16:45.821: INFO: Got endpoints: latency-svc-pmbsr [2.379267179s]
    Apr 18 05:16:45.834: INFO: Created: latency-svc-vnmfn
    Apr 18 05:16:45.904: INFO: Got endpoints: latency-svc-vnmfn [2.276736126s]
    Apr 18 05:16:46.047: INFO: Created: latency-svc-2kpb2
    Apr 18 05:16:46.579: INFO: Got endpoints: latency-svc-2kpb2 [2.833814806s]
    Apr 18 05:16:46.628: INFO: Created: latency-svc-tgh5w
    Apr 18 05:16:46.667: INFO: Got endpoints: latency-svc-tgh5w [2.891556983s]
    Apr 18 05:16:46.741: INFO: Created: latency-svc-zjjhn
    Apr 18 05:16:46.762: INFO: Got endpoints: latency-svc-zjjhn [2.882785996s]
    Apr 18 05:16:46.803: INFO: Created: latency-svc-wjrzm
    Apr 18 05:16:46.871: INFO: Got endpoints: latency-svc-wjrzm [2.176002546s]
    Apr 18 05:16:46.912: INFO: Created: latency-svc-82f5n
    Apr 18 05:16:46.984: INFO: Created: latency-svc-j8jgp
    Apr 18 05:16:47.021: INFO: Got endpoints: latency-svc-82f5n [2.265426684s]
    Apr 18 05:16:47.037: INFO: Got endpoints: latency-svc-j8jgp [2.191737276s]
    Apr 18 05:16:47.188: INFO: Created: latency-svc-vcj6v
    Apr 18 05:16:47.203: INFO: Got endpoints: latency-svc-vcj6v [2.174709521s]
    Apr 18 05:16:47.318: INFO: Created: latency-svc-8vsnh
    Apr 18 05:16:47.401: INFO: Got endpoints: latency-svc-8vsnh [2.283858536s]
    Apr 18 05:16:47.480: INFO: Created: latency-svc-7tlr7
    Apr 18 05:16:47.571: INFO: Got endpoints: latency-svc-7tlr7 [2.453056007s]
    Apr 18 05:16:47.596: INFO: Created: latency-svc-t6qlm
    Apr 18 05:16:47.596: INFO: Got endpoints: latency-svc-t6qlm [2.234076609s]
    Apr 18 05:16:47.668: INFO: Created: latency-svc-jbwpn
    Apr 18 05:16:47.723: INFO: Created: latency-svc-mf64n
    Apr 18 05:16:47.746: INFO: Got endpoints: latency-svc-jbwpn [2.23350446s]
    Apr 18 05:16:47.779: INFO: Got endpoints: latency-svc-mf64n [2.234172065s]
    Apr 18 05:16:47.921: INFO: Created: latency-svc-mj86c
    Apr 18 05:16:47.921: INFO: Got endpoints: latency-svc-mj86c [2.237301235s]
    Apr 18 05:16:47.939: INFO: Created: latency-svc-jwg6x
    Apr 18 05:16:48.081: INFO: Created: latency-svc-4rwgk
    Apr 18 05:16:48.088: INFO: Got endpoints: latency-svc-jwg6x [2.266940573s]
    Apr 18 05:16:48.112: INFO: Got endpoints: latency-svc-4rwgk [2.208029608s]
    Apr 18 05:16:48.163: INFO: Created: latency-svc-lwjlb
    Apr 18 05:16:48.288: INFO: Got endpoints: latency-svc-lwjlb [1.708845014s]
    Apr 18 05:16:48.288: INFO: Created: latency-svc-5b8gz
    Apr 18 05:16:48.446: INFO: Got endpoints: latency-svc-5b8gz [1.778404055s]
    Apr 18 05:16:48.493: INFO: Created: latency-svc-kv5l2
    Apr 18 05:16:48.544: INFO: Created: latency-svc-f4hw7
    Apr 18 05:16:48.629: INFO: Got endpoints: latency-svc-f4hw7 [1.867775493s]
    Apr 18 05:16:48.645: INFO: Got endpoints: latency-svc-kv5l2 [1.774065496s]
    Apr 18 05:16:48.646: INFO: Created: latency-svc-5s55p
    Apr 18 05:16:48.779: INFO: Got endpoints: latency-svc-5s55p [1.758021383s]
    Apr 18 05:16:48.873: INFO: Created: latency-svc-hxxxh
    Apr 18 05:16:48.971: INFO: Got endpoints: latency-svc-hxxxh [1.934029878s]
    Apr 18 05:16:49.033: INFO: Created: latency-svc-ktwzw
    Apr 18 05:16:49.230: INFO: Got endpoints: latency-svc-ktwzw [2.026593314s]
    Apr 18 05:16:49.247: INFO: Created: latency-svc-7lk5p
    Apr 18 05:16:49.392: INFO: Created: latency-svc-s8jqp
    Apr 18 05:16:49.396: INFO: Got endpoints: latency-svc-7lk5p [1.994710145s]
    Apr 18 05:16:49.428: INFO: Got endpoints: latency-svc-s8jqp [1.857257442s]
    Apr 18 05:16:49.554: INFO: Created: latency-svc-6rk77
    Apr 18 05:16:49.580: INFO: Got endpoints: latency-svc-6rk77 [1.983574726s]
    Apr 18 05:16:49.671: INFO: Created: latency-svc-zkwq6
    Apr 18 05:16:49.721: INFO: Created: latency-svc-56nj2
    Apr 18 05:16:49.746: INFO: Got endpoints: latency-svc-zkwq6 [2.000578443s]
    Apr 18 05:16:49.872: INFO: Created: latency-svc-8j79l
    Apr 18 05:16:49.879: INFO: Got endpoints: latency-svc-56nj2 [2.099277654s]
    Apr 18 05:16:49.888: INFO: Got endpoints: latency-svc-8j79l [1.966719713s]
    Apr 18 05:16:49.937: INFO: Created: latency-svc-c9x5t
    Apr 18 05:16:50.041: INFO: Got endpoints: latency-svc-c9x5t [1.953069216s]
    Apr 18 05:16:50.139: INFO: Created: latency-svc-rlsv6
    Apr 18 05:16:50.185: INFO: Created: latency-svc-hlk6l
    Apr 18 05:16:50.293: INFO: Created: latency-svc-fcb6x
    Apr 18 05:16:50.355: INFO: Got endpoints: latency-svc-hlk6l [2.242975868s]
    Apr 18 05:16:50.355: INFO: Got endpoints: latency-svc-rlsv6 [2.067598119s]
    Apr 18 05:16:50.413: INFO: Got endpoints: latency-svc-fcb6x [1.967800189s]
    Apr 18 05:16:50.485: INFO: Created: latency-svc-sh7l5
    Apr 18 05:16:50.538: INFO: Got endpoints: latency-svc-sh7l5 [1.908246393s]
    Apr 18 05:16:50.597: INFO: Created: latency-svc-l9pxt
    Apr 18 05:16:50.691: INFO: Got endpoints: latency-svc-l9pxt [2.046073815s]
    Apr 18 05:16:50.776: INFO: Created: latency-svc-fghjd
    Apr 18 05:16:50.831: INFO: Created: latency-svc-5klt6
    Apr 18 05:16:50.862: INFO: Got endpoints: latency-svc-fghjd [2.083296574s]
    Apr 18 05:16:50.872: INFO: Got endpoints: latency-svc-5klt6 [1.900834966s]
    Apr 18 05:16:51.039: INFO: Created: latency-svc-f6tx4
    Apr 18 05:16:51.107: INFO: Created: latency-svc-2vksw
    Apr 18 05:16:51.184: INFO: Created: latency-svc-vwsp7
    Apr 18 05:16:51.188: INFO: Got endpoints: latency-svc-f6tx4 [1.957654995s]
    Apr 18 05:16:51.217: INFO: Got endpoints: latency-svc-2vksw [1.821725497s]
    Apr 18 05:16:51.218: INFO: Got endpoints: latency-svc-vwsp7 [1.789298574s]
    Apr 18 05:16:51.352: INFO: Created: latency-svc-q4g7d
    Apr 18 05:16:51.379: INFO: Got endpoints: latency-svc-q4g7d [1.799523872s]
    Apr 18 05:16:51.441: INFO: Created: latency-svc-dwkcf
    Apr 18 05:16:51.509: INFO: Created: latency-svc-ht79h
    Apr 18 05:16:51.547: INFO: Got endpoints: latency-svc-dwkcf [1.80094015s]
    Apr 18 05:16:51.563: INFO: Got endpoints: latency-svc-ht79h [1.684321948s]
    Apr 18 05:16:51.666: INFO: Created: latency-svc-spxht
    Apr 18 05:16:51.721: INFO: Got endpoints: latency-svc-spxht [1.833366178s]
    Apr 18 05:16:51.774: INFO: Created: latency-svc-4k82t
    Apr 18 05:16:51.843: INFO: Created: latency-svc-n9n9n
    Apr 18 05:16:51.888: INFO: Got endpoints: latency-svc-n9n9n [1.533187508s]
    Apr 18 05:16:51.932: INFO: Got endpoints: latency-svc-4k82t [1.891247848s]
    Apr 18 05:16:52.040: INFO: Created: latency-svc-kkwb5
    Apr 18 05:16:52.164: INFO: Got endpoints: latency-svc-kkwb5 [1.808270172s]
    Apr 18 05:16:52.164: INFO: Created: latency-svc-j7pwt
    Apr 18 05:16:52.205: INFO: Got endpoints: latency-svc-j7pwt [1.791804832s]
    Apr 18 05:16:52.286: INFO: Created: latency-svc-gv295
    Apr 18 05:16:52.331: INFO: Got endpoints: latency-svc-gv295 [1.792753088s]
    Apr 18 05:16:52.348: INFO: Created: latency-svc-nnpgs
    Apr 18 05:16:52.481: INFO: Got endpoints: latency-svc-nnpgs [1.789756982s]
    Apr 18 05:16:52.490: INFO: Created: latency-svc-9wjhg
    Apr 18 05:16:52.514: INFO: Got endpoints: latency-svc-9wjhg [1.651470944s]
    Apr 18 05:16:52.607: INFO: Created: latency-svc-6wc9x
    Apr 18 05:16:52.688: INFO: Got endpoints: latency-svc-6wc9x [1.816136797s]
    Apr 18 05:16:52.714: INFO: Created: latency-svc-knnnx
    Apr 18 05:16:52.800: INFO: Created: latency-svc-6nzhp
    Apr 18 05:16:52.878: INFO: Got endpoints: latency-svc-knnnx [1.690141014s]
    Apr 18 05:16:52.878: INFO: Got endpoints: latency-svc-6nzhp [1.660379322s]
    Apr 18 05:16:52.951: INFO: Created: latency-svc-z7lhw
    Apr 18 05:16:52.993: INFO: Created: latency-svc-d4lnw
    Apr 18 05:16:53.014: INFO: Got endpoints: latency-svc-z7lhw [1.796534967s]
    Apr 18 05:16:53.030: INFO: Got endpoints: latency-svc-d4lnw [1.650433926s]
    Apr 18 05:16:53.141: INFO: Created: latency-svc-658jw
    Apr 18 05:16:53.186: INFO: Got endpoints: latency-svc-658jw [1.63826961s]
    Apr 18 05:16:53.198: INFO: Created: latency-svc-7px5t
    Apr 18 05:16:53.316: INFO: Got endpoints: latency-svc-7px5t [1.75272446s]
    Apr 18 05:16:53.316: INFO: Created: latency-svc-8wfds
    Apr 18 05:16:53.338: INFO: Got endpoints: latency-svc-8wfds [1.61713808s]
    Apr 18 05:16:53.381: INFO: Created: latency-svc-dgsp5
    Apr 18 05:16:53.397: INFO: Got endpoints: latency-svc-dgsp5 [1.508821226s]
    Apr 18 05:16:53.515: INFO: Created: latency-svc-f5kk8
    Apr 18 05:16:53.515: INFO: Created: latency-svc-crr9t
    Apr 18 05:16:53.548: INFO: Got endpoints: latency-svc-f5kk8 [1.384722148s]
    Apr 18 05:16:53.573: INFO: Created: latency-svc-j98f4
    Apr 18 05:16:53.656: INFO: Got endpoints: latency-svc-crr9t [1.723471041s]
    Apr 18 05:16:53.710: INFO: Created: latency-svc-rt8kn
    Apr 18 05:16:53.713: INFO: Got endpoints: latency-svc-j98f4 [1.507900445s]
    Apr 18 05:16:53.814: INFO: Got endpoints: latency-svc-rt8kn [1.48387942s]
    Apr 18 05:16:53.815: INFO: Created: latency-svc-ktnj7
    Apr 18 05:16:53.902: INFO: Got endpoints: latency-svc-ktnj7 [1.420732831s]
    Apr 18 05:16:53.916: INFO: Created: latency-svc-mzndx
    Apr 18 05:16:54.141: INFO: Got endpoints: latency-svc-mzndx [1.627244954s]
    Apr 18 05:16:54.149: INFO: Created: latency-svc-bcvrs
    Apr 18 05:16:54.181: INFO: Got endpoints: latency-svc-bcvrs [1.493150659s]
    Apr 18 05:16:54.349: INFO: Created: latency-svc-jxjx2
    Apr 18 05:16:54.385: INFO: Got endpoints: latency-svc-jxjx2 [1.506758267s]
    Apr 18 05:16:54.449: INFO: Created: latency-svc-j755s
    Apr 18 05:16:54.481: INFO: Got endpoints: latency-svc-j755s [1.602799867s]
    Apr 18 05:16:54.524: INFO: Created: latency-svc-rxpds
    Apr 18 05:16:54.636: INFO: Got endpoints: latency-svc-rxpds [1.622275629s]
    Apr 18 05:16:54.637: INFO: Created: latency-svc-fv6fp
    Apr 18 05:16:54.680: INFO: Got endpoints: latency-svc-fv6fp [1.650354091s]
    Apr 18 05:16:54.699: INFO: Created: latency-svc-2hksm
    Apr 18 05:16:54.781: INFO: Got endpoints: latency-svc-2hksm [1.595346363s]
    Apr 18 05:16:54.848: INFO: Created: latency-svc-wz8fq
    Apr 18 05:16:54.851: INFO: Created: latency-svc-pc2q8
    Apr 18 05:16:54.877: INFO: Got endpoints: latency-svc-wz8fq [1.538670119s]
    Apr 18 05:16:54.948: INFO: Got endpoints: latency-svc-pc2q8 [1.632039604s]
    Apr 18 05:16:54.991: INFO: Created: latency-svc-m5cvq
    Apr 18 05:16:54.999: INFO: Got endpoints: latency-svc-m5cvq [1.601390836s]
    Apr 18 05:16:55.144: INFO: Created: latency-svc-lh9pj
    Apr 18 05:16:55.198: INFO: Got endpoints: latency-svc-lh9pj [1.64961921s]
    Apr 18 05:16:55.199: INFO: Created: latency-svc-cmt2q
    Apr 18 05:16:55.256: INFO: Got endpoints: latency-svc-cmt2q [1.600211181s]
    Apr 18 05:16:55.332: INFO: Created: latency-svc-qtgmw
    Apr 18 05:16:55.348: INFO: Got endpoints: latency-svc-qtgmw [1.634637356s]
    Apr 18 05:16:55.388: INFO: Created: latency-svc-slhjx
    Apr 18 05:16:55.456: INFO: Got endpoints: latency-svc-slhjx [1.641672193s]
    Apr 18 05:16:55.599: INFO: Created: latency-svc-smmzw
    Apr 18 05:16:55.630: INFO: Got endpoints: latency-svc-smmzw [1.728269583s]
    Apr 18 05:16:55.674: INFO: Created: latency-svc-6bdk4
    Apr 18 05:16:55.724: INFO: Created: latency-svc-5rzbc
    Apr 18 05:16:55.901: INFO: Got endpoints: latency-svc-5rzbc [1.719215753s]
    Apr 18 05:16:55.901: INFO: Got endpoints: latency-svc-6bdk4 [1.759442058s]
    Apr 18 05:16:56.058: INFO: Created: latency-svc-pmn2t
    Apr 18 05:16:56.065: INFO: Got endpoints: latency-svc-pmn2t [1.679884325s]
    Apr 18 05:16:56.183: INFO: Created: latency-svc-58cfx
    Apr 18 05:16:56.215: INFO: Got endpoints: latency-svc-58cfx [1.734619396s]
    Apr 18 05:16:56.286: INFO: Created: latency-svc-8gq2j
    Apr 18 05:16:56.382: INFO: Got endpoints: latency-svc-8gq2j [1.745627409s]
    Apr 18 05:16:56.398: INFO: Created: latency-svc-gkhbt
    Apr 18 05:16:56.507: INFO: Got endpoints: latency-svc-gkhbt [1.826619274s]
    Apr 18 05:16:56.532: INFO: Created: latency-svc-j2cp6
    Apr 18 05:16:56.691: INFO: Created: latency-svc-pz6nl
    Apr 18 05:16:56.739: INFO: Got endpoints: latency-svc-j2cp6 [1.958235008s]
    Apr 18 05:16:56.807: INFO: Got endpoints: latency-svc-pz6nl [1.930341431s]
    Apr 18 05:16:56.892: INFO: Created: latency-svc-hvp7b
    Apr 18 05:16:56.950: INFO: Created: latency-svc-gpmp8
    Apr 18 05:16:57.011: INFO: Created: latency-svc-gv6n6
    Apr 18 05:16:57.014: INFO: Got endpoints: latency-svc-hvp7b [2.015590961s]
    Apr 18 05:16:57.014: INFO: Got endpoints: latency-svc-gpmp8 [2.06640385s]
    Apr 18 05:16:57.115: INFO: Got endpoints: latency-svc-gv6n6 [1.916917043s]
    Apr 18 05:16:57.132: INFO: Created: latency-svc-cfl9t
    Apr 18 05:16:57.149: INFO: Got endpoints: latency-svc-cfl9t [1.892723134s]
    Apr 18 05:16:57.311: INFO: Created: latency-svc-bmsl8
    Apr 18 05:16:57.316: INFO: Created: latency-svc-pfmxc
    Apr 18 05:16:57.348: INFO: Got endpoints: latency-svc-bmsl8 [2.000317999s]
    Apr 18 05:16:57.424: INFO: Got endpoints: latency-svc-pfmxc [1.967763237s]
    Apr 18 05:16:57.457: INFO: Created: latency-svc-kxbm7
    Apr 18 05:16:57.503: INFO: Got endpoints: latency-svc-kxbm7 [1.872770663s]
    Apr 18 05:16:57.516: INFO: Created: latency-svc-m4cj7
    Apr 18 05:16:57.616: INFO: Got endpoints: latency-svc-m4cj7 [1.715147605s]
    Apr 18 05:16:57.641: INFO: Created: latency-svc-99kx2
    Apr 18 05:16:57.677: INFO: Created: latency-svc-5s278
    Apr 18 05:16:57.699: INFO: Got endpoints: latency-svc-99kx2 [1.797809287s]
    Apr 18 05:16:57.706: INFO: Got endpoints: latency-svc-5s278 [1.64152025s]
    Apr 18 05:16:57.706: INFO: Latencies: [449.996502ms 742.987128ms 743.208254ms 1.008415328s 1.131980762s 1.324093269s 1.384722148s 1.420732831s 1.48387942s 1.493150659s 1.506758267s 1.507900445s 1.508821226s 1.533187508s 1.538670119s 1.595346363s 1.600211181s 1.601390836s 1.602799867s 1.61713808s 1.622275629s 1.627244954s 1.632039604s 1.634637356s 1.63826961s 1.64152025s 1.641672193s 1.64961921s 1.650354091s 1.650433926s 1.651470944s 1.660379322s 1.679884325s 1.684321948s 1.686362987s 1.690141014s 1.708845014s 1.715147605s 1.717289347s 1.719215753s 1.723471041s 1.728269583s 1.734619396s 1.737200465s 1.745627409s 1.749598295s 1.75272446s 1.756954957s 1.758021383s 1.758646786s 1.759442058s 1.767383009s 1.774065496s 1.778404055s 1.789298574s 1.789756982s 1.791804832s 1.792753088s 1.796534967s 1.797809287s 1.799523872s 1.80094015s 1.806127904s 1.808270172s 1.816136797s 1.817338083s 1.821725497s 1.826619274s 1.833366178s 1.834092295s 1.846324344s 1.857257442s 1.867775493s 1.872770663s 1.891247848s 1.892723134s 1.899523053s 1.900834966s 1.908246393s 1.909098394s 1.916917043s 1.919737865s 1.926263475s 1.92889006s 1.930341431s 1.934029878s 1.940538282s 1.9421656s 1.949500247s 1.953069216s 1.957654995s 1.958235008s 1.961292518s 1.966719713s 1.967763237s 1.967800189s 1.982980437s 1.983574726s 1.989988043s 1.991842249s 1.994710145s 2.000317999s 2.000347697s 2.000578443s 2.00626932s 2.012371718s 2.014716056s 2.015590961s 2.023114061s 2.025082689s 2.026593314s 2.033859097s 2.036998955s 2.041637977s 2.046073815s 2.056917175s 2.06640385s 2.067598119s 2.069099113s 2.069304928s 2.083296574s 2.084475185s 2.090876568s 2.096414066s 2.099277654s 2.133795405s 2.161252497s 2.174709521s 2.176002546s 2.181514095s 2.184560371s 2.19051822s 2.191737276s 2.192407812s 2.200588237s 2.207317834s 2.208029608s 2.214921066s 2.223017394s 2.226679274s 2.23350446s 2.234076609s 2.234172065s 2.237301235s 2.242975868s 2.263625956s 2.26481327s 2.265426684s 2.266940573s 2.267548404s 2.269358215s 2.274938316s 2.276736126s 2.28019601s 2.283858536s 2.291265704s 2.29188937s 2.300426124s 2.319336817s 2.331643568s 2.333460083s 2.334534356s 2.348954783s 2.351888914s 2.379267179s 2.39172029s 2.401818812s 2.409485006s 2.431651834s 2.434677566s 2.448896237s 2.453056007s 2.475202267s 2.485262568s 2.50147262s 2.524992497s 2.525605295s 2.527789696s 2.533089417s 2.533718533s 2.534410081s 2.574519891s 2.575695455s 2.581833532s 2.583676329s 2.584256603s 2.584428174s 2.585186307s 2.61680309s 2.643121238s 2.684963385s 2.686417666s 2.71310809s 2.757668159s 2.765459284s 2.7826164s 2.833814806s 2.843402936s 2.882785996s 2.891556983s]
    Apr 18 05:16:57.706: INFO: 50 %ile: 1.994710145s
    Apr 18 05:16:57.706: INFO: 90 %ile: 2.534410081s
    Apr 18 05:16:57.706: INFO: 99 %ile: 2.882785996s
    Apr 18 05:16:57.706: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Apr 18 05:16:57.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-5492" for this suite. 04/18/23 05:16:57.77
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:16:57.802
Apr 18 05:16:57.802: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sysctl 04/18/23 05:16:57.803
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:16:57.85
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:16:57.853
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 04/18/23 05:16:57.865
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 05:16:57.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-3895" for this suite. 04/18/23 05:16:57.967
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":183,"skipped":3230,"failed":0}
------------------------------
â€¢ [0.188 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:16:57.802
    Apr 18 05:16:57.802: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sysctl 04/18/23 05:16:57.803
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:16:57.85
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:16:57.853
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 04/18/23 05:16:57.865
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 05:16:57.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-3895" for this suite. 04/18/23 05:16:57.967
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:16:57.992
Apr 18 05:16:57.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replication-controller 04/18/23 05:16:57.993
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:16:58.117
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:16:58.12
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Apr 18 05:16:58.157: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/18/23 05:16:59.276
STEP: Checking rc "condition-test" has the desired failure condition set 04/18/23 05:16:59.31
STEP: Scaling down rc "condition-test" to satisfy pod quota 04/18/23 05:17:00.317
Apr 18 05:17:00.524: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 04/18/23 05:17:00.524
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 18 05:17:01.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1453" for this suite. 04/18/23 05:17:01.685
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":184,"skipped":3275,"failed":0}
------------------------------
â€¢ [3.851 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:16:57.992
    Apr 18 05:16:57.992: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replication-controller 04/18/23 05:16:57.993
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:16:58.117
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:16:58.12
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Apr 18 05:16:58.157: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/18/23 05:16:59.276
    STEP: Checking rc "condition-test" has the desired failure condition set 04/18/23 05:16:59.31
    STEP: Scaling down rc "condition-test" to satisfy pod quota 04/18/23 05:17:00.317
    Apr 18 05:17:00.524: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 04/18/23 05:17:00.524
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 18 05:17:01.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1453" for this suite. 04/18/23 05:17:01.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:17:01.844
Apr 18 05:17:01.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 05:17:01.845
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:17:02.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:17:02.064
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 04/18/23 05:17:02.067
Apr 18 05:17:02.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9330 create -f -'
Apr 18 05:17:03.613: INFO: stderr: ""
Apr 18 05:17:03.613: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/18/23 05:17:03.613
Apr 18 05:17:04.912: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 05:17:04.912: INFO: Found 0 / 1
Apr 18 05:17:05.637: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 05:17:05.637: INFO: Found 0 / 1
Apr 18 05:17:06.617: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 05:17:06.617: INFO: Found 0 / 1
Apr 18 05:17:07.640: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 05:17:07.640: INFO: Found 1 / 1
Apr 18 05:17:07.640: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 04/18/23 05:17:07.64
Apr 18 05:17:07.680: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 05:17:07.680: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 18 05:17:07.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9330 patch pod agnhost-primary-wfgd5 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 18 05:17:07.821: INFO: stderr: ""
Apr 18 05:17:07.821: INFO: stdout: "pod/agnhost-primary-wfgd5 patched\n"
STEP: checking annotations 04/18/23 05:17:07.821
Apr 18 05:17:07.834: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 18 05:17:07.834: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 05:17:07.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9330" for this suite. 04/18/23 05:17:07.846
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":185,"skipped":3287,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.133 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:17:01.844
    Apr 18 05:17:01.844: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 05:17:01.845
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:17:02.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:17:02.064
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 04/18/23 05:17:02.067
    Apr 18 05:17:02.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9330 create -f -'
    Apr 18 05:17:03.613: INFO: stderr: ""
    Apr 18 05:17:03.613: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/18/23 05:17:03.613
    Apr 18 05:17:04.912: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 05:17:04.912: INFO: Found 0 / 1
    Apr 18 05:17:05.637: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 05:17:05.637: INFO: Found 0 / 1
    Apr 18 05:17:06.617: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 05:17:06.617: INFO: Found 0 / 1
    Apr 18 05:17:07.640: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 05:17:07.640: INFO: Found 1 / 1
    Apr 18 05:17:07.640: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 04/18/23 05:17:07.64
    Apr 18 05:17:07.680: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 05:17:07.680: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 18 05:17:07.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9330 patch pod agnhost-primary-wfgd5 -p {"metadata":{"annotations":{"x":"y"}}}'
    Apr 18 05:17:07.821: INFO: stderr: ""
    Apr 18 05:17:07.821: INFO: stdout: "pod/agnhost-primary-wfgd5 patched\n"
    STEP: checking annotations 04/18/23 05:17:07.821
    Apr 18 05:17:07.834: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 18 05:17:07.834: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 05:17:07.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9330" for this suite. 04/18/23 05:17:07.846
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:17:07.978
Apr 18 05:17:07.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename deployment 04/18/23 05:17:07.979
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:17:08.195
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:17:08.198
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Apr 18 05:17:08.201: INFO: Creating deployment "test-recreate-deployment"
Apr 18 05:17:08.294: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 18 05:17:08.380: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 18 05:17:10.521: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 18 05:17:10.601: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:17:12.635: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:17:14.680: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 18 05:17:14.779: INFO: Updating deployment test-recreate-deployment
Apr 18 05:17:14.779: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 05:17:17.138: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-7336  02ccc00c-75ad-45b2-a391-567020897719 4108085 2 2023-04-18 05:17:08 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-18 05:17:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:17:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006d94768 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-18 05:17:16 +0000 UTC,LastTransitionTime:2023-04-18 05:17:16 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-04-18 05:17:16 +0000 UTC,LastTransitionTime:2023-04-18 05:17:08 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 18 05:17:17.188: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-7336  36ea9680-32a9-4481-ae6f-579c7580ba3f 4108078 1 2023-04-18 05:17:16 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 02ccc00c-75ad-45b2-a391-567020897719 0xc006d94c10 0xc006d94c11}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:17:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"02ccc00c-75ad-45b2-a391-567020897719\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:17:16 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006d94ca8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 05:17:17.188: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 18 05:17:17.188: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-7336  8c2a0782-b405-42a0-b428-d6a22338a85c 4108061 2 2023-04-18 05:17:08 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 02ccc00c-75ad-45b2-a391-567020897719 0xc006d94af7 0xc006d94af8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:17:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"02ccc00c-75ad-45b2-a391-567020897719\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:17:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006d94ba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 18 05:17:17.275: INFO: Pod "test-recreate-deployment-9d58999df-p4w2m" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-p4w2m test-recreate-deployment-9d58999df- deployment-7336  02199e10-0e54-4d5a-85e0-4d0ff7ff17bf 4108077 0 2023-04-18 05:17:16 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 36ea9680-32a9-4481-ae6f-579c7580ba3f 0xc006d95100 0xc006d95101}] [] [{kube-controller-manager Update v1 2023-04-18 05:17:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36ea9680-32a9-4481-ae6f-579c7580ba3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:17:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fqjpz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fqjpz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:17:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:17:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:17:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:17:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:,StartTime:2023-04-18 05:17:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 05:17:17.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7336" for this suite. 04/18/23 05:17:17.348
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":186,"skipped":3289,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.401 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:17:07.978
    Apr 18 05:17:07.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename deployment 04/18/23 05:17:07.979
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:17:08.195
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:17:08.198
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Apr 18 05:17:08.201: INFO: Creating deployment "test-recreate-deployment"
    Apr 18 05:17:08.294: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Apr 18 05:17:08.380: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Apr 18 05:17:10.521: INFO: Waiting deployment "test-recreate-deployment" to complete
    Apr 18 05:17:10.601: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:17:12.635: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 17, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:17:14.680: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Apr 18 05:17:14.779: INFO: Updating deployment test-recreate-deployment
    Apr 18 05:17:14.779: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 05:17:17.138: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-7336  02ccc00c-75ad-45b2-a391-567020897719 4108085 2 2023-04-18 05:17:08 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2023-04-18 05:17:14 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:17:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006d94768 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2023-04-18 05:17:16 +0000 UTC,LastTransitionTime:2023-04-18 05:17:16 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2023-04-18 05:17:16 +0000 UTC,LastTransitionTime:2023-04-18 05:17:08 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Apr 18 05:17:17.188: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-7336  36ea9680-32a9-4481-ae6f-579c7580ba3f 4108078 1 2023-04-18 05:17:16 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 02ccc00c-75ad-45b2-a391-567020897719 0xc006d94c10 0xc006d94c11}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:17:16 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"02ccc00c-75ad-45b2-a391-567020897719\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:17:16 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006d94ca8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 05:17:17.188: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Apr 18 05:17:17.188: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-7336  8c2a0782-b405-42a0-b428-d6a22338a85c 4108061 2 2023-04-18 05:17:08 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 02ccc00c-75ad-45b2-a391-567020897719 0xc006d94af7 0xc006d94af8}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:17:14 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"02ccc00c-75ad-45b2-a391-567020897719\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:17:15 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006d94ba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 05:17:17.275: INFO: Pod "test-recreate-deployment-9d58999df-p4w2m" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-p4w2m test-recreate-deployment-9d58999df- deployment-7336  02199e10-0e54-4d5a-85e0-4d0ff7ff17bf 4108077 0 2023-04-18 05:17:16 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 36ea9680-32a9-4481-ae6f-579c7580ba3f 0xc006d95100 0xc006d95101}] [] [{kube-controller-manager Update v1 2023-04-18 05:17:16 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"36ea9680-32a9-4481-ae6f-579c7580ba3f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2023-04-18 05:17:16 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fqjpz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fqjpz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:17:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:17:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:17:16 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:17:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:,StartTime:2023-04-18 05:17:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 05:17:17.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7336" for this suite. 04/18/23 05:17:17.348
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:17:17.387
Apr 18 05:17:17.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 05:17:17.388
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:17:17.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:17:17.785
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-587b52d3-b7a1-47ba-812d-f3a2d5fc5712 04/18/23 05:17:17.788
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 05:17:17.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4090" for this suite. 04/18/23 05:17:17.794
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":187,"skipped":3455,"failed":0}
------------------------------
â€¢ [0.516 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:17:17.387
    Apr 18 05:17:17.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 05:17:17.388
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:17:17.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:17:17.785
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-587b52d3-b7a1-47ba-812d-f3a2d5fc5712 04/18/23 05:17:17.788
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 05:17:17.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4090" for this suite. 04/18/23 05:17:17.794
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:17:17.904
Apr 18 05:17:17.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename statefulset 04/18/23 05:17:17.905
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:17:18.396
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:17:18.399
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4173 04/18/23 05:17:18.402
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 04/18/23 05:17:18.452
Apr 18 05:17:18.594: INFO: Found 0 stateful pods, waiting for 3
Apr 18 05:17:28.648: INFO: Found 2 stateful pods, waiting for 3
Apr 18 05:17:38.642: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 05:17:38.642: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 05:17:38.642: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/18/23 05:17:39.293
Apr 18 05:17:39.510: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/18/23 05:17:39.51
STEP: Not applying an update when the partition is greater than the number of replicas 04/18/23 05:17:49.885
STEP: Performing a canary update 04/18/23 05:17:49.885
Apr 18 05:17:49.939: INFO: Updating stateful set ss2
Apr 18 05:17:49.979: INFO: Waiting for Pod statefulset-4173/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 04/18/23 05:18:00.041
Apr 18 05:18:00.843: INFO: Found 2 stateful pods, waiting for 3
Apr 18 05:18:11.008: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 05:18:11.008: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 05:18:11.008: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 04/18/23 05:18:11.034
Apr 18 05:18:11.102: INFO: Updating stateful set ss2
Apr 18 05:18:11.108: INFO: Waiting for Pod statefulset-4173/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Apr 18 05:18:21.175: INFO: Updating stateful set ss2
Apr 18 05:18:21.193: INFO: Waiting for StatefulSet statefulset-4173/ss2 to complete update
Apr 18 05:18:21.193: INFO: Waiting for Pod statefulset-4173/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 05:18:31.203: INFO: Deleting all statefulset in ns statefulset-4173
Apr 18 05:18:31.206: INFO: Scaling statefulset ss2 to 0
Apr 18 05:18:41.257: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 05:18:41.260: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 05:18:41.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4173" for this suite. 04/18/23 05:18:41.297
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":188,"skipped":3468,"failed":0}
------------------------------
â€¢ [SLOW TEST] [83.528 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:17:17.904
    Apr 18 05:17:17.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename statefulset 04/18/23 05:17:17.905
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:17:18.396
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:17:18.399
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4173 04/18/23 05:17:18.402
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 04/18/23 05:17:18.452
    Apr 18 05:17:18.594: INFO: Found 0 stateful pods, waiting for 3
    Apr 18 05:17:28.648: INFO: Found 2 stateful pods, waiting for 3
    Apr 18 05:17:38.642: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 05:17:38.642: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 05:17:38.642: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/18/23 05:17:39.293
    Apr 18 05:17:39.510: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/18/23 05:17:39.51
    STEP: Not applying an update when the partition is greater than the number of replicas 04/18/23 05:17:49.885
    STEP: Performing a canary update 04/18/23 05:17:49.885
    Apr 18 05:17:49.939: INFO: Updating stateful set ss2
    Apr 18 05:17:49.979: INFO: Waiting for Pod statefulset-4173/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 04/18/23 05:18:00.041
    Apr 18 05:18:00.843: INFO: Found 2 stateful pods, waiting for 3
    Apr 18 05:18:11.008: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 05:18:11.008: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 05:18:11.008: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 04/18/23 05:18:11.034
    Apr 18 05:18:11.102: INFO: Updating stateful set ss2
    Apr 18 05:18:11.108: INFO: Waiting for Pod statefulset-4173/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Apr 18 05:18:21.175: INFO: Updating stateful set ss2
    Apr 18 05:18:21.193: INFO: Waiting for StatefulSet statefulset-4173/ss2 to complete update
    Apr 18 05:18:21.193: INFO: Waiting for Pod statefulset-4173/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 05:18:31.203: INFO: Deleting all statefulset in ns statefulset-4173
    Apr 18 05:18:31.206: INFO: Scaling statefulset ss2 to 0
    Apr 18 05:18:41.257: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 05:18:41.260: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 05:18:41.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4173" for this suite. 04/18/23 05:18:41.297
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:18:41.433
Apr 18 05:18:41.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:18:41.434
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:18:41.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:18:41.582
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 04/18/23 05:18:41.585
Apr 18 05:18:41.676: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd" in namespace "projected-7005" to be "Succeeded or Failed"
Apr 18 05:18:41.679: INFO: Pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.253305ms
Apr 18 05:18:43.684: INFO: Pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008256829s
Apr 18 05:18:45.684: INFO: Pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008307602s
Apr 18 05:18:47.683: INFO: Pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007458906s
STEP: Saw pod success 04/18/23 05:18:47.683
Apr 18 05:18:47.683: INFO: Pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd" satisfied condition "Succeeded or Failed"
Apr 18 05:18:47.687: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd container client-container: <nil>
STEP: delete the pod 04/18/23 05:18:47.7
Apr 18 05:18:47.855: INFO: Waiting for pod downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd to disappear
Apr 18 05:18:47.862: INFO: Pod downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 05:18:47.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7005" for this suite. 04/18/23 05:18:47.874
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":189,"skipped":3496,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.464 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:18:41.433
    Apr 18 05:18:41.433: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:18:41.434
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:18:41.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:18:41.582
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 04/18/23 05:18:41.585
    Apr 18 05:18:41.676: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd" in namespace "projected-7005" to be "Succeeded or Failed"
    Apr 18 05:18:41.679: INFO: Pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.253305ms
    Apr 18 05:18:43.684: INFO: Pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008256829s
    Apr 18 05:18:45.684: INFO: Pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008307602s
    Apr 18 05:18:47.683: INFO: Pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007458906s
    STEP: Saw pod success 04/18/23 05:18:47.683
    Apr 18 05:18:47.683: INFO: Pod "downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd" satisfied condition "Succeeded or Failed"
    Apr 18 05:18:47.687: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd container client-container: <nil>
    STEP: delete the pod 04/18/23 05:18:47.7
    Apr 18 05:18:47.855: INFO: Waiting for pod downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd to disappear
    Apr 18 05:18:47.862: INFO: Pod downwardapi-volume-f9b44e49-1e0e-4a9e-bb2a-ce11e9c7cbdd no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 05:18:47.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7005" for this suite. 04/18/23 05:18:47.874
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:18:47.897
Apr 18 05:18:47.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename init-container 04/18/23 05:18:47.898
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:18:48.078
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:18:48.081
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 04/18/23 05:18:48.084
Apr 18 05:18:48.084: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 18 05:18:58.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8270" for this suite. 04/18/23 05:18:58.04
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":190,"skipped":3500,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.177 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:18:47.897
    Apr 18 05:18:47.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename init-container 04/18/23 05:18:47.898
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:18:48.078
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:18:48.081
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 04/18/23 05:18:48.084
    Apr 18 05:18:48.084: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 18 05:18:58.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8270" for this suite. 04/18/23 05:18:58.04
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:18:58.077
Apr 18 05:18:58.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename dns 04/18/23 05:18:58.078
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:18:58.256
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:18:58.259
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 04/18/23 05:18:58.262
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1570.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1570.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 129.3.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.3.129_udp@PTR;check="$$(dig +tcp +noall +answer +search 129.3.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.3.129_tcp@PTR;sleep 1; done
 04/18/23 05:18:58.456
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1570.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1570.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 129.3.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.3.129_udp@PTR;check="$$(dig +tcp +noall +answer +search 129.3.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.3.129_tcp@PTR;sleep 1; done
 04/18/23 05:18:58.456
STEP: creating a pod to probe DNS 04/18/23 05:18:58.456
STEP: submitting the pod to kubernetes 04/18/23 05:18:58.456
Apr 18 05:18:58.608: INFO: Waiting up to 15m0s for pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220" in namespace "dns-1570" to be "running"
Apr 18 05:18:58.654: INFO: Pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220": Phase="Pending", Reason="", readiness=false. Elapsed: 46.315077ms
Apr 18 05:19:00.665: INFO: Pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057116572s
Apr 18 05:19:02.682: INFO: Pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074427346s
Apr 18 05:19:04.665: INFO: Pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220": Phase="Running", Reason="", readiness=true. Elapsed: 6.057687457s
Apr 18 05:19:04.665: INFO: Pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220" satisfied condition "running"
STEP: retrieving the pod 04/18/23 05:19:04.665
STEP: looking for the results for each expected name from probers 04/18/23 05:19:04.705
Apr 18 05:19:04.709: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:04.713: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:04.737: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:04.740: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:04.756: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:04.759: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:04.762: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:04.765: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:04.846: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

Apr 18 05:19:09.888: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:09.924: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:09.928: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:09.931: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:09.946: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:09.949: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:09.956: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:09.960: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:09.973: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

Apr 18 05:19:14.864: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:14.868: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:14.872: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:14.875: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:14.892: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:14.895: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:14.898: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:14.901: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:14.917: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

Apr 18 05:19:19.906: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:19.909: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:19.913: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:19.916: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:19.974: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:19.977: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:19.980: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:19.983: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:19.997: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

Apr 18 05:19:24.854: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:24.858: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:24.861: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:24.865: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:24.881: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:24.885: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:24.888: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:24.891: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:24.904: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

Apr 18 05:19:29.850: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:29.854: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:29.858: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:29.861: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:29.877: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:29.880: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:29.884: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:29.887: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
Apr 18 05:19:29.899: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

Apr 18 05:19:35.017: INFO: DNS probes using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 succeeded

STEP: deleting the pod 04/18/23 05:19:35.017
STEP: deleting the test service 04/18/23 05:19:35.426
STEP: deleting the test headless service 04/18/23 05:19:35.687
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 05:19:35.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1570" for this suite. 04/18/23 05:19:35.75
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":191,"skipped":3561,"failed":0}
------------------------------
â€¢ [SLOW TEST] [37.759 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:18:58.077
    Apr 18 05:18:58.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename dns 04/18/23 05:18:58.078
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:18:58.256
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:18:58.259
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 04/18/23 05:18:58.262
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1570.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1570.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 129.3.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.3.129_udp@PTR;check="$$(dig +tcp +noall +answer +search 129.3.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.3.129_tcp@PTR;sleep 1; done
     04/18/23 05:18:58.456
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1570.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1570.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1570.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1570.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1570.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 129.3.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.3.129_udp@PTR;check="$$(dig +tcp +noall +answer +search 129.3.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.3.129_tcp@PTR;sleep 1; done
     04/18/23 05:18:58.456
    STEP: creating a pod to probe DNS 04/18/23 05:18:58.456
    STEP: submitting the pod to kubernetes 04/18/23 05:18:58.456
    Apr 18 05:18:58.608: INFO: Waiting up to 15m0s for pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220" in namespace "dns-1570" to be "running"
    Apr 18 05:18:58.654: INFO: Pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220": Phase="Pending", Reason="", readiness=false. Elapsed: 46.315077ms
    Apr 18 05:19:00.665: INFO: Pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057116572s
    Apr 18 05:19:02.682: INFO: Pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074427346s
    Apr 18 05:19:04.665: INFO: Pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220": Phase="Running", Reason="", readiness=true. Elapsed: 6.057687457s
    Apr 18 05:19:04.665: INFO: Pod "dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 05:19:04.665
    STEP: looking for the results for each expected name from probers 04/18/23 05:19:04.705
    Apr 18 05:19:04.709: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:04.713: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:04.737: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:04.740: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:04.756: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:04.759: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:04.762: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:04.765: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:04.846: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

    Apr 18 05:19:09.888: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:09.924: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:09.928: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:09.931: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:09.946: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:09.949: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:09.956: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:09.960: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:09.973: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

    Apr 18 05:19:14.864: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:14.868: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:14.872: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:14.875: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:14.892: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:14.895: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:14.898: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:14.901: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:14.917: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

    Apr 18 05:19:19.906: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:19.909: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:19.913: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:19.916: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:19.974: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:19.977: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:19.980: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:19.983: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:19.997: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

    Apr 18 05:19:24.854: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:24.858: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:24.861: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:24.865: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:24.881: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:24.885: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:24.888: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:24.891: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:24.904: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

    Apr 18 05:19:29.850: INFO: Unable to read wheezy_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:29.854: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:29.858: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:29.861: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:29.877: INFO: Unable to read jessie_udp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:29.880: INFO: Unable to read jessie_tcp@dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:29.884: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:29.887: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local from pod dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220: the server could not find the requested resource (get pods dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220)
    Apr 18 05:19:29.899: INFO: Lookups using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 failed for: [wheezy_udp@dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@dns-test-service.dns-1570.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_udp@dns-test-service.dns-1570.svc.cluster.local jessie_tcp@dns-test-service.dns-1570.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1570.svc.cluster.local]

    Apr 18 05:19:35.017: INFO: DNS probes using dns-1570/dns-test-e4aca1c5-ddf4-4105-a05b-d5a099d4a220 succeeded

    STEP: deleting the pod 04/18/23 05:19:35.017
    STEP: deleting the test service 04/18/23 05:19:35.426
    STEP: deleting the test headless service 04/18/23 05:19:35.687
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 05:19:35.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1570" for this suite. 04/18/23 05:19:35.75
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:19:35.837
Apr 18 05:19:35.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename watch 04/18/23 05:19:35.838
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:19:35.969
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:19:35.972
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 04/18/23 05:19:36.045
STEP: modifying the configmap once 04/18/23 05:19:36.098
STEP: modifying the configmap a second time 04/18/23 05:19:36.114
STEP: deleting the configmap 04/18/23 05:19:36.347
STEP: creating a watch on configmaps from the resource version returned by the first update 04/18/23 05:19:36.395
STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/18/23 05:19:36.396
Apr 18 05:19:36.396: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8859  2a44ccae-fc0e-468c-91e3-a40dc4fd3493 4110010 0 2023-04-18 05:19:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-18 05:19:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:19:36.396: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8859  2a44ccae-fc0e-468c-91e3-a40dc4fd3493 4110011 0 2023-04-18 05:19:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-18 05:19:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 18 05:19:36.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8859" for this suite. 04/18/23 05:19:36.401
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":192,"skipped":3568,"failed":0}
------------------------------
â€¢ [0.586 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:19:35.837
    Apr 18 05:19:35.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename watch 04/18/23 05:19:35.838
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:19:35.969
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:19:35.972
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 04/18/23 05:19:36.045
    STEP: modifying the configmap once 04/18/23 05:19:36.098
    STEP: modifying the configmap a second time 04/18/23 05:19:36.114
    STEP: deleting the configmap 04/18/23 05:19:36.347
    STEP: creating a watch on configmaps from the resource version returned by the first update 04/18/23 05:19:36.395
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/18/23 05:19:36.396
    Apr 18 05:19:36.396: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8859  2a44ccae-fc0e-468c-91e3-a40dc4fd3493 4110010 0 2023-04-18 05:19:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-18 05:19:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:19:36.396: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8859  2a44ccae-fc0e-468c-91e3-a40dc4fd3493 4110011 0 2023-04-18 05:19:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-04-18 05:19:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 18 05:19:36.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8859" for this suite. 04/18/23 05:19:36.401
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:19:36.423
Apr 18 05:19:36.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sched-preemption 04/18/23 05:19:36.424
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:19:36.631
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:19:36.634
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 18 05:19:36.775: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 05:20:36.836: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 04/18/23 05:20:36.839
Apr 18 05:20:36.889: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 18 05:20:37.001: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 18 05:20:37.098: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 18 05:20:37.231: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 18 05:20:37.528: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 18 05:20:37.787: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/18/23 05:20:37.787
Apr 18 05:20:37.787: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-5692" to be "running"
Apr 18 05:20:37.822: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 35.097768ms
Apr 18 05:20:39.917: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.129742722s
Apr 18 05:20:42.301: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.513460352s
Apr 18 05:20:43.878: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.090708424s
Apr 18 05:20:43.878: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 18 05:20:43.878: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-5692" to be "running"
Apr 18 05:20:43.882: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.55911ms
Apr 18 05:20:43.882: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 05:20:43.882: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-5692" to be "running"
Apr 18 05:20:43.885: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.04972ms
Apr 18 05:20:43.885: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 05:20:43.885: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-5692" to be "running"
Apr 18 05:20:43.888: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.13014ms
Apr 18 05:20:43.888: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 05:20:43.888: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-5692" to be "running"
Apr 18 05:20:43.891: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.745491ms
Apr 18 05:20:43.891: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 18 05:20:43.891: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-5692" to be "running"
Apr 18 05:20:43.893: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.547897ms
Apr 18 05:20:43.893: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/18/23 05:20:43.893
Apr 18 05:20:43.916: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-5692" to be "running"
Apr 18 05:20:43.971: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 54.899053ms
Apr 18 05:20:45.976: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060048825s
Apr 18 05:20:47.975: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059878961s
Apr 18 05:20:49.976: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.06086269s
Apr 18 05:20:49.977: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:20:49.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-5692" for this suite. 04/18/23 05:20:50.001
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":193,"skipped":3584,"failed":0}
------------------------------
â€¢ [SLOW TEST] [73.919 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:19:36.423
    Apr 18 05:19:36.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sched-preemption 04/18/23 05:19:36.424
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:19:36.631
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:19:36.634
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 18 05:19:36.775: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 05:20:36.836: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 04/18/23 05:20:36.839
    Apr 18 05:20:36.889: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 18 05:20:37.001: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 18 05:20:37.098: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 18 05:20:37.231: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Apr 18 05:20:37.528: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Apr 18 05:20:37.787: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/18/23 05:20:37.787
    Apr 18 05:20:37.787: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-5692" to be "running"
    Apr 18 05:20:37.822: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 35.097768ms
    Apr 18 05:20:39.917: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.129742722s
    Apr 18 05:20:42.301: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.513460352s
    Apr 18 05:20:43.878: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.090708424s
    Apr 18 05:20:43.878: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 18 05:20:43.878: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-5692" to be "running"
    Apr 18 05:20:43.882: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.55911ms
    Apr 18 05:20:43.882: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 05:20:43.882: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-5692" to be "running"
    Apr 18 05:20:43.885: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.04972ms
    Apr 18 05:20:43.885: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 05:20:43.885: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-5692" to be "running"
    Apr 18 05:20:43.888: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.13014ms
    Apr 18 05:20:43.888: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 05:20:43.888: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-5692" to be "running"
    Apr 18 05:20:43.891: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.745491ms
    Apr 18 05:20:43.891: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 18 05:20:43.891: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-5692" to be "running"
    Apr 18 05:20:43.893: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.547897ms
    Apr 18 05:20:43.893: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/18/23 05:20:43.893
    Apr 18 05:20:43.916: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-5692" to be "running"
    Apr 18 05:20:43.971: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 54.899053ms
    Apr 18 05:20:45.976: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060048825s
    Apr 18 05:20:47.975: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059878961s
    Apr 18 05:20:49.976: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.06086269s
    Apr 18 05:20:49.977: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:20:49.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-5692" for this suite. 04/18/23 05:20:50.001
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:20:50.343
Apr 18 05:20:50.343: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 05:20:50.344
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:20:50.511
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:20:50.514
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 04/18/23 05:20:50.516
Apr 18 05:20:50.517: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-413 proxy --unix-socket=/tmp/kubectl-proxy-unix1911243360/test'
STEP: retrieving proxy /api/ output 04/18/23 05:20:50.573
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 05:20:50.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-413" for this suite. 04/18/23 05:20:50.579
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":194,"skipped":3589,"failed":0}
------------------------------
â€¢ [0.294 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:20:50.343
    Apr 18 05:20:50.343: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 05:20:50.344
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:20:50.511
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:20:50.514
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 04/18/23 05:20:50.516
    Apr 18 05:20:50.517: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-413 proxy --unix-socket=/tmp/kubectl-proxy-unix1911243360/test'
    STEP: retrieving proxy /api/ output 04/18/23 05:20:50.573
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 05:20:50.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-413" for this suite. 04/18/23 05:20:50.579
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:20:50.639
Apr 18 05:20:50.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename disruption 04/18/23 05:20:50.64
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:20:50.71
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:20:50.713
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 04/18/23 05:20:50.716
STEP: Waiting for the pdb to be processed 04/18/23 05:20:50.828
STEP: updating the pdb 04/18/23 05:20:52.836
STEP: Waiting for the pdb to be processed 04/18/23 05:20:52.869
STEP: patching the pdb 04/18/23 05:20:54.885
STEP: Waiting for the pdb to be processed 04/18/23 05:20:54.914
STEP: Waiting for the pdb to be deleted 04/18/23 05:20:57.001
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 18 05:20:57.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6255" for this suite. 04/18/23 05:20:57.179
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":195,"skipped":3637,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.642 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:20:50.639
    Apr 18 05:20:50.639: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename disruption 04/18/23 05:20:50.64
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:20:50.71
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:20:50.713
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 04/18/23 05:20:50.716
    STEP: Waiting for the pdb to be processed 04/18/23 05:20:50.828
    STEP: updating the pdb 04/18/23 05:20:52.836
    STEP: Waiting for the pdb to be processed 04/18/23 05:20:52.869
    STEP: patching the pdb 04/18/23 05:20:54.885
    STEP: Waiting for the pdb to be processed 04/18/23 05:20:54.914
    STEP: Waiting for the pdb to be deleted 04/18/23 05:20:57.001
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 18 05:20:57.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6255" for this suite. 04/18/23 05:20:57.179
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:20:57.281
Apr 18 05:20:57.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 05:20:57.282
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:20:57.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:20:57.759
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Apr 18 05:20:57.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 05:21:11.968
Apr 18 05:21:11.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-1847 --namespace=crd-publish-openapi-1847 create -f -'
Apr 18 05:21:13.518: INFO: stderr: ""
Apr 18 05:21:13.518: INFO: stdout: "e2e-test-crd-publish-openapi-6747-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 18 05:21:13.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-1847 --namespace=crd-publish-openapi-1847 delete e2e-test-crd-publish-openapi-6747-crds test-cr'
Apr 18 05:21:13.655: INFO: stderr: ""
Apr 18 05:21:13.655: INFO: stdout: "e2e-test-crd-publish-openapi-6747-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 18 05:21:13.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-1847 --namespace=crd-publish-openapi-1847 apply -f -'
Apr 18 05:21:15.128: INFO: stderr: ""
Apr 18 05:21:15.128: INFO: stdout: "e2e-test-crd-publish-openapi-6747-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 18 05:21:15.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-1847 --namespace=crd-publish-openapi-1847 delete e2e-test-crd-publish-openapi-6747-crds test-cr'
Apr 18 05:21:15.266: INFO: stderr: ""
Apr 18 05:21:15.267: INFO: stdout: "e2e-test-crd-publish-openapi-6747-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 04/18/23 05:21:15.267
Apr 18 05:21:15.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-1847 explain e2e-test-crd-publish-openapi-6747-crds'
Apr 18 05:21:16.664: INFO: stderr: ""
Apr 18 05:21:16.664: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6747-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:21:25.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1847" for this suite. 04/18/23 05:21:25.786
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":196,"skipped":3640,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.526 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:20:57.281
    Apr 18 05:20:57.282: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 05:20:57.282
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:20:57.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:20:57.759
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Apr 18 05:20:57.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 05:21:11.968
    Apr 18 05:21:11.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-1847 --namespace=crd-publish-openapi-1847 create -f -'
    Apr 18 05:21:13.518: INFO: stderr: ""
    Apr 18 05:21:13.518: INFO: stdout: "e2e-test-crd-publish-openapi-6747-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 18 05:21:13.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-1847 --namespace=crd-publish-openapi-1847 delete e2e-test-crd-publish-openapi-6747-crds test-cr'
    Apr 18 05:21:13.655: INFO: stderr: ""
    Apr 18 05:21:13.655: INFO: stdout: "e2e-test-crd-publish-openapi-6747-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Apr 18 05:21:13.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-1847 --namespace=crd-publish-openapi-1847 apply -f -'
    Apr 18 05:21:15.128: INFO: stderr: ""
    Apr 18 05:21:15.128: INFO: stdout: "e2e-test-crd-publish-openapi-6747-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 18 05:21:15.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-1847 --namespace=crd-publish-openapi-1847 delete e2e-test-crd-publish-openapi-6747-crds test-cr'
    Apr 18 05:21:15.266: INFO: stderr: ""
    Apr 18 05:21:15.267: INFO: stdout: "e2e-test-crd-publish-openapi-6747-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 04/18/23 05:21:15.267
    Apr 18 05:21:15.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-1847 explain e2e-test-crd-publish-openapi-6747-crds'
    Apr 18 05:21:16.664: INFO: stderr: ""
    Apr 18 05:21:16.664: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6747-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:21:25.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1847" for this suite. 04/18/23 05:21:25.786
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:21:25.808
Apr 18 05:21:25.808: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 05:21:25.809
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:21:25.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:21:25.868
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-806 04/18/23 05:21:25.925
STEP: creating service affinity-clusterip in namespace services-806 04/18/23 05:21:25.925
STEP: creating replication controller affinity-clusterip in namespace services-806 04/18/23 05:21:26
I0418 05:21:26.072391      22 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-806, replica count: 3
I0418 05:21:29.123238      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 05:21:32.125207      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 05:21:32.173: INFO: Creating new exec pod
Apr 18 05:21:32.223: INFO: Waiting up to 5m0s for pod "execpod-affinitywmtrj" in namespace "services-806" to be "running"
Apr 18 05:21:32.245: INFO: Pod "execpod-affinitywmtrj": Phase="Pending", Reason="", readiness=false. Elapsed: 21.60587ms
Apr 18 05:21:34.249: INFO: Pod "execpod-affinitywmtrj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025923277s
Apr 18 05:21:36.249: INFO: Pod "execpod-affinitywmtrj": Phase="Running", Reason="", readiness=true. Elapsed: 4.02587888s
Apr 18 05:21:36.249: INFO: Pod "execpod-affinitywmtrj" satisfied condition "running"
Apr 18 05:21:37.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-806 exec execpod-affinitywmtrj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Apr 18 05:21:37.428: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Apr 18 05:21:37.428: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:21:37.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-806 exec execpod-affinitywmtrj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.5.141 80'
Apr 18 05:21:37.594: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.5.141 80\nConnection to 10.96.5.141 80 port [tcp/http] succeeded!\n"
Apr 18 05:21:37.594: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:21:37.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-806 exec execpod-affinitywmtrj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.5.141:80/ ; done'
Apr 18 05:21:37.815: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n"
Apr 18 05:21:37.815: INFO: stdout: "\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k"
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
Apr 18 05:21:37.815: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-806, will wait for the garbage collector to delete the pods 04/18/23 05:21:38.187
Apr 18 05:21:38.306: INFO: Deleting ReplicationController affinity-clusterip took: 64.905122ms
Apr 18 05:21:38.608: INFO: Terminating ReplicationController affinity-clusterip pods took: 301.17395ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 05:21:41.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-806" for this suite. 04/18/23 05:21:41.915
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":197,"skipped":3645,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.334 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:21:25.808
    Apr 18 05:21:25.808: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 05:21:25.809
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:21:25.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:21:25.868
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-806 04/18/23 05:21:25.925
    STEP: creating service affinity-clusterip in namespace services-806 04/18/23 05:21:25.925
    STEP: creating replication controller affinity-clusterip in namespace services-806 04/18/23 05:21:26
    I0418 05:21:26.072391      22 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-806, replica count: 3
    I0418 05:21:29.123238      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 05:21:32.125207      22 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 05:21:32.173: INFO: Creating new exec pod
    Apr 18 05:21:32.223: INFO: Waiting up to 5m0s for pod "execpod-affinitywmtrj" in namespace "services-806" to be "running"
    Apr 18 05:21:32.245: INFO: Pod "execpod-affinitywmtrj": Phase="Pending", Reason="", readiness=false. Elapsed: 21.60587ms
    Apr 18 05:21:34.249: INFO: Pod "execpod-affinitywmtrj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025923277s
    Apr 18 05:21:36.249: INFO: Pod "execpod-affinitywmtrj": Phase="Running", Reason="", readiness=true. Elapsed: 4.02587888s
    Apr 18 05:21:36.249: INFO: Pod "execpod-affinitywmtrj" satisfied condition "running"
    Apr 18 05:21:37.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-806 exec execpod-affinitywmtrj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Apr 18 05:21:37.428: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Apr 18 05:21:37.428: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:21:37.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-806 exec execpod-affinitywmtrj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.5.141 80'
    Apr 18 05:21:37.594: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.5.141 80\nConnection to 10.96.5.141 80 port [tcp/http] succeeded!\n"
    Apr 18 05:21:37.594: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:21:37.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-806 exec execpod-affinitywmtrj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.96.5.141:80/ ; done'
    Apr 18 05:21:37.815: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.96.5.141:80/\n"
    Apr 18 05:21:37.815: INFO: stdout: "\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k\naffinity-clusterip-nrk5k"
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Received response from host: affinity-clusterip-nrk5k
    Apr 18 05:21:37.815: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-806, will wait for the garbage collector to delete the pods 04/18/23 05:21:38.187
    Apr 18 05:21:38.306: INFO: Deleting ReplicationController affinity-clusterip took: 64.905122ms
    Apr 18 05:21:38.608: INFO: Terminating ReplicationController affinity-clusterip pods took: 301.17395ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 05:21:41.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-806" for this suite. 04/18/23 05:21:41.915
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:21:42.143
Apr 18 05:21:42.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sched-pred 04/18/23 05:21:42.144
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:21:43.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:21:43.012
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 18 05:21:43.014: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 18 05:21:43.024: INFO: Waiting for terminating namespaces to be deleted...
Apr 18 05:21:43.062: INFO: 
Logging pods the apiserver thinks is on node apps-207 before test
Apr 18 05:21:43.107: INFO: addon-manager-5d75c94878-q9nwx from cocktail-addon started at 2023-04-14 07:23:24 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container addon-manager ready: true, restart count 1
Apr 18 05:21:43.107: INFO: agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w from cocktail-addon started at 2023-04-14 07:27:45 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container alarm-agent ready: true, restart count 0
Apr 18 05:21:43.107: INFO: alertmanager-monitoring-kube-prometheus-alertmanager-0 from cocktail-addon started at 2023-04-14 07:24:51 +0000 UTC (2 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container alertmanager ready: true, restart count 1
Apr 18 05:21:43.107: INFO: 	Container config-reloader ready: true, restart count 0
Apr 18 05:21:43.107: INFO: monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container kube-prometheus-stack ready: true, restart count 0
Apr 18 05:21:43.107: INFO: monitoring-kube-state-metrics-7dddf6695f-l8mlh from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container kube-state-metrics ready: true, restart count 0
Apr 18 05:21:43.107: INFO: monitoring-prometheus-node-exporter-d9xr5 from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 05:21:43.107: INFO: prometheus-monitoring-kube-prometheus-prometheus-0 from cocktail-addon started at 2023-04-14 11:20:12 +0000 UTC (2 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container config-reloader ready: true, restart count 0
Apr 18 05:21:43.107: INFO: 	Container prometheus ready: true, restart count 0
Apr 18 05:21:43.107: INFO: promtail-fjjqt from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container promtail ready: true, restart count 0
Apr 18 05:21:43.107: INFO: cocktail-api-gateway-648577694-g7lzt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container gateway ready: true, restart count 4
Apr 18 05:21:43.107: INFO: cocktail-batch-server-5895cd6748-x5qsz from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container batch ready: true, restart count 0
Apr 18 05:21:43.107: INFO: cocktail-build-api-5d65b8dd6-8tb9g from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container build-api ready: true, restart count 0
Apr 18 05:21:43.107: INFO: cocktail-build-queue-7855f6f4dd-vsc6p from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container nats-streaming ready: true, restart count 0
Apr 18 05:21:43.107: INFO: cocktail-cluster-api-6b5df5884f-4nbvz from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container cluster-api ready: true, restart count 2
Apr 18 05:21:43.107: INFO: cocktail-dashboard-86844bcfbd-wbnzx from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container dashboard ready: true, restart count 0
Apr 18 05:21:43.107: INFO: cocktail-dashboard-proxy-5476f6847-ptzhj from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container dashboard-proxy ready: true, restart count 0
Apr 18 05:21:43.107: INFO: cocktail-dashboard-queue-5745c9f74c-2gks8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container dashboard-queue ready: true, restart count 0
Apr 18 05:21:43.107: INFO: cocktail-dashboard-session-9d746547b-gk8d5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container dashboard-session ready: true, restart count 0
Apr 18 05:21:43.107: INFO: cocktail-monitoring-metric-collector-5695cb8669-mktvm from cocktail-system started at 2023-04-14 11:19:55 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container collector ready: true, restart count 4
Apr 18 05:21:43.107: INFO: calico-kube-controllers-74677b4c5f-rjqrf from kube-system started at 2023-04-11 08:28:10 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 18 05:21:43.107: INFO: calico-node-nmmjb from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 05:21:43.107: INFO: coredns-7ffbbc99d-5xc7c from kube-system started at 2023-04-11 08:28:13 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container coredns ready: true, restart count 0
Apr 18 05:21:43.107: INFO: csi-nfs-node-w5rjr from kube-system started at 2023-04-11 08:28:52 +0000 UTC (4 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:21:43.107: INFO: 	Container metrics ready: true, restart count 0
Apr 18 05:21:43.107: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:21:43.107: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 05:21:43.107: INFO: kube-apiserver-apps-207 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 05:21:43.107: INFO: kube-controller-manager-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.107: INFO: 	Container kube-controller-manager ready: true, restart count 1
Apr 18 05:21:43.107: INFO: kube-proxy-clw95 from kube-system started at 2023-04-11 08:28:27 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.108: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 05:21:43.108: INFO: kube-scheduler-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.108: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 18 05:21:43.108: INFO: metrics-server-7b879bf57b-vfp7l from kube-system started at 2023-04-13 06:15:39 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.108: INFO: 	Container metrics-server ready: true, restart count 0
Apr 18 05:21:43.108: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:21:43.108: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:21:43.108: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 05:21:43.108: INFO: 
Logging pods the apiserver thinks is on node apps-208 before test
Apr 18 05:21:43.147: INFO: monitoring-prometheus-node-exporter-x99mx from cocktail-addon started at 2023-04-18 04:30:51 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 05:21:43.147: INFO: nginx-ingress-nginx-controller-865cbc698d-sqwlm from cocktail-addon started at 2023-04-18 04:30:49 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container controller ready: true, restart count 0
Apr 18 05:21:43.147: INFO: nginx-ingress-nginx-defaultbackend-649fd8955b-wk6kv from cocktail-addon started at 2023-04-18 04:30:48 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container ingress-nginx-default-backend ready: true, restart count 0
Apr 18 05:21:43.147: INFO: promtail-c9qhr from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container promtail ready: true, restart count 0
Apr 18 05:21:43.147: INFO: calico-node-jstls from kube-system started at 2023-04-11 08:28:11 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 05:21:43.147: INFO: csi-nfs-node-t4zm5 from kube-system started at 2023-04-11 08:28:48 +0000 UTC (4 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:21:43.147: INFO: 	Container metrics ready: true, restart count 0
Apr 18 05:21:43.147: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:21:43.147: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 05:21:43.147: INFO: kube-apiserver-apps-208 from kube-system started at 2023-04-11 08:26:44 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 05:21:43.147: INFO: kube-controller-manager-apps-208 from kube-system started at 2023-04-05 06:51:47 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container kube-controller-manager ready: true, restart count 0
Apr 18 05:21:43.147: INFO: kube-proxy-vb944 from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 05:21:43.147: INFO: kube-scheduler-apps-208 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container kube-scheduler ready: true, restart count 0
Apr 18 05:21:43.147: INFO: sonobuoy from sonobuoy started at 2023-04-18 04:01:18 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 18 05:21:43.147: INFO: sonobuoy-e2e-job-5f413cbb3b804c34 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container e2e ready: true, restart count 0
Apr 18 05:21:43.147: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:21:43.147: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-lzt9z from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:21:43.147: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:21:43.147: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 18 05:21:43.147: INFO: 
Logging pods the apiserver thinks is on node apps-209 before test
Apr 18 05:21:43.170: INFO: agent-mdi1zj-1-event-agent-757455b86f-jzfp7 from cocktail-addon started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container event-agent ready: true, restart count 0
Apr 18 05:21:43.170: INFO: agent-mdi1zj-1-metric-agent-0 from cocktail-addon started at 2023-04-14 07:27:47 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container metric-agent ready: true, restart count 6
Apr 18 05:21:43.170: INFO: monitoring-extension-event-exporter-57bc857b7b-d2kgh from cocktail-addon started at 2023-04-14 07:26:55 +0000 UTC (2 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container caddy ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container event-exporter ready: true, restart count 0
Apr 18 05:21:43.170: INFO: monitoring-prometheus-node-exporter-tx7km from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container node-exporter ready: true, restart count 0
Apr 18 05:21:43.170: INFO: promtail-bgwzf from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container promtail ready: true, restart count 0
Apr 18 05:21:43.170: INFO: cocktail-api-cmdb-0 from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container api-cmdb ready: true, restart count 0
Apr 18 05:21:43.170: INFO: cocktail-api-server-5d47cb7fdd-5ptrt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container api-server ready: true, restart count 1
Apr 18 05:21:43.170: INFO: cocktail-log-api-6c69c456db-j8gr8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container api ready: true, restart count 0
Apr 18 05:21:43.170: INFO: cocktail-log-loki-0 from cocktail-system started at 2023-04-14 07:04:56 +0000 UTC (2 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container loki ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container tls-proxy ready: true, restart count 0
Apr 18 05:21:43.170: INFO: cocktail-monitoring-76bdf6974f-p5hs8 from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container monitoring ready: true, restart count 3
Apr 18 05:21:43.170: INFO: cocktail-monitoring-alarm-collector-78448f5d-gbmcs from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container collector ready: true, restart count 6
Apr 18 05:21:43.170: INFO: cocktail-monitoring-event-collector-7fd78d476d-9pw9f from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container collector ready: true, restart count 7
Apr 18 05:21:43.170: INFO: cocktail-monitoring-monitoring-db-0 from cocktail-system started at 2023-04-14 11:20:11 +0000 UTC (2 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container db ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container log-lotate ready: true, restart count 0
Apr 18 05:21:43.170: INFO: cocktail-monitoring-proxy-648c665797-jd2fs from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container monitoring-proxy ready: true, restart count 0
Apr 18 05:21:43.170: INFO: cocktail-mq-entity-operator-7964999574-5zzkb from cocktail-system started at 2023-04-14 07:07:37 +0000 UTC (3 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container tls-sidecar ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container topic-operator ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container user-operator ready: true, restart count 0
Apr 18 05:21:43.170: INFO: cocktail-mq-kafka-0 from cocktail-system started at 2023-04-14 07:08:16 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container kafka ready: true, restart count 0
Apr 18 05:21:43.170: INFO: cocktail-mq-zookeeper-0 from cocktail-system started at 2023-04-14 07:05:54 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container zookeeper ready: true, restart count 0
Apr 18 05:21:43.170: INFO: cocktail-package-5f59d96bd8-d2nj5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container package ready: true, restart count 1
Apr 18 05:21:43.170: INFO: strimzi-cluster-operator-668f4bff5c-zqqjr from cocktail-system started at 2023-04-14 11:05:05 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container strimzi-cluster-operator ready: true, restart count 0
Apr 18 05:21:43.170: INFO: calico-node-q6mxd from kube-system started at 2023-04-11 08:28:12 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container calico-node ready: true, restart count 0
Apr 18 05:21:43.170: INFO: coredns-7ffbbc99d-mkf8k from kube-system started at 2023-04-14 11:05:04 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container coredns ready: true, restart count 0
Apr 18 05:21:43.170: INFO: csi-nfs-controller-7ccd7c4947-dw42l from kube-system started at 2023-04-14 11:05:06 +0000 UTC (3 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container csi-provisioner ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:21:43.170: INFO: csi-nfs-node-nh5wf from kube-system started at 2023-04-11 08:28:49 +0000 UTC (4 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container liveness-probe ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container metrics ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container nfs ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container node-driver-registrar ready: true, restart count 0
Apr 18 05:21:43.170: INFO: kube-apiserver-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container kube-apiserver ready: true, restart count 0
Apr 18 05:21:43.170: INFO: kube-controller-manager-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container kube-controller-manager ready: true, restart count 1
Apr 18 05:21:43.170: INFO: kube-proxy-vmwrf from kube-system started at 2023-04-11 08:28:28 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 18 05:21:43.170: INFO: kube-scheduler-apps-209 from kube-system started at 2023-04-07 08:18:47 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container kube-scheduler ready: true, restart count 1
Apr 18 05:21:43.170: INFO: metrics-server-7b879bf57b-6vnbg from kube-system started at 2023-04-13 06:15:03 +0000 UTC (1 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container metrics-server ready: true, restart count 0
Apr 18 05:21:43.170: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-j4n44 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
Apr 18 05:21:43.170: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 18 05:21:43.170: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 05:21:43.17
Apr 18 05:21:43.258: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2550" to be "running"
Apr 18 05:21:43.262: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.372662ms
Apr 18 05:21:45.267: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007996166s
Apr 18 05:21:47.275: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.016796348s
Apr 18 05:21:47.275: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 05:21:47.28
STEP: Trying to apply a random label on the found node. 04/18/23 05:21:47.423
STEP: verifying the node has the label kubernetes.io/e2e-1550e638-6216-4c56-9532-1c1f589da115 95 04/18/23 05:21:47.596
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/18/23 05:21:47.658
Apr 18 05:21:47.709: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-2550" to be "not pending"
Apr 18 05:21:47.826: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 117.247568ms
Apr 18 05:21:49.831: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12193793s
Apr 18 05:21:51.830: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12085131s
Apr 18 05:21:53.832: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 6.123206993s
Apr 18 05:21:53.832: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.2.108 on the node which pod4 resides and expect not scheduled 04/18/23 05:21:53.832
Apr 18 05:21:53.866: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-2550" to be "not pending"
Apr 18 05:21:53.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.200717ms
Apr 18 05:21:55.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007322684s
Apr 18 05:21:57.896: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029309818s
Apr 18 05:21:59.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008632652s
Apr 18 05:22:01.877: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010911608s
Apr 18 05:22:03.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007854572s
Apr 18 05:22:05.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.007688694s
Apr 18 05:22:07.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007728355s
Apr 18 05:22:09.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.00860432s
Apr 18 05:22:11.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.007541675s
Apr 18 05:22:13.904: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.037814321s
Apr 18 05:22:15.877: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.010575647s
Apr 18 05:22:17.880: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.013115131s
Apr 18 05:22:19.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.009700507s
Apr 18 05:22:21.937: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.070521976s
Apr 18 05:22:23.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.00738991s
Apr 18 05:22:25.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.007636275s
Apr 18 05:22:27.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.007982109s
Apr 18 05:22:29.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.008091549s
Apr 18 05:22:31.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.006910158s
Apr 18 05:22:33.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.008756389s
Apr 18 05:22:35.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.007956768s
Apr 18 05:22:37.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.008353187s
Apr 18 05:22:39.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.009479831s
Apr 18 05:22:41.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.007714696s
Apr 18 05:22:43.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.008073911s
Apr 18 05:22:45.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.007393124s
Apr 18 05:22:47.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.008143815s
Apr 18 05:22:49.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.006712921s
Apr 18 05:22:51.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.007515869s
Apr 18 05:22:53.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.008061695s
Apr 18 05:22:55.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.007222079s
Apr 18 05:22:57.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.009868408s
Apr 18 05:22:59.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.009196025s
Apr 18 05:23:01.890: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.023965871s
Apr 18 05:23:03.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.008957688s
Apr 18 05:23:05.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.009197368s
Apr 18 05:23:07.878: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.011765587s
Apr 18 05:23:09.893: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.026391934s
Apr 18 05:23:11.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.007209176s
Apr 18 05:23:13.885: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.018284835s
Apr 18 05:23:15.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.008926521s
Apr 18 05:23:17.916: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.049819078s
Apr 18 05:23:19.884: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.017979226s
Apr 18 05:23:21.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.00806759s
Apr 18 05:23:23.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.008664252s
Apr 18 05:23:25.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.007070699s
Apr 18 05:23:27.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.007696065s
Apr 18 05:23:29.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.007853171s
Apr 18 05:23:31.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.007556268s
Apr 18 05:23:33.894: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.027162522s
Apr 18 05:23:35.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.007763548s
Apr 18 05:23:37.983: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.116217698s
Apr 18 05:23:39.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.008551361s
Apr 18 05:23:41.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.007469613s
Apr 18 05:23:43.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.008003866s
Apr 18 05:23:45.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.009137438s
Apr 18 05:23:47.894: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.027118912s
Apr 18 05:23:49.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.007969407s
Apr 18 05:23:51.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.007660443s
Apr 18 05:23:53.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.008578194s
Apr 18 05:23:55.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.006983537s
Apr 18 05:23:57.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.008446775s
Apr 18 05:23:59.909: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.042140419s
Apr 18 05:24:01.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.00962772s
Apr 18 05:24:03.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.008370655s
Apr 18 05:24:05.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.007150634s
Apr 18 05:24:07.913: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.046506559s
Apr 18 05:24:09.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.007813434s
Apr 18 05:24:11.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.007548508s
Apr 18 05:24:13.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.007075305s
Apr 18 05:24:15.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.007875986s
Apr 18 05:24:17.905: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.038907294s
Apr 18 05:24:19.931: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.064237511s
Apr 18 05:24:21.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.006887621s
Apr 18 05:24:23.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.007630609s
Apr 18 05:24:25.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.007702072s
Apr 18 05:24:27.889: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.022071545s
Apr 18 05:24:29.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.008308223s
Apr 18 05:24:31.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.007534079s
Apr 18 05:24:33.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.008578328s
Apr 18 05:24:35.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.006919112s
Apr 18 05:24:37.911: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.044783529s
Apr 18 05:24:39.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.009679726s
Apr 18 05:24:41.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.007128577s
Apr 18 05:24:43.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.0073006s
Apr 18 05:24:45.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.007058722s
Apr 18 05:24:47.926: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.059057472s
Apr 18 05:24:49.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.008897588s
Apr 18 05:24:51.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.007653526s
Apr 18 05:24:53.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.008719805s
Apr 18 05:24:55.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.007610892s
Apr 18 05:24:57.883: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.016761398s
Apr 18 05:24:59.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.008987476s
Apr 18 05:25:01.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.007471672s
Apr 18 05:25:03.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.008440757s
Apr 18 05:25:05.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.007480396s
Apr 18 05:25:07.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.007919676s
Apr 18 05:25:09.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.008079705s
Apr 18 05:25:11.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.006733359s
Apr 18 05:25:13.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.008200739s
Apr 18 05:25:15.916: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.049640794s
Apr 18 05:25:17.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.009071915s
Apr 18 05:25:19.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.008368117s
Apr 18 05:25:21.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.006998444s
Apr 18 05:25:23.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.008991974s
Apr 18 05:25:25.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.008399552s
Apr 18 05:25:27.908: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.041190707s
Apr 18 05:25:29.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.009140491s
Apr 18 05:25:31.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.007071067s
Apr 18 05:25:33.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.00833873s
Apr 18 05:25:35.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.008249696s
Apr 18 05:25:37.904: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.037778237s
Apr 18 05:25:39.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.007434815s
Apr 18 05:25:41.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.006807509s
Apr 18 05:25:43.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.008439445s
Apr 18 05:25:45.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.00723833s
Apr 18 05:25:47.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.008115511s
Apr 18 05:25:49.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.009200193s
Apr 18 05:25:51.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.007216756s
Apr 18 05:25:53.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.008093712s
Apr 18 05:25:55.915: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.048480461s
Apr 18 05:25:57.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.008025069s
Apr 18 05:25:59.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.00890637s
Apr 18 05:26:01.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.007136117s
Apr 18 05:26:03.901: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.0345385s
Apr 18 05:26:05.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.007548915s
Apr 18 05:26:07.896: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.029322013s
Apr 18 05:26:09.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.008641363s
Apr 18 05:26:11.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.006526722s
Apr 18 05:26:13.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.007719637s
Apr 18 05:26:15.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.007413872s
Apr 18 05:26:17.881: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.014771611s
Apr 18 05:26:19.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.008356296s
Apr 18 05:26:21.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.00799168s
Apr 18 05:26:23.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.008431129s
Apr 18 05:26:25.903: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.036169638s
Apr 18 05:26:27.886: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.01936934s
Apr 18 05:26:29.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.009602759s
Apr 18 05:26:31.884: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.017405576s
Apr 18 05:26:33.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.008382963s
Apr 18 05:26:35.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.007643365s
Apr 18 05:26:37.881: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.014561035s
Apr 18 05:26:39.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.007616912s
Apr 18 05:26:41.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.061303506s
Apr 18 05:26:43.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.007799007s
Apr 18 05:26:45.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.007425818s
Apr 18 05:26:47.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.007692821s
Apr 18 05:26:49.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.007203601s
Apr 18 05:26:51.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.007999191s
Apr 18 05:26:53.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.007990414s
Apr 18 05:26:53.877: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.010639698s
STEP: removing the label kubernetes.io/e2e-1550e638-6216-4c56-9532-1c1f589da115 off the node apps-208 04/18/23 05:26:53.877
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1550e638-6216-4c56-9532-1c1f589da115 04/18/23 05:26:53.918
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:26:53.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2550" for this suite. 04/18/23 05:26:53.926
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":198,"skipped":3652,"failed":0}
------------------------------
â€¢ [SLOW TEST] [311.804 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:21:42.143
    Apr 18 05:21:42.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sched-pred 04/18/23 05:21:42.144
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:21:43.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:21:43.012
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 18 05:21:43.014: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 18 05:21:43.024: INFO: Waiting for terminating namespaces to be deleted...
    Apr 18 05:21:43.062: INFO: 
    Logging pods the apiserver thinks is on node apps-207 before test
    Apr 18 05:21:43.107: INFO: addon-manager-5d75c94878-q9nwx from cocktail-addon started at 2023-04-14 07:23:24 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container addon-manager ready: true, restart count 1
    Apr 18 05:21:43.107: INFO: agent-mdi1zj-1-alarm-agent-86d84f85fc-nfr9w from cocktail-addon started at 2023-04-14 07:27:45 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container alarm-agent ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: alertmanager-monitoring-kube-prometheus-alertmanager-0 from cocktail-addon started at 2023-04-14 07:24:51 +0000 UTC (2 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container alertmanager ready: true, restart count 1
    Apr 18 05:21:43.107: INFO: 	Container config-reloader ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: monitoring-kube-prometheus-operator-7f6d85d6cb-s7zmj from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container kube-prometheus-stack ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: monitoring-kube-state-metrics-7dddf6695f-l8mlh from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: monitoring-prometheus-node-exporter-d9xr5 from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: prometheus-monitoring-kube-prometheus-prometheus-0 from cocktail-addon started at 2023-04-14 11:20:12 +0000 UTC (2 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container config-reloader ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: 	Container prometheus ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: promtail-fjjqt from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: cocktail-api-gateway-648577694-g7lzt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container gateway ready: true, restart count 4
    Apr 18 05:21:43.107: INFO: cocktail-batch-server-5895cd6748-x5qsz from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container batch ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: cocktail-build-api-5d65b8dd6-8tb9g from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container build-api ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: cocktail-build-queue-7855f6f4dd-vsc6p from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container nats-streaming ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: cocktail-cluster-api-6b5df5884f-4nbvz from cocktail-system started at 2023-04-14 07:05:18 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container cluster-api ready: true, restart count 2
    Apr 18 05:21:43.107: INFO: cocktail-dashboard-86844bcfbd-wbnzx from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container dashboard ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: cocktail-dashboard-proxy-5476f6847-ptzhj from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container dashboard-proxy ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: cocktail-dashboard-queue-5745c9f74c-2gks8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container dashboard-queue ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: cocktail-dashboard-session-9d746547b-gk8d5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container dashboard-session ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: cocktail-monitoring-metric-collector-5695cb8669-mktvm from cocktail-system started at 2023-04-14 11:19:55 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container collector ready: true, restart count 4
    Apr 18 05:21:43.107: INFO: calico-kube-controllers-74677b4c5f-rjqrf from kube-system started at 2023-04-11 08:28:10 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: calico-node-nmmjb from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: coredns-7ffbbc99d-5xc7c from kube-system started at 2023-04-11 08:28:13 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: csi-nfs-node-w5rjr from kube-system started at 2023-04-11 08:28:52 +0000 UTC (4 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: kube-apiserver-apps-207 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 05:21:43.107: INFO: kube-controller-manager-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.107: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Apr 18 05:21:43.107: INFO: kube-proxy-clw95 from kube-system started at 2023-04-11 08:28:27 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.108: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 05:21:43.108: INFO: kube-scheduler-apps-207 from kube-system started at 2023-04-05 06:51:50 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.108: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 18 05:21:43.108: INFO: metrics-server-7b879bf57b-vfp7l from kube-system started at 2023-04-13 06:15:39 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.108: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 18 05:21:43.108: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-xwstn from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:21:43.108: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:21:43.108: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 05:21:43.108: INFO: 
    Logging pods the apiserver thinks is on node apps-208 before test
    Apr 18 05:21:43.147: INFO: monitoring-prometheus-node-exporter-x99mx from cocktail-addon started at 2023-04-18 04:30:51 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: nginx-ingress-nginx-controller-865cbc698d-sqwlm from cocktail-addon started at 2023-04-18 04:30:49 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container controller ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: nginx-ingress-nginx-defaultbackend-649fd8955b-wk6kv from cocktail-addon started at 2023-04-18 04:30:48 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container ingress-nginx-default-backend ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: promtail-c9qhr from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: calico-node-jstls from kube-system started at 2023-04-11 08:28:11 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: csi-nfs-node-t4zm5 from kube-system started at 2023-04-11 08:28:48 +0000 UTC (4 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: kube-apiserver-apps-208 from kube-system started at 2023-04-11 08:26:44 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: kube-controller-manager-apps-208 from kube-system started at 2023-04-05 06:51:47 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container kube-controller-manager ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: kube-proxy-vb944 from kube-system started at 2023-04-11 08:28:30 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: kube-scheduler-apps-208 from kube-system started at 2023-04-05 06:52:12 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container kube-scheduler ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: sonobuoy from sonobuoy started at 2023-04-18 04:01:18 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: sonobuoy-e2e-job-5f413cbb3b804c34 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container e2e ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-lzt9z from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:21:43.147: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 18 05:21:43.147: INFO: 
    Logging pods the apiserver thinks is on node apps-209 before test
    Apr 18 05:21:43.170: INFO: agent-mdi1zj-1-event-agent-757455b86f-jzfp7 from cocktail-addon started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container event-agent ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: agent-mdi1zj-1-metric-agent-0 from cocktail-addon started at 2023-04-14 07:27:47 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container metric-agent ready: true, restart count 6
    Apr 18 05:21:43.170: INFO: monitoring-extension-event-exporter-57bc857b7b-d2kgh from cocktail-addon started at 2023-04-14 07:26:55 +0000 UTC (2 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container caddy ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container event-exporter ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: monitoring-prometheus-node-exporter-tx7km from cocktail-addon started at 2023-04-14 07:24:42 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: promtail-bgwzf from cocktail-addon started at 2023-04-14 07:31:25 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container promtail ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: cocktail-api-cmdb-0 from cocktail-system started at 2023-04-14 07:05:19 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container api-cmdb ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: cocktail-api-server-5d47cb7fdd-5ptrt from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container api-server ready: true, restart count 1
    Apr 18 05:21:43.170: INFO: cocktail-log-api-6c69c456db-j8gr8 from cocktail-system started at 2023-04-14 11:19:56 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container api ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: cocktail-log-loki-0 from cocktail-system started at 2023-04-14 07:04:56 +0000 UTC (2 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container loki ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container tls-proxy ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: cocktail-monitoring-76bdf6974f-p5hs8 from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container monitoring ready: true, restart count 3
    Apr 18 05:21:43.170: INFO: cocktail-monitoring-alarm-collector-78448f5d-gbmcs from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container collector ready: true, restart count 6
    Apr 18 05:21:43.170: INFO: cocktail-monitoring-event-collector-7fd78d476d-9pw9f from cocktail-system started at 2023-04-14 07:05:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container collector ready: true, restart count 7
    Apr 18 05:21:43.170: INFO: cocktail-monitoring-monitoring-db-0 from cocktail-system started at 2023-04-14 11:20:11 +0000 UTC (2 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container db ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container log-lotate ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: cocktail-monitoring-proxy-648c665797-jd2fs from cocktail-system started at 2023-04-14 11:05:07 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container monitoring-proxy ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: cocktail-mq-entity-operator-7964999574-5zzkb from cocktail-system started at 2023-04-14 07:07:37 +0000 UTC (3 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container tls-sidecar ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container topic-operator ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container user-operator ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: cocktail-mq-kafka-0 from cocktail-system started at 2023-04-14 07:08:16 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container kafka ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: cocktail-mq-zookeeper-0 from cocktail-system started at 2023-04-14 07:05:54 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container zookeeper ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: cocktail-package-5f59d96bd8-d2nj5 from cocktail-system started at 2023-04-14 07:05:17 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container package ready: true, restart count 1
    Apr 18 05:21:43.170: INFO: strimzi-cluster-operator-668f4bff5c-zqqjr from cocktail-system started at 2023-04-14 11:05:05 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container strimzi-cluster-operator ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: calico-node-q6mxd from kube-system started at 2023-04-11 08:28:12 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container calico-node ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: coredns-7ffbbc99d-mkf8k from kube-system started at 2023-04-14 11:05:04 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container coredns ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: csi-nfs-controller-7ccd7c4947-dw42l from kube-system started at 2023-04-14 11:05:06 +0000 UTC (3 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container csi-provisioner ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: csi-nfs-node-nh5wf from kube-system started at 2023-04-11 08:28:49 +0000 UTC (4 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container liveness-probe ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container metrics ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container nfs ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container node-driver-registrar ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: kube-apiserver-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container kube-apiserver ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: kube-controller-manager-apps-209 from kube-system started at 2023-04-07 08:18:48 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container kube-controller-manager ready: true, restart count 1
    Apr 18 05:21:43.170: INFO: kube-proxy-vmwrf from kube-system started at 2023-04-11 08:28:28 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: kube-scheduler-apps-209 from kube-system started at 2023-04-07 08:18:47 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container kube-scheduler ready: true, restart count 1
    Apr 18 05:21:43.170: INFO: metrics-server-7b879bf57b-6vnbg from kube-system started at 2023-04-13 06:15:03 +0000 UTC (1 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: sonobuoy-systemd-logs-daemon-set-79c9e0ab9cf64566-j4n44 from sonobuoy started at 2023-04-18 04:01:21 +0000 UTC (2 container statuses recorded)
    Apr 18 05:21:43.170: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 18 05:21:43.170: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 05:21:43.17
    Apr 18 05:21:43.258: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-2550" to be "running"
    Apr 18 05:21:43.262: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.372662ms
    Apr 18 05:21:45.267: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007996166s
    Apr 18 05:21:47.275: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.016796348s
    Apr 18 05:21:47.275: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 05:21:47.28
    STEP: Trying to apply a random label on the found node. 04/18/23 05:21:47.423
    STEP: verifying the node has the label kubernetes.io/e2e-1550e638-6216-4c56-9532-1c1f589da115 95 04/18/23 05:21:47.596
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/18/23 05:21:47.658
    Apr 18 05:21:47.709: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-2550" to be "not pending"
    Apr 18 05:21:47.826: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 117.247568ms
    Apr 18 05:21:49.831: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12193793s
    Apr 18 05:21:51.830: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12085131s
    Apr 18 05:21:53.832: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 6.123206993s
    Apr 18 05:21:53.832: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.2.108 on the node which pod4 resides and expect not scheduled 04/18/23 05:21:53.832
    Apr 18 05:21:53.866: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-2550" to be "not pending"
    Apr 18 05:21:53.870: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.200717ms
    Apr 18 05:21:55.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007322684s
    Apr 18 05:21:57.896: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029309818s
    Apr 18 05:21:59.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008632652s
    Apr 18 05:22:01.877: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010911608s
    Apr 18 05:22:03.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007854572s
    Apr 18 05:22:05.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.007688694s
    Apr 18 05:22:07.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007728355s
    Apr 18 05:22:09.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.00860432s
    Apr 18 05:22:11.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.007541675s
    Apr 18 05:22:13.904: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.037814321s
    Apr 18 05:22:15.877: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.010575647s
    Apr 18 05:22:17.880: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.013115131s
    Apr 18 05:22:19.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.009700507s
    Apr 18 05:22:21.937: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.070521976s
    Apr 18 05:22:23.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.00738991s
    Apr 18 05:22:25.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.007636275s
    Apr 18 05:22:27.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.007982109s
    Apr 18 05:22:29.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.008091549s
    Apr 18 05:22:31.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.006910158s
    Apr 18 05:22:33.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.008756389s
    Apr 18 05:22:35.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.007956768s
    Apr 18 05:22:37.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.008353187s
    Apr 18 05:22:39.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.009479831s
    Apr 18 05:22:41.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.007714696s
    Apr 18 05:22:43.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.008073911s
    Apr 18 05:22:45.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.007393124s
    Apr 18 05:22:47.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.008143815s
    Apr 18 05:22:49.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.006712921s
    Apr 18 05:22:51.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.007515869s
    Apr 18 05:22:53.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.008061695s
    Apr 18 05:22:55.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.007222079s
    Apr 18 05:22:57.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.009868408s
    Apr 18 05:22:59.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.009196025s
    Apr 18 05:23:01.890: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.023965871s
    Apr 18 05:23:03.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.008957688s
    Apr 18 05:23:05.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.009197368s
    Apr 18 05:23:07.878: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.011765587s
    Apr 18 05:23:09.893: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.026391934s
    Apr 18 05:23:11.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.007209176s
    Apr 18 05:23:13.885: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.018284835s
    Apr 18 05:23:15.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.008926521s
    Apr 18 05:23:17.916: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.049819078s
    Apr 18 05:23:19.884: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.017979226s
    Apr 18 05:23:21.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.00806759s
    Apr 18 05:23:23.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.008664252s
    Apr 18 05:23:25.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.007070699s
    Apr 18 05:23:27.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.007696065s
    Apr 18 05:23:29.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.007853171s
    Apr 18 05:23:31.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.007556268s
    Apr 18 05:23:33.894: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.027162522s
    Apr 18 05:23:35.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.007763548s
    Apr 18 05:23:37.983: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.116217698s
    Apr 18 05:23:39.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.008551361s
    Apr 18 05:23:41.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.007469613s
    Apr 18 05:23:43.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.008003866s
    Apr 18 05:23:45.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.009137438s
    Apr 18 05:23:47.894: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.027118912s
    Apr 18 05:23:49.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.007969407s
    Apr 18 05:23:51.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.007660443s
    Apr 18 05:23:53.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.008578194s
    Apr 18 05:23:55.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.006983537s
    Apr 18 05:23:57.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.008446775s
    Apr 18 05:23:59.909: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.042140419s
    Apr 18 05:24:01.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.00962772s
    Apr 18 05:24:03.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.008370655s
    Apr 18 05:24:05.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.007150634s
    Apr 18 05:24:07.913: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.046506559s
    Apr 18 05:24:09.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.007813434s
    Apr 18 05:24:11.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.007548508s
    Apr 18 05:24:13.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.007075305s
    Apr 18 05:24:15.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.007875986s
    Apr 18 05:24:17.905: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.038907294s
    Apr 18 05:24:19.931: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.064237511s
    Apr 18 05:24:21.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.006887621s
    Apr 18 05:24:23.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.007630609s
    Apr 18 05:24:25.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.007702072s
    Apr 18 05:24:27.889: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.022071545s
    Apr 18 05:24:29.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.008308223s
    Apr 18 05:24:31.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.007534079s
    Apr 18 05:24:33.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.008578328s
    Apr 18 05:24:35.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.006919112s
    Apr 18 05:24:37.911: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.044783529s
    Apr 18 05:24:39.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.009679726s
    Apr 18 05:24:41.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.007128577s
    Apr 18 05:24:43.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.0073006s
    Apr 18 05:24:45.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.007058722s
    Apr 18 05:24:47.926: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.059057472s
    Apr 18 05:24:49.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.008897588s
    Apr 18 05:24:51.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.007653526s
    Apr 18 05:24:53.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.008719805s
    Apr 18 05:24:55.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.007610892s
    Apr 18 05:24:57.883: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.016761398s
    Apr 18 05:24:59.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.008987476s
    Apr 18 05:25:01.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.007471672s
    Apr 18 05:25:03.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.008440757s
    Apr 18 05:25:05.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.007480396s
    Apr 18 05:25:07.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.007919676s
    Apr 18 05:25:09.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.008079705s
    Apr 18 05:25:11.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.006733359s
    Apr 18 05:25:13.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.008200739s
    Apr 18 05:25:15.916: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.049640794s
    Apr 18 05:25:17.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.009071915s
    Apr 18 05:25:19.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.008368117s
    Apr 18 05:25:21.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.006998444s
    Apr 18 05:25:23.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.008991974s
    Apr 18 05:25:25.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.008399552s
    Apr 18 05:25:27.908: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.041190707s
    Apr 18 05:25:29.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.009140491s
    Apr 18 05:25:31.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.007071067s
    Apr 18 05:25:33.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.00833873s
    Apr 18 05:25:35.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.008249696s
    Apr 18 05:25:37.904: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.037778237s
    Apr 18 05:25:39.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.007434815s
    Apr 18 05:25:41.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.006807509s
    Apr 18 05:25:43.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.008439445s
    Apr 18 05:25:45.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.00723833s
    Apr 18 05:25:47.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.008115511s
    Apr 18 05:25:49.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.009200193s
    Apr 18 05:25:51.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.007216756s
    Apr 18 05:25:53.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.008093712s
    Apr 18 05:25:55.915: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.048480461s
    Apr 18 05:25:57.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.008025069s
    Apr 18 05:25:59.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.00890637s
    Apr 18 05:26:01.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.007136117s
    Apr 18 05:26:03.901: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.0345385s
    Apr 18 05:26:05.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.007548915s
    Apr 18 05:26:07.896: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.029322013s
    Apr 18 05:26:09.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.008641363s
    Apr 18 05:26:11.873: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.006526722s
    Apr 18 05:26:13.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.007719637s
    Apr 18 05:26:15.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.007413872s
    Apr 18 05:26:17.881: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.014771611s
    Apr 18 05:26:19.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.008356296s
    Apr 18 05:26:21.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.00799168s
    Apr 18 05:26:23.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.008431129s
    Apr 18 05:26:25.903: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.036169638s
    Apr 18 05:26:27.886: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.01936934s
    Apr 18 05:26:29.876: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.009602759s
    Apr 18 05:26:31.884: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.017405576s
    Apr 18 05:26:33.875: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.008382963s
    Apr 18 05:26:35.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.007643365s
    Apr 18 05:26:37.881: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.014561035s
    Apr 18 05:26:39.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.007616912s
    Apr 18 05:26:41.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.061303506s
    Apr 18 05:26:43.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.007799007s
    Apr 18 05:26:45.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.007425818s
    Apr 18 05:26:47.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.007692821s
    Apr 18 05:26:49.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.007203601s
    Apr 18 05:26:51.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.007999191s
    Apr 18 05:26:53.874: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.007990414s
    Apr 18 05:26:53.877: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.010639698s
    STEP: removing the label kubernetes.io/e2e-1550e638-6216-4c56-9532-1c1f589da115 off the node apps-208 04/18/23 05:26:53.877
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-1550e638-6216-4c56-9532-1c1f589da115 04/18/23 05:26:53.918
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:26:53.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2550" for this suite. 04/18/23 05:26:53.926
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:26:53.948
Apr 18 05:26:53.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename var-expansion 04/18/23 05:26:53.949
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:26:54.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:26:54.051
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 04/18/23 05:26:54.075
Apr 18 05:26:54.101: INFO: Waiting up to 5m0s for pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d" in namespace "var-expansion-1181" to be "Succeeded or Failed"
Apr 18 05:26:54.156: INFO: Pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d": Phase="Pending", Reason="", readiness=false. Elapsed: 54.66271ms
Apr 18 05:26:56.160: INFO: Pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05883437s
Apr 18 05:26:58.162: INFO: Pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.060975776s
Apr 18 05:27:00.161: INFO: Pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059897326s
STEP: Saw pod success 04/18/23 05:27:00.161
Apr 18 05:27:00.161: INFO: Pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d" satisfied condition "Succeeded or Failed"
Apr 18 05:27:00.333: INFO: Trying to get logs from node apps-208 pod var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d container dapi-container: <nil>
STEP: delete the pod 04/18/23 05:27:00.387
Apr 18 05:27:00.599: INFO: Waiting for pod var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d to disappear
Apr 18 05:27:00.621: INFO: Pod var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 05:27:00.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1181" for this suite. 04/18/23 05:27:00.625
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":199,"skipped":3657,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.792 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:26:53.948
    Apr 18 05:26:53.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename var-expansion 04/18/23 05:26:53.949
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:26:54.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:26:54.051
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 04/18/23 05:26:54.075
    Apr 18 05:26:54.101: INFO: Waiting up to 5m0s for pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d" in namespace "var-expansion-1181" to be "Succeeded or Failed"
    Apr 18 05:26:54.156: INFO: Pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d": Phase="Pending", Reason="", readiness=false. Elapsed: 54.66271ms
    Apr 18 05:26:56.160: INFO: Pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05883437s
    Apr 18 05:26:58.162: INFO: Pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.060975776s
    Apr 18 05:27:00.161: INFO: Pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059897326s
    STEP: Saw pod success 04/18/23 05:27:00.161
    Apr 18 05:27:00.161: INFO: Pod "var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d" satisfied condition "Succeeded or Failed"
    Apr 18 05:27:00.333: INFO: Trying to get logs from node apps-208 pod var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d container dapi-container: <nil>
    STEP: delete the pod 04/18/23 05:27:00.387
    Apr 18 05:27:00.599: INFO: Waiting for pod var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d to disappear
    Apr 18 05:27:00.621: INFO: Pod var-expansion-f4d2d622-fa16-444f-8cab-80035695e15d no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 05:27:00.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1181" for this suite. 04/18/23 05:27:00.625
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:27:00.741
Apr 18 05:27:00.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 05:27:00.742
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:27:00.914
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:27:00.917
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 04/18/23 05:27:00.955
STEP: Creating a ResourceQuota 04/18/23 05:27:05.989
STEP: Ensuring resource quota status is calculated 04/18/23 05:27:06.026
STEP: Creating a Service 04/18/23 05:27:08.032
STEP: Creating a NodePort Service 04/18/23 05:27:08.199
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/18/23 05:27:08.27
STEP: Ensuring resource quota status captures service creation 04/18/23 05:27:08.562
STEP: Deleting Services 04/18/23 05:27:10.568
STEP: Ensuring resource quota status released usage 04/18/23 05:27:10.915
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 05:27:12.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4325" for this suite. 04/18/23 05:27:12.926
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":200,"skipped":3663,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.209 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:27:00.741
    Apr 18 05:27:00.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 05:27:00.742
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:27:00.914
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:27:00.917
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 04/18/23 05:27:00.955
    STEP: Creating a ResourceQuota 04/18/23 05:27:05.989
    STEP: Ensuring resource quota status is calculated 04/18/23 05:27:06.026
    STEP: Creating a Service 04/18/23 05:27:08.032
    STEP: Creating a NodePort Service 04/18/23 05:27:08.199
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/18/23 05:27:08.27
    STEP: Ensuring resource quota status captures service creation 04/18/23 05:27:08.562
    STEP: Deleting Services 04/18/23 05:27:10.568
    STEP: Ensuring resource quota status released usage 04/18/23 05:27:10.915
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 05:27:12.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4325" for this suite. 04/18/23 05:27:12.926
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:27:12.95
Apr 18 05:27:12.950: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename statefulset 04/18/23 05:27:12.951
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:27:13.06
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:27:13.063
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4643 04/18/23 05:27:13.065
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-4643 04/18/23 05:27:13.11
Apr 18 05:27:13.144: INFO: Found 0 stateful pods, waiting for 1
Apr 18 05:27:23.149: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 04/18/23 05:27:23.154
STEP: Getting /status 04/18/23 05:27:23.175
Apr 18 05:27:23.179: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 04/18/23 05:27:23.179
Apr 18 05:27:23.210: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 04/18/23 05:27:23.21
Apr 18 05:27:23.212: INFO: Observed &StatefulSet event: ADDED
Apr 18 05:27:23.212: INFO: Found Statefulset ss in namespace statefulset-4643 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 18 05:27:23.212: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 04/18/23 05:27:23.212
Apr 18 05:27:23.212: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 18 05:27:23.267: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 04/18/23 05:27:23.267
Apr 18 05:27:23.268: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 05:27:23.268: INFO: Deleting all statefulset in ns statefulset-4643
Apr 18 05:27:23.333: INFO: Scaling statefulset ss to 0
Apr 18 05:27:33.428: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 05:27:33.431: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 05:27:33.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4643" for this suite. 04/18/23 05:27:33.468
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":201,"skipped":3683,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.544 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:27:12.95
    Apr 18 05:27:12.950: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename statefulset 04/18/23 05:27:12.951
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:27:13.06
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:27:13.063
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4643 04/18/23 05:27:13.065
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-4643 04/18/23 05:27:13.11
    Apr 18 05:27:13.144: INFO: Found 0 stateful pods, waiting for 1
    Apr 18 05:27:23.149: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 04/18/23 05:27:23.154
    STEP: Getting /status 04/18/23 05:27:23.175
    Apr 18 05:27:23.179: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 04/18/23 05:27:23.179
    Apr 18 05:27:23.210: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 04/18/23 05:27:23.21
    Apr 18 05:27:23.212: INFO: Observed &StatefulSet event: ADDED
    Apr 18 05:27:23.212: INFO: Found Statefulset ss in namespace statefulset-4643 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 18 05:27:23.212: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 04/18/23 05:27:23.212
    Apr 18 05:27:23.212: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 18 05:27:23.267: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 04/18/23 05:27:23.267
    Apr 18 05:27:23.268: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 05:27:23.268: INFO: Deleting all statefulset in ns statefulset-4643
    Apr 18 05:27:23.333: INFO: Scaling statefulset ss to 0
    Apr 18 05:27:33.428: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 05:27:33.431: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 05:27:33.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4643" for this suite. 04/18/23 05:27:33.468
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:27:33.496
Apr 18 05:27:33.496: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename statefulset 04/18/23 05:27:33.497
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:27:33.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:27:33.654
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3087 04/18/23 05:27:33.657
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-3087 04/18/23 05:27:33.777
Apr 18 05:27:33.827: INFO: Found 0 stateful pods, waiting for 1
Apr 18 05:27:43.833: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 04/18/23 05:27:43.853
STEP: updating a scale subresource 04/18/23 05:27:43.856
STEP: verifying the statefulset Spec.Replicas was modified 04/18/23 05:27:43.886
STEP: Patch a scale subresource 04/18/23 05:27:43.891
STEP: verifying the statefulset Spec.Replicas was modified 04/18/23 05:27:44.05
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 05:27:44.117: INFO: Deleting all statefulset in ns statefulset-3087
Apr 18 05:27:44.145: INFO: Scaling statefulset ss to 0
Apr 18 05:27:54.313: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 05:27:54.316: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 05:27:54.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3087" for this suite. 04/18/23 05:27:54.389
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":202,"skipped":3710,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.964 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:27:33.496
    Apr 18 05:27:33.496: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename statefulset 04/18/23 05:27:33.497
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:27:33.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:27:33.654
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3087 04/18/23 05:27:33.657
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-3087 04/18/23 05:27:33.777
    Apr 18 05:27:33.827: INFO: Found 0 stateful pods, waiting for 1
    Apr 18 05:27:43.833: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 04/18/23 05:27:43.853
    STEP: updating a scale subresource 04/18/23 05:27:43.856
    STEP: verifying the statefulset Spec.Replicas was modified 04/18/23 05:27:43.886
    STEP: Patch a scale subresource 04/18/23 05:27:43.891
    STEP: verifying the statefulset Spec.Replicas was modified 04/18/23 05:27:44.05
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 05:27:44.117: INFO: Deleting all statefulset in ns statefulset-3087
    Apr 18 05:27:44.145: INFO: Scaling statefulset ss to 0
    Apr 18 05:27:54.313: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 05:27:54.316: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 05:27:54.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3087" for this suite. 04/18/23 05:27:54.389
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:27:54.46
Apr 18 05:27:54.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename svcaccounts 04/18/23 05:27:54.461
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:27:54.52
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:27:54.523
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 04/18/23 05:27:54.647
STEP: watching for the ServiceAccount to be added 04/18/23 05:27:54.689
STEP: patching the ServiceAccount 04/18/23 05:27:54.691
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/18/23 05:27:54.919
STEP: deleting the ServiceAccount 04/18/23 05:27:54.943
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 05:27:55.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1471" for this suite. 04/18/23 05:27:55.141
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":203,"skipped":3714,"failed":0}
------------------------------
â€¢ [0.825 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:27:54.46
    Apr 18 05:27:54.460: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 05:27:54.461
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:27:54.52
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:27:54.523
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 04/18/23 05:27:54.647
    STEP: watching for the ServiceAccount to be added 04/18/23 05:27:54.689
    STEP: patching the ServiceAccount 04/18/23 05:27:54.691
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/18/23 05:27:54.919
    STEP: deleting the ServiceAccount 04/18/23 05:27:54.943
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 05:27:55.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1471" for this suite. 04/18/23 05:27:55.141
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:27:55.289
Apr 18 05:27:55.289: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 05:27:55.29
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:27:55.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:27:55.356
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/18/23 05:27:55.386
Apr 18 05:27:55.446: INFO: Waiting up to 5m0s for pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3" in namespace "emptydir-6195" to be "Succeeded or Failed"
Apr 18 05:27:55.449: INFO: Pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.472369ms
Apr 18 05:27:57.453: INFO: Pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007138768s
Apr 18 05:27:59.454: INFO: Pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008100144s
Apr 18 05:28:01.530: INFO: Pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.083269514s
STEP: Saw pod success 04/18/23 05:28:01.53
Apr 18 05:28:01.530: INFO: Pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3" satisfied condition "Succeeded or Failed"
Apr 18 05:28:01.534: INFO: Trying to get logs from node apps-208 pod pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3 container test-container: <nil>
STEP: delete the pod 04/18/23 05:28:01.541
Apr 18 05:28:01.684: INFO: Waiting for pod pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3 to disappear
Apr 18 05:28:01.687: INFO: Pod pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 05:28:01.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6195" for this suite. 04/18/23 05:28:01.692
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":204,"skipped":3799,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.416 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:27:55.289
    Apr 18 05:27:55.289: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 05:27:55.29
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:27:55.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:27:55.356
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/18/23 05:27:55.386
    Apr 18 05:27:55.446: INFO: Waiting up to 5m0s for pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3" in namespace "emptydir-6195" to be "Succeeded or Failed"
    Apr 18 05:27:55.449: INFO: Pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.472369ms
    Apr 18 05:27:57.453: INFO: Pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007138768s
    Apr 18 05:27:59.454: INFO: Pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008100144s
    Apr 18 05:28:01.530: INFO: Pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.083269514s
    STEP: Saw pod success 04/18/23 05:28:01.53
    Apr 18 05:28:01.530: INFO: Pod "pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3" satisfied condition "Succeeded or Failed"
    Apr 18 05:28:01.534: INFO: Trying to get logs from node apps-208 pod pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3 container test-container: <nil>
    STEP: delete the pod 04/18/23 05:28:01.541
    Apr 18 05:28:01.684: INFO: Waiting for pod pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3 to disappear
    Apr 18 05:28:01.687: INFO: Pod pod-7f51eae9-ef86-4a33-91a9-02778f79b3c3 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 05:28:01.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6195" for this suite. 04/18/23 05:28:01.692
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:28:01.705
Apr 18 05:28:01.705: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 05:28:01.706
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:28:01.729
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:28:01.732
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-46a1132e-fe5f-4c2d-90b2-191d05e58bde 04/18/23 05:28:01.857
STEP: Creating configMap with name cm-test-opt-upd-404fa3d1-260f-429b-9b8a-9aaa643da84d 04/18/23 05:28:01.87
STEP: Creating the pod 04/18/23 05:28:01.904
Apr 18 05:28:01.954: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26" in namespace "configmap-1894" to be "running and ready"
Apr 18 05:28:02.046: INFO: Pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26": Phase="Pending", Reason="", readiness=false. Elapsed: 92.029856ms
Apr 18 05:28:02.046: INFO: The phase of Pod pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:28:04.081: INFO: Pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12684358s
Apr 18 05:28:04.081: INFO: The phase of Pod pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:28:06.051: INFO: Pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26": Phase="Pending", Reason="", readiness=false. Elapsed: 4.096498077s
Apr 18 05:28:06.051: INFO: The phase of Pod pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:28:08.052: INFO: Pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26": Phase="Running", Reason="", readiness=true. Elapsed: 6.097375052s
Apr 18 05:28:08.052: INFO: The phase of Pod pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26 is Running (Ready = true)
Apr 18 05:28:08.052: INFO: Pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-46a1132e-fe5f-4c2d-90b2-191d05e58bde 04/18/23 05:28:08.101
STEP: Updating configmap cm-test-opt-upd-404fa3d1-260f-429b-9b8a-9aaa643da84d 04/18/23 05:28:08.234
STEP: Creating configMap with name cm-test-opt-create-9c4fd191-c66e-471b-9590-c54eecb4ab22 04/18/23 05:28:08.256
STEP: waiting to observe update in volume 04/18/23 05:28:08.296
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 05:29:17.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1894" for this suite. 04/18/23 05:29:17.324
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":205,"skipped":3802,"failed":0}
------------------------------
â€¢ [SLOW TEST] [75.647 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:28:01.705
    Apr 18 05:28:01.705: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 05:28:01.706
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:28:01.729
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:28:01.732
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-46a1132e-fe5f-4c2d-90b2-191d05e58bde 04/18/23 05:28:01.857
    STEP: Creating configMap with name cm-test-opt-upd-404fa3d1-260f-429b-9b8a-9aaa643da84d 04/18/23 05:28:01.87
    STEP: Creating the pod 04/18/23 05:28:01.904
    Apr 18 05:28:01.954: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26" in namespace "configmap-1894" to be "running and ready"
    Apr 18 05:28:02.046: INFO: Pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26": Phase="Pending", Reason="", readiness=false. Elapsed: 92.029856ms
    Apr 18 05:28:02.046: INFO: The phase of Pod pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:28:04.081: INFO: Pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12684358s
    Apr 18 05:28:04.081: INFO: The phase of Pod pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:28:06.051: INFO: Pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26": Phase="Pending", Reason="", readiness=false. Elapsed: 4.096498077s
    Apr 18 05:28:06.051: INFO: The phase of Pod pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:28:08.052: INFO: Pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26": Phase="Running", Reason="", readiness=true. Elapsed: 6.097375052s
    Apr 18 05:28:08.052: INFO: The phase of Pod pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26 is Running (Ready = true)
    Apr 18 05:28:08.052: INFO: Pod "pod-configmaps-ac489824-677d-44e6-90e3-a83aad17ec26" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-46a1132e-fe5f-4c2d-90b2-191d05e58bde 04/18/23 05:28:08.101
    STEP: Updating configmap cm-test-opt-upd-404fa3d1-260f-429b-9b8a-9aaa643da84d 04/18/23 05:28:08.234
    STEP: Creating configMap with name cm-test-opt-create-9c4fd191-c66e-471b-9590-c54eecb4ab22 04/18/23 05:28:08.256
    STEP: waiting to observe update in volume 04/18/23 05:28:08.296
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 05:29:17.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1894" for this suite. 04/18/23 05:29:17.324
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:29:17.354
Apr 18 05:29:17.354: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename server-version 04/18/23 05:29:17.355
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:17.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:17.4
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 04/18/23 05:29:17.428
STEP: Confirm major version 04/18/23 05:29:17.429
Apr 18 05:29:17.429: INFO: Major version: 1
STEP: Confirm minor version 04/18/23 05:29:17.429
Apr 18 05:29:17.429: INFO: cleanMinorVersion: 25
Apr 18 05:29:17.429: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Apr 18 05:29:17.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-1869" for this suite. 04/18/23 05:29:17.463
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":206,"skipped":3822,"failed":0}
------------------------------
â€¢ [0.157 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:29:17.354
    Apr 18 05:29:17.354: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename server-version 04/18/23 05:29:17.355
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:17.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:17.4
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 04/18/23 05:29:17.428
    STEP: Confirm major version 04/18/23 05:29:17.429
    Apr 18 05:29:17.429: INFO: Major version: 1
    STEP: Confirm minor version 04/18/23 05:29:17.429
    Apr 18 05:29:17.429: INFO: cleanMinorVersion: 25
    Apr 18 05:29:17.429: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Apr 18 05:29:17.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-1869" for this suite. 04/18/23 05:29:17.463
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:29:17.512
Apr 18 05:29:17.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pod-network-test 04/18/23 05:29:17.513
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:17.599
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:17.601
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-9006 04/18/23 05:29:17.604
STEP: creating a selector 04/18/23 05:29:17.604
STEP: Creating the service pods in kubernetes 04/18/23 05:29:17.604
Apr 18 05:29:17.604: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 18 05:29:17.921: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9006" to be "running and ready"
Apr 18 05:29:18.194: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 273.466575ms
Apr 18 05:29:18.195: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:29:20.204: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.283368644s
Apr 18 05:29:20.204: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:29:22.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.277553276s
Apr 18 05:29:22.199: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:29:24.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.490581374s
Apr 18 05:29:24.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:29:26.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.278445462s
Apr 18 05:29:26.199: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:29:28.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.277967488s
Apr 18 05:29:28.199: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:29:30.200: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.279390857s
Apr 18 05:29:30.200: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:29:32.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.277786763s
Apr 18 05:29:32.199: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:29:34.244: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.32337062s
Apr 18 05:29:34.244: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:29:36.200: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.278899967s
Apr 18 05:29:36.200: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:29:38.200: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.279396135s
Apr 18 05:29:38.200: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:29:40.213: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.292470057s
Apr 18 05:29:40.214: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 18 05:29:40.214: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 18 05:29:40.217: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9006" to be "running and ready"
Apr 18 05:29:40.220: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.166882ms
Apr 18 05:29:40.220: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 18 05:29:40.220: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 18 05:29:40.222: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9006" to be "running and ready"
Apr 18 05:29:40.269: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 46.574526ms
Apr 18 05:29:40.269: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 18 05:29:40.269: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/18/23 05:29:40.295
Apr 18 05:29:40.354: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9006" to be "running"
Apr 18 05:29:40.391: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 37.124403ms
Apr 18 05:29:42.397: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042576458s
Apr 18 05:29:44.397: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.042556544s
Apr 18 05:29:44.397: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 18 05:29:44.400: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9006" to be "running"
Apr 18 05:29:44.403: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.983441ms
Apr 18 05:29:44.403: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 18 05:29:44.406: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 18 05:29:44.406: INFO: Going to poll 172.16.100.132 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 18 05:29:44.409: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.100.132:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9006 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:29:44.409: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:29:44.409: INFO: ExecWithOptions: Clientset creation
Apr 18 05:29:44.409: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9006/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.100.132%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 05:29:44.503: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 18 05:29:44.503: INFO: Going to poll 172.16.125.24 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 18 05:29:44.506: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.125.24:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9006 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:29:44.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:29:44.507: INFO: ExecWithOptions: Clientset creation
Apr 18 05:29:44.507: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9006/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.125.24%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 05:29:44.592: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 18 05:29:44.592: INFO: Going to poll 172.16.144.11 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Apr 18 05:29:44.596: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.144.11:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9006 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:29:44.596: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:29:44.596: INFO: ExecWithOptions: Clientset creation
Apr 18 05:29:44.596: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9006/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.144.11%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 05:29:44.684: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 18 05:29:44.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9006" for this suite. 04/18/23 05:29:44.692
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":207,"skipped":3840,"failed":0}
------------------------------
â€¢ [SLOW TEST] [27.252 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:29:17.512
    Apr 18 05:29:17.512: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pod-network-test 04/18/23 05:29:17.513
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:17.599
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:17.601
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-9006 04/18/23 05:29:17.604
    STEP: creating a selector 04/18/23 05:29:17.604
    STEP: Creating the service pods in kubernetes 04/18/23 05:29:17.604
    Apr 18 05:29:17.604: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 18 05:29:17.921: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9006" to be "running and ready"
    Apr 18 05:29:18.194: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 273.466575ms
    Apr 18 05:29:18.195: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:29:20.204: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.283368644s
    Apr 18 05:29:20.204: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:29:22.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.277553276s
    Apr 18 05:29:22.199: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:29:24.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.490581374s
    Apr 18 05:29:24.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:29:26.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.278445462s
    Apr 18 05:29:26.199: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:29:28.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.277967488s
    Apr 18 05:29:28.199: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:29:30.200: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.279390857s
    Apr 18 05:29:30.200: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:29:32.199: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.277786763s
    Apr 18 05:29:32.199: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:29:34.244: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.32337062s
    Apr 18 05:29:34.244: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:29:36.200: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.278899967s
    Apr 18 05:29:36.200: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:29:38.200: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.279396135s
    Apr 18 05:29:38.200: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:29:40.213: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.292470057s
    Apr 18 05:29:40.214: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 18 05:29:40.214: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 18 05:29:40.217: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9006" to be "running and ready"
    Apr 18 05:29:40.220: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.166882ms
    Apr 18 05:29:40.220: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 18 05:29:40.220: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 18 05:29:40.222: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9006" to be "running and ready"
    Apr 18 05:29:40.269: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 46.574526ms
    Apr 18 05:29:40.269: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 18 05:29:40.269: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/18/23 05:29:40.295
    Apr 18 05:29:40.354: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9006" to be "running"
    Apr 18 05:29:40.391: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 37.124403ms
    Apr 18 05:29:42.397: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042576458s
    Apr 18 05:29:44.397: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.042556544s
    Apr 18 05:29:44.397: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 18 05:29:44.400: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-9006" to be "running"
    Apr 18 05:29:44.403: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.983441ms
    Apr 18 05:29:44.403: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 18 05:29:44.406: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 18 05:29:44.406: INFO: Going to poll 172.16.100.132 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 05:29:44.409: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.100.132:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9006 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:29:44.409: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:29:44.409: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:29:44.409: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9006/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.100.132%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 05:29:44.503: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 18 05:29:44.503: INFO: Going to poll 172.16.125.24 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 05:29:44.506: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.125.24:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9006 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:29:44.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:29:44.507: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:29:44.507: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9006/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.125.24%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 05:29:44.592: INFO: Found all 1 expected endpoints: [netserver-1]
    Apr 18 05:29:44.592: INFO: Going to poll 172.16.144.11 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Apr 18 05:29:44.596: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.16.144.11:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9006 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:29:44.596: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:29:44.596: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:29:44.596: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9006/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F172.16.144.11%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 05:29:44.684: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 18 05:29:44.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-9006" for this suite. 04/18/23 05:29:44.692
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:29:44.764
Apr 18 05:29:44.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 05:29:44.765
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:44.812
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:44.815
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 05:29:44.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4695" for this suite. 04/18/23 05:29:44.896
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":208,"skipped":3849,"failed":0}
------------------------------
â€¢ [0.157 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:29:44.764
    Apr 18 05:29:44.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 05:29:44.765
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:44.812
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:44.815
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 05:29:44.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4695" for this suite. 04/18/23 05:29:44.896
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:29:44.922
Apr 18 05:29:44.922: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubelet-test 04/18/23 05:29:44.923
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:44.965
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:44.969
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Apr 18 05:29:45.055: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3" in namespace "kubelet-test-9053" to be "running and ready"
Apr 18 05:29:45.058: INFO: Pod "busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.997305ms
Apr 18 05:29:45.058: INFO: The phase of Pod busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:29:47.064: INFO: Pod "busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008733061s
Apr 18 05:29:47.064: INFO: The phase of Pod busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:29:49.063: INFO: Pod "busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3": Phase="Running", Reason="", readiness=true. Elapsed: 4.008526467s
Apr 18 05:29:49.063: INFO: The phase of Pod busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3 is Running (Ready = true)
Apr 18 05:29:49.063: INFO: Pod "busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 18 05:29:49.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9053" for this suite. 04/18/23 05:29:49.078
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":209,"skipped":3858,"failed":0}
------------------------------
â€¢ [4.244 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:29:44.922
    Apr 18 05:29:44.922: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubelet-test 04/18/23 05:29:44.923
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:44.965
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:44.969
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Apr 18 05:29:45.055: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3" in namespace "kubelet-test-9053" to be "running and ready"
    Apr 18 05:29:45.058: INFO: Pod "busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.997305ms
    Apr 18 05:29:45.058: INFO: The phase of Pod busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:29:47.064: INFO: Pod "busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008733061s
    Apr 18 05:29:47.064: INFO: The phase of Pod busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:29:49.063: INFO: Pod "busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3": Phase="Running", Reason="", readiness=true. Elapsed: 4.008526467s
    Apr 18 05:29:49.063: INFO: The phase of Pod busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3 is Running (Ready = true)
    Apr 18 05:29:49.063: INFO: Pod "busybox-readonly-fs6513a7c2-0405-47b8-a5b0-003e8ab7a6e3" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 18 05:29:49.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-9053" for this suite. 04/18/23 05:29:49.078
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:29:49.166
Apr 18 05:29:49.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replication-controller 04/18/23 05:29:49.167
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:49.271
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:49.274
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432 04/18/23 05:29:49.277
Apr 18 05:29:49.345: INFO: Pod name my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432: Found 0 pods out of 1
Apr 18 05:29:54.354: INFO: Pod name my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432: Found 1 pods out of 1
Apr 18 05:29:54.354: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432" are running
Apr 18 05:29:54.354: INFO: Waiting up to 5m0s for pod "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l" in namespace "replication-controller-4453" to be "running"
Apr 18 05:29:54.403: INFO: Pod "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l": Phase="Running", Reason="", readiness=true. Elapsed: 49.047572ms
Apr 18 05:29:54.403: INFO: Pod "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l" satisfied condition "running"
Apr 18 05:29:54.403: INFO: Pod "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 05:29:49 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 05:29:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 05:29:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 05:29:49 +0000 UTC Reason: Message:}])
Apr 18 05:29:54.403: INFO: Trying to dial the pod
Apr 18 05:29:59.440: INFO: Controller my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432: Got expected result from replica 1 [my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l]: "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 18 05:29:59.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4453" for this suite. 04/18/23 05:29:59.445
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":210,"skipped":3862,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.301 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:29:49.166
    Apr 18 05:29:49.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replication-controller 04/18/23 05:29:49.167
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:49.271
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:49.274
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432 04/18/23 05:29:49.277
    Apr 18 05:29:49.345: INFO: Pod name my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432: Found 0 pods out of 1
    Apr 18 05:29:54.354: INFO: Pod name my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432: Found 1 pods out of 1
    Apr 18 05:29:54.354: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432" are running
    Apr 18 05:29:54.354: INFO: Waiting up to 5m0s for pod "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l" in namespace "replication-controller-4453" to be "running"
    Apr 18 05:29:54.403: INFO: Pod "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l": Phase="Running", Reason="", readiness=true. Elapsed: 49.047572ms
    Apr 18 05:29:54.403: INFO: Pod "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l" satisfied condition "running"
    Apr 18 05:29:54.403: INFO: Pod "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 05:29:49 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 05:29:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 05:29:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-18 05:29:49 +0000 UTC Reason: Message:}])
    Apr 18 05:29:54.403: INFO: Trying to dial the pod
    Apr 18 05:29:59.440: INFO: Controller my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432: Got expected result from replica 1 [my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l]: "my-hostname-basic-5769a79c-bbc2-44ce-a08b-4d530e69e432-4qp7l", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 18 05:29:59.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-4453" for this suite. 04/18/23 05:29:59.445
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:29:59.468
Apr 18 05:29:59.469: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename svcaccounts 04/18/23 05:29:59.469
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:59.572
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:59.575
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Apr 18 05:29:59.940: INFO: created pod
Apr 18 05:29:59.940: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-5678" to be "Succeeded or Failed"
Apr 18 05:29:59.951: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.87188ms
Apr 18 05:30:01.956: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01586278s
Apr 18 05:30:03.957: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016582195s
Apr 18 05:30:05.956: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015221724s
STEP: Saw pod success 04/18/23 05:30:05.956
Apr 18 05:30:05.956: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Apr 18 05:30:35.956: INFO: polling logs
Apr 18 05:30:35.963: INFO: Pod logs: 
I0418 05:30:02.176515       1 log.go:195] OK: Got token
I0418 05:30:02.176554       1 log.go:195] validating with in-cluster discovery
I0418 05:30:02.176923       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
I0418 05:30:02.176954       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-5678:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681796400, NotBefore:1681795800, IssuedAt:1681795800, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5678", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"ef784768-80d3-4046-8973-bfd8cadf4c7c"}}}
I0418 05:30:02.187103       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
I0418 05:30:02.193972       1 log.go:195] OK: Validated signature on JWT
I0418 05:30:02.194065       1 log.go:195] OK: Got valid claims from token!
I0418 05:30:02.194095       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-5678:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681796400, NotBefore:1681795800, IssuedAt:1681795800, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5678", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"ef784768-80d3-4046-8973-bfd8cadf4c7c"}}}

Apr 18 05:30:35.963: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 05:30:35.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5678" for this suite. 04/18/23 05:30:35.996
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":211,"skipped":3877,"failed":0}
------------------------------
â€¢ [SLOW TEST] [36.545 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:29:59.468
    Apr 18 05:29:59.469: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 05:29:59.469
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:29:59.572
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:29:59.575
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Apr 18 05:29:59.940: INFO: created pod
    Apr 18 05:29:59.940: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-5678" to be "Succeeded or Failed"
    Apr 18 05:29:59.951: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.87188ms
    Apr 18 05:30:01.956: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01586278s
    Apr 18 05:30:03.957: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016582195s
    Apr 18 05:30:05.956: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015221724s
    STEP: Saw pod success 04/18/23 05:30:05.956
    Apr 18 05:30:05.956: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Apr 18 05:30:35.956: INFO: polling logs
    Apr 18 05:30:35.963: INFO: Pod logs: 
    I0418 05:30:02.176515       1 log.go:195] OK: Got token
    I0418 05:30:02.176554       1 log.go:195] validating with in-cluster discovery
    I0418 05:30:02.176923       1 log.go:195] OK: got issuer https://kubernetes.default.svc.cluster.local
    I0418 05:30:02.176954       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-5678:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681796400, NotBefore:1681795800, IssuedAt:1681795800, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5678", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"ef784768-80d3-4046-8973-bfd8cadf4c7c"}}}
    I0418 05:30:02.187103       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
    I0418 05:30:02.193972       1 log.go:195] OK: Validated signature on JWT
    I0418 05:30:02.194065       1 log.go:195] OK: Got valid claims from token!
    I0418 05:30:02.194095       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-5678:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1681796400, NotBefore:1681795800, IssuedAt:1681795800, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-5678", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"ef784768-80d3-4046-8973-bfd8cadf4c7c"}}}

    Apr 18 05:30:35.963: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 05:30:35.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-5678" for this suite. 04/18/23 05:30:35.996
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:30:36.014
Apr 18 05:30:36.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 05:30:36.015
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:30:36.16
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:30:36.162
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-b887ef87-0b39-4557-9e73-87de459d5cf1 04/18/23 05:30:36.41
STEP: Creating a pod to test consume secrets 04/18/23 05:30:36.477
Apr 18 05:30:36.544: INFO: Waiting up to 5m0s for pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f" in namespace "secrets-2092" to be "Succeeded or Failed"
Apr 18 05:30:36.546: INFO: Pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.685601ms
Apr 18 05:30:38.610: INFO: Pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066625289s
Apr 18 05:30:40.579: INFO: Pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035626955s
Apr 18 05:30:42.551: INFO: Pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007026085s
STEP: Saw pod success 04/18/23 05:30:42.551
Apr 18 05:30:42.551: INFO: Pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f" satisfied condition "Succeeded or Failed"
Apr 18 05:30:42.554: INFO: Trying to get logs from node apps-208 pod pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 05:30:42.56
Apr 18 05:30:42.619: INFO: Waiting for pod pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f to disappear
Apr 18 05:30:42.623: INFO: Pod pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 05:30:42.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2092" for this suite. 04/18/23 05:30:42.707
STEP: Destroying namespace "secret-namespace-3682" for this suite. 04/18/23 05:30:42.744
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":212,"skipped":3886,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.751 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:30:36.014
    Apr 18 05:30:36.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 05:30:36.015
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:30:36.16
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:30:36.162
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-b887ef87-0b39-4557-9e73-87de459d5cf1 04/18/23 05:30:36.41
    STEP: Creating a pod to test consume secrets 04/18/23 05:30:36.477
    Apr 18 05:30:36.544: INFO: Waiting up to 5m0s for pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f" in namespace "secrets-2092" to be "Succeeded or Failed"
    Apr 18 05:30:36.546: INFO: Pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.685601ms
    Apr 18 05:30:38.610: INFO: Pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066625289s
    Apr 18 05:30:40.579: INFO: Pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035626955s
    Apr 18 05:30:42.551: INFO: Pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007026085s
    STEP: Saw pod success 04/18/23 05:30:42.551
    Apr 18 05:30:42.551: INFO: Pod "pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f" satisfied condition "Succeeded or Failed"
    Apr 18 05:30:42.554: INFO: Trying to get logs from node apps-208 pod pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 05:30:42.56
    Apr 18 05:30:42.619: INFO: Waiting for pod pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f to disappear
    Apr 18 05:30:42.623: INFO: Pod pod-secrets-490b8143-f374-4c7f-a998-1661bab4496f no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 05:30:42.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2092" for this suite. 04/18/23 05:30:42.707
    STEP: Destroying namespace "secret-namespace-3682" for this suite. 04/18/23 05:30:42.744
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:30:42.766
Apr 18 05:30:42.766: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 05:30:42.767
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:30:42.894
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:30:42.897
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 05:30:42.928
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:30:43.463
STEP: Deploying the webhook pod 04/18/23 05:30:43.478
STEP: Wait for the deployment to be ready 04/18/23 05:30:43.588
Apr 18 05:30:43.672: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Apr 18 05:30:45.716: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 30, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 30, 43, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 30, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 30, 43, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 05:30:47.721
STEP: Verifying the service has paired with the endpoint 04/18/23 05:30:47.779
Apr 18 05:30:48.779: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 04/18/23 05:30:48.832
STEP: create a pod that should be denied by the webhook 04/18/23 05:30:48.992
STEP: create a pod that causes the webhook to hang 04/18/23 05:30:49.049
STEP: create a configmap that should be denied by the webhook 04/18/23 05:30:59.056
STEP: create a configmap that should be admitted by the webhook 04/18/23 05:30:59.167
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/18/23 05:30:59.196
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/18/23 05:30:59.203
STEP: create a namespace that bypass the webhook 04/18/23 05:30:59.208
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/18/23 05:30:59.237
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:30:59.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2610" for this suite. 04/18/23 05:30:59.457
STEP: Destroying namespace "webhook-2610-markers" for this suite. 04/18/23 05:30:59.479
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":213,"skipped":3911,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.921 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:30:42.766
    Apr 18 05:30:42.766: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 05:30:42.767
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:30:42.894
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:30:42.897
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 05:30:42.928
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:30:43.463
    STEP: Deploying the webhook pod 04/18/23 05:30:43.478
    STEP: Wait for the deployment to be ready 04/18/23 05:30:43.588
    Apr 18 05:30:43.672: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Apr 18 05:30:45.716: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 30, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 30, 43, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 30, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 30, 43, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 05:30:47.721
    STEP: Verifying the service has paired with the endpoint 04/18/23 05:30:47.779
    Apr 18 05:30:48.779: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 04/18/23 05:30:48.832
    STEP: create a pod that should be denied by the webhook 04/18/23 05:30:48.992
    STEP: create a pod that causes the webhook to hang 04/18/23 05:30:49.049
    STEP: create a configmap that should be denied by the webhook 04/18/23 05:30:59.056
    STEP: create a configmap that should be admitted by the webhook 04/18/23 05:30:59.167
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/18/23 05:30:59.196
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/18/23 05:30:59.203
    STEP: create a namespace that bypass the webhook 04/18/23 05:30:59.208
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/18/23 05:30:59.237
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:30:59.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2610" for this suite. 04/18/23 05:30:59.457
    STEP: Destroying namespace "webhook-2610-markers" for this suite. 04/18/23 05:30:59.479
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:30:59.688
Apr 18 05:30:59.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 05:30:59.689
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:30:59.804
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:30:59.807
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 04/18/23 05:30:59.922
Apr 18 05:31:00.109: INFO: Waiting up to 5m0s for pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58" in namespace "downward-api-2790" to be "Succeeded or Failed"
Apr 18 05:31:00.154: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58": Phase="Pending", Reason="", readiness=false. Elapsed: 45.207277ms
Apr 18 05:31:02.172: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062275443s
Apr 18 05:31:04.160: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05107496s
Apr 18 05:31:06.436: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58": Phase="Pending", Reason="", readiness=false. Elapsed: 6.326551262s
Apr 18 05:31:08.159: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.049676071s
STEP: Saw pod success 04/18/23 05:31:08.159
Apr 18 05:31:08.159: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58" satisfied condition "Succeeded or Failed"
Apr 18 05:31:08.177: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58 container client-container: <nil>
STEP: delete the pod 04/18/23 05:31:08.183
Apr 18 05:31:08.247: INFO: Waiting for pod downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58 to disappear
Apr 18 05:31:08.250: INFO: Pod downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 05:31:08.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2790" for this suite. 04/18/23 05:31:08.255
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":214,"skipped":3914,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.592 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:30:59.688
    Apr 18 05:30:59.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 05:30:59.689
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:30:59.804
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:30:59.807
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 04/18/23 05:30:59.922
    Apr 18 05:31:00.109: INFO: Waiting up to 5m0s for pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58" in namespace "downward-api-2790" to be "Succeeded or Failed"
    Apr 18 05:31:00.154: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58": Phase="Pending", Reason="", readiness=false. Elapsed: 45.207277ms
    Apr 18 05:31:02.172: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062275443s
    Apr 18 05:31:04.160: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05107496s
    Apr 18 05:31:06.436: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58": Phase="Pending", Reason="", readiness=false. Elapsed: 6.326551262s
    Apr 18 05:31:08.159: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.049676071s
    STEP: Saw pod success 04/18/23 05:31:08.159
    Apr 18 05:31:08.159: INFO: Pod "downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58" satisfied condition "Succeeded or Failed"
    Apr 18 05:31:08.177: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58 container client-container: <nil>
    STEP: delete the pod 04/18/23 05:31:08.183
    Apr 18 05:31:08.247: INFO: Waiting for pod downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58 to disappear
    Apr 18 05:31:08.250: INFO: Pod downwardapi-volume-634c6d12-d8dd-49b7-9497-fbab12fc1b58 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 05:31:08.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2790" for this suite. 04/18/23 05:31:08.255
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:31:08.28
Apr 18 05:31:08.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:31:08.281
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:31:08.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:31:08.416
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-23372a36-98f4-4e33-a501-c7b4a6767f3e 04/18/23 05:31:08.418
STEP: Creating a pod to test consume configMaps 04/18/23 05:31:08.43
Apr 18 05:31:08.454: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff" in namespace "projected-6997" to be "Succeeded or Failed"
Apr 18 05:31:08.458: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.22821ms
Apr 18 05:31:10.462: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007963531s
Apr 18 05:31:12.466: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011403025s
Apr 18 05:31:14.465: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011136956s
Apr 18 05:31:16.463: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.008394087s
STEP: Saw pod success 04/18/23 05:31:16.463
Apr 18 05:31:16.463: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff" satisfied condition "Succeeded or Failed"
Apr 18 05:31:16.466: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:31:16.472
Apr 18 05:31:16.596: INFO: Waiting for pod pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff to disappear
Apr 18 05:31:16.598: INFO: Pod pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 05:31:16.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6997" for this suite. 04/18/23 05:31:16.603
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":215,"skipped":3934,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.393 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:31:08.28
    Apr 18 05:31:08.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:31:08.281
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:31:08.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:31:08.416
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-23372a36-98f4-4e33-a501-c7b4a6767f3e 04/18/23 05:31:08.418
    STEP: Creating a pod to test consume configMaps 04/18/23 05:31:08.43
    Apr 18 05:31:08.454: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff" in namespace "projected-6997" to be "Succeeded or Failed"
    Apr 18 05:31:08.458: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.22821ms
    Apr 18 05:31:10.462: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007963531s
    Apr 18 05:31:12.466: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011403025s
    Apr 18 05:31:14.465: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011136956s
    Apr 18 05:31:16.463: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.008394087s
    STEP: Saw pod success 04/18/23 05:31:16.463
    Apr 18 05:31:16.463: INFO: Pod "pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff" satisfied condition "Succeeded or Failed"
    Apr 18 05:31:16.466: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:31:16.472
    Apr 18 05:31:16.596: INFO: Waiting for pod pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff to disappear
    Apr 18 05:31:16.598: INFO: Pod pod-projected-configmaps-57471aa4-0cee-4c27-be96-af9358ec4eff no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 05:31:16.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6997" for this suite. 04/18/23 05:31:16.603
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:31:16.675
Apr 18 05:31:16.675: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 05:31:16.676
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:31:16.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:31:16.731
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 05:31:16.802
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:31:17.163
STEP: Deploying the webhook pod 04/18/23 05:31:17.235
STEP: Wait for the deployment to be ready 04/18/23 05:31:17.282
Apr 18 05:31:17.372: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Apr 18 05:31:19.382: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 31, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 31, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 31, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 31, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 05:31:21.388
STEP: Verifying the service has paired with the endpoint 04/18/23 05:31:21.424
Apr 18 05:31:22.424: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 04/18/23 05:31:23.249
STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 05:31:23.281
STEP: Deleting the collection of validation webhooks 04/18/23 05:31:23.302
STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 05:31:23.718
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:31:23.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7152" for this suite. 04/18/23 05:31:23.791
STEP: Destroying namespace "webhook-7152-markers" for this suite. 04/18/23 05:31:23.823
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":216,"skipped":3960,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.617 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:31:16.675
    Apr 18 05:31:16.675: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 05:31:16.676
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:31:16.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:31:16.731
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 05:31:16.802
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:31:17.163
    STEP: Deploying the webhook pod 04/18/23 05:31:17.235
    STEP: Wait for the deployment to be ready 04/18/23 05:31:17.282
    Apr 18 05:31:17.372: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Apr 18 05:31:19.382: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 31, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 31, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 31, 17, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 31, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 05:31:21.388
    STEP: Verifying the service has paired with the endpoint 04/18/23 05:31:21.424
    Apr 18 05:31:22.424: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 04/18/23 05:31:23.249
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 05:31:23.281
    STEP: Deleting the collection of validation webhooks 04/18/23 05:31:23.302
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/18/23 05:31:23.718
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:31:23.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7152" for this suite. 04/18/23 05:31:23.791
    STEP: Destroying namespace "webhook-7152-markers" for this suite. 04/18/23 05:31:23.823
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:31:24.294
Apr 18 05:31:24.294: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replicaset 04/18/23 05:31:24.295
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:31:24.692
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:31:24.695
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Apr 18 05:31:24.790: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 18 05:31:29.798: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 05:31:29.798
STEP: Scaling up "test-rs" replicaset  04/18/23 05:31:29.798
Apr 18 05:31:29.865: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 04/18/23 05:31:29.865
W0418 05:31:29.949756      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 18 05:31:29.951: INFO: observed ReplicaSet test-rs in namespace replicaset-8198 with ReadyReplicas 1, AvailableReplicas 1
Apr 18 05:31:30.116: INFO: observed ReplicaSet test-rs in namespace replicaset-8198 with ReadyReplicas 1, AvailableReplicas 1
Apr 18 05:31:30.243: INFO: observed ReplicaSet test-rs in namespace replicaset-8198 with ReadyReplicas 1, AvailableReplicas 1
Apr 18 05:31:30.284: INFO: observed ReplicaSet test-rs in namespace replicaset-8198 with ReadyReplicas 1, AvailableReplicas 1
Apr 18 05:31:33.310: INFO: observed ReplicaSet test-rs in namespace replicaset-8198 with ReadyReplicas 2, AvailableReplicas 2
Apr 18 05:31:34.144: INFO: observed Replicaset test-rs in namespace replicaset-8198 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 05:31:34.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8198" for this suite. 04/18/23 05:31:34.149
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":217,"skipped":4005,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.869 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:31:24.294
    Apr 18 05:31:24.294: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replicaset 04/18/23 05:31:24.295
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:31:24.692
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:31:24.695
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Apr 18 05:31:24.790: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 18 05:31:29.798: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 05:31:29.798
    STEP: Scaling up "test-rs" replicaset  04/18/23 05:31:29.798
    Apr 18 05:31:29.865: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 04/18/23 05:31:29.865
    W0418 05:31:29.949756      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 18 05:31:29.951: INFO: observed ReplicaSet test-rs in namespace replicaset-8198 with ReadyReplicas 1, AvailableReplicas 1
    Apr 18 05:31:30.116: INFO: observed ReplicaSet test-rs in namespace replicaset-8198 with ReadyReplicas 1, AvailableReplicas 1
    Apr 18 05:31:30.243: INFO: observed ReplicaSet test-rs in namespace replicaset-8198 with ReadyReplicas 1, AvailableReplicas 1
    Apr 18 05:31:30.284: INFO: observed ReplicaSet test-rs in namespace replicaset-8198 with ReadyReplicas 1, AvailableReplicas 1
    Apr 18 05:31:33.310: INFO: observed ReplicaSet test-rs in namespace replicaset-8198 with ReadyReplicas 2, AvailableReplicas 2
    Apr 18 05:31:34.144: INFO: observed Replicaset test-rs in namespace replicaset-8198 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 05:31:34.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-8198" for this suite. 04/18/23 05:31:34.149
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:31:34.164
Apr 18 05:31:34.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename var-expansion 04/18/23 05:31:34.165
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:31:34.276
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:31:34.279
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 04/18/23 05:31:34.282
STEP: waiting for pod running 04/18/23 05:31:34.31
Apr 18 05:31:34.310: INFO: Waiting up to 2m0s for pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" in namespace "var-expansion-4961" to be "running"
Apr 18 05:31:34.312: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.586118ms
Apr 18 05:31:36.320: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010490712s
Apr 18 05:31:38.318: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a": Phase="Running", Reason="", readiness=true. Elapsed: 4.008481885s
Apr 18 05:31:38.318: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" satisfied condition "running"
STEP: creating a file in subpath 04/18/23 05:31:38.318
Apr 18 05:31:38.321: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4961 PodName:var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:31:38.321: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:31:38.322: INFO: ExecWithOptions: Clientset creation
Apr 18 05:31:38.322: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-4961/pods/var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 04/18/23 05:31:38.402
Apr 18 05:31:38.405: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4961 PodName:var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:31:38.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:31:38.405: INFO: ExecWithOptions: Clientset creation
Apr 18 05:31:38.406: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-4961/pods/var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 04/18/23 05:31:38.483
Apr 18 05:31:39.050: INFO: Successfully updated pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a"
STEP: waiting for annotated pod running 04/18/23 05:31:39.05
Apr 18 05:31:39.050: INFO: Waiting up to 2m0s for pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" in namespace "var-expansion-4961" to be "running"
Apr 18 05:31:39.059: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a": Phase="Running", Reason="", readiness=true. Elapsed: 8.967208ms
Apr 18 05:31:39.059: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" satisfied condition "running"
STEP: deleting the pod gracefully 04/18/23 05:31:39.059
Apr 18 05:31:39.060: INFO: Deleting pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" in namespace "var-expansion-4961"
Apr 18 05:31:39.110: INFO: Wait up to 5m0s for pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 05:32:13.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4961" for this suite. 04/18/23 05:32:13.123
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":218,"skipped":4012,"failed":0}
------------------------------
â€¢ [SLOW TEST] [38.999 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:31:34.164
    Apr 18 05:31:34.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename var-expansion 04/18/23 05:31:34.165
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:31:34.276
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:31:34.279
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 04/18/23 05:31:34.282
    STEP: waiting for pod running 04/18/23 05:31:34.31
    Apr 18 05:31:34.310: INFO: Waiting up to 2m0s for pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" in namespace "var-expansion-4961" to be "running"
    Apr 18 05:31:34.312: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.586118ms
    Apr 18 05:31:36.320: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010490712s
    Apr 18 05:31:38.318: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a": Phase="Running", Reason="", readiness=true. Elapsed: 4.008481885s
    Apr 18 05:31:38.318: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" satisfied condition "running"
    STEP: creating a file in subpath 04/18/23 05:31:38.318
    Apr 18 05:31:38.321: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4961 PodName:var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:31:38.321: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:31:38.322: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:31:38.322: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-4961/pods/var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 04/18/23 05:31:38.402
    Apr 18 05:31:38.405: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4961 PodName:var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:31:38.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:31:38.405: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:31:38.406: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/var-expansion-4961/pods/var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 04/18/23 05:31:38.483
    Apr 18 05:31:39.050: INFO: Successfully updated pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a"
    STEP: waiting for annotated pod running 04/18/23 05:31:39.05
    Apr 18 05:31:39.050: INFO: Waiting up to 2m0s for pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" in namespace "var-expansion-4961" to be "running"
    Apr 18 05:31:39.059: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a": Phase="Running", Reason="", readiness=true. Elapsed: 8.967208ms
    Apr 18 05:31:39.059: INFO: Pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" satisfied condition "running"
    STEP: deleting the pod gracefully 04/18/23 05:31:39.059
    Apr 18 05:31:39.060: INFO: Deleting pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" in namespace "var-expansion-4961"
    Apr 18 05:31:39.110: INFO: Wait up to 5m0s for pod "var-expansion-1304bda2-2686-4081-bd0e-30c5d4c4504a" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 05:32:13.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4961" for this suite. 04/18/23 05:32:13.123
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:32:13.164
Apr 18 05:32:13.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:32:13.165
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:13.295
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:13.298
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-5edab6df-9b7f-43c1-a394-2e4b6cb6b244 04/18/23 05:32:13.446
STEP: Creating secret with name secret-projected-all-test-volume-d51b57bb-6f4d-478c-9b84-804d2440fe53 04/18/23 05:32:13.463
STEP: Creating a pod to test Check all projections for projected volume plugin 04/18/23 05:32:13.471
Apr 18 05:32:13.569: INFO: Waiting up to 5m0s for pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511" in namespace "projected-3998" to be "Succeeded or Failed"
Apr 18 05:32:13.584: INFO: Pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511": Phase="Pending", Reason="", readiness=false. Elapsed: 15.099652ms
Apr 18 05:32:15.597: INFO: Pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027862742s
Apr 18 05:32:17.588: INFO: Pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019724938s
Apr 18 05:32:19.589: INFO: Pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020379777s
STEP: Saw pod success 04/18/23 05:32:19.589
Apr 18 05:32:19.589: INFO: Pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511" satisfied condition "Succeeded or Failed"
Apr 18 05:32:19.593: INFO: Trying to get logs from node apps-208 pod projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511 container projected-all-volume-test: <nil>
STEP: delete the pod 04/18/23 05:32:19.618
Apr 18 05:32:19.714: INFO: Waiting for pod projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511 to disappear
Apr 18 05:32:19.761: INFO: Pod projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511 no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Apr 18 05:32:19.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3998" for this suite. 04/18/23 05:32:19.817
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":219,"skipped":4036,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.691 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:32:13.164
    Apr 18 05:32:13.164: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:32:13.165
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:13.295
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:13.298
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-5edab6df-9b7f-43c1-a394-2e4b6cb6b244 04/18/23 05:32:13.446
    STEP: Creating secret with name secret-projected-all-test-volume-d51b57bb-6f4d-478c-9b84-804d2440fe53 04/18/23 05:32:13.463
    STEP: Creating a pod to test Check all projections for projected volume plugin 04/18/23 05:32:13.471
    Apr 18 05:32:13.569: INFO: Waiting up to 5m0s for pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511" in namespace "projected-3998" to be "Succeeded or Failed"
    Apr 18 05:32:13.584: INFO: Pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511": Phase="Pending", Reason="", readiness=false. Elapsed: 15.099652ms
    Apr 18 05:32:15.597: INFO: Pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027862742s
    Apr 18 05:32:17.588: INFO: Pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019724938s
    Apr 18 05:32:19.589: INFO: Pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020379777s
    STEP: Saw pod success 04/18/23 05:32:19.589
    Apr 18 05:32:19.589: INFO: Pod "projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511" satisfied condition "Succeeded or Failed"
    Apr 18 05:32:19.593: INFO: Trying to get logs from node apps-208 pod projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511 container projected-all-volume-test: <nil>
    STEP: delete the pod 04/18/23 05:32:19.618
    Apr 18 05:32:19.714: INFO: Waiting for pod projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511 to disappear
    Apr 18 05:32:19.761: INFO: Pod projected-volume-fe7ae1b1-86d9-4d7d-b68d-8692dd1e6511 no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Apr 18 05:32:19.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3998" for this suite. 04/18/23 05:32:19.817
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:32:19.855
Apr 18 05:32:19.856: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 05:32:19.856
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:20.021
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:20.024
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 04/18/23 05:32:20.026
STEP: setting up watch 04/18/23 05:32:20.027
STEP: submitting the pod to kubernetes 04/18/23 05:32:20.13
STEP: verifying the pod is in kubernetes 04/18/23 05:32:20.167
STEP: verifying pod creation was observed 04/18/23 05:32:20.169
Apr 18 05:32:20.170: INFO: Waiting up to 5m0s for pod "pod-submit-remove-4d60270b-7b3a-4e8e-beb5-0acdbaa14f2f" in namespace "pods-7192" to be "running"
Apr 18 05:32:20.266: INFO: Pod "pod-submit-remove-4d60270b-7b3a-4e8e-beb5-0acdbaa14f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 96.276015ms
Apr 18 05:32:22.281: INFO: Pod "pod-submit-remove-4d60270b-7b3a-4e8e-beb5-0acdbaa14f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.111308972s
Apr 18 05:32:24.290: INFO: Pod "pod-submit-remove-4d60270b-7b3a-4e8e-beb5-0acdbaa14f2f": Phase="Running", Reason="", readiness=true. Elapsed: 4.120625803s
Apr 18 05:32:24.290: INFO: Pod "pod-submit-remove-4d60270b-7b3a-4e8e-beb5-0acdbaa14f2f" satisfied condition "running"
STEP: deleting the pod gracefully 04/18/23 05:32:24.294
STEP: verifying pod deletion was observed 04/18/23 05:32:24.34
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 05:32:27.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7192" for this suite. 04/18/23 05:32:27.297
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":220,"skipped":4056,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.456 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:32:19.855
    Apr 18 05:32:19.856: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 05:32:19.856
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:20.021
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:20.024
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 04/18/23 05:32:20.026
    STEP: setting up watch 04/18/23 05:32:20.027
    STEP: submitting the pod to kubernetes 04/18/23 05:32:20.13
    STEP: verifying the pod is in kubernetes 04/18/23 05:32:20.167
    STEP: verifying pod creation was observed 04/18/23 05:32:20.169
    Apr 18 05:32:20.170: INFO: Waiting up to 5m0s for pod "pod-submit-remove-4d60270b-7b3a-4e8e-beb5-0acdbaa14f2f" in namespace "pods-7192" to be "running"
    Apr 18 05:32:20.266: INFO: Pod "pod-submit-remove-4d60270b-7b3a-4e8e-beb5-0acdbaa14f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 96.276015ms
    Apr 18 05:32:22.281: INFO: Pod "pod-submit-remove-4d60270b-7b3a-4e8e-beb5-0acdbaa14f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.111308972s
    Apr 18 05:32:24.290: INFO: Pod "pod-submit-remove-4d60270b-7b3a-4e8e-beb5-0acdbaa14f2f": Phase="Running", Reason="", readiness=true. Elapsed: 4.120625803s
    Apr 18 05:32:24.290: INFO: Pod "pod-submit-remove-4d60270b-7b3a-4e8e-beb5-0acdbaa14f2f" satisfied condition "running"
    STEP: deleting the pod gracefully 04/18/23 05:32:24.294
    STEP: verifying pod deletion was observed 04/18/23 05:32:24.34
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 05:32:27.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7192" for this suite. 04/18/23 05:32:27.297
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:32:27.311
Apr 18 05:32:27.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 05:32:27.312
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:27.463
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:27.466
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-9c9572aa-9eac-4ec4-be01-e66c9d763a6d 04/18/23 05:32:27.47
STEP: Creating a pod to test consume secrets 04/18/23 05:32:27.537
Apr 18 05:32:27.603: INFO: Waiting up to 5m0s for pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2" in namespace "secrets-6792" to be "Succeeded or Failed"
Apr 18 05:32:27.623: INFO: Pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2": Phase="Pending", Reason="", readiness=false. Elapsed: 19.903579ms
Apr 18 05:32:29.648: INFO: Pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044679536s
Apr 18 05:32:31.628: INFO: Pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024934409s
Apr 18 05:32:33.628: INFO: Pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025181314s
STEP: Saw pod success 04/18/23 05:32:33.628
Apr 18 05:32:33.629: INFO: Pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2" satisfied condition "Succeeded or Failed"
Apr 18 05:32:33.631: INFO: Trying to get logs from node apps-208 pod pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 05:32:33.638
Apr 18 05:32:33.800: INFO: Waiting for pod pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2 to disappear
Apr 18 05:32:33.823: INFO: Pod pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 05:32:33.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6792" for this suite. 04/18/23 05:32:33.827
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":221,"skipped":4058,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.596 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:32:27.311
    Apr 18 05:32:27.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 05:32:27.312
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:27.463
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:27.466
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-9c9572aa-9eac-4ec4-be01-e66c9d763a6d 04/18/23 05:32:27.47
    STEP: Creating a pod to test consume secrets 04/18/23 05:32:27.537
    Apr 18 05:32:27.603: INFO: Waiting up to 5m0s for pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2" in namespace "secrets-6792" to be "Succeeded or Failed"
    Apr 18 05:32:27.623: INFO: Pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2": Phase="Pending", Reason="", readiness=false. Elapsed: 19.903579ms
    Apr 18 05:32:29.648: INFO: Pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044679536s
    Apr 18 05:32:31.628: INFO: Pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024934409s
    Apr 18 05:32:33.628: INFO: Pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025181314s
    STEP: Saw pod success 04/18/23 05:32:33.628
    Apr 18 05:32:33.629: INFO: Pod "pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2" satisfied condition "Succeeded or Failed"
    Apr 18 05:32:33.631: INFO: Trying to get logs from node apps-208 pod pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 05:32:33.638
    Apr 18 05:32:33.800: INFO: Waiting for pod pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2 to disappear
    Apr 18 05:32:33.823: INFO: Pod pod-secrets-b87e3186-a47e-4d18-9be5-9d607a9714b2 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 05:32:33.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6792" for this suite. 04/18/23 05:32:33.827
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:32:33.907
Apr 18 05:32:33.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename watch 04/18/23 05:32:33.908
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:34.015
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:34.018
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 04/18/23 05:32:34.058
STEP: creating a new configmap 04/18/23 05:32:34.059
STEP: modifying the configmap once 04/18/23 05:32:34.07
STEP: changing the label value of the configmap 04/18/23 05:32:34.23
STEP: Expecting to observe a delete notification for the watched object 04/18/23 05:32:34.257
Apr 18 05:32:34.257: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4113992 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:32:34.257: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4113993 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:32:34.258: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4113994 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 04/18/23 05:32:34.258
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/18/23 05:32:34.383
STEP: changing the label value of the configmap back 04/18/23 05:32:44.383
STEP: modifying the configmap a third time 04/18/23 05:32:44.455
STEP: deleting the configmap 04/18/23 05:32:44.475
STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/18/23 05:32:44.574
Apr 18 05:32:44.574: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4114040 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:32:44.574: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4114041 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:32:44.575: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4114042 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 18 05:32:44.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2724" for this suite. 04/18/23 05:32:44.611
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":222,"skipped":4059,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.722 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:32:33.907
    Apr 18 05:32:33.907: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename watch 04/18/23 05:32:33.908
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:34.015
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:34.018
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 04/18/23 05:32:34.058
    STEP: creating a new configmap 04/18/23 05:32:34.059
    STEP: modifying the configmap once 04/18/23 05:32:34.07
    STEP: changing the label value of the configmap 04/18/23 05:32:34.23
    STEP: Expecting to observe a delete notification for the watched object 04/18/23 05:32:34.257
    Apr 18 05:32:34.257: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4113992 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:32:34.257: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4113993 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:32:34.258: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4113994 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 04/18/23 05:32:34.258
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/18/23 05:32:34.383
    STEP: changing the label value of the configmap back 04/18/23 05:32:44.383
    STEP: modifying the configmap a third time 04/18/23 05:32:44.455
    STEP: deleting the configmap 04/18/23 05:32:44.475
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/18/23 05:32:44.574
    Apr 18 05:32:44.574: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4114040 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:32:44.574: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4114041 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:32:44.575: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2724  886a7571-ca57-48a7-a5ca-d2293ba65c0c 4114042 0 2023-04-18 05:32:34 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 18 05:32:44.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2724" for this suite. 04/18/23 05:32:44.611
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:32:44.63
Apr 18 05:32:44.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename watch 04/18/23 05:32:44.631
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:44.73
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:44.732
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 04/18/23 05:32:44.741
STEP: creating a new configmap 04/18/23 05:32:44.743
STEP: modifying the configmap once 04/18/23 05:32:44.75
STEP: closing the watch once it receives two notifications 04/18/23 05:32:44.771
Apr 18 05:32:44.772: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5786  6ca28e3f-ecaf-463d-bbdf-ae5d03cd551e 4114049 0 2023-04-18 05:32:44 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:32:44.772: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5786  6ca28e3f-ecaf-463d-bbdf-ae5d03cd551e 4114050 0 2023-04-18 05:32:44 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 04/18/23 05:32:44.772
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/18/23 05:32:44.783
STEP: deleting the configmap 04/18/23 05:32:44.784
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/18/23 05:32:44.897
Apr 18 05:32:44.897: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5786  6ca28e3f-ecaf-463d-bbdf-ae5d03cd551e 4114051 0 2023-04-18 05:32:44 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:32:44.897: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5786  6ca28e3f-ecaf-463d-bbdf-ae5d03cd551e 4114052 0 2023-04-18 05:32:44 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 18 05:32:44.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5786" for this suite. 04/18/23 05:32:44.901
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":223,"skipped":4063,"failed":0}
------------------------------
â€¢ [0.296 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:32:44.63
    Apr 18 05:32:44.630: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename watch 04/18/23 05:32:44.631
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:44.73
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:44.732
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 04/18/23 05:32:44.741
    STEP: creating a new configmap 04/18/23 05:32:44.743
    STEP: modifying the configmap once 04/18/23 05:32:44.75
    STEP: closing the watch once it receives two notifications 04/18/23 05:32:44.771
    Apr 18 05:32:44.772: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5786  6ca28e3f-ecaf-463d-bbdf-ae5d03cd551e 4114049 0 2023-04-18 05:32:44 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:32:44.772: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5786  6ca28e3f-ecaf-463d-bbdf-ae5d03cd551e 4114050 0 2023-04-18 05:32:44 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 04/18/23 05:32:44.772
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/18/23 05:32:44.783
    STEP: deleting the configmap 04/18/23 05:32:44.784
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/18/23 05:32:44.897
    Apr 18 05:32:44.897: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5786  6ca28e3f-ecaf-463d-bbdf-ae5d03cd551e 4114051 0 2023-04-18 05:32:44 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:32:44.897: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5786  6ca28e3f-ecaf-463d-bbdf-ae5d03cd551e 4114052 0 2023-04-18 05:32:44 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-04-18 05:32:44 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 18 05:32:44.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-5786" for this suite. 04/18/23 05:32:44.901
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:32:44.927
Apr 18 05:32:44.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-probe 04/18/23 05:32:44.928
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:45.05
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:45.053
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb in namespace container-probe-9776 04/18/23 05:32:45.072
Apr 18 05:32:45.125: INFO: Waiting up to 5m0s for pod "liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb" in namespace "container-probe-9776" to be "not pending"
Apr 18 05:32:45.127: INFO: Pod "liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.503151ms
Apr 18 05:32:47.184: INFO: Pod "liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059118892s
Apr 18 05:32:49.132: INFO: Pod "liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb": Phase="Running", Reason="", readiness=true. Elapsed: 4.007283686s
Apr 18 05:32:49.132: INFO: Pod "liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb" satisfied condition "not pending"
Apr 18 05:32:49.132: INFO: Started pod liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb in namespace container-probe-9776
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 05:32:49.132
Apr 18 05:32:49.136: INFO: Initial restart count of pod liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is 0
Apr 18 05:33:09.275: INFO: Restart count of pod container-probe-9776/liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is now 1 (20.139497858s elapsed)
Apr 18 05:33:27.362: INFO: Restart count of pod container-probe-9776/liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is now 2 (38.226746396s elapsed)
Apr 18 05:33:47.416: INFO: Restart count of pod container-probe-9776/liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is now 3 (58.280428889s elapsed)
Apr 18 05:34:07.468: INFO: Restart count of pod container-probe-9776/liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is now 4 (1m18.332225334s elapsed)
Apr 18 05:35:18.030: INFO: Restart count of pod container-probe-9776/liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is now 5 (2m28.894023465s elapsed)
STEP: deleting the pod 04/18/23 05:35:18.03
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 05:35:18.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9776" for this suite. 04/18/23 05:35:18.228
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":224,"skipped":4090,"failed":0}
------------------------------
â€¢ [SLOW TEST] [153.312 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:32:44.927
    Apr 18 05:32:44.927: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-probe 04/18/23 05:32:44.928
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:32:45.05
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:32:45.053
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb in namespace container-probe-9776 04/18/23 05:32:45.072
    Apr 18 05:32:45.125: INFO: Waiting up to 5m0s for pod "liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb" in namespace "container-probe-9776" to be "not pending"
    Apr 18 05:32:45.127: INFO: Pod "liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.503151ms
    Apr 18 05:32:47.184: INFO: Pod "liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059118892s
    Apr 18 05:32:49.132: INFO: Pod "liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb": Phase="Running", Reason="", readiness=true. Elapsed: 4.007283686s
    Apr 18 05:32:49.132: INFO: Pod "liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb" satisfied condition "not pending"
    Apr 18 05:32:49.132: INFO: Started pod liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb in namespace container-probe-9776
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 05:32:49.132
    Apr 18 05:32:49.136: INFO: Initial restart count of pod liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is 0
    Apr 18 05:33:09.275: INFO: Restart count of pod container-probe-9776/liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is now 1 (20.139497858s elapsed)
    Apr 18 05:33:27.362: INFO: Restart count of pod container-probe-9776/liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is now 2 (38.226746396s elapsed)
    Apr 18 05:33:47.416: INFO: Restart count of pod container-probe-9776/liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is now 3 (58.280428889s elapsed)
    Apr 18 05:34:07.468: INFO: Restart count of pod container-probe-9776/liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is now 4 (1m18.332225334s elapsed)
    Apr 18 05:35:18.030: INFO: Restart count of pod container-probe-9776/liveness-cd6d6520-eca0-4806-a360-dfc3663fcfcb is now 5 (2m28.894023465s elapsed)
    STEP: deleting the pod 04/18/23 05:35:18.03
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 05:35:18.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9776" for this suite. 04/18/23 05:35:18.228
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:35:18.242
Apr 18 05:35:18.242: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir-wrapper 04/18/23 05:35:18.243
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:35:18.342
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:35:18.345
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Apr 18 05:35:18.532: INFO: Waiting up to 5m0s for pod "pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638" in namespace "emptydir-wrapper-7297" to be "running and ready"
Apr 18 05:35:18.535: INFO: Pod "pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638": Phase="Pending", Reason="", readiness=false. Elapsed: 2.614569ms
Apr 18 05:35:18.535: INFO: The phase of Pod pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:35:20.540: INFO: Pod "pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007729227s
Apr 18 05:35:20.540: INFO: The phase of Pod pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:35:22.564: INFO: Pod "pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638": Phase="Running", Reason="", readiness=true. Elapsed: 4.031806727s
Apr 18 05:35:22.564: INFO: The phase of Pod pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638 is Running (Ready = true)
Apr 18 05:35:22.564: INFO: Pod "pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638" satisfied condition "running and ready"
STEP: Cleaning up the secret 04/18/23 05:35:22.583
STEP: Cleaning up the configmap 04/18/23 05:35:22.61
STEP: Cleaning up the pod 04/18/23 05:35:22.643
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Apr 18 05:35:22.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7297" for this suite. 04/18/23 05:35:22.849
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":225,"skipped":4105,"failed":0}
------------------------------
â€¢ [4.701 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:35:18.242
    Apr 18 05:35:18.242: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir-wrapper 04/18/23 05:35:18.243
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:35:18.342
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:35:18.345
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Apr 18 05:35:18.532: INFO: Waiting up to 5m0s for pod "pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638" in namespace "emptydir-wrapper-7297" to be "running and ready"
    Apr 18 05:35:18.535: INFO: Pod "pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638": Phase="Pending", Reason="", readiness=false. Elapsed: 2.614569ms
    Apr 18 05:35:18.535: INFO: The phase of Pod pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:35:20.540: INFO: Pod "pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007729227s
    Apr 18 05:35:20.540: INFO: The phase of Pod pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:35:22.564: INFO: Pod "pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638": Phase="Running", Reason="", readiness=true. Elapsed: 4.031806727s
    Apr 18 05:35:22.564: INFO: The phase of Pod pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638 is Running (Ready = true)
    Apr 18 05:35:22.564: INFO: Pod "pod-secrets-c9dce54a-e414-468c-8e17-fdba54f52638" satisfied condition "running and ready"
    STEP: Cleaning up the secret 04/18/23 05:35:22.583
    STEP: Cleaning up the configmap 04/18/23 05:35:22.61
    STEP: Cleaning up the pod 04/18/23 05:35:22.643
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Apr 18 05:35:22.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-7297" for this suite. 04/18/23 05:35:22.849
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:35:22.945
Apr 18 05:35:22.945: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename gc 04/18/23 05:35:22.946
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:35:23.124
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:35:23.127
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 04/18/23 05:35:23.163
STEP: Wait for the Deployment to create new ReplicaSet 04/18/23 05:35:23.185
STEP: delete the deployment 04/18/23 05:35:24.43
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/18/23 05:35:24.511
STEP: Gathering metrics 04/18/23 05:35:25.238
Apr 18 05:35:25.265: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
Apr 18 05:35:25.268: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 3.058318ms
Apr 18 05:35:25.268: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
Apr 18 05:35:25.268: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
Apr 18 05:35:25.318: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 05:35:25.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5249" for this suite. 04/18/23 05:35:25.33
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":226,"skipped":4131,"failed":0}
------------------------------
â€¢ [2.458 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:35:22.945
    Apr 18 05:35:22.945: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename gc 04/18/23 05:35:22.946
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:35:23.124
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:35:23.127
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 04/18/23 05:35:23.163
    STEP: Wait for the Deployment to create new ReplicaSet 04/18/23 05:35:23.185
    STEP: delete the deployment 04/18/23 05:35:24.43
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/18/23 05:35:24.511
    STEP: Gathering metrics 04/18/23 05:35:25.238
    Apr 18 05:35:25.265: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
    Apr 18 05:35:25.268: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 3.058318ms
    Apr 18 05:35:25.268: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
    Apr 18 05:35:25.268: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
    Apr 18 05:35:25.318: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 05:35:25.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5249" for this suite. 04/18/23 05:35:25.33
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:35:25.403
Apr 18 05:35:25.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename var-expansion 04/18/23 05:35:25.404
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:35:25.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:35:25.454
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 04/18/23 05:35:25.489
Apr 18 05:35:25.586: INFO: Waiting up to 5m0s for pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c" in namespace "var-expansion-2255" to be "Succeeded or Failed"
Apr 18 05:35:25.602: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.717842ms
Apr 18 05:35:27.698: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.111166172s
Apr 18 05:35:29.647: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c": Phase="Running", Reason="", readiness=true. Elapsed: 4.060233965s
Apr 18 05:35:31.607: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c": Phase="Running", Reason="", readiness=false. Elapsed: 6.020148461s
Apr 18 05:35:33.607: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020391787s
STEP: Saw pod success 04/18/23 05:35:33.607
Apr 18 05:35:33.607: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c" satisfied condition "Succeeded or Failed"
Apr 18 05:35:33.610: INFO: Trying to get logs from node apps-208 pod var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c container dapi-container: <nil>
STEP: delete the pod 04/18/23 05:35:33.623
Apr 18 05:35:33.771: INFO: Waiting for pod var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c to disappear
Apr 18 05:35:33.774: INFO: Pod var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 05:35:33.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2255" for this suite. 04/18/23 05:35:33.779
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":227,"skipped":4138,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.468 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:35:25.403
    Apr 18 05:35:25.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename var-expansion 04/18/23 05:35:25.404
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:35:25.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:35:25.454
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 04/18/23 05:35:25.489
    Apr 18 05:35:25.586: INFO: Waiting up to 5m0s for pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c" in namespace "var-expansion-2255" to be "Succeeded or Failed"
    Apr 18 05:35:25.602: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.717842ms
    Apr 18 05:35:27.698: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.111166172s
    Apr 18 05:35:29.647: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c": Phase="Running", Reason="", readiness=true. Elapsed: 4.060233965s
    Apr 18 05:35:31.607: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c": Phase="Running", Reason="", readiness=false. Elapsed: 6.020148461s
    Apr 18 05:35:33.607: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020391787s
    STEP: Saw pod success 04/18/23 05:35:33.607
    Apr 18 05:35:33.607: INFO: Pod "var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c" satisfied condition "Succeeded or Failed"
    Apr 18 05:35:33.610: INFO: Trying to get logs from node apps-208 pod var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c container dapi-container: <nil>
    STEP: delete the pod 04/18/23 05:35:33.623
    Apr 18 05:35:33.771: INFO: Waiting for pod var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c to disappear
    Apr 18 05:35:33.774: INFO: Pod var-expansion-f4b23333-c818-41ec-8d2d-6163c2e89b8c no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 05:35:33.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2255" for this suite. 04/18/23 05:35:33.779
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:35:33.872
Apr 18 05:35:33.873: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename daemonsets 04/18/23 05:35:33.873
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:35:33.928
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:35:33.93
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Apr 18 05:35:34.043: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 05:35:34.054
Apr 18 05:35:34.060: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:35:34.060: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:35:35.168: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:35:35.168: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:35:36.164: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:35:36.164: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:35:37.197: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 05:35:37.197: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:35:38.112: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 05:35:38.112: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 04/18/23 05:35:38.124
STEP: Check that daemon pods images are updated. 04/18/23 05:35:38.167
Apr 18 05:35:38.188: INFO: Wrong image for pod: daemon-set-62krn. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:38.188: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:38.188: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:39.263: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:39.263: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:40.196: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:40.196: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:41.332: INFO: Pod daemon-set-76h87 is not available
Apr 18 05:35:41.332: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:41.332: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:42.261: INFO: Pod daemon-set-76h87 is not available
Apr 18 05:35:42.261: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:42.261: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:43.198: INFO: Pod daemon-set-76h87 is not available
Apr 18 05:35:43.198: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:43.198: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:44.250: INFO: Pod daemon-set-76h87 is not available
Apr 18 05:35:44.250: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:44.250: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:45.198: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:46.197: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:47.233: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:48.197: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:48.197: INFO: Pod daemon-set-th2b6 is not available
Apr 18 05:35:49.197: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:49.197: INFO: Pod daemon-set-th2b6 is not available
Apr 18 05:35:50.198: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 18 05:35:50.198: INFO: Pod daemon-set-th2b6 is not available
Apr 18 05:35:53.197: INFO: Pod daemon-set-4ghxz is not available
STEP: Check that daemon pods are still running on every node of the cluster. 04/18/23 05:35:53.201
Apr 18 05:35:53.209: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 05:35:53.209: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:35:54.354: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 05:35:54.354: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:35:55.264: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 05:35:55.264: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:35:56.219: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 05:35:56.219: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 05:35:56.233
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3950, will wait for the garbage collector to delete the pods 04/18/23 05:35:56.233
Apr 18 05:35:56.321: INFO: Deleting DaemonSet.extensions daemon-set took: 34.235538ms
Apr 18 05:35:56.421: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.248925ms
Apr 18 05:35:59.299: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:35:59.299: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 05:35:59.302: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4115007"},"items":null}

Apr 18 05:35:59.305: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4115007"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:35:59.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3950" for this suite. 04/18/23 05:35:59.322
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":228,"skipped":4153,"failed":0}
------------------------------
â€¢ [SLOW TEST] [25.509 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:35:33.872
    Apr 18 05:35:33.873: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename daemonsets 04/18/23 05:35:33.873
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:35:33.928
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:35:33.93
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Apr 18 05:35:34.043: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 05:35:34.054
    Apr 18 05:35:34.060: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:35:34.060: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:35:35.168: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:35:35.168: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:35:36.164: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:35:36.164: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:35:37.197: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 05:35:37.197: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:35:38.112: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 05:35:38.112: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 04/18/23 05:35:38.124
    STEP: Check that daemon pods images are updated. 04/18/23 05:35:38.167
    Apr 18 05:35:38.188: INFO: Wrong image for pod: daemon-set-62krn. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:38.188: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:38.188: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:39.263: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:39.263: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:40.196: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:40.196: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:41.332: INFO: Pod daemon-set-76h87 is not available
    Apr 18 05:35:41.332: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:41.332: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:42.261: INFO: Pod daemon-set-76h87 is not available
    Apr 18 05:35:42.261: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:42.261: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:43.198: INFO: Pod daemon-set-76h87 is not available
    Apr 18 05:35:43.198: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:43.198: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:44.250: INFO: Pod daemon-set-76h87 is not available
    Apr 18 05:35:44.250: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:44.250: INFO: Wrong image for pod: daemon-set-h5fns. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:45.198: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:46.197: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:47.233: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:48.197: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:48.197: INFO: Pod daemon-set-th2b6 is not available
    Apr 18 05:35:49.197: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:49.197: INFO: Pod daemon-set-th2b6 is not available
    Apr 18 05:35:50.198: INFO: Wrong image for pod: daemon-set-gqrpk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 18 05:35:50.198: INFO: Pod daemon-set-th2b6 is not available
    Apr 18 05:35:53.197: INFO: Pod daemon-set-4ghxz is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 04/18/23 05:35:53.201
    Apr 18 05:35:53.209: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 05:35:53.209: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:35:54.354: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 05:35:54.354: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:35:55.264: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 05:35:55.264: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:35:56.219: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 05:35:56.219: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 05:35:56.233
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3950, will wait for the garbage collector to delete the pods 04/18/23 05:35:56.233
    Apr 18 05:35:56.321: INFO: Deleting DaemonSet.extensions daemon-set took: 34.235538ms
    Apr 18 05:35:56.421: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.248925ms
    Apr 18 05:35:59.299: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:35:59.299: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 05:35:59.302: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4115007"},"items":null}

    Apr 18 05:35:59.305: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4115007"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:35:59.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3950" for this suite. 04/18/23 05:35:59.322
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:35:59.382
Apr 18 05:35:59.382: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename ingress 04/18/23 05:35:59.383
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:35:59.501
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:35:59.503
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 04/18/23 05:35:59.554
STEP: getting /apis/networking.k8s.io 04/18/23 05:35:59.556
STEP: getting /apis/networking.k8s.iov1 04/18/23 05:35:59.557
STEP: creating 04/18/23 05:35:59.558
STEP: getting 04/18/23 05:35:59.715
STEP: listing 04/18/23 05:35:59.718
STEP: watching 04/18/23 05:35:59.769
Apr 18 05:35:59.770: INFO: starting watch
STEP: cluster-wide listing 04/18/23 05:35:59.771
STEP: cluster-wide watching 04/18/23 05:35:59.774
Apr 18 05:35:59.774: INFO: starting watch
STEP: patching 04/18/23 05:35:59.775
STEP: updating 04/18/23 05:35:59.818
Apr 18 05:35:59.863: INFO: waiting for watch events with expected annotations
Apr 18 05:35:59.863: INFO: saw patched and updated annotations
STEP: patching /status 04/18/23 05:35:59.863
STEP: updating /status 04/18/23 05:35:59.889
STEP: get /status 04/18/23 05:36:00.013
STEP: deleting 04/18/23 05:36:00.016
STEP: deleting a collection 04/18/23 05:36:00.1
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Apr 18 05:36:00.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-6145" for this suite. 04/18/23 05:36:00.248
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":229,"skipped":4155,"failed":0}
------------------------------
â€¢ [0.948 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:35:59.382
    Apr 18 05:35:59.382: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename ingress 04/18/23 05:35:59.383
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:35:59.501
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:35:59.503
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 04/18/23 05:35:59.554
    STEP: getting /apis/networking.k8s.io 04/18/23 05:35:59.556
    STEP: getting /apis/networking.k8s.iov1 04/18/23 05:35:59.557
    STEP: creating 04/18/23 05:35:59.558
    STEP: getting 04/18/23 05:35:59.715
    STEP: listing 04/18/23 05:35:59.718
    STEP: watching 04/18/23 05:35:59.769
    Apr 18 05:35:59.770: INFO: starting watch
    STEP: cluster-wide listing 04/18/23 05:35:59.771
    STEP: cluster-wide watching 04/18/23 05:35:59.774
    Apr 18 05:35:59.774: INFO: starting watch
    STEP: patching 04/18/23 05:35:59.775
    STEP: updating 04/18/23 05:35:59.818
    Apr 18 05:35:59.863: INFO: waiting for watch events with expected annotations
    Apr 18 05:35:59.863: INFO: saw patched and updated annotations
    STEP: patching /status 04/18/23 05:35:59.863
    STEP: updating /status 04/18/23 05:35:59.889
    STEP: get /status 04/18/23 05:36:00.013
    STEP: deleting 04/18/23 05:36:00.016
    STEP: deleting a collection 04/18/23 05:36:00.1
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Apr 18 05:36:00.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-6145" for this suite. 04/18/23 05:36:00.248
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:36:00.331
Apr 18 05:36:00.331: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:36:00.332
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:36:00.375
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:36:00.377
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-8afe4ff3-7bc9-4515-bf48-9ffab3a60a81 04/18/23 05:36:00.38
STEP: Creating a pod to test consume secrets 04/18/23 05:36:00.449
Apr 18 05:36:00.618: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657" in namespace "projected-5202" to be "Succeeded or Failed"
Apr 18 05:36:00.620: INFO: Pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657": Phase="Pending", Reason="", readiness=false. Elapsed: 2.500684ms
Apr 18 05:36:02.636: INFO: Pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017733095s
Apr 18 05:36:04.625: INFO: Pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657": Phase="Running", Reason="", readiness=false. Elapsed: 4.007383071s
Apr 18 05:36:06.640: INFO: Pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022317841s
STEP: Saw pod success 04/18/23 05:36:06.64
Apr 18 05:36:06.640: INFO: Pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657" satisfied condition "Succeeded or Failed"
Apr 18 05:36:06.649: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/18/23 05:36:06.69
Apr 18 05:36:06.875: INFO: Waiting for pod pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657 to disappear
Apr 18 05:36:06.878: INFO: Pod pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 18 05:36:06.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5202" for this suite. 04/18/23 05:36:06.9
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":230,"skipped":4189,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.702 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:36:00.331
    Apr 18 05:36:00.331: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:36:00.332
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:36:00.375
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:36:00.377
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-8afe4ff3-7bc9-4515-bf48-9ffab3a60a81 04/18/23 05:36:00.38
    STEP: Creating a pod to test consume secrets 04/18/23 05:36:00.449
    Apr 18 05:36:00.618: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657" in namespace "projected-5202" to be "Succeeded or Failed"
    Apr 18 05:36:00.620: INFO: Pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657": Phase="Pending", Reason="", readiness=false. Elapsed: 2.500684ms
    Apr 18 05:36:02.636: INFO: Pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017733095s
    Apr 18 05:36:04.625: INFO: Pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657": Phase="Running", Reason="", readiness=false. Elapsed: 4.007383071s
    Apr 18 05:36:06.640: INFO: Pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022317841s
    STEP: Saw pod success 04/18/23 05:36:06.64
    Apr 18 05:36:06.640: INFO: Pod "pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657" satisfied condition "Succeeded or Failed"
    Apr 18 05:36:06.649: INFO: Trying to get logs from node apps-208 pod pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 05:36:06.69
    Apr 18 05:36:06.875: INFO: Waiting for pod pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657 to disappear
    Apr 18 05:36:06.878: INFO: Pod pod-projected-secrets-f584ba8c-f80b-48f4-8f44-bf2ad6633657 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 18 05:36:06.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5202" for this suite. 04/18/23 05:36:06.9
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:36:07.036
Apr 18 05:36:07.036: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 05:36:07.037
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:36:07.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:36:07.18
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 05:36:07.233
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:36:08.304
STEP: Deploying the webhook pod 04/18/23 05:36:08.339
STEP: Wait for the deployment to be ready 04/18/23 05:36:08.456
Apr 18 05:36:08.492: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 18 05:36:10.502: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 36, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 36, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 36, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 36, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 05:36:12.52
STEP: Verifying the service has paired with the endpoint 04/18/23 05:36:12.844
Apr 18 05:36:13.845: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/18/23 05:36:13.905
STEP: create a namespace for the webhook 04/18/23 05:36:13.948
STEP: create a configmap should be unconditionally rejected by the webhook 04/18/23 05:36:14.104
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:36:14.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3598" for this suite. 04/18/23 05:36:14.289
STEP: Destroying namespace "webhook-3598-markers" for this suite. 04/18/23 05:36:14.312
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":231,"skipped":4249,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.550 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:36:07.036
    Apr 18 05:36:07.036: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 05:36:07.037
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:36:07.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:36:07.18
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 05:36:07.233
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:36:08.304
    STEP: Deploying the webhook pod 04/18/23 05:36:08.339
    STEP: Wait for the deployment to be ready 04/18/23 05:36:08.456
    Apr 18 05:36:08.492: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 18 05:36:10.502: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 36, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 36, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 36, 8, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 36, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 05:36:12.52
    STEP: Verifying the service has paired with the endpoint 04/18/23 05:36:12.844
    Apr 18 05:36:13.845: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/18/23 05:36:13.905
    STEP: create a namespace for the webhook 04/18/23 05:36:13.948
    STEP: create a configmap should be unconditionally rejected by the webhook 04/18/23 05:36:14.104
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:36:14.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3598" for this suite. 04/18/23 05:36:14.289
    STEP: Destroying namespace "webhook-3598-markers" for this suite. 04/18/23 05:36:14.312
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:36:14.586
Apr 18 05:36:14.587: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename disruption 04/18/23 05:36:14.587
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:36:14.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:36:14.893
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 04/18/23 05:36:14.971
STEP: Waiting for all pods to be running 04/18/23 05:36:17.246
Apr 18 05:36:17.303: INFO: running pods: 0 < 3
Apr 18 05:36:19.341: INFO: running pods: 0 < 3
Apr 18 05:36:21.324: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 18 05:36:23.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9963" for this suite. 04/18/23 05:36:23.322
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":232,"skipped":4254,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.800 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:36:14.586
    Apr 18 05:36:14.587: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename disruption 04/18/23 05:36:14.587
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:36:14.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:36:14.893
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 04/18/23 05:36:14.971
    STEP: Waiting for all pods to be running 04/18/23 05:36:17.246
    Apr 18 05:36:17.303: INFO: running pods: 0 < 3
    Apr 18 05:36:19.341: INFO: running pods: 0 < 3
    Apr 18 05:36:21.324: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 18 05:36:23.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9963" for this suite. 04/18/23 05:36:23.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:36:23.388
Apr 18 05:36:23.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-runtime 04/18/23 05:36:23.389
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:36:23.488
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:36:23.491
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 04/18/23 05:36:23.493
STEP: wait for the container to reach Succeeded 04/18/23 05:36:23.516
STEP: get the container status 04/18/23 05:36:30.709
STEP: the container should be terminated 04/18/23 05:36:30.75
STEP: the termination message should be set 04/18/23 05:36:30.75
Apr 18 05:36:30.750: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/18/23 05:36:30.75
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 18 05:36:30.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1520" for this suite. 04/18/23 05:36:30.977
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":233,"skipped":4263,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.617 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:36:23.388
    Apr 18 05:36:23.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-runtime 04/18/23 05:36:23.389
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:36:23.488
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:36:23.491
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 04/18/23 05:36:23.493
    STEP: wait for the container to reach Succeeded 04/18/23 05:36:23.516
    STEP: get the container status 04/18/23 05:36:30.709
    STEP: the container should be terminated 04/18/23 05:36:30.75
    STEP: the termination message should be set 04/18/23 05:36:30.75
    Apr 18 05:36:30.750: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/18/23 05:36:30.75
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 18 05:36:30.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1520" for this suite. 04/18/23 05:36:30.977
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:36:31.006
Apr 18 05:36:31.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename job 04/18/23 05:36:31.007
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:36:31.173
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:36:31.176
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 04/18/23 05:36:31.229
STEP: Ensuring active pods == parallelism 04/18/23 05:36:31.269
STEP: delete a job 04/18/23 05:36:37.315
STEP: deleting Job.batch foo in namespace job-4870, will wait for the garbage collector to delete the pods 04/18/23 05:36:37.315
Apr 18 05:36:37.392: INFO: Deleting Job.batch foo took: 21.779294ms
Apr 18 05:36:37.692: INFO: Terminating Job.batch foo pods took: 300.394919ms
STEP: Ensuring job was deleted 04/18/23 05:37:10.393
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 05:37:10.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4870" for this suite. 04/18/23 05:37:10.402
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":234,"skipped":4287,"failed":0}
------------------------------
â€¢ [SLOW TEST] [39.453 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:36:31.006
    Apr 18 05:36:31.006: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename job 04/18/23 05:36:31.007
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:36:31.173
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:36:31.176
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 04/18/23 05:36:31.229
    STEP: Ensuring active pods == parallelism 04/18/23 05:36:31.269
    STEP: delete a job 04/18/23 05:36:37.315
    STEP: deleting Job.batch foo in namespace job-4870, will wait for the garbage collector to delete the pods 04/18/23 05:36:37.315
    Apr 18 05:36:37.392: INFO: Deleting Job.batch foo took: 21.779294ms
    Apr 18 05:36:37.692: INFO: Terminating Job.batch foo pods took: 300.394919ms
    STEP: Ensuring job was deleted 04/18/23 05:37:10.393
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 05:37:10.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4870" for this suite. 04/18/23 05:37:10.402
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:37:10.459
Apr 18 05:37:10.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename endpointslice 04/18/23 05:37:10.46
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:10.546
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:10.548
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 04/18/23 05:37:10.558
STEP: getting /apis/discovery.k8s.io 04/18/23 05:37:10.56
STEP: getting /apis/discovery.k8s.iov1 04/18/23 05:37:10.561
STEP: creating 04/18/23 05:37:10.562
STEP: getting 04/18/23 05:37:10.792
STEP: listing 04/18/23 05:37:10.845
STEP: watching 04/18/23 05:37:10.848
Apr 18 05:37:10.848: INFO: starting watch
STEP: cluster-wide listing 04/18/23 05:37:10.849
STEP: cluster-wide watching 04/18/23 05:37:10.862
Apr 18 05:37:10.862: INFO: starting watch
STEP: patching 04/18/23 05:37:10.863
STEP: updating 04/18/23 05:37:10.893
Apr 18 05:37:11.020: INFO: waiting for watch events with expected annotations
Apr 18 05:37:11.020: INFO: saw patched and updated annotations
STEP: deleting 04/18/23 05:37:11.02
STEP: deleting a collection 04/18/23 05:37:11.056
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 18 05:37:11.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8734" for this suite. 04/18/23 05:37:11.202
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":235,"skipped":4296,"failed":0}
------------------------------
â€¢ [0.774 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:37:10.459
    Apr 18 05:37:10.459: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename endpointslice 04/18/23 05:37:10.46
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:10.546
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:10.548
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 04/18/23 05:37:10.558
    STEP: getting /apis/discovery.k8s.io 04/18/23 05:37:10.56
    STEP: getting /apis/discovery.k8s.iov1 04/18/23 05:37:10.561
    STEP: creating 04/18/23 05:37:10.562
    STEP: getting 04/18/23 05:37:10.792
    STEP: listing 04/18/23 05:37:10.845
    STEP: watching 04/18/23 05:37:10.848
    Apr 18 05:37:10.848: INFO: starting watch
    STEP: cluster-wide listing 04/18/23 05:37:10.849
    STEP: cluster-wide watching 04/18/23 05:37:10.862
    Apr 18 05:37:10.862: INFO: starting watch
    STEP: patching 04/18/23 05:37:10.863
    STEP: updating 04/18/23 05:37:10.893
    Apr 18 05:37:11.020: INFO: waiting for watch events with expected annotations
    Apr 18 05:37:11.020: INFO: saw patched and updated annotations
    STEP: deleting 04/18/23 05:37:11.02
    STEP: deleting a collection 04/18/23 05:37:11.056
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 18 05:37:11.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-8734" for this suite. 04/18/23 05:37:11.202
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:37:11.235
Apr 18 05:37:11.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 05:37:11.236
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:11.325
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:11.327
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 04/18/23 05:37:11.33
STEP: Creating a ResourceQuota 04/18/23 05:37:16.344
STEP: Ensuring resource quota status is calculated 04/18/23 05:37:16.368
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 05:37:18.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4644" for this suite. 04/18/23 05:37:18.376
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":236,"skipped":4318,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.169 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:37:11.235
    Apr 18 05:37:11.235: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 05:37:11.236
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:11.325
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:11.327
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 04/18/23 05:37:11.33
    STEP: Creating a ResourceQuota 04/18/23 05:37:16.344
    STEP: Ensuring resource quota status is calculated 04/18/23 05:37:16.368
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 05:37:18.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4644" for this suite. 04/18/23 05:37:18.376
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:37:18.405
Apr 18 05:37:18.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename events 04/18/23 05:37:18.406
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:18.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:18.77
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 04/18/23 05:37:18.773
STEP: listing all events in all namespaces 04/18/23 05:37:18.812
STEP: patching the test event 04/18/23 05:37:18.861
STEP: fetching the test event 04/18/23 05:37:18.927
STEP: updating the test event 04/18/23 05:37:19.02
STEP: getting the test event 04/18/23 05:37:19.118
STEP: deleting the test event 04/18/23 05:37:19.121
STEP: listing all events in all namespaces 04/18/23 05:37:19.239
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Apr 18 05:37:19.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1398" for this suite. 04/18/23 05:37:19.248
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":237,"skipped":4336,"failed":0}
------------------------------
â€¢ [0.872 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:37:18.405
    Apr 18 05:37:18.405: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename events 04/18/23 05:37:18.406
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:18.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:18.77
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 04/18/23 05:37:18.773
    STEP: listing all events in all namespaces 04/18/23 05:37:18.812
    STEP: patching the test event 04/18/23 05:37:18.861
    STEP: fetching the test event 04/18/23 05:37:18.927
    STEP: updating the test event 04/18/23 05:37:19.02
    STEP: getting the test event 04/18/23 05:37:19.118
    STEP: deleting the test event 04/18/23 05:37:19.121
    STEP: listing all events in all namespaces 04/18/23 05:37:19.239
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Apr 18 05:37:19.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1398" for this suite. 04/18/23 05:37:19.248
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:37:19.277
Apr 18 05:37:19.277: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 05:37:19.278
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:19.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:19.312
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-aaea627c-ffb6-42ce-a6f6-c42053c8ec25 04/18/23 05:37:19.386
STEP: Creating a pod to test consume secrets 04/18/23 05:37:19.418
Apr 18 05:37:19.494: INFO: Waiting up to 5m0s for pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814" in namespace "secrets-9060" to be "Succeeded or Failed"
Apr 18 05:37:19.496: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814": Phase="Pending", Reason="", readiness=false. Elapsed: 2.352548ms
Apr 18 05:37:21.501: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007418633s
Apr 18 05:37:23.501: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0077s
Apr 18 05:37:25.519: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025142872s
Apr 18 05:37:27.501: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.00681861s
STEP: Saw pod success 04/18/23 05:37:27.501
Apr 18 05:37:27.501: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814" satisfied condition "Succeeded or Failed"
Apr 18 05:37:27.504: INFO: Trying to get logs from node apps-208 pod pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 05:37:27.512
Apr 18 05:37:27.586: INFO: Waiting for pod pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814 to disappear
Apr 18 05:37:27.659: INFO: Pod pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 05:37:27.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9060" for this suite. 04/18/23 05:37:27.664
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":238,"skipped":4338,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.410 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:37:19.277
    Apr 18 05:37:19.277: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 05:37:19.278
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:19.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:19.312
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-aaea627c-ffb6-42ce-a6f6-c42053c8ec25 04/18/23 05:37:19.386
    STEP: Creating a pod to test consume secrets 04/18/23 05:37:19.418
    Apr 18 05:37:19.494: INFO: Waiting up to 5m0s for pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814" in namespace "secrets-9060" to be "Succeeded or Failed"
    Apr 18 05:37:19.496: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814": Phase="Pending", Reason="", readiness=false. Elapsed: 2.352548ms
    Apr 18 05:37:21.501: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007418633s
    Apr 18 05:37:23.501: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0077s
    Apr 18 05:37:25.519: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025142872s
    Apr 18 05:37:27.501: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.00681861s
    STEP: Saw pod success 04/18/23 05:37:27.501
    Apr 18 05:37:27.501: INFO: Pod "pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814" satisfied condition "Succeeded or Failed"
    Apr 18 05:37:27.504: INFO: Trying to get logs from node apps-208 pod pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 05:37:27.512
    Apr 18 05:37:27.586: INFO: Waiting for pod pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814 to disappear
    Apr 18 05:37:27.659: INFO: Pod pod-secrets-28408c0b-1cc5-468d-b41b-cf98fb7ab814 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 05:37:27.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9060" for this suite. 04/18/23 05:37:27.664
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:37:27.688
Apr 18 05:37:27.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 05:37:27.689
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:27.718
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:27.72
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 04/18/23 05:37:27.73
Apr 18 05:37:27.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 create -f -'
Apr 18 05:37:29.292: INFO: stderr: ""
Apr 18 05:37:29.292: INFO: stdout: "pod/pause created\n"
Apr 18 05:37:29.292: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 18 05:37:29.292: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-277" to be "running and ready"
Apr 18 05:37:29.377: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 84.905129ms
Apr 18 05:37:29.377: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '' to be 'Running' but was 'Pending'
Apr 18 05:37:31.434: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.141775101s
Apr 18 05:37:31.434: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'apps-208' to be 'Running' but was 'Pending'
Apr 18 05:37:33.382: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.089613048s
Apr 18 05:37:33.382: INFO: Pod "pause" satisfied condition "running and ready"
Apr 18 05:37:33.382: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 04/18/23 05:37:33.382
Apr 18 05:37:33.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 label pods pause testing-label=testing-label-value'
Apr 18 05:37:33.499: INFO: stderr: ""
Apr 18 05:37:33.499: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 04/18/23 05:37:33.499
Apr 18 05:37:33.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 get pod pause -L testing-label'
Apr 18 05:37:33.574: INFO: stderr: ""
Apr 18 05:37:33.574: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod 04/18/23 05:37:33.574
Apr 18 05:37:33.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 label pods pause testing-label-'
Apr 18 05:37:33.680: INFO: stderr: ""
Apr 18 05:37:33.680: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 04/18/23 05:37:33.68
Apr 18 05:37:33.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 get pod pause -L testing-label'
Apr 18 05:37:33.780: INFO: stderr: ""
Apr 18 05:37:33.781: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 04/18/23 05:37:33.781
Apr 18 05:37:33.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 delete --grace-period=0 --force -f -'
Apr 18 05:37:33.951: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 05:37:33.951: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 18 05:37:33.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 get rc,svc -l name=pause --no-headers'
Apr 18 05:37:34.047: INFO: stderr: "No resources found in kubectl-277 namespace.\n"
Apr 18 05:37:34.047: INFO: stdout: ""
Apr 18 05:37:34.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 18 05:37:34.123: INFO: stderr: ""
Apr 18 05:37:34.123: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 05:37:34.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-277" for this suite. 04/18/23 05:37:34.131
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":239,"skipped":4342,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.456 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:37:27.688
    Apr 18 05:37:27.688: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 05:37:27.689
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:27.718
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:27.72
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 04/18/23 05:37:27.73
    Apr 18 05:37:27.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 create -f -'
    Apr 18 05:37:29.292: INFO: stderr: ""
    Apr 18 05:37:29.292: INFO: stdout: "pod/pause created\n"
    Apr 18 05:37:29.292: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Apr 18 05:37:29.292: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-277" to be "running and ready"
    Apr 18 05:37:29.377: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 84.905129ms
    Apr 18 05:37:29.377: INFO: Error evaluating pod condition running and ready: want pod 'pause' on '' to be 'Running' but was 'Pending'
    Apr 18 05:37:31.434: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.141775101s
    Apr 18 05:37:31.434: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'apps-208' to be 'Running' but was 'Pending'
    Apr 18 05:37:33.382: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.089613048s
    Apr 18 05:37:33.382: INFO: Pod "pause" satisfied condition "running and ready"
    Apr 18 05:37:33.382: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 04/18/23 05:37:33.382
    Apr 18 05:37:33.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 label pods pause testing-label=testing-label-value'
    Apr 18 05:37:33.499: INFO: stderr: ""
    Apr 18 05:37:33.499: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 04/18/23 05:37:33.499
    Apr 18 05:37:33.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 get pod pause -L testing-label'
    Apr 18 05:37:33.574: INFO: stderr: ""
    Apr 18 05:37:33.574: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 04/18/23 05:37:33.574
    Apr 18 05:37:33.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 label pods pause testing-label-'
    Apr 18 05:37:33.680: INFO: stderr: ""
    Apr 18 05:37:33.680: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 04/18/23 05:37:33.68
    Apr 18 05:37:33.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 get pod pause -L testing-label'
    Apr 18 05:37:33.780: INFO: stderr: ""
    Apr 18 05:37:33.781: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 04/18/23 05:37:33.781
    Apr 18 05:37:33.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 delete --grace-period=0 --force -f -'
    Apr 18 05:37:33.951: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 05:37:33.951: INFO: stdout: "pod \"pause\" force deleted\n"
    Apr 18 05:37:33.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 get rc,svc -l name=pause --no-headers'
    Apr 18 05:37:34.047: INFO: stderr: "No resources found in kubectl-277 namespace.\n"
    Apr 18 05:37:34.047: INFO: stdout: ""
    Apr 18 05:37:34.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-277 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 18 05:37:34.123: INFO: stderr: ""
    Apr 18 05:37:34.123: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 05:37:34.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-277" for this suite. 04/18/23 05:37:34.131
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:37:34.144
Apr 18 05:37:34.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 05:37:34.146
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:34.293
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:34.296
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-5265 04/18/23 05:37:34.299
STEP: creating service affinity-nodeport-transition in namespace services-5265 04/18/23 05:37:34.299
STEP: creating replication controller affinity-nodeport-transition in namespace services-5265 04/18/23 05:37:34.457
I0418 05:37:34.486426      22 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-5265, replica count: 3
I0418 05:37:37.536917      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 05:37:40.538158      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 05:37:40.549: INFO: Creating new exec pod
Apr 18 05:37:40.585: INFO: Waiting up to 5m0s for pod "execpod-affinityvsw46" in namespace "services-5265" to be "running"
Apr 18 05:37:40.604: INFO: Pod "execpod-affinityvsw46": Phase="Pending", Reason="", readiness=false. Elapsed: 19.126376ms
Apr 18 05:37:42.643: INFO: Pod "execpod-affinityvsw46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05759032s
Apr 18 05:37:44.608: INFO: Pod "execpod-affinityvsw46": Phase="Running", Reason="", readiness=true. Elapsed: 4.02294265s
Apr 18 05:37:44.608: INFO: Pod "execpod-affinityvsw46" satisfied condition "running"
Apr 18 05:37:45.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Apr 18 05:37:45.774: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Apr 18 05:37:45.774: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:37:45.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.4.17 80'
Apr 18 05:37:45.933: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.4.17 80\nConnection to 10.96.4.17 80 port [tcp/http] succeeded!\n"
Apr 18 05:37:45.933: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:37:45.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.108 31081'
Apr 18 05:37:46.095: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.108 31081\nConnection to 192.168.2.108 31081 port [tcp/*] succeeded!\n"
Apr 18 05:37:46.095: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:37:46.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.109 31081'
Apr 18 05:37:46.238: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.109 31081\nConnection to 192.168.2.109 31081 port [tcp/*] succeeded!\n"
Apr 18 05:37:46.238: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:37:46.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.2.107:31081/ ; done'
Apr 18 05:37:46.507: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n"
Apr 18 05:37:46.507: INFO: stdout: "\naffinity-nodeport-transition-9zlkm\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-rdkn8\naffinity-nodeport-transition-9zlkm\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-rdkn8\naffinity-nodeport-transition-9zlkm\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-rdkn8\naffinity-nodeport-transition-9zlkm\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-rdkn8\naffinity-nodeport-transition-9zlkm\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-rdkn8\naffinity-nodeport-transition-9zlkm"
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-rdkn8
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-rdkn8
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-rdkn8
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-rdkn8
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-rdkn8
Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
Apr 18 05:37:46.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.2.107:31081/ ; done'
Apr 18 05:37:46.858: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n"
Apr 18 05:37:46.858: INFO: stdout: "\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl"
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
Apr 18 05:37:46.858: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-5265, will wait for the garbage collector to delete the pods 04/18/23 05:37:47.208
Apr 18 05:37:47.321: INFO: Deleting ReplicationController affinity-nodeport-transition took: 52.393351ms
Apr 18 05:37:47.621: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 300.436271ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 05:37:51.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5265" for this suite. 04/18/23 05:37:51.862
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":240,"skipped":4345,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.734 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:37:34.144
    Apr 18 05:37:34.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 05:37:34.146
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:34.293
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:34.296
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-5265 04/18/23 05:37:34.299
    STEP: creating service affinity-nodeport-transition in namespace services-5265 04/18/23 05:37:34.299
    STEP: creating replication controller affinity-nodeport-transition in namespace services-5265 04/18/23 05:37:34.457
    I0418 05:37:34.486426      22 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-5265, replica count: 3
    I0418 05:37:37.536917      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 0 running, 3 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 05:37:40.538158      22 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 05:37:40.549: INFO: Creating new exec pod
    Apr 18 05:37:40.585: INFO: Waiting up to 5m0s for pod "execpod-affinityvsw46" in namespace "services-5265" to be "running"
    Apr 18 05:37:40.604: INFO: Pod "execpod-affinityvsw46": Phase="Pending", Reason="", readiness=false. Elapsed: 19.126376ms
    Apr 18 05:37:42.643: INFO: Pod "execpod-affinityvsw46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05759032s
    Apr 18 05:37:44.608: INFO: Pod "execpod-affinityvsw46": Phase="Running", Reason="", readiness=true. Elapsed: 4.02294265s
    Apr 18 05:37:44.608: INFO: Pod "execpod-affinityvsw46" satisfied condition "running"
    Apr 18 05:37:45.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Apr 18 05:37:45.774: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Apr 18 05:37:45.774: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:37:45.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.4.17 80'
    Apr 18 05:37:45.933: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.4.17 80\nConnection to 10.96.4.17 80 port [tcp/http] succeeded!\n"
    Apr 18 05:37:45.933: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:37:45.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.108 31081'
    Apr 18 05:37:46.095: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.108 31081\nConnection to 192.168.2.108 31081 port [tcp/*] succeeded!\n"
    Apr 18 05:37:46.095: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:37:46.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.109 31081'
    Apr 18 05:37:46.238: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.109 31081\nConnection to 192.168.2.109 31081 port [tcp/*] succeeded!\n"
    Apr 18 05:37:46.238: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:37:46.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.2.107:31081/ ; done'
    Apr 18 05:37:46.507: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n"
    Apr 18 05:37:46.507: INFO: stdout: "\naffinity-nodeport-transition-9zlkm\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-rdkn8\naffinity-nodeport-transition-9zlkm\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-rdkn8\naffinity-nodeport-transition-9zlkm\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-rdkn8\naffinity-nodeport-transition-9zlkm\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-rdkn8\naffinity-nodeport-transition-9zlkm\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-rdkn8\naffinity-nodeport-transition-9zlkm"
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-rdkn8
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-rdkn8
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-rdkn8
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-rdkn8
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-rdkn8
    Apr 18 05:37:46.507: INFO: Received response from host: affinity-nodeport-transition-9zlkm
    Apr 18 05:37:46.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5265 exec execpod-affinityvsw46 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.2.107:31081/ ; done'
    Apr 18 05:37:46.858: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.2.107:31081/\n"
    Apr 18 05:37:46.858: INFO: stdout: "\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl\naffinity-nodeport-transition-p5kvl"
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Received response from host: affinity-nodeport-transition-p5kvl
    Apr 18 05:37:46.858: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-5265, will wait for the garbage collector to delete the pods 04/18/23 05:37:47.208
    Apr 18 05:37:47.321: INFO: Deleting ReplicationController affinity-nodeport-transition took: 52.393351ms
    Apr 18 05:37:47.621: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 300.436271ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 05:37:51.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5265" for this suite. 04/18/23 05:37:51.862
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:37:51.88
Apr 18 05:37:51.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 05:37:51.881
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:51.997
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:52
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 05:37:52.034
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:37:52.613
STEP: Deploying the webhook pod 04/18/23 05:37:52.708
STEP: Wait for the deployment to be ready 04/18/23 05:37:53.33
Apr 18 05:37:53.376: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 18 05:37:55.450: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 37, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 37, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 37, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 37, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 05:37:57.466
STEP: Verifying the service has paired with the endpoint 04/18/23 05:37:57.51
Apr 18 05:37:58.511: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Apr 18 05:37:58.514: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3675-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 05:38:04.14
STEP: Creating a custom resource while v1 is storage version 04/18/23 05:38:04.209
STEP: Patching Custom Resource Definition to set v2 as storage 04/18/23 05:38:06.3
STEP: Patching the custom resource while v2 is storage version 04/18/23 05:38:06.34
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:38:06.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5185" for this suite. 04/18/23 05:38:06.982
STEP: Destroying namespace "webhook-5185-markers" for this suite. 04/18/23 05:38:07.008
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":241,"skipped":4366,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.624 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:37:51.88
    Apr 18 05:37:51.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 05:37:51.881
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:37:51.997
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:37:52
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 05:37:52.034
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:37:52.613
    STEP: Deploying the webhook pod 04/18/23 05:37:52.708
    STEP: Wait for the deployment to be ready 04/18/23 05:37:53.33
    Apr 18 05:37:53.376: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 18 05:37:55.450: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 37, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 37, 53, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 37, 53, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 37, 53, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 05:37:57.466
    STEP: Verifying the service has paired with the endpoint 04/18/23 05:37:57.51
    Apr 18 05:37:58.511: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Apr 18 05:37:58.514: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3675-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 05:38:04.14
    STEP: Creating a custom resource while v1 is storage version 04/18/23 05:38:04.209
    STEP: Patching Custom Resource Definition to set v2 as storage 04/18/23 05:38:06.3
    STEP: Patching the custom resource while v2 is storage version 04/18/23 05:38:06.34
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:38:06.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5185" for this suite. 04/18/23 05:38:06.982
    STEP: Destroying namespace "webhook-5185-markers" for this suite. 04/18/23 05:38:07.008
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:38:07.507
Apr 18 05:38:07.507: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 05:38:07.508
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:07.699
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:07.702
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Apr 18 05:38:07.706: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 05:38:22.256
Apr 18 05:38:22.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-5387 --namespace=crd-publish-openapi-5387 create -f -'
Apr 18 05:38:23.868: INFO: stderr: ""
Apr 18 05:38:23.868: INFO: stdout: "e2e-test-crd-publish-openapi-2291-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 18 05:38:23.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-5387 --namespace=crd-publish-openapi-5387 delete e2e-test-crd-publish-openapi-2291-crds test-cr'
Apr 18 05:38:24.022: INFO: stderr: ""
Apr 18 05:38:24.022: INFO: stdout: "e2e-test-crd-publish-openapi-2291-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 18 05:38:24.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-5387 --namespace=crd-publish-openapi-5387 apply -f -'
Apr 18 05:38:25.403: INFO: stderr: ""
Apr 18 05:38:25.403: INFO: stdout: "e2e-test-crd-publish-openapi-2291-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 18 05:38:25.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-5387 --namespace=crd-publish-openapi-5387 delete e2e-test-crd-publish-openapi-2291-crds test-cr'
Apr 18 05:38:25.569: INFO: stderr: ""
Apr 18 05:38:25.569: INFO: stdout: "e2e-test-crd-publish-openapi-2291-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/18/23 05:38:25.569
Apr 18 05:38:25.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-5387 explain e2e-test-crd-publish-openapi-2291-crds'
Apr 18 05:38:26.983: INFO: stderr: ""
Apr 18 05:38:26.983: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2291-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:38:35.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5387" for this suite. 04/18/23 05:38:35.925
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":242,"skipped":4434,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.445 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:38:07.507
    Apr 18 05:38:07.507: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 05:38:07.508
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:07.699
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:07.702
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Apr 18 05:38:07.706: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 05:38:22.256
    Apr 18 05:38:22.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-5387 --namespace=crd-publish-openapi-5387 create -f -'
    Apr 18 05:38:23.868: INFO: stderr: ""
    Apr 18 05:38:23.868: INFO: stdout: "e2e-test-crd-publish-openapi-2291-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 18 05:38:23.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-5387 --namespace=crd-publish-openapi-5387 delete e2e-test-crd-publish-openapi-2291-crds test-cr'
    Apr 18 05:38:24.022: INFO: stderr: ""
    Apr 18 05:38:24.022: INFO: stdout: "e2e-test-crd-publish-openapi-2291-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Apr 18 05:38:24.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-5387 --namespace=crd-publish-openapi-5387 apply -f -'
    Apr 18 05:38:25.403: INFO: stderr: ""
    Apr 18 05:38:25.403: INFO: stdout: "e2e-test-crd-publish-openapi-2291-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 18 05:38:25.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-5387 --namespace=crd-publish-openapi-5387 delete e2e-test-crd-publish-openapi-2291-crds test-cr'
    Apr 18 05:38:25.569: INFO: stderr: ""
    Apr 18 05:38:25.569: INFO: stdout: "e2e-test-crd-publish-openapi-2291-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/18/23 05:38:25.569
    Apr 18 05:38:25.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-5387 explain e2e-test-crd-publish-openapi-2291-crds'
    Apr 18 05:38:26.983: INFO: stderr: ""
    Apr 18 05:38:26.983: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2291-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:38:35.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5387" for this suite. 04/18/23 05:38:35.925
  << End Captured GinkgoWriter Output
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:38:35.952
Apr 18 05:38:35.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename svcaccounts 04/18/23 05:38:35.953
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:36.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:36.088
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Apr 18 05:38:36.096: INFO: Got root ca configmap in namespace "svcaccounts-8681"
Apr 18 05:38:36.118: INFO: Deleted root ca configmap in namespace "svcaccounts-8681"
STEP: waiting for a new root ca configmap created 04/18/23 05:38:36.619
Apr 18 05:38:36.652: INFO: Recreated root ca configmap in namespace "svcaccounts-8681"
Apr 18 05:38:36.702: INFO: Updated root ca configmap in namespace "svcaccounts-8681"
STEP: waiting for the root ca configmap reconciled 04/18/23 05:38:37.202
Apr 18 05:38:37.206: INFO: Reconciled root ca configmap in namespace "svcaccounts-8681"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 05:38:37.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8681" for this suite. 04/18/23 05:38:37.213
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":243,"skipped":4434,"failed":0}
------------------------------
â€¢ [1.297 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:38:35.952
    Apr 18 05:38:35.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 05:38:35.953
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:36.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:36.088
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Apr 18 05:38:36.096: INFO: Got root ca configmap in namespace "svcaccounts-8681"
    Apr 18 05:38:36.118: INFO: Deleted root ca configmap in namespace "svcaccounts-8681"
    STEP: waiting for a new root ca configmap created 04/18/23 05:38:36.619
    Apr 18 05:38:36.652: INFO: Recreated root ca configmap in namespace "svcaccounts-8681"
    Apr 18 05:38:36.702: INFO: Updated root ca configmap in namespace "svcaccounts-8681"
    STEP: waiting for the root ca configmap reconciled 04/18/23 05:38:37.202
    Apr 18 05:38:37.206: INFO: Reconciled root ca configmap in namespace "svcaccounts-8681"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 05:38:37.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8681" for this suite. 04/18/23 05:38:37.213
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:38:37.25
Apr 18 05:38:37.250: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 05:38:37.251
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:37.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:37.313
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 04/18/23 05:38:37.368
Apr 18 05:38:37.416: INFO: Waiting up to 5m0s for pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9" in namespace "downward-api-4446" to be "Succeeded or Failed"
Apr 18 05:38:37.420: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.215164ms
Apr 18 05:38:39.425: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008843775s
Apr 18 05:38:41.427: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9": Phase="Running", Reason="", readiness=true. Elapsed: 4.011294302s
Apr 18 05:38:43.425: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9": Phase="Running", Reason="", readiness=false. Elapsed: 6.009174564s
Apr 18 05:38:45.425: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.009024034s
STEP: Saw pod success 04/18/23 05:38:45.425
Apr 18 05:38:45.425: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9" satisfied condition "Succeeded or Failed"
Apr 18 05:38:45.428: INFO: Trying to get logs from node apps-208 pod downward-api-15e64fe8-3e6f-4566-9138-9780188536d9 container dapi-container: <nil>
STEP: delete the pod 04/18/23 05:38:45.435
Apr 18 05:38:45.570: INFO: Waiting for pod downward-api-15e64fe8-3e6f-4566-9138-9780188536d9 to disappear
Apr 18 05:38:45.572: INFO: Pod downward-api-15e64fe8-3e6f-4566-9138-9780188536d9 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 18 05:38:45.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4446" for this suite. 04/18/23 05:38:45.577
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":244,"skipped":4467,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.341 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:38:37.25
    Apr 18 05:38:37.250: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 05:38:37.251
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:37.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:37.313
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 04/18/23 05:38:37.368
    Apr 18 05:38:37.416: INFO: Waiting up to 5m0s for pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9" in namespace "downward-api-4446" to be "Succeeded or Failed"
    Apr 18 05:38:37.420: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.215164ms
    Apr 18 05:38:39.425: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008843775s
    Apr 18 05:38:41.427: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9": Phase="Running", Reason="", readiness=true. Elapsed: 4.011294302s
    Apr 18 05:38:43.425: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9": Phase="Running", Reason="", readiness=false. Elapsed: 6.009174564s
    Apr 18 05:38:45.425: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.009024034s
    STEP: Saw pod success 04/18/23 05:38:45.425
    Apr 18 05:38:45.425: INFO: Pod "downward-api-15e64fe8-3e6f-4566-9138-9780188536d9" satisfied condition "Succeeded or Failed"
    Apr 18 05:38:45.428: INFO: Trying to get logs from node apps-208 pod downward-api-15e64fe8-3e6f-4566-9138-9780188536d9 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 05:38:45.435
    Apr 18 05:38:45.570: INFO: Waiting for pod downward-api-15e64fe8-3e6f-4566-9138-9780188536d9 to disappear
    Apr 18 05:38:45.572: INFO: Pod downward-api-15e64fe8-3e6f-4566-9138-9780188536d9 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 18 05:38:45.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4446" for this suite. 04/18/23 05:38:45.577
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:38:45.592
Apr 18 05:38:45.592: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 05:38:45.593
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:45.64
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:45.643
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-22d4d102-2bff-4cc5-ac79-fb222a5f8a09 04/18/23 05:38:45.645
STEP: Creating a pod to test consume configMaps 04/18/23 05:38:45.732
Apr 18 05:38:45.761: INFO: Waiting up to 5m0s for pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4" in namespace "configmap-3699" to be "Succeeded or Failed"
Apr 18 05:38:45.764: INFO: Pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.742115ms
Apr 18 05:38:47.768: INFO: Pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007037516s
Apr 18 05:38:49.769: INFO: Pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007606126s
Apr 18 05:38:51.846: INFO: Pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.084436559s
STEP: Saw pod success 04/18/23 05:38:51.846
Apr 18 05:38:51.846: INFO: Pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4" satisfied condition "Succeeded or Failed"
Apr 18 05:38:51.849: INFO: Trying to get logs from node apps-208 pod pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:38:51.854
Apr 18 05:38:51.912: INFO: Waiting for pod pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4 to disappear
Apr 18 05:38:51.915: INFO: Pod pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 05:38:51.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3699" for this suite. 04/18/23 05:38:51.919
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":245,"skipped":4482,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.391 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:38:45.592
    Apr 18 05:38:45.592: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 05:38:45.593
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:45.64
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:45.643
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-22d4d102-2bff-4cc5-ac79-fb222a5f8a09 04/18/23 05:38:45.645
    STEP: Creating a pod to test consume configMaps 04/18/23 05:38:45.732
    Apr 18 05:38:45.761: INFO: Waiting up to 5m0s for pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4" in namespace "configmap-3699" to be "Succeeded or Failed"
    Apr 18 05:38:45.764: INFO: Pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.742115ms
    Apr 18 05:38:47.768: INFO: Pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007037516s
    Apr 18 05:38:49.769: INFO: Pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007606126s
    Apr 18 05:38:51.846: INFO: Pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.084436559s
    STEP: Saw pod success 04/18/23 05:38:51.846
    Apr 18 05:38:51.846: INFO: Pod "pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4" satisfied condition "Succeeded or Failed"
    Apr 18 05:38:51.849: INFO: Trying to get logs from node apps-208 pod pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:38:51.854
    Apr 18 05:38:51.912: INFO: Waiting for pod pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4 to disappear
    Apr 18 05:38:51.915: INFO: Pod pod-configmaps-3a628366-c624-4b31-bf60-76aa23c763a4 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 05:38:51.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3699" for this suite. 04/18/23 05:38:51.919
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:38:51.984
Apr 18 05:38:51.984: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename dns 04/18/23 05:38:51.985
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:52.053
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:52.056
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/18/23 05:38:52.058
Apr 18 05:38:52.070: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8200  0092fa9a-1806-4d13-bb86-d0f20c73d312 4116337 0 2023-04-18 05:38:52 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-18 05:38:52 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8x4g5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8x4g5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 18 05:38:52.070: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-8200" to be "running and ready"
Apr 18 05:38:52.073: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.424615ms
Apr 18 05:38:52.073: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:38:54.109: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03841597s
Apr 18 05:38:54.109: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:38:56.077: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 4.006183764s
Apr 18 05:38:56.077: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Apr 18 05:38:56.077: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 04/18/23 05:38:56.077
Apr 18 05:38:56.077: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8200 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:38:56.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:38:56.077: INFO: ExecWithOptions: Clientset creation
Apr 18 05:38:56.077: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-8200/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 04/18/23 05:38:56.182
Apr 18 05:38:56.182: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8200 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:38:56.182: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:38:56.183: INFO: ExecWithOptions: Clientset creation
Apr 18 05:38:56.183: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-8200/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 18 05:38:56.276: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 05:38:56.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8200" for this suite. 04/18/23 05:38:56.363
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":246,"skipped":4487,"failed":0}
------------------------------
â€¢ [4.403 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:38:51.984
    Apr 18 05:38:51.984: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename dns 04/18/23 05:38:51.985
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:52.053
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:52.056
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/18/23 05:38:52.058
    Apr 18 05:38:52.070: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-8200  0092fa9a-1806-4d13-bb86-d0f20c73d312 4116337 0 2023-04-18 05:38:52 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-04-18 05:38:52 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8x4g5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8x4g5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 18 05:38:52.070: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-8200" to be "running and ready"
    Apr 18 05:38:52.073: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.424615ms
    Apr 18 05:38:52.073: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:38:54.109: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03841597s
    Apr 18 05:38:54.109: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:38:56.077: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 4.006183764s
    Apr 18 05:38:56.077: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Apr 18 05:38:56.077: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 04/18/23 05:38:56.077
    Apr 18 05:38:56.077: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8200 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:38:56.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:38:56.077: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:38:56.077: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-8200/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 04/18/23 05:38:56.182
    Apr 18 05:38:56.182: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8200 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:38:56.182: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:38:56.183: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:38:56.183: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/dns-8200/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 18 05:38:56.276: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 05:38:56.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8200" for this suite. 04/18/23 05:38:56.363
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:38:56.388
Apr 18 05:38:56.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename job 04/18/23 05:38:56.389
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:56.492
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:56.495
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 04/18/23 05:38:56.497
STEP: Ensuring job reaches completions 04/18/23 05:38:56.524
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 05:39:16.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4432" for this suite. 04/18/23 05:39:16.568
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":247,"skipped":4496,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.242 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:38:56.388
    Apr 18 05:38:56.388: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename job 04/18/23 05:38:56.389
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:38:56.492
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:38:56.495
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 04/18/23 05:38:56.497
    STEP: Ensuring job reaches completions 04/18/23 05:38:56.524
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 05:39:16.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4432" for this suite. 04/18/23 05:39:16.568
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:39:16.631
Apr 18 05:39:16.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubelet-test 04/18/23 05:39:16.632
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:16.857
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:39:16.86
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 18 05:39:17.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4684" for this suite. 04/18/23 05:39:17.045
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":248,"skipped":4528,"failed":0}
------------------------------
â€¢ [0.490 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:39:16.631
    Apr 18 05:39:16.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubelet-test 04/18/23 05:39:16.632
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:16.857
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:39:16.86
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 18 05:39:17.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-4684" for this suite. 04/18/23 05:39:17.045
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:39:17.123
Apr 18 05:39:17.123: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename disruption 04/18/23 05:39:17.124
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:17.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:39:17.342
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 04/18/23 05:39:17.385
STEP: Updating PodDisruptionBudget status 04/18/23 05:39:19.561
STEP: Waiting for all pods to be running 04/18/23 05:39:19.592
Apr 18 05:39:19.605: INFO: running pods: 0 < 1
Apr 18 05:39:21.642: INFO: running pods: 0 < 1
STEP: locating a running pod 04/18/23 05:39:23.609
STEP: Waiting for the pdb to be processed 04/18/23 05:39:23.665
STEP: Patching PodDisruptionBudget status 04/18/23 05:39:23.765
STEP: Waiting for the pdb to be processed 04/18/23 05:39:23.844
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 18 05:39:23.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-8526" for this suite. 04/18/23 05:39:23.903
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":249,"skipped":4549,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.845 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:39:17.123
    Apr 18 05:39:17.123: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename disruption 04/18/23 05:39:17.124
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:17.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:39:17.342
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 04/18/23 05:39:17.385
    STEP: Updating PodDisruptionBudget status 04/18/23 05:39:19.561
    STEP: Waiting for all pods to be running 04/18/23 05:39:19.592
    Apr 18 05:39:19.605: INFO: running pods: 0 < 1
    Apr 18 05:39:21.642: INFO: running pods: 0 < 1
    STEP: locating a running pod 04/18/23 05:39:23.609
    STEP: Waiting for the pdb to be processed 04/18/23 05:39:23.665
    STEP: Patching PodDisruptionBudget status 04/18/23 05:39:23.765
    STEP: Waiting for the pdb to be processed 04/18/23 05:39:23.844
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 18 05:39:23.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-8526" for this suite. 04/18/23 05:39:23.903
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:39:23.969
Apr 18 05:39:23.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 05:39:23.97
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:24.001
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:39:24.004
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 04/18/23 05:39:24.017
STEP: Creating a ResourceQuota 04/18/23 05:39:29.084
STEP: Ensuring resource quota status is calculated 04/18/23 05:39:29.124
STEP: Creating a ReplicaSet 04/18/23 05:39:31.128
STEP: Ensuring resource quota status captures replicaset creation 04/18/23 05:39:31.21
STEP: Deleting a ReplicaSet 04/18/23 05:39:33.215
STEP: Ensuring resource quota status released usage 04/18/23 05:39:33.243
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 05:39:35.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5560" for this suite. 04/18/23 05:39:35.252
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":250,"skipped":4574,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.307 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:39:23.969
    Apr 18 05:39:23.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 05:39:23.97
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:24.001
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:39:24.004
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 04/18/23 05:39:24.017
    STEP: Creating a ResourceQuota 04/18/23 05:39:29.084
    STEP: Ensuring resource quota status is calculated 04/18/23 05:39:29.124
    STEP: Creating a ReplicaSet 04/18/23 05:39:31.128
    STEP: Ensuring resource quota status captures replicaset creation 04/18/23 05:39:31.21
    STEP: Deleting a ReplicaSet 04/18/23 05:39:33.215
    STEP: Ensuring resource quota status released usage 04/18/23 05:39:33.243
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 05:39:35.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5560" for this suite. 04/18/23 05:39:35.252
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:39:35.278
Apr 18 05:39:35.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename namespaces 04/18/23 05:39:35.279
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:35.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:39:35.405
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 04/18/23 05:39:35.407
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:35.476
STEP: Creating a pod in the namespace 04/18/23 05:39:35.478
STEP: Waiting for the pod to have running status 04/18/23 05:39:35.568
Apr 18 05:39:35.568: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-6722" to be "running"
Apr 18 05:39:35.602: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 33.352605ms
Apr 18 05:39:37.607: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039068543s
Apr 18 05:39:39.606: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.038189215s
Apr 18 05:39:39.607: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 04/18/23 05:39:39.607
STEP: Waiting for the namespace to be removed. 04/18/23 05:39:39.627
STEP: Recreating the namespace 04/18/23 05:39:51.631
STEP: Verifying there are no pods in the namespace 04/18/23 05:39:51.727
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:39:51.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6932" for this suite. 04/18/23 05:39:51.735
STEP: Destroying namespace "nsdeletetest-6722" for this suite. 04/18/23 05:39:51.744
Apr 18 05:39:51.747: INFO: Namespace nsdeletetest-6722 was already deleted
STEP: Destroying namespace "nsdeletetest-4745" for this suite. 04/18/23 05:39:51.747
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":251,"skipped":4599,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.483 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:39:35.278
    Apr 18 05:39:35.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename namespaces 04/18/23 05:39:35.279
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:35.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:39:35.405
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 04/18/23 05:39:35.407
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:35.476
    STEP: Creating a pod in the namespace 04/18/23 05:39:35.478
    STEP: Waiting for the pod to have running status 04/18/23 05:39:35.568
    Apr 18 05:39:35.568: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-6722" to be "running"
    Apr 18 05:39:35.602: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 33.352605ms
    Apr 18 05:39:37.607: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039068543s
    Apr 18 05:39:39.606: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.038189215s
    Apr 18 05:39:39.607: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 04/18/23 05:39:39.607
    STEP: Waiting for the namespace to be removed. 04/18/23 05:39:39.627
    STEP: Recreating the namespace 04/18/23 05:39:51.631
    STEP: Verifying there are no pods in the namespace 04/18/23 05:39:51.727
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:39:51.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-6932" for this suite. 04/18/23 05:39:51.735
    STEP: Destroying namespace "nsdeletetest-6722" for this suite. 04/18/23 05:39:51.744
    Apr 18 05:39:51.747: INFO: Namespace nsdeletetest-6722 was already deleted
    STEP: Destroying namespace "nsdeletetest-4745" for this suite. 04/18/23 05:39:51.747
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:39:51.762
Apr 18 05:39:51.762: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename statefulset 04/18/23 05:39:51.763
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:51.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:39:51.788
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9125 04/18/23 05:39:51.811
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Apr 18 05:39:51.948: INFO: Found 0 stateful pods, waiting for 1
Apr 18 05:40:01.953: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 04/18/23 05:40:01.96
W0418 05:40:01.991378      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 18 05:40:02.020: INFO: Found 1 stateful pods, waiting for 2
Apr 18 05:40:12.025: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Apr 18 05:40:22.055: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 05:40:22.055: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 04/18/23 05:40:22.067
STEP: Delete all of the StatefulSets 04/18/23 05:40:22.072
STEP: Verify that StatefulSets have been deleted 04/18/23 05:40:22.125
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 05:40:22.183: INFO: Deleting all statefulset in ns statefulset-9125
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 05:40:22.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9125" for this suite. 04/18/23 05:40:22.37
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":252,"skipped":4630,"failed":0}
------------------------------
â€¢ [SLOW TEST] [30.926 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:39:51.762
    Apr 18 05:39:51.762: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename statefulset 04/18/23 05:39:51.763
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:39:51.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:39:51.788
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9125 04/18/23 05:39:51.811
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Apr 18 05:39:51.948: INFO: Found 0 stateful pods, waiting for 1
    Apr 18 05:40:01.953: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 04/18/23 05:40:01.96
    W0418 05:40:01.991378      22 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 18 05:40:02.020: INFO: Found 1 stateful pods, waiting for 2
    Apr 18 05:40:12.025: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    Apr 18 05:40:22.055: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 05:40:22.055: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 04/18/23 05:40:22.067
    STEP: Delete all of the StatefulSets 04/18/23 05:40:22.072
    STEP: Verify that StatefulSets have been deleted 04/18/23 05:40:22.125
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 05:40:22.183: INFO: Deleting all statefulset in ns statefulset-9125
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 05:40:22.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9125" for this suite. 04/18/23 05:40:22.37
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:40:22.689
Apr 18 05:40:22.689: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename svcaccounts 04/18/23 05:40:22.69
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:22.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:22.939
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  04/18/23 05:40:23.059
Apr 18 05:40:23.120: INFO: Waiting up to 5m0s for pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b" in namespace "svcaccounts-6358" to be "Succeeded or Failed"
Apr 18 05:40:23.180: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b": Phase="Pending", Reason="", readiness=false. Elapsed: 60.081132ms
Apr 18 05:40:25.184: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064695745s
Apr 18 05:40:27.184: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.064345962s
Apr 18 05:40:29.185: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0649978s
Apr 18 05:40:31.197: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.077586785s
STEP: Saw pod success 04/18/23 05:40:31.197
Apr 18 05:40:31.198: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b" satisfied condition "Succeeded or Failed"
Apr 18 05:40:31.233: INFO: Trying to get logs from node apps-208 pod test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:40:31.245
Apr 18 05:40:31.380: INFO: Waiting for pod test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b to disappear
Apr 18 05:40:31.382: INFO: Pod test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 05:40:31.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6358" for this suite. 04/18/23 05:40:31.396
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":253,"skipped":4640,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.728 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:40:22.689
    Apr 18 05:40:22.689: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 05:40:22.69
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:22.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:22.939
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  04/18/23 05:40:23.059
    Apr 18 05:40:23.120: INFO: Waiting up to 5m0s for pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b" in namespace "svcaccounts-6358" to be "Succeeded or Failed"
    Apr 18 05:40:23.180: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b": Phase="Pending", Reason="", readiness=false. Elapsed: 60.081132ms
    Apr 18 05:40:25.184: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064695745s
    Apr 18 05:40:27.184: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.064345962s
    Apr 18 05:40:29.185: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0649978s
    Apr 18 05:40:31.197: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.077586785s
    STEP: Saw pod success 04/18/23 05:40:31.197
    Apr 18 05:40:31.198: INFO: Pod "test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b" satisfied condition "Succeeded or Failed"
    Apr 18 05:40:31.233: INFO: Trying to get logs from node apps-208 pod test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:40:31.245
    Apr 18 05:40:31.380: INFO: Waiting for pod test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b to disappear
    Apr 18 05:40:31.382: INFO: Pod test-pod-f9e8bb97-7b69-4f8a-ad4f-58fe1c6f2f4b no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 05:40:31.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-6358" for this suite. 04/18/23 05:40:31.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:40:31.417
Apr 18 05:40:31.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename job 04/18/23 05:40:31.419
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:31.44
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:31.443
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 04/18/23 05:40:31.45
STEP: Ensure pods equal to paralellism count is attached to the job 04/18/23 05:40:31.547
STEP: patching /status 04/18/23 05:40:37.552
STEP: updating /status 04/18/23 05:40:37.614
STEP: get /status 04/18/23 05:40:37.622
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 05:40:37.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6197" for this suite. 04/18/23 05:40:37.629
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":254,"skipped":4662,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.233 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:40:31.417
    Apr 18 05:40:31.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename job 04/18/23 05:40:31.419
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:31.44
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:31.443
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 04/18/23 05:40:31.45
    STEP: Ensure pods equal to paralellism count is attached to the job 04/18/23 05:40:31.547
    STEP: patching /status 04/18/23 05:40:37.552
    STEP: updating /status 04/18/23 05:40:37.614
    STEP: get /status 04/18/23 05:40:37.622
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 05:40:37.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6197" for this suite. 04/18/23 05:40:37.629
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:40:37.651
Apr 18 05:40:37.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 05:40:37.652
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:37.733
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:37.736
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-19077698-1928-4d6c-aaf6-f44cb1683e36 04/18/23 05:40:37.761
STEP: Creating a pod to test consume secrets 04/18/23 05:40:37.776
Apr 18 05:40:37.792: INFO: Waiting up to 5m0s for pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7" in namespace "secrets-145" to be "Succeeded or Failed"
Apr 18 05:40:37.813: INFO: Pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.955107ms
Apr 18 05:40:39.822: INFO: Pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0297458s
Apr 18 05:40:41.816: INFO: Pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7": Phase="Running", Reason="", readiness=false. Elapsed: 4.024125429s
Apr 18 05:40:43.847: INFO: Pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054641935s
STEP: Saw pod success 04/18/23 05:40:43.847
Apr 18 05:40:43.847: INFO: Pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7" satisfied condition "Succeeded or Failed"
Apr 18 05:40:43.875: INFO: Trying to get logs from node apps-208 pod pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 05:40:43.882
Apr 18 05:40:43.943: INFO: Waiting for pod pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7 to disappear
Apr 18 05:40:43.946: INFO: Pod pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 05:40:43.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-145" for this suite. 04/18/23 05:40:43.99
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":255,"skipped":4678,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.401 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:40:37.651
    Apr 18 05:40:37.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 05:40:37.652
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:37.733
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:37.736
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-19077698-1928-4d6c-aaf6-f44cb1683e36 04/18/23 05:40:37.761
    STEP: Creating a pod to test consume secrets 04/18/23 05:40:37.776
    Apr 18 05:40:37.792: INFO: Waiting up to 5m0s for pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7" in namespace "secrets-145" to be "Succeeded or Failed"
    Apr 18 05:40:37.813: INFO: Pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.955107ms
    Apr 18 05:40:39.822: INFO: Pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0297458s
    Apr 18 05:40:41.816: INFO: Pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7": Phase="Running", Reason="", readiness=false. Elapsed: 4.024125429s
    Apr 18 05:40:43.847: INFO: Pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054641935s
    STEP: Saw pod success 04/18/23 05:40:43.847
    Apr 18 05:40:43.847: INFO: Pod "pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7" satisfied condition "Succeeded or Failed"
    Apr 18 05:40:43.875: INFO: Trying to get logs from node apps-208 pod pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 05:40:43.882
    Apr 18 05:40:43.943: INFO: Waiting for pod pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7 to disappear
    Apr 18 05:40:43.946: INFO: Pod pod-secrets-8dd168c3-ebcd-41a1-99cd-d3d42f5afdb7 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 05:40:43.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-145" for this suite. 04/18/23 05:40:43.99
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:40:44.053
Apr 18 05:40:44.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename proxy 04/18/23 05:40:44.054
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:44.075
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:44.078
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Apr 18 05:40:44.093: INFO: Creating pod...
Apr 18 05:40:44.235: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-6875" to be "running"
Apr 18 05:40:44.238: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 3.538144ms
Apr 18 05:40:46.243: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008201365s
Apr 18 05:40:48.242: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.007653013s
Apr 18 05:40:48.242: INFO: Pod "agnhost" satisfied condition "running"
Apr 18 05:40:48.242: INFO: Creating service...
Apr 18 05:40:48.277: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/DELETE
Apr 18 05:40:48.281: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 18 05:40:48.281: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/GET
Apr 18 05:40:48.322: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 18 05:40:48.322: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/HEAD
Apr 18 05:40:48.358: INFO: http.Client request:HEAD | StatusCode:200
Apr 18 05:40:48.358: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/OPTIONS
Apr 18 05:40:48.390: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 18 05:40:48.390: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/PATCH
Apr 18 05:40:48.393: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 18 05:40:48.393: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/POST
Apr 18 05:40:48.397: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 18 05:40:48.397: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/PUT
Apr 18 05:40:48.400: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 18 05:40:48.400: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/DELETE
Apr 18 05:40:48.404: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 18 05:40:48.404: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/GET
Apr 18 05:40:48.409: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 18 05:40:48.409: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/HEAD
Apr 18 05:40:48.448: INFO: http.Client request:HEAD | StatusCode:200
Apr 18 05:40:48.448: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/OPTIONS
Apr 18 05:40:48.454: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 18 05:40:48.454: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/PATCH
Apr 18 05:40:48.489: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 18 05:40:48.489: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/POST
Apr 18 05:40:48.533: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 18 05:40:48.533: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/PUT
Apr 18 05:40:48.538: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 18 05:40:48.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6875" for this suite. 04/18/23 05:40:48.542
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":256,"skipped":4685,"failed":0}
------------------------------
â€¢ [4.527 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:40:44.053
    Apr 18 05:40:44.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename proxy 04/18/23 05:40:44.054
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:44.075
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:44.078
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Apr 18 05:40:44.093: INFO: Creating pod...
    Apr 18 05:40:44.235: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-6875" to be "running"
    Apr 18 05:40:44.238: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 3.538144ms
    Apr 18 05:40:46.243: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008201365s
    Apr 18 05:40:48.242: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.007653013s
    Apr 18 05:40:48.242: INFO: Pod "agnhost" satisfied condition "running"
    Apr 18 05:40:48.242: INFO: Creating service...
    Apr 18 05:40:48.277: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/DELETE
    Apr 18 05:40:48.281: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 18 05:40:48.281: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/GET
    Apr 18 05:40:48.322: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 18 05:40:48.322: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/HEAD
    Apr 18 05:40:48.358: INFO: http.Client request:HEAD | StatusCode:200
    Apr 18 05:40:48.358: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/OPTIONS
    Apr 18 05:40:48.390: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 18 05:40:48.390: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/PATCH
    Apr 18 05:40:48.393: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 18 05:40:48.393: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/POST
    Apr 18 05:40:48.397: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 18 05:40:48.397: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/pods/agnhost/proxy/some/path/with/PUT
    Apr 18 05:40:48.400: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 18 05:40:48.400: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/DELETE
    Apr 18 05:40:48.404: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 18 05:40:48.404: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/GET
    Apr 18 05:40:48.409: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 18 05:40:48.409: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/HEAD
    Apr 18 05:40:48.448: INFO: http.Client request:HEAD | StatusCode:200
    Apr 18 05:40:48.448: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/OPTIONS
    Apr 18 05:40:48.454: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 18 05:40:48.454: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/PATCH
    Apr 18 05:40:48.489: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 18 05:40:48.489: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/POST
    Apr 18 05:40:48.533: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 18 05:40:48.533: INFO: Starting http.Client for https://10.96.0.1:443/api/v1/namespaces/proxy-6875/services/test-service/proxy/some/path/with/PUT
    Apr 18 05:40:48.538: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 18 05:40:48.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-6875" for this suite. 04/18/23 05:40:48.542
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:40:48.582
Apr 18 05:40:48.582: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 05:40:48.582
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:48.701
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:48.704
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 05:40:48.786
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:40:49.308
STEP: Deploying the webhook pod 04/18/23 05:40:49.344
STEP: Wait for the deployment to be ready 04/18/23 05:40:49.415
Apr 18 05:40:49.428: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Apr 18 05:40:51.445: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 40, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 40, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 40, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 40, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 05:40:53.514
STEP: Verifying the service has paired with the endpoint 04/18/23 05:40:53.553
Apr 18 05:40:54.554: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 04/18/23 05:40:55.131
STEP: Creating a configMap that should be mutated 04/18/23 05:40:55.152
STEP: Deleting the collection of validation webhooks 04/18/23 05:40:55.411
STEP: Creating a configMap that should not be mutated 04/18/23 05:40:56.816
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:40:57.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2922" for this suite. 04/18/23 05:40:57.204
STEP: Destroying namespace "webhook-2922-markers" for this suite. 04/18/23 05:40:57.451
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":257,"skipped":4724,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.645 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:40:48.582
    Apr 18 05:40:48.582: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 05:40:48.582
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:48.701
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:48.704
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 05:40:48.786
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:40:49.308
    STEP: Deploying the webhook pod 04/18/23 05:40:49.344
    STEP: Wait for the deployment to be ready 04/18/23 05:40:49.415
    Apr 18 05:40:49.428: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Apr 18 05:40:51.445: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 40, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 40, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 40, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 40, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 05:40:53.514
    STEP: Verifying the service has paired with the endpoint 04/18/23 05:40:53.553
    Apr 18 05:40:54.554: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 04/18/23 05:40:55.131
    STEP: Creating a configMap that should be mutated 04/18/23 05:40:55.152
    STEP: Deleting the collection of validation webhooks 04/18/23 05:40:55.411
    STEP: Creating a configMap that should not be mutated 04/18/23 05:40:56.816
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:40:57.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2922" for this suite. 04/18/23 05:40:57.204
    STEP: Destroying namespace "webhook-2922-markers" for this suite. 04/18/23 05:40:57.451
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:40:58.226
Apr 18 05:40:58.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 05:40:58.228
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:58.289
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:58.292
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 04/18/23 05:40:58.337
Apr 18 05:40:58.380: INFO: Waiting up to 5m0s for pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389" in namespace "emptydir-3358" to be "Succeeded or Failed"
Apr 18 05:40:58.430: INFO: Pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389": Phase="Pending", Reason="", readiness=false. Elapsed: 49.634855ms
Apr 18 05:41:00.435: INFO: Pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05422898s
Apr 18 05:41:02.434: INFO: Pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389": Phase="Running", Reason="", readiness=false. Elapsed: 4.053780213s
Apr 18 05:41:04.455: INFO: Pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.074389286s
STEP: Saw pod success 04/18/23 05:41:04.455
Apr 18 05:41:04.455: INFO: Pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389" satisfied condition "Succeeded or Failed"
Apr 18 05:41:04.458: INFO: Trying to get logs from node apps-208 pod pod-fb49fbb7-0758-4792-bea0-055e128fb389 container test-container: <nil>
STEP: delete the pod 04/18/23 05:41:04.464
Apr 18 05:41:04.597: INFO: Waiting for pod pod-fb49fbb7-0758-4792-bea0-055e128fb389 to disappear
Apr 18 05:41:04.600: INFO: Pod pod-fb49fbb7-0758-4792-bea0-055e128fb389 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 05:41:04.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3358" for this suite. 04/18/23 05:41:04.625
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":258,"skipped":4724,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.420 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:40:58.226
    Apr 18 05:40:58.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 05:40:58.228
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:40:58.289
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:40:58.292
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/18/23 05:40:58.337
    Apr 18 05:40:58.380: INFO: Waiting up to 5m0s for pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389" in namespace "emptydir-3358" to be "Succeeded or Failed"
    Apr 18 05:40:58.430: INFO: Pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389": Phase="Pending", Reason="", readiness=false. Elapsed: 49.634855ms
    Apr 18 05:41:00.435: INFO: Pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05422898s
    Apr 18 05:41:02.434: INFO: Pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389": Phase="Running", Reason="", readiness=false. Elapsed: 4.053780213s
    Apr 18 05:41:04.455: INFO: Pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.074389286s
    STEP: Saw pod success 04/18/23 05:41:04.455
    Apr 18 05:41:04.455: INFO: Pod "pod-fb49fbb7-0758-4792-bea0-055e128fb389" satisfied condition "Succeeded or Failed"
    Apr 18 05:41:04.458: INFO: Trying to get logs from node apps-208 pod pod-fb49fbb7-0758-4792-bea0-055e128fb389 container test-container: <nil>
    STEP: delete the pod 04/18/23 05:41:04.464
    Apr 18 05:41:04.597: INFO: Waiting for pod pod-fb49fbb7-0758-4792-bea0-055e128fb389 to disappear
    Apr 18 05:41:04.600: INFO: Pod pod-fb49fbb7-0758-4792-bea0-055e128fb389 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 05:41:04.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3358" for this suite. 04/18/23 05:41:04.625
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:41:04.648
Apr 18 05:41:04.648: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename lease-test 04/18/23 05:41:04.649
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:04.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:04.792
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Apr 18 05:41:05.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-1565" for this suite. 04/18/23 05:41:05.228
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":259,"skipped":4766,"failed":0}
------------------------------
â€¢ [0.592 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:41:04.648
    Apr 18 05:41:04.648: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename lease-test 04/18/23 05:41:04.649
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:04.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:04.792
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Apr 18 05:41:05.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-1565" for this suite. 04/18/23 05:41:05.228
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:41:05.241
Apr 18 05:41:05.241: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 05:41:05.242
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:05.263
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:05.265
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-d32feb7e-a23d-49c0-a4ac-f74d587afdf0 04/18/23 05:41:05.341
STEP: Creating a pod to test consume secrets 04/18/23 05:41:05.38
Apr 18 05:41:05.391: INFO: Waiting up to 5m0s for pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4" in namespace "secrets-7909" to be "Succeeded or Failed"
Apr 18 05:41:05.415: INFO: Pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.872679ms
Apr 18 05:41:07.451: INFO: Pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060095549s
Apr 18 05:41:09.420: INFO: Pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029299536s
Apr 18 05:41:11.422: INFO: Pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031049465s
STEP: Saw pod success 04/18/23 05:41:11.422
Apr 18 05:41:11.422: INFO: Pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4" satisfied condition "Succeeded or Failed"
Apr 18 05:41:11.425: INFO: Trying to get logs from node apps-208 pod pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4 container secret-env-test: <nil>
STEP: delete the pod 04/18/23 05:41:11.43
Apr 18 05:41:11.556: INFO: Waiting for pod pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4 to disappear
Apr 18 05:41:11.580: INFO: Pod pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 18 05:41:11.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7909" for this suite. 04/18/23 05:41:11.584
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":260,"skipped":4773,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.389 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:41:05.241
    Apr 18 05:41:05.241: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 05:41:05.242
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:05.263
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:05.265
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-d32feb7e-a23d-49c0-a4ac-f74d587afdf0 04/18/23 05:41:05.341
    STEP: Creating a pod to test consume secrets 04/18/23 05:41:05.38
    Apr 18 05:41:05.391: INFO: Waiting up to 5m0s for pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4" in namespace "secrets-7909" to be "Succeeded or Failed"
    Apr 18 05:41:05.415: INFO: Pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.872679ms
    Apr 18 05:41:07.451: INFO: Pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060095549s
    Apr 18 05:41:09.420: INFO: Pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029299536s
    Apr 18 05:41:11.422: INFO: Pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031049465s
    STEP: Saw pod success 04/18/23 05:41:11.422
    Apr 18 05:41:11.422: INFO: Pod "pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4" satisfied condition "Succeeded or Failed"
    Apr 18 05:41:11.425: INFO: Trying to get logs from node apps-208 pod pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4 container secret-env-test: <nil>
    STEP: delete the pod 04/18/23 05:41:11.43
    Apr 18 05:41:11.556: INFO: Waiting for pod pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4 to disappear
    Apr 18 05:41:11.580: INFO: Pod pod-secrets-e9716ce7-c633-46f3-87ba-41dbb2532ff4 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 05:41:11.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7909" for this suite. 04/18/23 05:41:11.584
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:41:11.632
Apr 18 05:41:11.632: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 05:41:11.633
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:11.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:11.761
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 04/18/23 05:41:11.791
STEP: listing secrets in all namespaces to ensure that there are more than zero 04/18/23 05:41:11.814
STEP: patching the secret 04/18/23 05:41:11.843
STEP: deleting the secret using a LabelSelector 04/18/23 05:41:11.895
STEP: listing secrets in all namespaces, searching for label name and value in patch 04/18/23 05:41:11.964
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 18 05:41:11.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5298" for this suite. 04/18/23 05:41:12.031
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":261,"skipped":4824,"failed":0}
------------------------------
â€¢ [0.457 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:41:11.632
    Apr 18 05:41:11.632: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 05:41:11.633
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:11.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:11.761
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 04/18/23 05:41:11.791
    STEP: listing secrets in all namespaces to ensure that there are more than zero 04/18/23 05:41:11.814
    STEP: patching the secret 04/18/23 05:41:11.843
    STEP: deleting the secret using a LabelSelector 04/18/23 05:41:11.895
    STEP: listing secrets in all namespaces, searching for label name and value in patch 04/18/23 05:41:11.964
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 05:41:11.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5298" for this suite. 04/18/23 05:41:12.031
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:41:12.09
Apr 18 05:41:12.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 05:41:12.091
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:12.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:12.152
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 04/18/23 05:41:12.155
Apr 18 05:41:12.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6" in namespace "downward-api-3726" to be "Succeeded or Failed"
Apr 18 05:41:12.276: INFO: Pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.317859ms
Apr 18 05:41:14.553: INFO: Pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.279507462s
Apr 18 05:41:16.286: INFO: Pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012463074s
Apr 18 05:41:18.292: INFO: Pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019248054s
STEP: Saw pod success 04/18/23 05:41:18.292
Apr 18 05:41:18.293: INFO: Pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6" satisfied condition "Succeeded or Failed"
Apr 18 05:41:18.296: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6 container client-container: <nil>
STEP: delete the pod 04/18/23 05:41:18.394
Apr 18 05:41:18.460: INFO: Waiting for pod downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6 to disappear
Apr 18 05:41:18.465: INFO: Pod downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 05:41:18.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3726" for this suite. 04/18/23 05:41:18.476
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":262,"skipped":4835,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.493 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:41:12.09
    Apr 18 05:41:12.090: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 05:41:12.091
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:12.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:12.152
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 04/18/23 05:41:12.155
    Apr 18 05:41:12.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6" in namespace "downward-api-3726" to be "Succeeded or Failed"
    Apr 18 05:41:12.276: INFO: Pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.317859ms
    Apr 18 05:41:14.553: INFO: Pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.279507462s
    Apr 18 05:41:16.286: INFO: Pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012463074s
    Apr 18 05:41:18.292: INFO: Pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019248054s
    STEP: Saw pod success 04/18/23 05:41:18.292
    Apr 18 05:41:18.293: INFO: Pod "downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6" satisfied condition "Succeeded or Failed"
    Apr 18 05:41:18.296: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6 container client-container: <nil>
    STEP: delete the pod 04/18/23 05:41:18.394
    Apr 18 05:41:18.460: INFO: Waiting for pod downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6 to disappear
    Apr 18 05:41:18.465: INFO: Pod downwardapi-volume-a953089d-eea8-4eae-b093-86fcc15df9e6 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 05:41:18.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3726" for this suite. 04/18/23 05:41:18.476
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:41:18.585
Apr 18 05:41:18.585: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename events 04/18/23 05:41:18.586
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:18.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:18.627
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 04/18/23 05:41:18.636
STEP: listing events in all namespaces 04/18/23 05:41:18.74
STEP: listing events in test namespace 04/18/23 05:41:18.744
STEP: listing events with field selection filtering on source 04/18/23 05:41:18.746
STEP: listing events with field selection filtering on reportingController 04/18/23 05:41:18.749
STEP: getting the test event 04/18/23 05:41:18.76
STEP: patching the test event 04/18/23 05:41:18.771
STEP: getting the test event 04/18/23 05:41:18.799
STEP: updating the test event 04/18/23 05:41:18.816
STEP: getting the test event 04/18/23 05:41:18.9
STEP: deleting the test event 04/18/23 05:41:18.913
STEP: listing events in all namespaces 04/18/23 05:41:18.95
STEP: listing events in test namespace 04/18/23 05:41:18.953
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Apr 18 05:41:18.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4396" for this suite. 04/18/23 05:41:18.959
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":263,"skipped":4872,"failed":0}
------------------------------
â€¢ [0.383 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:41:18.585
    Apr 18 05:41:18.585: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename events 04/18/23 05:41:18.586
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:18.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:18.627
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 04/18/23 05:41:18.636
    STEP: listing events in all namespaces 04/18/23 05:41:18.74
    STEP: listing events in test namespace 04/18/23 05:41:18.744
    STEP: listing events with field selection filtering on source 04/18/23 05:41:18.746
    STEP: listing events with field selection filtering on reportingController 04/18/23 05:41:18.749
    STEP: getting the test event 04/18/23 05:41:18.76
    STEP: patching the test event 04/18/23 05:41:18.771
    STEP: getting the test event 04/18/23 05:41:18.799
    STEP: updating the test event 04/18/23 05:41:18.816
    STEP: getting the test event 04/18/23 05:41:18.9
    STEP: deleting the test event 04/18/23 05:41:18.913
    STEP: listing events in all namespaces 04/18/23 05:41:18.95
    STEP: listing events in test namespace 04/18/23 05:41:18.953
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Apr 18 05:41:18.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-4396" for this suite. 04/18/23 05:41:18.959
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:41:18.969
Apr 18 05:41:18.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename runtimeclass 04/18/23 05:41:18.97
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:19.091
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:19.093
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Apr 18 05:41:19.136: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-5518 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 18 05:41:19.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-5518" for this suite. 04/18/23 05:41:19.288
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":264,"skipped":4905,"failed":0}
------------------------------
â€¢ [0.422 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:41:18.969
    Apr 18 05:41:18.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename runtimeclass 04/18/23 05:41:18.97
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:19.091
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:19.093
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Apr 18 05:41:19.136: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-5518 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 18 05:41:19.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-5518" for this suite. 04/18/23 05:41:19.288
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:41:19.392
Apr 18 05:41:19.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename containers 04/18/23 05:41:19.393
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:19.441
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:19.443
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 04/18/23 05:41:19.501
Apr 18 05:41:19.557: INFO: Waiting up to 5m0s for pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b" in namespace "containers-7598" to be "Succeeded or Failed"
Apr 18 05:41:19.600: INFO: Pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.851643ms
Apr 18 05:41:21.795: INFO: Pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.237861652s
Apr 18 05:41:23.604: INFO: Pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046616806s
Apr 18 05:41:25.606: INFO: Pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04866051s
STEP: Saw pod success 04/18/23 05:41:25.606
Apr 18 05:41:25.606: INFO: Pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b" satisfied condition "Succeeded or Failed"
Apr 18 05:41:25.609: INFO: Trying to get logs from node apps-208 pod client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:41:25.628
Apr 18 05:41:25.812: INFO: Waiting for pod client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b to disappear
Apr 18 05:41:25.874: INFO: Pod client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 18 05:41:25.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7598" for this suite. 04/18/23 05:41:25.909
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":265,"skipped":4917,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.567 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:41:19.392
    Apr 18 05:41:19.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename containers 04/18/23 05:41:19.393
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:19.441
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:19.443
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 04/18/23 05:41:19.501
    Apr 18 05:41:19.557: INFO: Waiting up to 5m0s for pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b" in namespace "containers-7598" to be "Succeeded or Failed"
    Apr 18 05:41:19.600: INFO: Pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b": Phase="Pending", Reason="", readiness=false. Elapsed: 42.851643ms
    Apr 18 05:41:21.795: INFO: Pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.237861652s
    Apr 18 05:41:23.604: INFO: Pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046616806s
    Apr 18 05:41:25.606: INFO: Pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.04866051s
    STEP: Saw pod success 04/18/23 05:41:25.606
    Apr 18 05:41:25.606: INFO: Pod "client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b" satisfied condition "Succeeded or Failed"
    Apr 18 05:41:25.609: INFO: Trying to get logs from node apps-208 pod client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:41:25.628
    Apr 18 05:41:25.812: INFO: Waiting for pod client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b to disappear
    Apr 18 05:41:25.874: INFO: Pod client-containers-d4b65eca-a8bb-4e33-a0e2-6b305942392b no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 18 05:41:25.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7598" for this suite. 04/18/23 05:41:25.909
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:41:25.96
Apr 18 05:41:25.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 05:41:25.961
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:26.032
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:26.035
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-77052daa-a86e-4f0f-8ea4-2df54cc6c855 04/18/23 05:41:26.072
STEP: Creating a pod to test consume configMaps 04/18/23 05:41:26.575
Apr 18 05:41:26.626: INFO: Waiting up to 5m0s for pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35" in namespace "configmap-884" to be "Succeeded or Failed"
Apr 18 05:41:26.676: INFO: Pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35": Phase="Pending", Reason="", readiness=false. Elapsed: 49.806629ms
Apr 18 05:41:28.684: INFO: Pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057351007s
Apr 18 05:41:30.684: INFO: Pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35": Phase="Running", Reason="", readiness=false. Elapsed: 4.057246852s
Apr 18 05:41:32.685: INFO: Pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.058839252s
STEP: Saw pod success 04/18/23 05:41:32.685
Apr 18 05:41:32.686: INFO: Pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35" satisfied condition "Succeeded or Failed"
Apr 18 05:41:32.707: INFO: Trying to get logs from node apps-208 pod pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:41:32.713
Apr 18 05:41:32.938: INFO: Waiting for pod pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35 to disappear
Apr 18 05:41:32.941: INFO: Pod pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 05:41:32.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-884" for this suite. 04/18/23 05:41:32.968
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":266,"skipped":4946,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.032 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:41:25.96
    Apr 18 05:41:25.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 05:41:25.961
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:26.032
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:26.035
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-77052daa-a86e-4f0f-8ea4-2df54cc6c855 04/18/23 05:41:26.072
    STEP: Creating a pod to test consume configMaps 04/18/23 05:41:26.575
    Apr 18 05:41:26.626: INFO: Waiting up to 5m0s for pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35" in namespace "configmap-884" to be "Succeeded or Failed"
    Apr 18 05:41:26.676: INFO: Pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35": Phase="Pending", Reason="", readiness=false. Elapsed: 49.806629ms
    Apr 18 05:41:28.684: INFO: Pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057351007s
    Apr 18 05:41:30.684: INFO: Pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35": Phase="Running", Reason="", readiness=false. Elapsed: 4.057246852s
    Apr 18 05:41:32.685: INFO: Pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.058839252s
    STEP: Saw pod success 04/18/23 05:41:32.685
    Apr 18 05:41:32.686: INFO: Pod "pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35" satisfied condition "Succeeded or Failed"
    Apr 18 05:41:32.707: INFO: Trying to get logs from node apps-208 pod pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:41:32.713
    Apr 18 05:41:32.938: INFO: Waiting for pod pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35 to disappear
    Apr 18 05:41:32.941: INFO: Pod pod-configmaps-279cc09a-b16a-4e60-8884-ab32f1880d35 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 05:41:32.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-884" for this suite. 04/18/23 05:41:32.968
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:41:32.993
Apr 18 05:41:32.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 05:41:32.994
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:33.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:33.186
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Apr 18 05:41:33.386: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 05:41:47.708
Apr 18 05:41:47.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-935 --namespace=crd-publish-openapi-935 create -f -'
Apr 18 05:41:49.298: INFO: stderr: ""
Apr 18 05:41:49.298: INFO: stdout: "e2e-test-crd-publish-openapi-4053-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 18 05:41:49.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-935 --namespace=crd-publish-openapi-935 delete e2e-test-crd-publish-openapi-4053-crds test-cr'
Apr 18 05:41:49.466: INFO: stderr: ""
Apr 18 05:41:49.466: INFO: stdout: "e2e-test-crd-publish-openapi-4053-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 18 05:41:49.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-935 --namespace=crd-publish-openapi-935 apply -f -'
Apr 18 05:41:50.937: INFO: stderr: ""
Apr 18 05:41:50.937: INFO: stdout: "e2e-test-crd-publish-openapi-4053-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 18 05:41:50.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-935 --namespace=crd-publish-openapi-935 delete e2e-test-crd-publish-openapi-4053-crds test-cr'
Apr 18 05:41:51.093: INFO: stderr: ""
Apr 18 05:41:51.093: INFO: stdout: "e2e-test-crd-publish-openapi-4053-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/18/23 05:41:51.093
Apr 18 05:41:51.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-935 explain e2e-test-crd-publish-openapi-4053-crds'
Apr 18 05:41:52.471: INFO: stderr: ""
Apr 18 05:41:52.471: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4053-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:42:01.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-935" for this suite. 04/18/23 05:42:01.424
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":267,"skipped":4955,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.464 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:41:32.993
    Apr 18 05:41:32.993: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 05:41:32.994
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:41:33.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:41:33.186
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Apr 18 05:41:33.386: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/18/23 05:41:47.708
    Apr 18 05:41:47.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-935 --namespace=crd-publish-openapi-935 create -f -'
    Apr 18 05:41:49.298: INFO: stderr: ""
    Apr 18 05:41:49.298: INFO: stdout: "e2e-test-crd-publish-openapi-4053-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 18 05:41:49.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-935 --namespace=crd-publish-openapi-935 delete e2e-test-crd-publish-openapi-4053-crds test-cr'
    Apr 18 05:41:49.466: INFO: stderr: ""
    Apr 18 05:41:49.466: INFO: stdout: "e2e-test-crd-publish-openapi-4053-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Apr 18 05:41:49.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-935 --namespace=crd-publish-openapi-935 apply -f -'
    Apr 18 05:41:50.937: INFO: stderr: ""
    Apr 18 05:41:50.937: INFO: stdout: "e2e-test-crd-publish-openapi-4053-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 18 05:41:50.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-935 --namespace=crd-publish-openapi-935 delete e2e-test-crd-publish-openapi-4053-crds test-cr'
    Apr 18 05:41:51.093: INFO: stderr: ""
    Apr 18 05:41:51.093: INFO: stdout: "e2e-test-crd-publish-openapi-4053-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/18/23 05:41:51.093
    Apr 18 05:41:51.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=crd-publish-openapi-935 explain e2e-test-crd-publish-openapi-4053-crds'
    Apr 18 05:41:52.471: INFO: stderr: ""
    Apr 18 05:41:52.471: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4053-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:42:01.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-935" for this suite. 04/18/23 05:42:01.424
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:42:01.457
Apr 18 05:42:01.458: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename runtimeclass 04/18/23 05:42:01.459
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:42:01.601
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:42:01.604
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-6376-delete-me 04/18/23 05:42:01.618
STEP: Waiting for the RuntimeClass to disappear 04/18/23 05:42:01.749
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 18 05:42:01.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6376" for this suite. 04/18/23 05:42:01.842
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":268,"skipped":4965,"failed":0}
------------------------------
â€¢ [0.411 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:42:01.457
    Apr 18 05:42:01.458: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename runtimeclass 04/18/23 05:42:01.459
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:42:01.601
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:42:01.604
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-6376-delete-me 04/18/23 05:42:01.618
    STEP: Waiting for the RuntimeClass to disappear 04/18/23 05:42:01.749
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 18 05:42:01.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6376" for this suite. 04/18/23 05:42:01.842
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:42:01.869
Apr 18 05:42:01.869: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename job 04/18/23 05:42:01.87
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:42:01.902
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:42:01.904
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 04/18/23 05:42:01.951
STEP: Patching the Job 04/18/23 05:42:02.028
STEP: Watching for Job to be patched 04/18/23 05:42:02.069
Apr 18 05:42:02.071: INFO: Event ADDED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z] and annotations: map[batch.kubernetes.io/job-tracking:]
Apr 18 05:42:02.071: INFO: Event MODIFIED found for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 04/18/23 05:42:02.071
STEP: Watching for Job to be updated 04/18/23 05:42:02.386
Apr 18 05:42:02.388: INFO: Event MODIFIED found for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 05:42:02.388: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 04/18/23 05:42:02.388
Apr 18 05:42:02.458: INFO: Job: e2e-s4w5z as labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched]
STEP: Waiting for job to complete 04/18/23 05:42:02.458
STEP: Delete a job collection with a labelselector 04/18/23 05:42:18.463
STEP: Watching for Job to be deleted 04/18/23 05:42:18.481
Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 18 05:42:18.483: INFO: Event DELETED found for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 04/18/23 05:42:18.483
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 18 05:42:18.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7157" for this suite. 04/18/23 05:42:18.49
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":269,"skipped":4977,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.672 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:42:01.869
    Apr 18 05:42:01.869: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename job 04/18/23 05:42:01.87
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:42:01.902
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:42:01.904
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 04/18/23 05:42:01.951
    STEP: Patching the Job 04/18/23 05:42:02.028
    STEP: Watching for Job to be patched 04/18/23 05:42:02.069
    Apr 18 05:42:02.071: INFO: Event ADDED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z] and annotations: map[batch.kubernetes.io/job-tracking:]
    Apr 18 05:42:02.071: INFO: Event MODIFIED found for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 04/18/23 05:42:02.071
    STEP: Watching for Job to be updated 04/18/23 05:42:02.386
    Apr 18 05:42:02.388: INFO: Event MODIFIED found for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 05:42:02.388: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 04/18/23 05:42:02.388
    Apr 18 05:42:02.458: INFO: Job: e2e-s4w5z as labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched]
    STEP: Waiting for job to complete 04/18/23 05:42:02.458
    STEP: Delete a job collection with a labelselector 04/18/23 05:42:18.463
    STEP: Watching for Job to be deleted 04/18/23 05:42:18.481
    Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 05:42:18.483: INFO: Event MODIFIED observed for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 18 05:42:18.483: INFO: Event DELETED found for Job e2e-s4w5z in namespace job-7157 with labels: map[e2e-job-label:e2e-s4w5z e2e-s4w5z:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 04/18/23 05:42:18.483
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 18 05:42:18.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7157" for this suite. 04/18/23 05:42:18.49
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:42:18.547
Apr 18 05:42:18.547: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 05:42:18.548
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:42:18.806
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:42:18.81
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 04/18/23 05:42:18.813
Apr 18 05:42:18.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 create -f -'
Apr 18 05:42:20.443: INFO: stderr: ""
Apr 18 05:42:20.443: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 05:42:20.443
Apr 18 05:42:20.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 05:42:20.972: INFO: stderr: ""
Apr 18 05:42:20.972: INFO: stdout: "update-demo-nautilus-kpjzf update-demo-nautilus-tf7hg "
Apr 18 05:42:20.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-kpjzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 05:42:21.224: INFO: stderr: ""
Apr 18 05:42:21.224: INFO: stdout: ""
Apr 18 05:42:21.224: INFO: update-demo-nautilus-kpjzf is created but not running
Apr 18 05:42:26.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 05:42:26.304: INFO: stderr: ""
Apr 18 05:42:26.305: INFO: stdout: "update-demo-nautilus-kpjzf update-demo-nautilus-tf7hg "
Apr 18 05:42:26.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-kpjzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 05:42:26.377: INFO: stderr: ""
Apr 18 05:42:26.377: INFO: stdout: "true"
Apr 18 05:42:26.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-kpjzf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 05:42:26.451: INFO: stderr: ""
Apr 18 05:42:26.451: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 05:42:26.451: INFO: validating pod update-demo-nautilus-kpjzf
Apr 18 05:42:26.456: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 05:42:26.456: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 05:42:26.456: INFO: update-demo-nautilus-kpjzf is verified up and running
Apr 18 05:42:26.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 05:42:26.531: INFO: stderr: ""
Apr 18 05:42:26.531: INFO: stdout: "true"
Apr 18 05:42:26.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 05:42:26.621: INFO: stderr: ""
Apr 18 05:42:26.621: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 05:42:26.621: INFO: validating pod update-demo-nautilus-tf7hg
Apr 18 05:42:26.626: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 05:42:26.626: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 05:42:26.626: INFO: update-demo-nautilus-tf7hg is verified up and running
STEP: scaling down the replication controller 04/18/23 05:42:26.626
Apr 18 05:42:26.628: INFO: scanned /root for discovery docs: <nil>
Apr 18 05:42:26.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Apr 18 05:42:28.140: INFO: stderr: ""
Apr 18 05:42:28.140: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 05:42:28.14
Apr 18 05:42:28.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 05:42:28.220: INFO: stderr: ""
Apr 18 05:42:28.220: INFO: stdout: "update-demo-nautilus-kpjzf update-demo-nautilus-tf7hg "
STEP: Replicas for name=update-demo: expected=1 actual=2 04/18/23 05:42:28.22
Apr 18 05:42:33.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 05:42:33.299: INFO: stderr: ""
Apr 18 05:42:33.299: INFO: stdout: "update-demo-nautilus-tf7hg "
Apr 18 05:42:33.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 05:42:33.399: INFO: stderr: ""
Apr 18 05:42:33.399: INFO: stdout: "true"
Apr 18 05:42:33.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 05:42:33.483: INFO: stderr: ""
Apr 18 05:42:33.483: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 05:42:33.483: INFO: validating pod update-demo-nautilus-tf7hg
Apr 18 05:42:33.488: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 05:42:33.488: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 05:42:33.488: INFO: update-demo-nautilus-tf7hg is verified up and running
STEP: scaling up the replication controller 04/18/23 05:42:33.488
Apr 18 05:42:33.490: INFO: scanned /root for discovery docs: <nil>
Apr 18 05:42:33.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Apr 18 05:42:34.641: INFO: stderr: ""
Apr 18 05:42:34.641: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 05:42:34.641
Apr 18 05:42:34.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 05:42:34.719: INFO: stderr: ""
Apr 18 05:42:34.719: INFO: stdout: "update-demo-nautilus-4d2kf update-demo-nautilus-tf7hg "
Apr 18 05:42:34.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-4d2kf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 05:42:34.792: INFO: stderr: ""
Apr 18 05:42:34.792: INFO: stdout: ""
Apr 18 05:42:34.792: INFO: update-demo-nautilus-4d2kf is created but not running
Apr 18 05:42:39.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 18 05:42:39.874: INFO: stderr: ""
Apr 18 05:42:39.874: INFO: stdout: "update-demo-nautilus-4d2kf update-demo-nautilus-tf7hg "
Apr 18 05:42:39.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-4d2kf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 05:42:39.981: INFO: stderr: ""
Apr 18 05:42:39.981: INFO: stdout: "true"
Apr 18 05:42:39.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-4d2kf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 05:42:40.054: INFO: stderr: ""
Apr 18 05:42:40.054: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 05:42:40.054: INFO: validating pod update-demo-nautilus-4d2kf
Apr 18 05:42:40.060: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 05:42:40.060: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 05:42:40.060: INFO: update-demo-nautilus-4d2kf is verified up and running
Apr 18 05:42:40.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 18 05:42:40.129: INFO: stderr: ""
Apr 18 05:42:40.129: INFO: stdout: "true"
Apr 18 05:42:40.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 18 05:42:40.202: INFO: stderr: ""
Apr 18 05:42:40.202: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 18 05:42:40.202: INFO: validating pod update-demo-nautilus-tf7hg
Apr 18 05:42:40.207: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 18 05:42:40.207: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 18 05:42:40.207: INFO: update-demo-nautilus-tf7hg is verified up and running
STEP: using delete to clean up resources 04/18/23 05:42:40.207
Apr 18 05:42:40.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 delete --grace-period=0 --force -f -'
Apr 18 05:42:40.306: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 05:42:40.306: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 18 05:42:40.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get rc,svc -l name=update-demo --no-headers'
Apr 18 05:42:40.440: INFO: stderr: "No resources found in kubectl-6972 namespace.\n"
Apr 18 05:42:40.440: INFO: stdout: ""
Apr 18 05:42:40.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 18 05:42:40.522: INFO: stderr: ""
Apr 18 05:42:40.522: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 05:42:40.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6972" for this suite. 04/18/23 05:42:40.567
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":270,"skipped":4981,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.211 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:42:18.547
    Apr 18 05:42:18.547: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 05:42:18.548
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:42:18.806
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:42:18.81
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 04/18/23 05:42:18.813
    Apr 18 05:42:18.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 create -f -'
    Apr 18 05:42:20.443: INFO: stderr: ""
    Apr 18 05:42:20.443: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 05:42:20.443
    Apr 18 05:42:20.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 05:42:20.972: INFO: stderr: ""
    Apr 18 05:42:20.972: INFO: stdout: "update-demo-nautilus-kpjzf update-demo-nautilus-tf7hg "
    Apr 18 05:42:20.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-kpjzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 05:42:21.224: INFO: stderr: ""
    Apr 18 05:42:21.224: INFO: stdout: ""
    Apr 18 05:42:21.224: INFO: update-demo-nautilus-kpjzf is created but not running
    Apr 18 05:42:26.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 05:42:26.304: INFO: stderr: ""
    Apr 18 05:42:26.305: INFO: stdout: "update-demo-nautilus-kpjzf update-demo-nautilus-tf7hg "
    Apr 18 05:42:26.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-kpjzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 05:42:26.377: INFO: stderr: ""
    Apr 18 05:42:26.377: INFO: stdout: "true"
    Apr 18 05:42:26.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-kpjzf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 05:42:26.451: INFO: stderr: ""
    Apr 18 05:42:26.451: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 05:42:26.451: INFO: validating pod update-demo-nautilus-kpjzf
    Apr 18 05:42:26.456: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 05:42:26.456: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 05:42:26.456: INFO: update-demo-nautilus-kpjzf is verified up and running
    Apr 18 05:42:26.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 05:42:26.531: INFO: stderr: ""
    Apr 18 05:42:26.531: INFO: stdout: "true"
    Apr 18 05:42:26.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 05:42:26.621: INFO: stderr: ""
    Apr 18 05:42:26.621: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 05:42:26.621: INFO: validating pod update-demo-nautilus-tf7hg
    Apr 18 05:42:26.626: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 05:42:26.626: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 05:42:26.626: INFO: update-demo-nautilus-tf7hg is verified up and running
    STEP: scaling down the replication controller 04/18/23 05:42:26.626
    Apr 18 05:42:26.628: INFO: scanned /root for discovery docs: <nil>
    Apr 18 05:42:26.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Apr 18 05:42:28.140: INFO: stderr: ""
    Apr 18 05:42:28.140: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 05:42:28.14
    Apr 18 05:42:28.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 05:42:28.220: INFO: stderr: ""
    Apr 18 05:42:28.220: INFO: stdout: "update-demo-nautilus-kpjzf update-demo-nautilus-tf7hg "
    STEP: Replicas for name=update-demo: expected=1 actual=2 04/18/23 05:42:28.22
    Apr 18 05:42:33.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 05:42:33.299: INFO: stderr: ""
    Apr 18 05:42:33.299: INFO: stdout: "update-demo-nautilus-tf7hg "
    Apr 18 05:42:33.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 05:42:33.399: INFO: stderr: ""
    Apr 18 05:42:33.399: INFO: stdout: "true"
    Apr 18 05:42:33.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 05:42:33.483: INFO: stderr: ""
    Apr 18 05:42:33.483: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 05:42:33.483: INFO: validating pod update-demo-nautilus-tf7hg
    Apr 18 05:42:33.488: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 05:42:33.488: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 05:42:33.488: INFO: update-demo-nautilus-tf7hg is verified up and running
    STEP: scaling up the replication controller 04/18/23 05:42:33.488
    Apr 18 05:42:33.490: INFO: scanned /root for discovery docs: <nil>
    Apr 18 05:42:33.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Apr 18 05:42:34.641: INFO: stderr: ""
    Apr 18 05:42:34.641: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/18/23 05:42:34.641
    Apr 18 05:42:34.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 05:42:34.719: INFO: stderr: ""
    Apr 18 05:42:34.719: INFO: stdout: "update-demo-nautilus-4d2kf update-demo-nautilus-tf7hg "
    Apr 18 05:42:34.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-4d2kf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 05:42:34.792: INFO: stderr: ""
    Apr 18 05:42:34.792: INFO: stdout: ""
    Apr 18 05:42:34.792: INFO: update-demo-nautilus-4d2kf is created but not running
    Apr 18 05:42:39.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 18 05:42:39.874: INFO: stderr: ""
    Apr 18 05:42:39.874: INFO: stdout: "update-demo-nautilus-4d2kf update-demo-nautilus-tf7hg "
    Apr 18 05:42:39.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-4d2kf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 05:42:39.981: INFO: stderr: ""
    Apr 18 05:42:39.981: INFO: stdout: "true"
    Apr 18 05:42:39.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-4d2kf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 05:42:40.054: INFO: stderr: ""
    Apr 18 05:42:40.054: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 05:42:40.054: INFO: validating pod update-demo-nautilus-4d2kf
    Apr 18 05:42:40.060: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 05:42:40.060: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 05:42:40.060: INFO: update-demo-nautilus-4d2kf is verified up and running
    Apr 18 05:42:40.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 18 05:42:40.129: INFO: stderr: ""
    Apr 18 05:42:40.129: INFO: stdout: "true"
    Apr 18 05:42:40.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods update-demo-nautilus-tf7hg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 18 05:42:40.202: INFO: stderr: ""
    Apr 18 05:42:40.202: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 18 05:42:40.202: INFO: validating pod update-demo-nautilus-tf7hg
    Apr 18 05:42:40.207: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 18 05:42:40.207: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 18 05:42:40.207: INFO: update-demo-nautilus-tf7hg is verified up and running
    STEP: using delete to clean up resources 04/18/23 05:42:40.207
    Apr 18 05:42:40.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 delete --grace-period=0 --force -f -'
    Apr 18 05:42:40.306: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 05:42:40.306: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 18 05:42:40.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get rc,svc -l name=update-demo --no-headers'
    Apr 18 05:42:40.440: INFO: stderr: "No resources found in kubectl-6972 namespace.\n"
    Apr 18 05:42:40.440: INFO: stdout: ""
    Apr 18 05:42:40.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6972 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 18 05:42:40.522: INFO: stderr: ""
    Apr 18 05:42:40.522: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 05:42:40.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6972" for this suite. 04/18/23 05:42:40.567
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:42:40.761
Apr 18 05:42:40.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 05:42:40.762
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:42:40.904
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:42:40.907
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 04/18/23 05:42:41.092
Apr 18 05:42:41.321: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc" in namespace "downward-api-3245" to be "Succeeded or Failed"
Apr 18 05:42:41.375: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc": Phase="Pending", Reason="", readiness=false. Elapsed: 53.721376ms
Apr 18 05:42:43.424: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102271812s
Apr 18 05:42:45.380: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc": Phase="Running", Reason="", readiness=true. Elapsed: 4.058684747s
Apr 18 05:42:47.379: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc": Phase="Running", Reason="", readiness=false. Elapsed: 6.057451505s
Apr 18 05:42:49.381: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.059733609s
STEP: Saw pod success 04/18/23 05:42:49.381
Apr 18 05:42:49.381: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc" satisfied condition "Succeeded or Failed"
Apr 18 05:42:49.385: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc container client-container: <nil>
STEP: delete the pod 04/18/23 05:42:49.393
Apr 18 05:42:49.496: INFO: Waiting for pod downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc to disappear
Apr 18 05:42:49.499: INFO: Pod downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 05:42:49.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3245" for this suite. 04/18/23 05:42:49.505
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":271,"skipped":5030,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.757 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:42:40.761
    Apr 18 05:42:40.761: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 05:42:40.762
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:42:40.904
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:42:40.907
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 04/18/23 05:42:41.092
    Apr 18 05:42:41.321: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc" in namespace "downward-api-3245" to be "Succeeded or Failed"
    Apr 18 05:42:41.375: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc": Phase="Pending", Reason="", readiness=false. Elapsed: 53.721376ms
    Apr 18 05:42:43.424: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102271812s
    Apr 18 05:42:45.380: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc": Phase="Running", Reason="", readiness=true. Elapsed: 4.058684747s
    Apr 18 05:42:47.379: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc": Phase="Running", Reason="", readiness=false. Elapsed: 6.057451505s
    Apr 18 05:42:49.381: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.059733609s
    STEP: Saw pod success 04/18/23 05:42:49.381
    Apr 18 05:42:49.381: INFO: Pod "downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc" satisfied condition "Succeeded or Failed"
    Apr 18 05:42:49.385: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc container client-container: <nil>
    STEP: delete the pod 04/18/23 05:42:49.393
    Apr 18 05:42:49.496: INFO: Waiting for pod downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc to disappear
    Apr 18 05:42:49.499: INFO: Pod downwardapi-volume-d886920d-997a-4d22-83a1-c02233fd12bc no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 05:42:49.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3245" for this suite. 04/18/23 05:42:49.505
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:42:49.518
Apr 18 05:42:49.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 05:42:49.519
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:42:49.67
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:42:49.674
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 05:42:49.851
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:42:50.345
STEP: Deploying the webhook pod 04/18/23 05:42:50.394
STEP: Wait for the deployment to be ready 04/18/23 05:42:50.48
Apr 18 05:42:50.516: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 18 05:42:52.615: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 42, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 42, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 42, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 42, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 05:42:54.648
STEP: Verifying the service has paired with the endpoint 04/18/23 05:42:55.087
Apr 18 05:42:56.088: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/18/23 05:42:56.092
STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 05:42:56.092
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/18/23 05:42:56.14
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/18/23 05:42:57.239
STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 05:42:57.239
Apr 18 05:42:57.427: INFO: Waiting for webhook configuration to be ready...
STEP: Having no error when timeout is longer than webhook latency 04/18/23 05:42:58.654
STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 05:42:58.655
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/18/23 05:43:03.788
STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 05:43:03.788
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:43:08.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3850" for this suite. 04/18/23 05:43:08.957
STEP: Destroying namespace "webhook-3850-markers" for this suite. 04/18/23 05:43:09.007
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":272,"skipped":5031,"failed":0}
------------------------------
â€¢ [SLOW TEST] [19.814 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:42:49.518
    Apr 18 05:42:49.518: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 05:42:49.519
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:42:49.67
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:42:49.674
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 05:42:49.851
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:42:50.345
    STEP: Deploying the webhook pod 04/18/23 05:42:50.394
    STEP: Wait for the deployment to be ready 04/18/23 05:42:50.48
    Apr 18 05:42:50.516: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 18 05:42:52.615: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 42, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 42, 51, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 42, 51, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 42, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 05:42:54.648
    STEP: Verifying the service has paired with the endpoint 04/18/23 05:42:55.087
    Apr 18 05:42:56.088: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/18/23 05:42:56.092
    STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 05:42:56.092
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/18/23 05:42:56.14
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/18/23 05:42:57.239
    STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 05:42:57.239
    Apr 18 05:42:57.427: INFO: Waiting for webhook configuration to be ready...
    STEP: Having no error when timeout is longer than webhook latency 04/18/23 05:42:58.654
    STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 05:42:58.655
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/18/23 05:43:03.788
    STEP: Registering slow webhook via the AdmissionRegistration API 04/18/23 05:43:03.788
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:43:08.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3850" for this suite. 04/18/23 05:43:08.957
    STEP: Destroying namespace "webhook-3850-markers" for this suite. 04/18/23 05:43:09.007
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:43:09.333
Apr 18 05:43:09.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename statefulset 04/18/23 05:43:09.334
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:43:09.764
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:43:09.767
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-592 04/18/23 05:43:09.769
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 04/18/23 05:43:09.794
Apr 18 05:43:09.833: INFO: Found 0 stateful pods, waiting for 3
Apr 18 05:43:19.838: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 05:43:19.838: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 05:43:19.838: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 18 05:43:19.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-592 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 05:43:20.028: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 05:43:20.028: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 05:43:20.028: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/18/23 05:43:30.083
Apr 18 05:43:30.141: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/18/23 05:43:30.141
STEP: Updating Pods in reverse ordinal order 04/18/23 05:43:40.227
Apr 18 05:43:40.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-592 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 05:43:40.386: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 05:43:40.386: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 05:43:40.386: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 04/18/23 05:44:00.482
Apr 18 05:44:00.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-592 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 18 05:44:00.694: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 18 05:44:00.694: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 18 05:44:00.694: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 18 05:44:10.898: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 04/18/23 05:44:20.977
Apr 18 05:44:21.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-592 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 18 05:44:21.275: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 18 05:44:21.275: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 18 05:44:21.275: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 05:44:41.312: INFO: Deleting all statefulset in ns statefulset-592
Apr 18 05:44:41.314: INFO: Scaling statefulset ss2 to 0
Apr 18 05:44:51.363: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 05:44:51.366: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 05:44:51.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-592" for this suite. 04/18/23 05:44:51.396
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":273,"skipped":5049,"failed":0}
------------------------------
â€¢ [SLOW TEST] [102.133 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:43:09.333
    Apr 18 05:43:09.333: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename statefulset 04/18/23 05:43:09.334
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:43:09.764
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:43:09.767
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-592 04/18/23 05:43:09.769
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 04/18/23 05:43:09.794
    Apr 18 05:43:09.833: INFO: Found 0 stateful pods, waiting for 3
    Apr 18 05:43:19.838: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 05:43:19.838: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 05:43:19.838: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Apr 18 05:43:19.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-592 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 05:43:20.028: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 05:43:20.028: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 05:43:20.028: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/18/23 05:43:30.083
    Apr 18 05:43:30.141: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/18/23 05:43:30.141
    STEP: Updating Pods in reverse ordinal order 04/18/23 05:43:40.227
    Apr 18 05:43:40.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-592 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 05:43:40.386: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 05:43:40.386: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 05:43:40.386: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 04/18/23 05:44:00.482
    Apr 18 05:44:00.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-592 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 18 05:44:00.694: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 18 05:44:00.694: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 18 05:44:00.694: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 18 05:44:10.898: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 04/18/23 05:44:20.977
    Apr 18 05:44:21.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=statefulset-592 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 18 05:44:21.275: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 18 05:44:21.275: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 18 05:44:21.275: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 05:44:41.312: INFO: Deleting all statefulset in ns statefulset-592
    Apr 18 05:44:41.314: INFO: Scaling statefulset ss2 to 0
    Apr 18 05:44:51.363: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 05:44:51.366: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 05:44:51.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-592" for this suite. 04/18/23 05:44:51.396
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:44:51.467
Apr 18 05:44:51.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:44:51.468
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:44:52.112
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:44:52.115
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-1f2fd767-e414-4471-957a-4562910c1377 04/18/23 05:44:52.117
STEP: Creating a pod to test consume configMaps 04/18/23 05:44:52.346
Apr 18 05:44:52.374: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7" in namespace "projected-871" to be "Succeeded or Failed"
Apr 18 05:44:52.377: INFO: Pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.567747ms
Apr 18 05:44:54.383: INFO: Pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008764287s
Apr 18 05:44:56.381: INFO: Pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006221411s
Apr 18 05:44:58.432: INFO: Pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.057613623s
STEP: Saw pod success 04/18/23 05:44:58.432
Apr 18 05:44:58.432: INFO: Pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7" satisfied condition "Succeeded or Failed"
Apr 18 05:44:58.471: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:44:58.551
Apr 18 05:44:58.717: INFO: Waiting for pod pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7 to disappear
Apr 18 05:44:58.778: INFO: Pod pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 05:44:58.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-871" for this suite. 04/18/23 05:44:58.782
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":274,"skipped":5068,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.345 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:44:51.467
    Apr 18 05:44:51.467: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:44:51.468
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:44:52.112
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:44:52.115
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-1f2fd767-e414-4471-957a-4562910c1377 04/18/23 05:44:52.117
    STEP: Creating a pod to test consume configMaps 04/18/23 05:44:52.346
    Apr 18 05:44:52.374: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7" in namespace "projected-871" to be "Succeeded or Failed"
    Apr 18 05:44:52.377: INFO: Pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.567747ms
    Apr 18 05:44:54.383: INFO: Pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008764287s
    Apr 18 05:44:56.381: INFO: Pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006221411s
    Apr 18 05:44:58.432: INFO: Pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.057613623s
    STEP: Saw pod success 04/18/23 05:44:58.432
    Apr 18 05:44:58.432: INFO: Pod "pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7" satisfied condition "Succeeded or Failed"
    Apr 18 05:44:58.471: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:44:58.551
    Apr 18 05:44:58.717: INFO: Waiting for pod pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7 to disappear
    Apr 18 05:44:58.778: INFO: Pod pod-projected-configmaps-09bab434-b838-46d0-b62d-e8e9f2ea95b7 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 05:44:58.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-871" for this suite. 04/18/23 05:44:58.782
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:44:58.812
Apr 18 05:44:58.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename conformance-tests 04/18/23 05:44:58.813
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:44:59.083
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:44:59.086
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 04/18/23 05:44:59.089
Apr 18 05:44:59.089: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Apr 18 05:44:59.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-5664" for this suite. 04/18/23 05:44:59.106
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":275,"skipped":5073,"failed":0}
------------------------------
â€¢ [0.316 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:44:58.812
    Apr 18 05:44:58.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename conformance-tests 04/18/23 05:44:58.813
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:44:59.083
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:44:59.086
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 04/18/23 05:44:59.089
    Apr 18 05:44:59.089: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Apr 18 05:44:59.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-5664" for this suite. 04/18/23 05:44:59.106
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:44:59.129
Apr 18 05:44:59.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubelet-test 04/18/23 05:44:59.13
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:44:59.283
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:44:59.286
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 04/18/23 05:44:59.409
Apr 18 05:44:59.409: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c" in namespace "kubelet-test-3341" to be "completed"
Apr 18 05:44:59.429: INFO: Pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.867996ms
Apr 18 05:45:01.433: INFO: Pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024470968s
Apr 18 05:45:03.435: INFO: Pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025828809s
Apr 18 05:45:05.453: INFO: Pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043915211s
Apr 18 05:45:05.453: INFO: Pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 18 05:45:05.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3341" for this suite. 04/18/23 05:45:05.497
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":276,"skipped":5082,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.430 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:44:59.129
    Apr 18 05:44:59.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubelet-test 04/18/23 05:44:59.13
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:44:59.283
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:44:59.286
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 04/18/23 05:44:59.409
    Apr 18 05:44:59.409: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c" in namespace "kubelet-test-3341" to be "completed"
    Apr 18 05:44:59.429: INFO: Pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.867996ms
    Apr 18 05:45:01.433: INFO: Pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024470968s
    Apr 18 05:45:03.435: INFO: Pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025828809s
    Apr 18 05:45:05.453: INFO: Pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043915211s
    Apr 18 05:45:05.453: INFO: Pod "agnhost-host-aliasesb0ea8ea2-db97-46b2-ae9f-903e3143211c" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 18 05:45:05.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3341" for this suite. 04/18/23 05:45:05.497
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:45:05.559
Apr 18 05:45:05.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replicaset 04/18/23 05:45:05.56
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:45:05.609
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:45:05.612
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/18/23 05:45:05.66
Apr 18 05:45:05.741: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-1349" to be "running and ready"
Apr 18 05:45:05.744: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.916457ms
Apr 18 05:45:05.744: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:45:07.760: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019085579s
Apr 18 05:45:07.760: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:45:09.748: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.007576314s
Apr 18 05:45:09.748: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Apr 18 05:45:09.748: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 04/18/23 05:45:09.751
STEP: Then the orphan pod is adopted 04/18/23 05:45:09.776
STEP: When the matched label of one of its pods change 04/18/23 05:45:10.803
Apr 18 05:45:10.806: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 04/18/23 05:45:10.969
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 05:45:12.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1349" for this suite. 04/18/23 05:45:12.075
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":277,"skipped":5083,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.552 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:45:05.559
    Apr 18 05:45:05.559: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replicaset 04/18/23 05:45:05.56
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:45:05.609
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:45:05.612
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/18/23 05:45:05.66
    Apr 18 05:45:05.741: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-1349" to be "running and ready"
    Apr 18 05:45:05.744: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.916457ms
    Apr 18 05:45:05.744: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:45:07.760: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019085579s
    Apr 18 05:45:07.760: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:45:09.748: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 4.007576314s
    Apr 18 05:45:09.748: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Apr 18 05:45:09.748: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 04/18/23 05:45:09.751
    STEP: Then the orphan pod is adopted 04/18/23 05:45:09.776
    STEP: When the matched label of one of its pods change 04/18/23 05:45:10.803
    Apr 18 05:45:10.806: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/18/23 05:45:10.969
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 05:45:12.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1349" for this suite. 04/18/23 05:45:12.075
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:45:12.111
Apr 18 05:45:12.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pod-network-test 04/18/23 05:45:12.112
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:45:12.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:45:12.25
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-9234 04/18/23 05:45:12.252
STEP: creating a selector 04/18/23 05:45:12.252
STEP: Creating the service pods in kubernetes 04/18/23 05:45:12.252
Apr 18 05:45:12.252: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 18 05:45:12.581: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9234" to be "running and ready"
Apr 18 05:45:12.583: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.622159ms
Apr 18 05:45:12.583: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:45:14.719: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.138602161s
Apr 18 05:45:14.719: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:45:16.604: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022878618s
Apr 18 05:45:16.604: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:45:18.588: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.007375273s
Apr 18 05:45:18.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:45:20.588: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.007207143s
Apr 18 05:45:20.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:45:22.645: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.064513997s
Apr 18 05:45:22.645: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:45:24.588: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.007801074s
Apr 18 05:45:24.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:45:26.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.006831465s
Apr 18 05:45:26.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:45:28.591: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.010422031s
Apr 18 05:45:28.591: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:45:30.588: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.007802656s
Apr 18 05:45:30.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:45:32.597: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.016214497s
Apr 18 05:45:32.597: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 18 05:45:34.589: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.00846129s
Apr 18 05:45:34.589: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 18 05:45:34.589: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 18 05:45:34.611: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9234" to be "running and ready"
Apr 18 05:45:34.614: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.881516ms
Apr 18 05:45:34.614: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 18 05:45:34.614: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 18 05:45:34.655: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9234" to be "running and ready"
Apr 18 05:45:34.657: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.309607ms
Apr 18 05:45:34.657: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 18 05:45:34.657: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/18/23 05:45:34.672
Apr 18 05:45:34.726: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9234" to be "running"
Apr 18 05:45:34.771: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 45.106589ms
Apr 18 05:45:36.775: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049333298s
Apr 18 05:45:38.777: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.050741724s
Apr 18 05:45:38.777: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 18 05:45:38.779: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 18 05:45:38.779: INFO: Breadth first check of 172.16.100.183 on host 192.168.2.107...
Apr 18 05:45:38.782: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.45:9080/dial?request=hostname&protocol=http&host=172.16.100.183&port=8083&tries=1'] Namespace:pod-network-test-9234 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:45:38.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:45:38.783: INFO: ExecWithOptions: Clientset creation
Apr 18 05:45:38.783: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9234/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.45%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.100.183%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 05:45:38.875: INFO: Waiting for responses: map[]
Apr 18 05:45:38.875: INFO: reached 172.16.100.183 after 0/1 tries
Apr 18 05:45:38.875: INFO: Breadth first check of 172.16.125.38 on host 192.168.2.108...
Apr 18 05:45:38.880: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.45:9080/dial?request=hostname&protocol=http&host=172.16.125.38&port=8083&tries=1'] Namespace:pod-network-test-9234 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:45:38.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:45:38.881: INFO: ExecWithOptions: Clientset creation
Apr 18 05:45:38.881: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9234/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.45%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.125.38%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 05:45:39.014: INFO: Waiting for responses: map[]
Apr 18 05:45:39.014: INFO: reached 172.16.125.38 after 0/1 tries
Apr 18 05:45:39.014: INFO: Breadth first check of 172.16.144.21 on host 192.168.2.109...
Apr 18 05:45:39.018: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.45:9080/dial?request=hostname&protocol=http&host=172.16.144.21&port=8083&tries=1'] Namespace:pod-network-test-9234 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 18 05:45:39.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:45:39.019: INFO: ExecWithOptions: Clientset creation
Apr 18 05:45:39.019: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9234/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.45%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.144.21%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 18 05:45:39.091: INFO: Waiting for responses: map[]
Apr 18 05:45:39.091: INFO: reached 172.16.144.21 after 0/1 tries
Apr 18 05:45:39.091: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 18 05:45:39.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9234" for this suite. 04/18/23 05:45:39.096
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":278,"skipped":5092,"failed":0}
------------------------------
â€¢ [SLOW TEST] [27.124 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:45:12.111
    Apr 18 05:45:12.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pod-network-test 04/18/23 05:45:12.112
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:45:12.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:45:12.25
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-9234 04/18/23 05:45:12.252
    STEP: creating a selector 04/18/23 05:45:12.252
    STEP: Creating the service pods in kubernetes 04/18/23 05:45:12.252
    Apr 18 05:45:12.252: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 18 05:45:12.581: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-9234" to be "running and ready"
    Apr 18 05:45:12.583: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.622159ms
    Apr 18 05:45:12.583: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:45:14.719: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.138602161s
    Apr 18 05:45:14.719: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:45:16.604: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.022878618s
    Apr 18 05:45:16.604: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:45:18.588: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.007375273s
    Apr 18 05:45:18.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:45:20.588: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.007207143s
    Apr 18 05:45:20.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:45:22.645: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.064513997s
    Apr 18 05:45:22.645: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:45:24.588: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.007801074s
    Apr 18 05:45:24.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:45:26.587: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.006831465s
    Apr 18 05:45:26.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:45:28.591: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.010422031s
    Apr 18 05:45:28.591: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:45:30.588: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.007802656s
    Apr 18 05:45:30.588: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:45:32.597: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.016214497s
    Apr 18 05:45:32.597: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 18 05:45:34.589: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.00846129s
    Apr 18 05:45:34.589: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 18 05:45:34.589: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 18 05:45:34.611: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-9234" to be "running and ready"
    Apr 18 05:45:34.614: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 2.881516ms
    Apr 18 05:45:34.614: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 18 05:45:34.614: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 18 05:45:34.655: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-9234" to be "running and ready"
    Apr 18 05:45:34.657: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 2.309607ms
    Apr 18 05:45:34.657: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 18 05:45:34.657: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/18/23 05:45:34.672
    Apr 18 05:45:34.726: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-9234" to be "running"
    Apr 18 05:45:34.771: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 45.106589ms
    Apr 18 05:45:36.775: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049333298s
    Apr 18 05:45:38.777: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.050741724s
    Apr 18 05:45:38.777: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 18 05:45:38.779: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 18 05:45:38.779: INFO: Breadth first check of 172.16.100.183 on host 192.168.2.107...
    Apr 18 05:45:38.782: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.45:9080/dial?request=hostname&protocol=http&host=172.16.100.183&port=8083&tries=1'] Namespace:pod-network-test-9234 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:45:38.782: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:45:38.783: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:45:38.783: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9234/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.45%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.100.183%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 05:45:38.875: INFO: Waiting for responses: map[]
    Apr 18 05:45:38.875: INFO: reached 172.16.100.183 after 0/1 tries
    Apr 18 05:45:38.875: INFO: Breadth first check of 172.16.125.38 on host 192.168.2.108...
    Apr 18 05:45:38.880: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.45:9080/dial?request=hostname&protocol=http&host=172.16.125.38&port=8083&tries=1'] Namespace:pod-network-test-9234 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:45:38.880: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:45:38.881: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:45:38.881: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9234/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.45%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.125.38%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 05:45:39.014: INFO: Waiting for responses: map[]
    Apr 18 05:45:39.014: INFO: reached 172.16.125.38 after 0/1 tries
    Apr 18 05:45:39.014: INFO: Breadth first check of 172.16.144.21 on host 192.168.2.109...
    Apr 18 05:45:39.018: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.16.125.45:9080/dial?request=hostname&protocol=http&host=172.16.144.21&port=8083&tries=1'] Namespace:pod-network-test-9234 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 18 05:45:39.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:45:39.019: INFO: ExecWithOptions: Clientset creation
    Apr 18 05:45:39.019: INFO: ExecWithOptions: execute(POST https://10.96.0.1:443/api/v1/namespaces/pod-network-test-9234/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F172.16.125.45%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D172.16.144.21%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 18 05:45:39.091: INFO: Waiting for responses: map[]
    Apr 18 05:45:39.091: INFO: reached 172.16.144.21 after 0/1 tries
    Apr 18 05:45:39.091: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 18 05:45:39.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-9234" for this suite. 04/18/23 05:45:39.096
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:45:39.236
Apr 18 05:45:39.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename daemonsets 04/18/23 05:45:39.237
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:45:39.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:45:39.316
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Apr 18 05:45:39.431: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 04/18/23 05:45:39.455
Apr 18 05:45:39.458: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:39.458: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 04/18/23 05:45:39.458
Apr 18 05:45:39.764: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:39.764: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:40.768: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:40.768: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:41.768: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:41.768: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:42.769: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 05:45:42.769: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 04/18/23 05:45:42.772
Apr 18 05:45:42.828: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 05:45:42.828: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Apr 18 05:45:43.912: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:43.912: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/18/23 05:45:43.912
Apr 18 05:45:43.958: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:43.958: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:44.970: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:44.970: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:46.147: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:46.147: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:46.992: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:46.992: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:48.005: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:48.005: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:49.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:49.095: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:50.162: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:50.162: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:50.966: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:50.966: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:51.962: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:51.962: INFO: Node apps-208 is running 0 daemon pod, expected 1
Apr 18 05:45:52.962: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 18 05:45:52.962: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 05:45:52.968
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7197, will wait for the garbage collector to delete the pods 04/18/23 05:45:52.968
Apr 18 05:45:53.040: INFO: Deleting DaemonSet.extensions daemon-set took: 19.107729ms
Apr 18 05:45:53.341: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.597325ms
Apr 18 05:45:56.474: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:45:56.474: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 05:45:56.502: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4119742"},"items":null}

Apr 18 05:45:56.511: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4119742"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:45:56.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7197" for this suite. 04/18/23 05:45:56.57
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":279,"skipped":5100,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.396 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:45:39.236
    Apr 18 05:45:39.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename daemonsets 04/18/23 05:45:39.237
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:45:39.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:45:39.316
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Apr 18 05:45:39.431: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 04/18/23 05:45:39.455
    Apr 18 05:45:39.458: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:39.458: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 04/18/23 05:45:39.458
    Apr 18 05:45:39.764: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:39.764: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:40.768: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:40.768: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:41.768: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:41.768: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:42.769: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 05:45:42.769: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 04/18/23 05:45:42.772
    Apr 18 05:45:42.828: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 05:45:42.828: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Apr 18 05:45:43.912: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:43.912: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/18/23 05:45:43.912
    Apr 18 05:45:43.958: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:43.958: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:44.970: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:44.970: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:46.147: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:46.147: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:46.992: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:46.992: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:48.005: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:48.005: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:49.095: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:49.095: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:50.162: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:50.162: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:50.966: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:50.966: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:51.962: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:51.962: INFO: Node apps-208 is running 0 daemon pod, expected 1
    Apr 18 05:45:52.962: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 18 05:45:52.962: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 05:45:52.968
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7197, will wait for the garbage collector to delete the pods 04/18/23 05:45:52.968
    Apr 18 05:45:53.040: INFO: Deleting DaemonSet.extensions daemon-set took: 19.107729ms
    Apr 18 05:45:53.341: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.597325ms
    Apr 18 05:45:56.474: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:45:56.474: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 05:45:56.502: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4119742"},"items":null}

    Apr 18 05:45:56.511: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4119742"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:45:56.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7197" for this suite. 04/18/23 05:45:56.57
  << End Captured GinkgoWriter Output
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:45:56.632
Apr 18 05:45:56.633: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename certificates 04/18/23 05:45:56.634
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:45:56.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:45:56.691
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 04/18/23 05:45:57.902
STEP: getting /apis/certificates.k8s.io 04/18/23 05:45:57.905
STEP: getting /apis/certificates.k8s.io/v1 04/18/23 05:45:57.906
STEP: creating 04/18/23 05:45:57.907
STEP: getting 04/18/23 05:45:58.611
STEP: listing 04/18/23 05:45:58.629
STEP: watching 04/18/23 05:45:58.633
Apr 18 05:45:58.633: INFO: starting watch
STEP: patching 04/18/23 05:45:58.634
STEP: updating 04/18/23 05:45:58.679
Apr 18 05:45:58.778: INFO: waiting for watch events with expected annotations
Apr 18 05:45:58.778: INFO: saw patched and updated annotations
STEP: getting /approval 04/18/23 05:45:58.778
STEP: patching /approval 04/18/23 05:45:58.781
STEP: updating /approval 04/18/23 05:45:58.846
STEP: getting /status 04/18/23 05:45:58.95
STEP: patching /status 04/18/23 05:45:58.987
STEP: updating /status 04/18/23 05:45:59.021
STEP: deleting 04/18/23 05:45:59.099
STEP: deleting a collection 04/18/23 05:45:59.295
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:45:59.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-4292" for this suite. 04/18/23 05:45:59.374
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":280,"skipped":5100,"failed":0}
------------------------------
â€¢ [2.809 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:45:56.632
    Apr 18 05:45:56.633: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename certificates 04/18/23 05:45:56.634
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:45:56.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:45:56.691
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 04/18/23 05:45:57.902
    STEP: getting /apis/certificates.k8s.io 04/18/23 05:45:57.905
    STEP: getting /apis/certificates.k8s.io/v1 04/18/23 05:45:57.906
    STEP: creating 04/18/23 05:45:57.907
    STEP: getting 04/18/23 05:45:58.611
    STEP: listing 04/18/23 05:45:58.629
    STEP: watching 04/18/23 05:45:58.633
    Apr 18 05:45:58.633: INFO: starting watch
    STEP: patching 04/18/23 05:45:58.634
    STEP: updating 04/18/23 05:45:58.679
    Apr 18 05:45:58.778: INFO: waiting for watch events with expected annotations
    Apr 18 05:45:58.778: INFO: saw patched and updated annotations
    STEP: getting /approval 04/18/23 05:45:58.778
    STEP: patching /approval 04/18/23 05:45:58.781
    STEP: updating /approval 04/18/23 05:45:58.846
    STEP: getting /status 04/18/23 05:45:58.95
    STEP: patching /status 04/18/23 05:45:58.987
    STEP: updating /status 04/18/23 05:45:59.021
    STEP: deleting 04/18/23 05:45:59.099
    STEP: deleting a collection 04/18/23 05:45:59.295
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:45:59.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-4292" for this suite. 04/18/23 05:45:59.374
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:45:59.444
Apr 18 05:45:59.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 05:45:59.445
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:45:59.616
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:45:59.619
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 05:45:59.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6466" for this suite. 04/18/23 05:46:00.034
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":281,"skipped":5143,"failed":0}
------------------------------
â€¢ [0.648 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:45:59.444
    Apr 18 05:45:59.444: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 05:45:59.445
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:45:59.616
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:45:59.619
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 05:45:59.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6466" for this suite. 04/18/23 05:46:00.034
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:46:00.092
Apr 18 05:46:00.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename gc 04/18/23 05:46:00.094
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:46:00.116
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:46:00.118
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 04/18/23 05:46:00.154
STEP: delete the rc 04/18/23 05:46:05.626
STEP: wait for the rc to be deleted 04/18/23 05:46:05.971
Apr 18 05:46:08.118: INFO: 88 pods remaining
Apr 18 05:46:08.118: INFO: 81 pods has nil DeletionTimestamp
Apr 18 05:46:08.118: INFO: 
Apr 18 05:46:09.552: INFO: 79 pods remaining
Apr 18 05:46:09.552: INFO: 72 pods has nil DeletionTimestamp
Apr 18 05:46:09.552: INFO: 
Apr 18 05:46:10.969: INFO: 65 pods remaining
Apr 18 05:46:10.969: INFO: 62 pods has nil DeletionTimestamp
Apr 18 05:46:10.969: INFO: 
Apr 18 05:46:12.070: INFO: 59 pods remaining
Apr 18 05:46:12.070: INFO: 51 pods has nil DeletionTimestamp
Apr 18 05:46:12.070: INFO: 
Apr 18 05:46:14.347: INFO: 42 pods remaining
Apr 18 05:46:14.347: INFO: 39 pods has nil DeletionTimestamp
Apr 18 05:46:14.347: INFO: 
Apr 18 05:46:15.884: INFO: 29 pods remaining
Apr 18 05:46:15.884: INFO: 23 pods has nil DeletionTimestamp
Apr 18 05:46:15.884: INFO: 
Apr 18 05:46:17.410: INFO: 18 pods remaining
Apr 18 05:46:17.410: INFO: 13 pods has nil DeletionTimestamp
Apr 18 05:46:17.410: INFO: 
Apr 18 05:46:18.525: INFO: 7 pods remaining
Apr 18 05:46:18.525: INFO: 2 pods has nil DeletionTimestamp
Apr 18 05:46:18.525: INFO: 
Apr 18 05:46:19.411: INFO: 1 pods remaining
Apr 18 05:46:19.411: INFO: 0 pods has nil DeletionTimestamp
Apr 18 05:46:19.411: INFO: 
STEP: Gathering metrics 04/18/23 05:46:20.165
Apr 18 05:46:20.235: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
Apr 18 05:46:20.431: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 195.659524ms
Apr 18 05:46:20.431: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
Apr 18 05:46:20.431: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
Apr 18 05:46:20.644: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 05:46:20.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9220" for this suite. 04/18/23 05:46:20.888
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":282,"skipped":5157,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.866 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:46:00.092
    Apr 18 05:46:00.093: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename gc 04/18/23 05:46:00.094
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:46:00.116
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:46:00.118
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 04/18/23 05:46:00.154
    STEP: delete the rc 04/18/23 05:46:05.626
    STEP: wait for the rc to be deleted 04/18/23 05:46:05.971
    Apr 18 05:46:08.118: INFO: 88 pods remaining
    Apr 18 05:46:08.118: INFO: 81 pods has nil DeletionTimestamp
    Apr 18 05:46:08.118: INFO: 
    Apr 18 05:46:09.552: INFO: 79 pods remaining
    Apr 18 05:46:09.552: INFO: 72 pods has nil DeletionTimestamp
    Apr 18 05:46:09.552: INFO: 
    Apr 18 05:46:10.969: INFO: 65 pods remaining
    Apr 18 05:46:10.969: INFO: 62 pods has nil DeletionTimestamp
    Apr 18 05:46:10.969: INFO: 
    Apr 18 05:46:12.070: INFO: 59 pods remaining
    Apr 18 05:46:12.070: INFO: 51 pods has nil DeletionTimestamp
    Apr 18 05:46:12.070: INFO: 
    Apr 18 05:46:14.347: INFO: 42 pods remaining
    Apr 18 05:46:14.347: INFO: 39 pods has nil DeletionTimestamp
    Apr 18 05:46:14.347: INFO: 
    Apr 18 05:46:15.884: INFO: 29 pods remaining
    Apr 18 05:46:15.884: INFO: 23 pods has nil DeletionTimestamp
    Apr 18 05:46:15.884: INFO: 
    Apr 18 05:46:17.410: INFO: 18 pods remaining
    Apr 18 05:46:17.410: INFO: 13 pods has nil DeletionTimestamp
    Apr 18 05:46:17.410: INFO: 
    Apr 18 05:46:18.525: INFO: 7 pods remaining
    Apr 18 05:46:18.525: INFO: 2 pods has nil DeletionTimestamp
    Apr 18 05:46:18.525: INFO: 
    Apr 18 05:46:19.411: INFO: 1 pods remaining
    Apr 18 05:46:19.411: INFO: 0 pods has nil DeletionTimestamp
    Apr 18 05:46:19.411: INFO: 
    STEP: Gathering metrics 04/18/23 05:46:20.165
    Apr 18 05:46:20.235: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
    Apr 18 05:46:20.431: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 195.659524ms
    Apr 18 05:46:20.431: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
    Apr 18 05:46:20.431: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
    Apr 18 05:46:20.644: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 05:46:20.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9220" for this suite. 04/18/23 05:46:20.888
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:46:20.96
Apr 18 05:46:20.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename aggregator 04/18/23 05:46:20.961
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:46:21.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:46:21.332
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Apr 18 05:46:21.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 04/18/23 05:46:21.424
Apr 18 05:46:24.551: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 18 05:46:30.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:32.553: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:34.536: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:36.288: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:38.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:40.310: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:42.255: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:44.270: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:46.254: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:48.255: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:50.256: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:52.254: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:54.255: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:56.255: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:46:58.255: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:47:00.257: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 18 05:47:02.455: INFO: Waited 154.10369ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 04/18/23 05:47:02.792
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/18/23 05:47:02.814
STEP: List APIServices 04/18/23 05:47:02.874
Apr 18 05:47:02.881: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Apr 18 05:47:04.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2457" for this suite. 04/18/23 05:47:04.308
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":283,"skipped":5176,"failed":0}
------------------------------
â€¢ [SLOW TEST] [43.363 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:46:20.96
    Apr 18 05:46:20.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename aggregator 04/18/23 05:46:20.961
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:46:21.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:46:21.332
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Apr 18 05:46:21.423: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 04/18/23 05:46:21.424
    Apr 18 05:46:24.551: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Apr 18 05:46:30.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:32.553: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:34.536: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:36.288: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:38.519: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:40.310: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:42.255: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:44.270: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:46.254: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:48.255: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:50.256: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:52.254: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:54.255: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:56.255: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:46:58.255: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:47:00.257: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 46, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 46, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5885c99c55\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 18 05:47:02.455: INFO: Waited 154.10369ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 04/18/23 05:47:02.792
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/18/23 05:47:02.814
    STEP: List APIServices 04/18/23 05:47:02.874
    Apr 18 05:47:02.881: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Apr 18 05:47:04.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-2457" for this suite. 04/18/23 05:47:04.308
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:47:04.323
Apr 18 05:47:04.323: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 05:47:04.324
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:04.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:04.359
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 04/18/23 05:47:04.452
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/18/23 05:47:04.453
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/18/23 05:47:04.453
STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/18/23 05:47:04.453
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/18/23 05:47:04.455
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/18/23 05:47:04.455
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/18/23 05:47:04.456
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:47:04.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4321" for this suite. 04/18/23 05:47:04.486
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":284,"skipped":5182,"failed":0}
------------------------------
â€¢ [0.190 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:47:04.323
    Apr 18 05:47:04.323: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename custom-resource-definition 04/18/23 05:47:04.324
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:04.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:04.359
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 04/18/23 05:47:04.452
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/18/23 05:47:04.453
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/18/23 05:47:04.453
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/18/23 05:47:04.453
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/18/23 05:47:04.455
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/18/23 05:47:04.455
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/18/23 05:47:04.456
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:47:04.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-4321" for this suite. 04/18/23 05:47:04.486
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:47:04.513
Apr 18 05:47:04.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 05:47:04.514
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:04.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:04.669
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/18/23 05:47:04.785
Apr 18 05:47:04.824: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5747" to be "running and ready"
Apr 18 05:47:04.847: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 22.853969ms
Apr 18 05:47:04.847: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:47:06.948: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123360355s
Apr 18 05:47:06.948: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:47:08.851: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.027273954s
Apr 18 05:47:08.851: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 18 05:47:08.851: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 04/18/23 05:47:08.854
Apr 18 05:47:08.924: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-5747" to be "running and ready"
Apr 18 05:47:08.975: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 50.529165ms
Apr 18 05:47:08.975: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:47:10.992: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067589172s
Apr 18 05:47:10.992: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:47:12.980: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.055291678s
Apr 18 05:47:12.980: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Apr 18 05:47:12.980: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/18/23 05:47:12.982
Apr 18 05:47:13.026: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 18 05:47:13.029: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 18 05:47:15.030: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 18 05:47:15.059: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 18 05:47:17.030: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 18 05:47:17.034: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 04/18/23 05:47:17.034
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 18 05:47:17.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5747" for this suite. 04/18/23 05:47:17.078
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":285,"skipped":5189,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.595 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:47:04.513
    Apr 18 05:47:04.513: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/18/23 05:47:04.514
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:04.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:04.669
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/18/23 05:47:04.785
    Apr 18 05:47:04.824: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5747" to be "running and ready"
    Apr 18 05:47:04.847: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 22.853969ms
    Apr 18 05:47:04.847: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:47:06.948: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123360355s
    Apr 18 05:47:06.948: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:47:08.851: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 4.027273954s
    Apr 18 05:47:08.851: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 18 05:47:08.851: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 04/18/23 05:47:08.854
    Apr 18 05:47:08.924: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-5747" to be "running and ready"
    Apr 18 05:47:08.975: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 50.529165ms
    Apr 18 05:47:08.975: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:47:10.992: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067589172s
    Apr 18 05:47:10.992: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:47:12.980: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 4.055291678s
    Apr 18 05:47:12.980: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Apr 18 05:47:12.980: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/18/23 05:47:12.982
    Apr 18 05:47:13.026: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 18 05:47:13.029: INFO: Pod pod-with-prestop-exec-hook still exists
    Apr 18 05:47:15.030: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 18 05:47:15.059: INFO: Pod pod-with-prestop-exec-hook still exists
    Apr 18 05:47:17.030: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 18 05:47:17.034: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 04/18/23 05:47:17.034
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 18 05:47:17.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-5747" for this suite. 04/18/23 05:47:17.078
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:47:17.109
Apr 18 05:47:17.109: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:47:17.11
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:17.258
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:17.261
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 04/18/23 05:47:17.318
Apr 18 05:47:17.386: INFO: Waiting up to 5m0s for pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be" in namespace "projected-8203" to be "running and ready"
Apr 18 05:47:17.560: INFO: Pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be": Phase="Pending", Reason="", readiness=false. Elapsed: 173.698364ms
Apr 18 05:47:17.560: INFO: The phase of Pod labelsupdate23275047-a742-47a0-b454-13fb96b9c1be is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:47:19.564: INFO: Pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.17765833s
Apr 18 05:47:19.564: INFO: The phase of Pod labelsupdate23275047-a742-47a0-b454-13fb96b9c1be is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:47:21.565: INFO: Pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be": Phase="Running", Reason="", readiness=true. Elapsed: 4.178358698s
Apr 18 05:47:21.565: INFO: The phase of Pod labelsupdate23275047-a742-47a0-b454-13fb96b9c1be is Running (Ready = true)
Apr 18 05:47:21.565: INFO: Pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be" satisfied condition "running and ready"
Apr 18 05:47:22.128: INFO: Successfully updated pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 05:47:24.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8203" for this suite. 04/18/23 05:47:24.252
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":286,"skipped":5191,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.200 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:47:17.109
    Apr 18 05:47:17.109: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:47:17.11
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:17.258
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:17.261
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 04/18/23 05:47:17.318
    Apr 18 05:47:17.386: INFO: Waiting up to 5m0s for pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be" in namespace "projected-8203" to be "running and ready"
    Apr 18 05:47:17.560: INFO: Pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be": Phase="Pending", Reason="", readiness=false. Elapsed: 173.698364ms
    Apr 18 05:47:17.560: INFO: The phase of Pod labelsupdate23275047-a742-47a0-b454-13fb96b9c1be is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:47:19.564: INFO: Pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.17765833s
    Apr 18 05:47:19.564: INFO: The phase of Pod labelsupdate23275047-a742-47a0-b454-13fb96b9c1be is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:47:21.565: INFO: Pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be": Phase="Running", Reason="", readiness=true. Elapsed: 4.178358698s
    Apr 18 05:47:21.565: INFO: The phase of Pod labelsupdate23275047-a742-47a0-b454-13fb96b9c1be is Running (Ready = true)
    Apr 18 05:47:21.565: INFO: Pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be" satisfied condition "running and ready"
    Apr 18 05:47:22.128: INFO: Successfully updated pod "labelsupdate23275047-a742-47a0-b454-13fb96b9c1be"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 05:47:24.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8203" for this suite. 04/18/23 05:47:24.252
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:47:24.31
Apr 18 05:47:24.310: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 05:47:24.311
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:24.392
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:24.394
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 04/18/23 05:47:24.401
Apr 18 05:47:24.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-3963 cluster-info'
Apr 18 05:47:24.477: INFO: stderr: ""
Apr 18 05:47:24.477: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 05:47:24.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3963" for this suite. 04/18/23 05:47:24.521
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":287,"skipped":5202,"failed":0}
------------------------------
â€¢ [0.274 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:47:24.31
    Apr 18 05:47:24.310: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 05:47:24.311
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:24.392
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:24.394
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 04/18/23 05:47:24.401
    Apr 18 05:47:24.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-3963 cluster-info'
    Apr 18 05:47:24.477: INFO: stderr: ""
    Apr 18 05:47:24.477: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 05:47:24.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3963" for this suite. 04/18/23 05:47:24.521
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:47:24.585
Apr 18 05:47:24.585: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename dns 04/18/23 05:47:24.586
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:24.76
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:24.764
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/18/23 05:47:24.766
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/18/23 05:47:24.766
STEP: creating a pod to probe DNS 04/18/23 05:47:24.766
STEP: submitting the pod to kubernetes 04/18/23 05:47:24.766
Apr 18 05:47:24.960: INFO: Waiting up to 15m0s for pod "dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f" in namespace "dns-2753" to be "running"
Apr 18 05:47:24.964: INFO: Pod "dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.450123ms
Apr 18 05:47:27.265: INFO: Pod "dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.304905105s
Apr 18 05:47:29.341: INFO: Pod "dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f": Phase="Running", Reason="", readiness=true. Elapsed: 4.380847315s
Apr 18 05:47:29.341: INFO: Pod "dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f" satisfied condition "running"
STEP: retrieving the pod 04/18/23 05:47:29.341
STEP: looking for the results for each expected name from probers 04/18/23 05:47:29.361
Apr 18 05:47:29.413: INFO: DNS probes using dns-2753/dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f succeeded

STEP: deleting the pod 04/18/23 05:47:29.413
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 05:47:29.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2753" for this suite. 04/18/23 05:47:29.587
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":288,"skipped":5219,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.059 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:47:24.585
    Apr 18 05:47:24.585: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename dns 04/18/23 05:47:24.586
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:24.76
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:24.764
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/18/23 05:47:24.766
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/18/23 05:47:24.766
    STEP: creating a pod to probe DNS 04/18/23 05:47:24.766
    STEP: submitting the pod to kubernetes 04/18/23 05:47:24.766
    Apr 18 05:47:24.960: INFO: Waiting up to 15m0s for pod "dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f" in namespace "dns-2753" to be "running"
    Apr 18 05:47:24.964: INFO: Pod "dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.450123ms
    Apr 18 05:47:27.265: INFO: Pod "dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.304905105s
    Apr 18 05:47:29.341: INFO: Pod "dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f": Phase="Running", Reason="", readiness=true. Elapsed: 4.380847315s
    Apr 18 05:47:29.341: INFO: Pod "dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 05:47:29.341
    STEP: looking for the results for each expected name from probers 04/18/23 05:47:29.361
    Apr 18 05:47:29.413: INFO: DNS probes using dns-2753/dns-test-7761715b-7a62-47e7-b5b6-896b98c04f2f succeeded

    STEP: deleting the pod 04/18/23 05:47:29.413
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 05:47:29.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2753" for this suite. 04/18/23 05:47:29.587
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:47:29.646
Apr 18 05:47:29.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sched-preemption 04/18/23 05:47:29.647
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:29.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:29.83
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 18 05:47:29.969: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 05:48:30.037: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:48:30.04
Apr 18 05:48:30.041: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sched-preemption-path 04/18/23 05:48:30.041
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:48:30.17
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:48:30.174
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 04/18/23 05:48:30.177
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 05:48:30.177
Apr 18 05:48:30.282: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-6213" to be "running"
Apr 18 05:48:30.292: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 9.770458ms
Apr 18 05:48:32.297: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014810946s
Apr 18 05:48:34.296: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.01436414s
Apr 18 05:48:34.296: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 05:48:34.299
Apr 18 05:48:34.458: INFO: found a healthy node: apps-208
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Apr 18 05:48:46.947: INFO: pods created so far: [1 1 1]
Apr 18 05:48:46.947: INFO: length of pods created so far: 3
Apr 18 05:48:50.985: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Apr 18 05:48:57.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-6213" for this suite. 04/18/23 05:48:58.055
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:48:58.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8721" for this suite. 04/18/23 05:48:58.25
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":289,"skipped":5267,"failed":0}
------------------------------
â€¢ [SLOW TEST] [88.771 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:47:29.646
    Apr 18 05:47:29.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sched-preemption 04/18/23 05:47:29.647
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:47:29.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:47:29.83
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 18 05:47:29.969: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 05:48:30.037: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:48:30.04
    Apr 18 05:48:30.041: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sched-preemption-path 04/18/23 05:48:30.041
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:48:30.17
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:48:30.174
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 04/18/23 05:48:30.177
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/18/23 05:48:30.177
    Apr 18 05:48:30.282: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-6213" to be "running"
    Apr 18 05:48:30.292: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 9.770458ms
    Apr 18 05:48:32.297: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014810946s
    Apr 18 05:48:34.296: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 4.01436414s
    Apr 18 05:48:34.296: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/18/23 05:48:34.299
    Apr 18 05:48:34.458: INFO: found a healthy node: apps-208
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Apr 18 05:48:46.947: INFO: pods created so far: [1 1 1]
    Apr 18 05:48:46.947: INFO: length of pods created so far: 3
    Apr 18 05:48:50.985: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Apr 18 05:48:57.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-6213" for this suite. 04/18/23 05:48:58.055
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:48:58.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8721" for this suite. 04/18/23 05:48:58.25
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:48:58.418
Apr 18 05:48:58.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 05:48:58.419
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:48:58.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:48:58.509
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 05:48:58.511
Apr 18 05:48:58.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9080 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Apr 18 05:48:58.654: INFO: stderr: ""
Apr 18 05:48:58.654: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 04/18/23 05:48:58.654
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Apr 18 05:48:58.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9080 delete pods e2e-test-httpd-pod'
Apr 18 05:49:03.864: INFO: stderr: ""
Apr 18 05:49:03.864: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 05:49:03.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9080" for this suite. 04/18/23 05:49:03.874
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":290,"skipped":5279,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.478 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:48:58.418
    Apr 18 05:48:58.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 05:48:58.419
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:48:58.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:48:58.509
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 05:48:58.511
    Apr 18 05:48:58.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9080 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Apr 18 05:48:58.654: INFO: stderr: ""
    Apr 18 05:48:58.654: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 04/18/23 05:48:58.654
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Apr 18 05:48:58.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-9080 delete pods e2e-test-httpd-pod'
    Apr 18 05:49:03.864: INFO: stderr: ""
    Apr 18 05:49:03.864: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 05:49:03.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9080" for this suite. 04/18/23 05:49:03.874
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:49:03.897
Apr 18 05:49:03.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename events 04/18/23 05:49:03.898
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:04.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:04.012
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 04/18/23 05:49:04.015
Apr 18 05:49:04.027: INFO: created test-event-1
Apr 18 05:49:04.045: INFO: created test-event-2
Apr 18 05:49:04.063: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 04/18/23 05:49:04.063
STEP: delete collection of events 04/18/23 05:49:04.08
Apr 18 05:49:04.080: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/18/23 05:49:04.278
Apr 18 05:49:04.279: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Apr 18 05:49:04.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9289" for this suite. 04/18/23 05:49:04.44
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":291,"skipped":5296,"failed":0}
------------------------------
â€¢ [0.572 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:49:03.897
    Apr 18 05:49:03.897: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename events 04/18/23 05:49:03.898
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:04.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:04.012
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 04/18/23 05:49:04.015
    Apr 18 05:49:04.027: INFO: created test-event-1
    Apr 18 05:49:04.045: INFO: created test-event-2
    Apr 18 05:49:04.063: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 04/18/23 05:49:04.063
    STEP: delete collection of events 04/18/23 05:49:04.08
    Apr 18 05:49:04.080: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/18/23 05:49:04.278
    Apr 18 05:49:04.279: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Apr 18 05:49:04.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-9289" for this suite. 04/18/23 05:49:04.44
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:49:04.475
Apr 18 05:49:04.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 05:49:04.476
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:04.73
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:04.733
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 04/18/23 05:49:21.74
STEP: Creating a ResourceQuota 04/18/23 05:49:26.745
STEP: Ensuring resource quota status is calculated 04/18/23 05:49:26.781
STEP: Creating a ConfigMap 04/18/23 05:49:28.785
STEP: Ensuring resource quota status captures configMap creation 04/18/23 05:49:28.839
STEP: Deleting a ConfigMap 04/18/23 05:49:30.844
STEP: Ensuring resource quota status released usage 04/18/23 05:49:30.871
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 05:49:32.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6619" for this suite. 04/18/23 05:49:32.88
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":292,"skipped":5372,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.429 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:49:04.475
    Apr 18 05:49:04.475: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 05:49:04.476
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:04.73
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:04.733
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 04/18/23 05:49:21.74
    STEP: Creating a ResourceQuota 04/18/23 05:49:26.745
    STEP: Ensuring resource quota status is calculated 04/18/23 05:49:26.781
    STEP: Creating a ConfigMap 04/18/23 05:49:28.785
    STEP: Ensuring resource quota status captures configMap creation 04/18/23 05:49:28.839
    STEP: Deleting a ConfigMap 04/18/23 05:49:30.844
    STEP: Ensuring resource quota status released usage 04/18/23 05:49:30.871
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 05:49:32.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6619" for this suite. 04/18/23 05:49:32.88
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:49:32.905
Apr 18 05:49:32.906: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 05:49:32.907
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:33.045
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:33.048
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-4d07c453-067b-4d99-ba56-22c0aed51cfc 04/18/23 05:49:33.051
STEP: Creating a pod to test consume configMaps 04/18/23 05:49:33.062
Apr 18 05:49:33.176: INFO: Waiting up to 5m0s for pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4" in namespace "configmap-4685" to be "Succeeded or Failed"
Apr 18 05:49:33.224: INFO: Pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4": Phase="Pending", Reason="", readiness=false. Elapsed: 47.601754ms
Apr 18 05:49:35.269: INFO: Pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092746108s
Apr 18 05:49:37.228: INFO: Pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4": Phase="Running", Reason="", readiness=false. Elapsed: 4.05225585s
Apr 18 05:49:39.228: INFO: Pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052111168s
STEP: Saw pod success 04/18/23 05:49:39.228
Apr 18 05:49:39.228: INFO: Pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4" satisfied condition "Succeeded or Failed"
Apr 18 05:49:39.231: INFO: Trying to get logs from node apps-208 pod pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:49:39.243
Apr 18 05:49:39.432: INFO: Waiting for pod pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4 to disappear
Apr 18 05:49:39.463: INFO: Pod pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 05:49:39.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4685" for this suite. 04/18/23 05:49:39.468
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":293,"skipped":5379,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.620 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:49:32.905
    Apr 18 05:49:32.906: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 05:49:32.907
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:33.045
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:33.048
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-4d07c453-067b-4d99-ba56-22c0aed51cfc 04/18/23 05:49:33.051
    STEP: Creating a pod to test consume configMaps 04/18/23 05:49:33.062
    Apr 18 05:49:33.176: INFO: Waiting up to 5m0s for pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4" in namespace "configmap-4685" to be "Succeeded or Failed"
    Apr 18 05:49:33.224: INFO: Pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4": Phase="Pending", Reason="", readiness=false. Elapsed: 47.601754ms
    Apr 18 05:49:35.269: INFO: Pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092746108s
    Apr 18 05:49:37.228: INFO: Pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4": Phase="Running", Reason="", readiness=false. Elapsed: 4.05225585s
    Apr 18 05:49:39.228: INFO: Pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052111168s
    STEP: Saw pod success 04/18/23 05:49:39.228
    Apr 18 05:49:39.228: INFO: Pod "pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4" satisfied condition "Succeeded or Failed"
    Apr 18 05:49:39.231: INFO: Trying to get logs from node apps-208 pod pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:49:39.243
    Apr 18 05:49:39.432: INFO: Waiting for pod pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4 to disappear
    Apr 18 05:49:39.463: INFO: Pod pod-configmaps-58b993c7-be86-4ee2-a387-48013cfd9fe4 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 05:49:39.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4685" for this suite. 04/18/23 05:49:39.468
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:49:39.526
Apr 18 05:49:39.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 05:49:39.527
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:39.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:39.625
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/18/23 05:49:39.643
Apr 18 05:49:39.748: INFO: Waiting up to 5m0s for pod "pod-3753d919-ec36-4890-86ce-184d601afc85" in namespace "emptydir-1884" to be "Succeeded or Failed"
Apr 18 05:49:39.752: INFO: Pod "pod-3753d919-ec36-4890-86ce-184d601afc85": Phase="Pending", Reason="", readiness=false. Elapsed: 3.779241ms
Apr 18 05:49:41.758: INFO: Pod "pod-3753d919-ec36-4890-86ce-184d601afc85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009329391s
Apr 18 05:49:43.756: INFO: Pod "pod-3753d919-ec36-4890-86ce-184d601afc85": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00825573s
Apr 18 05:49:45.756: INFO: Pod "pod-3753d919-ec36-4890-86ce-184d601afc85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008066479s
STEP: Saw pod success 04/18/23 05:49:45.756
Apr 18 05:49:45.756: INFO: Pod "pod-3753d919-ec36-4890-86ce-184d601afc85" satisfied condition "Succeeded or Failed"
Apr 18 05:49:45.764: INFO: Trying to get logs from node apps-208 pod pod-3753d919-ec36-4890-86ce-184d601afc85 container test-container: <nil>
STEP: delete the pod 04/18/23 05:49:45.77
Apr 18 05:49:45.841: INFO: Waiting for pod pod-3753d919-ec36-4890-86ce-184d601afc85 to disappear
Apr 18 05:49:45.948: INFO: Pod pod-3753d919-ec36-4890-86ce-184d601afc85 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 05:49:45.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1884" for this suite. 04/18/23 05:49:45.957
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":294,"skipped":5396,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.456 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:49:39.526
    Apr 18 05:49:39.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 05:49:39.527
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:39.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:39.625
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/18/23 05:49:39.643
    Apr 18 05:49:39.748: INFO: Waiting up to 5m0s for pod "pod-3753d919-ec36-4890-86ce-184d601afc85" in namespace "emptydir-1884" to be "Succeeded or Failed"
    Apr 18 05:49:39.752: INFO: Pod "pod-3753d919-ec36-4890-86ce-184d601afc85": Phase="Pending", Reason="", readiness=false. Elapsed: 3.779241ms
    Apr 18 05:49:41.758: INFO: Pod "pod-3753d919-ec36-4890-86ce-184d601afc85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009329391s
    Apr 18 05:49:43.756: INFO: Pod "pod-3753d919-ec36-4890-86ce-184d601afc85": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00825573s
    Apr 18 05:49:45.756: INFO: Pod "pod-3753d919-ec36-4890-86ce-184d601afc85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008066479s
    STEP: Saw pod success 04/18/23 05:49:45.756
    Apr 18 05:49:45.756: INFO: Pod "pod-3753d919-ec36-4890-86ce-184d601afc85" satisfied condition "Succeeded or Failed"
    Apr 18 05:49:45.764: INFO: Trying to get logs from node apps-208 pod pod-3753d919-ec36-4890-86ce-184d601afc85 container test-container: <nil>
    STEP: delete the pod 04/18/23 05:49:45.77
    Apr 18 05:49:45.841: INFO: Waiting for pod pod-3753d919-ec36-4890-86ce-184d601afc85 to disappear
    Apr 18 05:49:45.948: INFO: Pod pod-3753d919-ec36-4890-86ce-184d601afc85 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 05:49:45.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1884" for this suite. 04/18/23 05:49:45.957
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:49:45.983
Apr 18 05:49:45.983: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename svcaccounts 04/18/23 05:49:45.984
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:46.148
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:46.151
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Apr 18 05:49:46.307: INFO: created pod pod-service-account-defaultsa
Apr 18 05:49:46.307: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 18 05:49:46.380: INFO: created pod pod-service-account-mountsa
Apr 18 05:49:46.380: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 18 05:49:46.457: INFO: created pod pod-service-account-nomountsa
Apr 18 05:49:46.457: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 18 05:49:46.564: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 18 05:49:46.565: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 18 05:49:46.814: INFO: created pod pod-service-account-mountsa-mountspec
Apr 18 05:49:46.814: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 18 05:49:46.937: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 18 05:49:46.937: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 18 05:49:47.122: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 18 05:49:47.122: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 18 05:49:47.164: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 18 05:49:47.164: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 18 05:49:47.264: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 18 05:49:47.264: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 18 05:49:47.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2500" for this suite. 04/18/23 05:49:47.859
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":295,"skipped":5426,"failed":0}
------------------------------
â€¢ [2.044 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:49:45.983
    Apr 18 05:49:45.983: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename svcaccounts 04/18/23 05:49:45.984
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:46.148
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:46.151
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Apr 18 05:49:46.307: INFO: created pod pod-service-account-defaultsa
    Apr 18 05:49:46.307: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Apr 18 05:49:46.380: INFO: created pod pod-service-account-mountsa
    Apr 18 05:49:46.380: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Apr 18 05:49:46.457: INFO: created pod pod-service-account-nomountsa
    Apr 18 05:49:46.457: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Apr 18 05:49:46.564: INFO: created pod pod-service-account-defaultsa-mountspec
    Apr 18 05:49:46.565: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Apr 18 05:49:46.814: INFO: created pod pod-service-account-mountsa-mountspec
    Apr 18 05:49:46.814: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Apr 18 05:49:46.937: INFO: created pod pod-service-account-nomountsa-mountspec
    Apr 18 05:49:46.937: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Apr 18 05:49:47.122: INFO: created pod pod-service-account-defaultsa-nomountspec
    Apr 18 05:49:47.122: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Apr 18 05:49:47.164: INFO: created pod pod-service-account-mountsa-nomountspec
    Apr 18 05:49:47.164: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Apr 18 05:49:47.264: INFO: created pod pod-service-account-nomountsa-nomountspec
    Apr 18 05:49:47.264: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 18 05:49:47.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2500" for this suite. 04/18/23 05:49:47.859
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:49:48.029
Apr 18 05:49:48.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename containers 04/18/23 05:49:48.03
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:48.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:48.354
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 04/18/23 05:49:48.357
Apr 18 05:49:48.901: INFO: Waiting up to 5m0s for pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037" in namespace "containers-8562" to be "Succeeded or Failed"
Apr 18 05:49:49.008: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 106.489844ms
Apr 18 05:49:51.012: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110749591s
Apr 18 05:49:53.012: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110673389s
Apr 18 05:49:55.574: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 6.673220919s
Apr 18 05:49:57.089: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 8.187609434s
Apr 18 05:49:59.013: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 10.111700499s
Apr 18 05:50:01.048: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 12.146496666s
Apr 18 05:50:03.012: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 14.110966562s
Apr 18 05:50:05.012: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 16.110963048s
Apr 18 05:50:07.071: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 18.169361438s
Apr 18 05:50:09.027: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 20.125482366s
Apr 18 05:50:11.014: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.113161419s
STEP: Saw pod success 04/18/23 05:50:11.014
Apr 18 05:50:11.015: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037" satisfied condition "Succeeded or Failed"
Apr 18 05:50:11.017: INFO: Trying to get logs from node apps-208 pod client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:50:11.023
Apr 18 05:50:11.095: INFO: Waiting for pod client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037 to disappear
Apr 18 05:50:11.097: INFO: Pod client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 18 05:50:11.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8562" for this suite. 04/18/23 05:50:11.166
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":296,"skipped":5452,"failed":0}
------------------------------
â€¢ [SLOW TEST] [23.230 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:49:48.029
    Apr 18 05:49:48.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename containers 04/18/23 05:49:48.03
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:49:48.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:49:48.354
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 04/18/23 05:49:48.357
    Apr 18 05:49:48.901: INFO: Waiting up to 5m0s for pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037" in namespace "containers-8562" to be "Succeeded or Failed"
    Apr 18 05:49:49.008: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 106.489844ms
    Apr 18 05:49:51.012: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110749591s
    Apr 18 05:49:53.012: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110673389s
    Apr 18 05:49:55.574: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 6.673220919s
    Apr 18 05:49:57.089: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 8.187609434s
    Apr 18 05:49:59.013: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 10.111700499s
    Apr 18 05:50:01.048: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 12.146496666s
    Apr 18 05:50:03.012: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 14.110966562s
    Apr 18 05:50:05.012: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 16.110963048s
    Apr 18 05:50:07.071: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 18.169361438s
    Apr 18 05:50:09.027: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Pending", Reason="", readiness=false. Elapsed: 20.125482366s
    Apr 18 05:50:11.014: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.113161419s
    STEP: Saw pod success 04/18/23 05:50:11.014
    Apr 18 05:50:11.015: INFO: Pod "client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037" satisfied condition "Succeeded or Failed"
    Apr 18 05:50:11.017: INFO: Trying to get logs from node apps-208 pod client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:50:11.023
    Apr 18 05:50:11.095: INFO: Waiting for pod client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037 to disappear
    Apr 18 05:50:11.097: INFO: Pod client-containers-a691bf7a-fb42-4324-be5d-df3b861ef037 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 18 05:50:11.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-8562" for this suite. 04/18/23 05:50:11.166
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:50:11.261
Apr 18 05:50:11.261: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 05:50:11.262
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:50:11.484
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:50:11.488
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 04/18/23 05:50:11.544
STEP: Ensuring ResourceQuota status is calculated 04/18/23 05:50:11.631
STEP: Creating a ResourceQuota with not terminating scope 04/18/23 05:50:13.637
STEP: Ensuring ResourceQuota status is calculated 04/18/23 05:50:13.661
STEP: Creating a long running pod 04/18/23 05:50:15.665
STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/18/23 05:50:15.728
STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/18/23 05:50:17.733
STEP: Deleting the pod 04/18/23 05:50:19.737
STEP: Ensuring resource quota status released the pod usage 04/18/23 05:50:19.883
STEP: Creating a terminating pod 04/18/23 05:50:21.888
STEP: Ensuring resource quota with terminating scope captures the pod usage 04/18/23 05:50:21.975
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/18/23 05:50:24.079
STEP: Deleting the pod 04/18/23 05:50:26.085
STEP: Ensuring resource quota status released the pod usage 04/18/23 05:50:26.252
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 05:50:28.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5062" for this suite. 04/18/23 05:50:28.323
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":297,"skipped":5488,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.107 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:50:11.261
    Apr 18 05:50:11.261: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 05:50:11.262
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:50:11.484
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:50:11.488
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 04/18/23 05:50:11.544
    STEP: Ensuring ResourceQuota status is calculated 04/18/23 05:50:11.631
    STEP: Creating a ResourceQuota with not terminating scope 04/18/23 05:50:13.637
    STEP: Ensuring ResourceQuota status is calculated 04/18/23 05:50:13.661
    STEP: Creating a long running pod 04/18/23 05:50:15.665
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/18/23 05:50:15.728
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/18/23 05:50:17.733
    STEP: Deleting the pod 04/18/23 05:50:19.737
    STEP: Ensuring resource quota status released the pod usage 04/18/23 05:50:19.883
    STEP: Creating a terminating pod 04/18/23 05:50:21.888
    STEP: Ensuring resource quota with terminating scope captures the pod usage 04/18/23 05:50:21.975
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/18/23 05:50:24.079
    STEP: Deleting the pod 04/18/23 05:50:26.085
    STEP: Ensuring resource quota status released the pod usage 04/18/23 05:50:26.252
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 05:50:28.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5062" for this suite. 04/18/23 05:50:28.323
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:50:28.368
Apr 18 05:50:28.368: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename disruption 04/18/23 05:50:28.369
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:50:28.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:50:28.397
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 04/18/23 05:50:28.448
STEP: Waiting for the pdb to be processed 04/18/23 05:50:28.479
STEP: First trying to evict a pod which shouldn't be evictable 04/18/23 05:50:30.57
STEP: Waiting for all pods to be running 04/18/23 05:50:30.57
Apr 18 05:50:30.573: INFO: pods: 0 < 3
Apr 18 05:50:32.752: INFO: running pods: 0 < 3
STEP: locating a running pod 04/18/23 05:50:34.58
STEP: Updating the pdb to allow a pod to be evicted 04/18/23 05:50:34.798
STEP: Waiting for the pdb to be processed 04/18/23 05:50:34.904
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/18/23 05:50:34.986
STEP: Waiting for all pods to be running 04/18/23 05:50:34.986
STEP: Waiting for the pdb to observed all healthy pods 04/18/23 05:50:35.017
STEP: Patching the pdb to disallow a pod to be evicted 04/18/23 05:50:35.223
STEP: Waiting for the pdb to be processed 04/18/23 05:50:35.38
STEP: Waiting for all pods to be running 04/18/23 05:50:37.568
Apr 18 05:50:37.572: INFO: running pods: 2 < 3
STEP: locating a running pod 04/18/23 05:50:39.578
STEP: Deleting the pdb to allow a pod to be evicted 04/18/23 05:50:39.588
STEP: Waiting for the pdb to be deleted 04/18/23 05:50:39.615
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/18/23 05:50:39.618
STEP: Waiting for all pods to be running 04/18/23 05:50:39.618
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 18 05:50:39.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-3497" for this suite. 04/18/23 05:50:39.71
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":298,"skipped":5488,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.430 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:50:28.368
    Apr 18 05:50:28.368: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename disruption 04/18/23 05:50:28.369
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:50:28.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:50:28.397
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 04/18/23 05:50:28.448
    STEP: Waiting for the pdb to be processed 04/18/23 05:50:28.479
    STEP: First trying to evict a pod which shouldn't be evictable 04/18/23 05:50:30.57
    STEP: Waiting for all pods to be running 04/18/23 05:50:30.57
    Apr 18 05:50:30.573: INFO: pods: 0 < 3
    Apr 18 05:50:32.752: INFO: running pods: 0 < 3
    STEP: locating a running pod 04/18/23 05:50:34.58
    STEP: Updating the pdb to allow a pod to be evicted 04/18/23 05:50:34.798
    STEP: Waiting for the pdb to be processed 04/18/23 05:50:34.904
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/18/23 05:50:34.986
    STEP: Waiting for all pods to be running 04/18/23 05:50:34.986
    STEP: Waiting for the pdb to observed all healthy pods 04/18/23 05:50:35.017
    STEP: Patching the pdb to disallow a pod to be evicted 04/18/23 05:50:35.223
    STEP: Waiting for the pdb to be processed 04/18/23 05:50:35.38
    STEP: Waiting for all pods to be running 04/18/23 05:50:37.568
    Apr 18 05:50:37.572: INFO: running pods: 2 < 3
    STEP: locating a running pod 04/18/23 05:50:39.578
    STEP: Deleting the pdb to allow a pod to be evicted 04/18/23 05:50:39.588
    STEP: Waiting for the pdb to be deleted 04/18/23 05:50:39.615
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/18/23 05:50:39.618
    STEP: Waiting for all pods to be running 04/18/23 05:50:39.618
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 18 05:50:39.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-3497" for this suite. 04/18/23 05:50:39.71
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:50:39.799
Apr 18 05:50:39.800: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 05:50:39.801
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:50:39.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:50:39.988
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 04/18/23 05:50:40.113
STEP: Creating a ResourceQuota 04/18/23 05:50:45.117
STEP: Ensuring resource quota status is calculated 04/18/23 05:50:45.174
STEP: Creating a ReplicationController 04/18/23 05:50:47.227
STEP: Ensuring resource quota status captures replication controller creation 04/18/23 05:50:47.467
STEP: Deleting a ReplicationController 04/18/23 05:50:49.471
STEP: Ensuring resource quota status released usage 04/18/23 05:50:49.491
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 05:50:51.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6075" for this suite. 04/18/23 05:50:51.501
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":299,"skipped":5507,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.740 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:50:39.799
    Apr 18 05:50:39.800: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 05:50:39.801
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:50:39.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:50:39.988
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 04/18/23 05:50:40.113
    STEP: Creating a ResourceQuota 04/18/23 05:50:45.117
    STEP: Ensuring resource quota status is calculated 04/18/23 05:50:45.174
    STEP: Creating a ReplicationController 04/18/23 05:50:47.227
    STEP: Ensuring resource quota status captures replication controller creation 04/18/23 05:50:47.467
    STEP: Deleting a ReplicationController 04/18/23 05:50:49.471
    STEP: Ensuring resource quota status released usage 04/18/23 05:50:49.491
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 05:50:51.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6075" for this suite. 04/18/23 05:50:51.501
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:50:51.541
Apr 18 05:50:51.541: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 05:50:51.542
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:50:51.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:50:51.673
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4695 04/18/23 05:50:51.676
STEP: changing the ExternalName service to type=NodePort 04/18/23 05:50:51.7
STEP: creating replication controller externalname-service in namespace services-4695 04/18/23 05:50:51.945
I0418 05:50:52.042762      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4695, replica count: 2
I0418 05:50:55.093852      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 05:50:55.093: INFO: Creating new exec pod
Apr 18 05:50:55.179: INFO: Waiting up to 5m0s for pod "execpodl2kn4" in namespace "services-4695" to be "running"
Apr 18 05:50:55.227: INFO: Pod "execpodl2kn4": Phase="Pending", Reason="", readiness=false. Elapsed: 47.135461ms
Apr 18 05:50:57.250: INFO: Pod "execpodl2kn4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070549927s
Apr 18 05:50:59.235: INFO: Pod "execpodl2kn4": Phase="Running", Reason="", readiness=true. Elapsed: 4.055745844s
Apr 18 05:50:59.235: INFO: Pod "execpodl2kn4" satisfied condition "running"
Apr 18 05:51:00.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-4695 exec execpodl2kn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 18 05:51:00.403: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 18 05:51:00.403: INFO: stdout: "externalname-service-cw6rg"
Apr 18 05:51:00.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-4695 exec execpodl2kn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.13.133 80'
Apr 18 05:51:00.564: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.13.133 80\nConnection to 10.96.13.133 80 port [tcp/http] succeeded!\n"
Apr 18 05:51:00.564: INFO: stdout: "externalname-service-h7zqx"
Apr 18 05:51:00.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-4695 exec execpodl2kn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.107 31578'
Apr 18 05:51:00.762: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.107 31578\nConnection to 192.168.2.107 31578 port [tcp/*] succeeded!\n"
Apr 18 05:51:00.762: INFO: stdout: "externalname-service-cw6rg"
Apr 18 05:51:00.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-4695 exec execpodl2kn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.109 31578'
Apr 18 05:51:00.914: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.109 31578\nConnection to 192.168.2.109 31578 port [tcp/*] succeeded!\n"
Apr 18 05:51:00.914: INFO: stdout: "externalname-service-cw6rg"
Apr 18 05:51:00.914: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 05:51:01.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4695" for this suite. 04/18/23 05:51:01.168
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":300,"skipped":5518,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.694 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:50:51.541
    Apr 18 05:50:51.541: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 05:50:51.542
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:50:51.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:50:51.673
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-4695 04/18/23 05:50:51.676
    STEP: changing the ExternalName service to type=NodePort 04/18/23 05:50:51.7
    STEP: creating replication controller externalname-service in namespace services-4695 04/18/23 05:50:51.945
    I0418 05:50:52.042762      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4695, replica count: 2
    I0418 05:50:55.093852      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 05:50:55.093: INFO: Creating new exec pod
    Apr 18 05:50:55.179: INFO: Waiting up to 5m0s for pod "execpodl2kn4" in namespace "services-4695" to be "running"
    Apr 18 05:50:55.227: INFO: Pod "execpodl2kn4": Phase="Pending", Reason="", readiness=false. Elapsed: 47.135461ms
    Apr 18 05:50:57.250: INFO: Pod "execpodl2kn4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070549927s
    Apr 18 05:50:59.235: INFO: Pod "execpodl2kn4": Phase="Running", Reason="", readiness=true. Elapsed: 4.055745844s
    Apr 18 05:50:59.235: INFO: Pod "execpodl2kn4" satisfied condition "running"
    Apr 18 05:51:00.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-4695 exec execpodl2kn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 18 05:51:00.403: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 18 05:51:00.403: INFO: stdout: "externalname-service-cw6rg"
    Apr 18 05:51:00.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-4695 exec execpodl2kn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.13.133 80'
    Apr 18 05:51:00.564: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.13.133 80\nConnection to 10.96.13.133 80 port [tcp/http] succeeded!\n"
    Apr 18 05:51:00.564: INFO: stdout: "externalname-service-h7zqx"
    Apr 18 05:51:00.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-4695 exec execpodl2kn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.107 31578'
    Apr 18 05:51:00.762: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.107 31578\nConnection to 192.168.2.107 31578 port [tcp/*] succeeded!\n"
    Apr 18 05:51:00.762: INFO: stdout: "externalname-service-cw6rg"
    Apr 18 05:51:00.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-4695 exec execpodl2kn4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.109 31578'
    Apr 18 05:51:00.914: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.109 31578\nConnection to 192.168.2.109 31578 port [tcp/*] succeeded!\n"
    Apr 18 05:51:00.914: INFO: stdout: "externalname-service-cw6rg"
    Apr 18 05:51:00.914: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 05:51:01.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4695" for this suite. 04/18/23 05:51:01.168
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:51:01.235
Apr 18 05:51:01.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:51:01.237
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:51:01.396
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:51:01.4
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 04/18/23 05:51:01.403
Apr 18 05:51:01.481: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e" in namespace "projected-3135" to be "Succeeded or Failed"
Apr 18 05:51:01.485: INFO: Pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.168605ms
Apr 18 05:51:03.490: INFO: Pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008528216s
Apr 18 05:51:05.494: INFO: Pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012681522s
Apr 18 05:51:07.490: INFO: Pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00808119s
STEP: Saw pod success 04/18/23 05:51:07.49
Apr 18 05:51:07.490: INFO: Pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e" satisfied condition "Succeeded or Failed"
Apr 18 05:51:07.512: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e container client-container: <nil>
STEP: delete the pod 04/18/23 05:51:07.517
Apr 18 05:51:08.012: INFO: Waiting for pod downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e to disappear
Apr 18 05:51:08.061: INFO: Pod downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 18 05:51:08.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3135" for this suite. 04/18/23 05:51:08.069
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":301,"skipped":5527,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.909 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:51:01.235
    Apr 18 05:51:01.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:51:01.237
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:51:01.396
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:51:01.4
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 04/18/23 05:51:01.403
    Apr 18 05:51:01.481: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e" in namespace "projected-3135" to be "Succeeded or Failed"
    Apr 18 05:51:01.485: INFO: Pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.168605ms
    Apr 18 05:51:03.490: INFO: Pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008528216s
    Apr 18 05:51:05.494: INFO: Pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012681522s
    Apr 18 05:51:07.490: INFO: Pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00808119s
    STEP: Saw pod success 04/18/23 05:51:07.49
    Apr 18 05:51:07.490: INFO: Pod "downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e" satisfied condition "Succeeded or Failed"
    Apr 18 05:51:07.512: INFO: Trying to get logs from node apps-208 pod downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e container client-container: <nil>
    STEP: delete the pod 04/18/23 05:51:07.517
    Apr 18 05:51:08.012: INFO: Waiting for pod downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e to disappear
    Apr 18 05:51:08.061: INFO: Pod downwardapi-volume-17e219ce-43ff-41d8-a82a-f853356b8a2e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 18 05:51:08.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3135" for this suite. 04/18/23 05:51:08.069
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:51:08.145
Apr 18 05:51:08.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 05:51:08.146
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:51:08.333
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:51:08.336
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-5331 04/18/23 05:51:08.421
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5331 to expose endpoints map[] 04/18/23 05:51:08.544
Apr 18 05:51:08.550: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Apr 18 05:51:09.557: INFO: successfully validated that service endpoint-test2 in namespace services-5331 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5331 04/18/23 05:51:09.557
Apr 18 05:51:09.578: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5331" to be "running and ready"
Apr 18 05:51:09.601: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 23.278778ms
Apr 18 05:51:09.601: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:51:11.852: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.273985569s
Apr 18 05:51:11.852: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:51:13.609: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.031346511s
Apr 18 05:51:13.609: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 18 05:51:13.609: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5331 to expose endpoints map[pod1:[80]] 04/18/23 05:51:13.613
Apr 18 05:51:13.675: INFO: successfully validated that service endpoint-test2 in namespace services-5331 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 04/18/23 05:51:13.675
Apr 18 05:51:13.675: INFO: Creating new exec pod
Apr 18 05:51:13.695: INFO: Waiting up to 5m0s for pod "execpodkfr6n" in namespace "services-5331" to be "running"
Apr 18 05:51:13.698: INFO: Pod "execpodkfr6n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.462978ms
Apr 18 05:51:15.701: INFO: Pod "execpodkfr6n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005901442s
Apr 18 05:51:17.705: INFO: Pod "execpodkfr6n": Phase="Running", Reason="", readiness=true. Elapsed: 4.009498693s
Apr 18 05:51:17.705: INFO: Pod "execpodkfr6n" satisfied condition "running"
Apr 18 05:51:18.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 18 05:51:18.874: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 18 05:51:18.874: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:51:18.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.8.239 80'
Apr 18 05:51:19.032: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.8.239 80\nConnection to 10.96.8.239 80 port [tcp/http] succeeded!\n"
Apr 18 05:51:19.032: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-5331 04/18/23 05:51:19.032
Apr 18 05:51:19.055: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5331" to be "running and ready"
Apr 18 05:51:19.103: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 48.456603ms
Apr 18 05:51:19.103: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:51:21.108: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053511392s
Apr 18 05:51:21.108: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:51:23.109: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.054122399s
Apr 18 05:51:23.109: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 18 05:51:23.109: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5331 to expose endpoints map[pod1:[80] pod2:[80]] 04/18/23 05:51:23.112
Apr 18 05:51:23.170: INFO: successfully validated that service endpoint-test2 in namespace services-5331 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 04/18/23 05:51:23.17
Apr 18 05:51:24.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 18 05:51:24.721: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 18 05:51:24.721: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:51:24.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.8.239 80'
Apr 18 05:51:24.872: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.8.239 80\nConnection to 10.96.8.239 80 port [tcp/http] succeeded!\n"
Apr 18 05:51:24.872: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5331 04/18/23 05:51:24.872
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5331 to expose endpoints map[pod2:[80]] 04/18/23 05:51:24.971
Apr 18 05:51:27.075: INFO: successfully validated that service endpoint-test2 in namespace services-5331 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 04/18/23 05:51:27.075
Apr 18 05:51:28.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 18 05:51:28.233: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 18 05:51:28.234: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 18 05:51:28.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.8.239 80'
Apr 18 05:51:28.418: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.8.239 80\nConnection to 10.96.8.239 80 port [tcp/http] succeeded!\n"
Apr 18 05:51:28.418: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-5331 04/18/23 05:51:28.418
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5331 to expose endpoints map[] 04/18/23 05:51:29.203
Apr 18 05:51:29.271: INFO: successfully validated that service endpoint-test2 in namespace services-5331 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 05:51:29.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5331" for this suite. 04/18/23 05:51:29.614
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":302,"skipped":5532,"failed":0}
------------------------------
â€¢ [SLOW TEST] [21.590 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:51:08.145
    Apr 18 05:51:08.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 05:51:08.146
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:51:08.333
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:51:08.336
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-5331 04/18/23 05:51:08.421
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5331 to expose endpoints map[] 04/18/23 05:51:08.544
    Apr 18 05:51:08.550: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
    Apr 18 05:51:09.557: INFO: successfully validated that service endpoint-test2 in namespace services-5331 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-5331 04/18/23 05:51:09.557
    Apr 18 05:51:09.578: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5331" to be "running and ready"
    Apr 18 05:51:09.601: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 23.278778ms
    Apr 18 05:51:09.601: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:51:11.852: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.273985569s
    Apr 18 05:51:11.852: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:51:13.609: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 4.031346511s
    Apr 18 05:51:13.609: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 18 05:51:13.609: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5331 to expose endpoints map[pod1:[80]] 04/18/23 05:51:13.613
    Apr 18 05:51:13.675: INFO: successfully validated that service endpoint-test2 in namespace services-5331 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 04/18/23 05:51:13.675
    Apr 18 05:51:13.675: INFO: Creating new exec pod
    Apr 18 05:51:13.695: INFO: Waiting up to 5m0s for pod "execpodkfr6n" in namespace "services-5331" to be "running"
    Apr 18 05:51:13.698: INFO: Pod "execpodkfr6n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.462978ms
    Apr 18 05:51:15.701: INFO: Pod "execpodkfr6n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005901442s
    Apr 18 05:51:17.705: INFO: Pod "execpodkfr6n": Phase="Running", Reason="", readiness=true. Elapsed: 4.009498693s
    Apr 18 05:51:17.705: INFO: Pod "execpodkfr6n" satisfied condition "running"
    Apr 18 05:51:18.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 18 05:51:18.874: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 18 05:51:18.874: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:51:18.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.8.239 80'
    Apr 18 05:51:19.032: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.8.239 80\nConnection to 10.96.8.239 80 port [tcp/http] succeeded!\n"
    Apr 18 05:51:19.032: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-5331 04/18/23 05:51:19.032
    Apr 18 05:51:19.055: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5331" to be "running and ready"
    Apr 18 05:51:19.103: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 48.456603ms
    Apr 18 05:51:19.103: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:51:21.108: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053511392s
    Apr 18 05:51:21.108: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:51:23.109: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.054122399s
    Apr 18 05:51:23.109: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 18 05:51:23.109: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5331 to expose endpoints map[pod1:[80] pod2:[80]] 04/18/23 05:51:23.112
    Apr 18 05:51:23.170: INFO: successfully validated that service endpoint-test2 in namespace services-5331 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 04/18/23 05:51:23.17
    Apr 18 05:51:24.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 18 05:51:24.721: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 18 05:51:24.721: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:51:24.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.8.239 80'
    Apr 18 05:51:24.872: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.8.239 80\nConnection to 10.96.8.239 80 port [tcp/http] succeeded!\n"
    Apr 18 05:51:24.872: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-5331 04/18/23 05:51:24.872
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5331 to expose endpoints map[pod2:[80]] 04/18/23 05:51:24.971
    Apr 18 05:51:27.075: INFO: successfully validated that service endpoint-test2 in namespace services-5331 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 04/18/23 05:51:27.075
    Apr 18 05:51:28.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 18 05:51:28.233: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 18 05:51:28.234: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 18 05:51:28.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5331 exec execpodkfr6n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.8.239 80'
    Apr 18 05:51:28.418: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.8.239 80\nConnection to 10.96.8.239 80 port [tcp/http] succeeded!\n"
    Apr 18 05:51:28.418: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-5331 04/18/23 05:51:28.418
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5331 to expose endpoints map[] 04/18/23 05:51:29.203
    Apr 18 05:51:29.271: INFO: successfully validated that service endpoint-test2 in namespace services-5331 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 05:51:29.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5331" for this suite. 04/18/23 05:51:29.614
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:51:29.736
Apr 18 05:51:29.736: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename deployment 04/18/23 05:51:29.737
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:51:30.07
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:51:30.073
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Apr 18 05:51:30.273: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 05:51:30.273
Apr 18 05:51:30.273: INFO: Waiting up to 5m0s for pod "test-cleanup-controller-nb5vx" in namespace "deployment-701" to be "running"
Apr 18 05:51:30.963: INFO: Pod "test-cleanup-controller-nb5vx": Phase="Pending", Reason="", readiness=false. Elapsed: 689.901797ms
Apr 18 05:51:32.968: INFO: Pod "test-cleanup-controller-nb5vx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.694740185s
Apr 18 05:51:35.059: INFO: Pod "test-cleanup-controller-nb5vx": Phase="Running", Reason="", readiness=true. Elapsed: 4.785934432s
Apr 18 05:51:35.059: INFO: Pod "test-cleanup-controller-nb5vx" satisfied condition "running"
Apr 18 05:51:35.059: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/18/23 05:51:35.173
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 18 05:51:41.242: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-701  bc4c60cd-01c5-49bb-b8ba-728f85ef4909 4122877 1 2023-04-18 05:51:35 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-18 05:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:51:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00a10cba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 05:51:35 +0000 UTC,LastTransitionTime:2023-04-18 05:51:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2023-04-18 05:51:39 +0000 UTC,LastTransitionTime:2023-04-18 05:51:35 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 18 05:51:41.245: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-701  2670f3e3-a745-4def-a9cb-f5b75cb445ab 4122867 1 2023-04-18 05:51:35 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment bc4c60cd-01c5-49bb-b8ba-728f85ef4909 0xc00a10cf87 0xc00a10cf88}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bc4c60cd-01c5-49bb-b8ba-728f85ef4909\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:51:39 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00a10d048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 18 05:51:41.287: INFO: Pod "test-cleanup-deployment-69cb9c5497-rhjp8" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-rhjp8 test-cleanup-deployment-69cb9c5497- deployment-701  91971e6e-683d-46ee-a6f2-52fa2ff04564 4122866 0 2023-04-18 05:51:35 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:8dbbaca827786cc081c14823df6c2a526c0431519a28d310d15c43811510780a cni.projectcalico.org/podIP:172.16.125.3/32 cni.projectcalico.org/podIPs:172.16.125.3/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 2670f3e3-a745-4def-a9cb-f5b75cb445ab 0xc00a10d437 0xc00a10d438}] [] [{kube-controller-manager Update v1 2023-04-18 05:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2670f3e3-a745-4def-a9cb-f5b75cb445ab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:51:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nn9xs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nn9xs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:51:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:51:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.3,StartTime:2023-04-18 05:51:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:51:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://a73e642f523d482d6e5687832f90b827ceee31f5df1c025c8864bc2069dab0c2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 18 05:51:41.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-701" for this suite. 04/18/23 05:51:41.292
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":303,"skipped":5545,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.581 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:51:29.736
    Apr 18 05:51:29.736: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename deployment 04/18/23 05:51:29.737
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:51:30.07
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:51:30.073
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Apr 18 05:51:30.273: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 05:51:30.273
    Apr 18 05:51:30.273: INFO: Waiting up to 5m0s for pod "test-cleanup-controller-nb5vx" in namespace "deployment-701" to be "running"
    Apr 18 05:51:30.963: INFO: Pod "test-cleanup-controller-nb5vx": Phase="Pending", Reason="", readiness=false. Elapsed: 689.901797ms
    Apr 18 05:51:32.968: INFO: Pod "test-cleanup-controller-nb5vx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.694740185s
    Apr 18 05:51:35.059: INFO: Pod "test-cleanup-controller-nb5vx": Phase="Running", Reason="", readiness=true. Elapsed: 4.785934432s
    Apr 18 05:51:35.059: INFO: Pod "test-cleanup-controller-nb5vx" satisfied condition "running"
    Apr 18 05:51:35.059: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/18/23 05:51:35.173
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 18 05:51:41.242: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-701  bc4c60cd-01c5-49bb-b8ba-728f85ef4909 4122877 1 2023-04-18 05:51:35 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2023-04-18 05:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:51:39 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00a10cba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2023-04-18 05:51:35 +0000 UTC,LastTransitionTime:2023-04-18 05:51:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2023-04-18 05:51:39 +0000 UTC,LastTransitionTime:2023-04-18 05:51:35 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 18 05:51:41.245: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-701  2670f3e3-a745-4def-a9cb-f5b75cb445ab 4122867 1 2023-04-18 05:51:35 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment bc4c60cd-01c5-49bb-b8ba-728f85ef4909 0xc00a10cf87 0xc00a10cf88}] [] [{kube-controller-manager Update apps/v1 2023-04-18 05:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bc4c60cd-01c5-49bb-b8ba-728f85ef4909\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2023-04-18 05:51:39 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00a10d048 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 18 05:51:41.287: INFO: Pod "test-cleanup-deployment-69cb9c5497-rhjp8" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-rhjp8 test-cleanup-deployment-69cb9c5497- deployment-701  91971e6e-683d-46ee-a6f2-52fa2ff04564 4122866 0 2023-04-18 05:51:35 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:8dbbaca827786cc081c14823df6c2a526c0431519a28d310d15c43811510780a cni.projectcalico.org/podIP:172.16.125.3/32 cni.projectcalico.org/podIPs:172.16.125.3/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 2670f3e3-a745-4def-a9cb-f5b75cb445ab 0xc00a10d437 0xc00a10d438}] [] [{kube-controller-manager Update v1 2023-04-18 05:51:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"2670f3e3-a745-4def-a9cb-f5b75cb445ab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2023-04-18 05:51:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2023-04-18 05:51:39 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.3\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nn9xs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nn9xs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:apps-208,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*30,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:51:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:51:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2023-04-18 05:51:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.2.108,PodIP:172.16.125.3,StartTime:2023-04-18 05:51:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2023-04-18 05:51:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://a73e642f523d482d6e5687832f90b827ceee31f5df1c025c8864bc2069dab0c2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.16.125.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 18 05:51:41.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-701" for this suite. 04/18/23 05:51:41.292
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:51:41.318
Apr 18 05:51:41.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename projected 04/18/23 05:51:41.319
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:51:41.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:51:41.364
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-ffb27aa2-93b7-49b3-b2e1-ff56dd476a78 04/18/23 05:51:41.367
STEP: Creating a pod to test consume configMaps 04/18/23 05:51:41.449
Apr 18 05:51:41.462: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92" in namespace "projected-7035" to be "Succeeded or Failed"
Apr 18 05:51:41.501: INFO: Pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92": Phase="Pending", Reason="", readiness=false. Elapsed: 39.393046ms
Apr 18 05:51:43.507: INFO: Pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045310052s
Apr 18 05:51:45.538: INFO: Pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92": Phase="Pending", Reason="", readiness=false. Elapsed: 4.076214806s
Apr 18 05:51:47.547: INFO: Pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.085266857s
STEP: Saw pod success 04/18/23 05:51:47.547
Apr 18 05:51:47.547: INFO: Pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92" satisfied condition "Succeeded or Failed"
Apr 18 05:51:47.610: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92 container agnhost-container: <nil>
STEP: delete the pod 04/18/23 05:51:47.616
Apr 18 05:51:47.813: INFO: Waiting for pod pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92 to disappear
Apr 18 05:51:47.816: INFO: Pod pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 18 05:51:47.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7035" for this suite. 04/18/23 05:51:47.821
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":304,"skipped":5571,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.556 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:51:41.318
    Apr 18 05:51:41.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename projected 04/18/23 05:51:41.319
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:51:41.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:51:41.364
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-ffb27aa2-93b7-49b3-b2e1-ff56dd476a78 04/18/23 05:51:41.367
    STEP: Creating a pod to test consume configMaps 04/18/23 05:51:41.449
    Apr 18 05:51:41.462: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92" in namespace "projected-7035" to be "Succeeded or Failed"
    Apr 18 05:51:41.501: INFO: Pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92": Phase="Pending", Reason="", readiness=false. Elapsed: 39.393046ms
    Apr 18 05:51:43.507: INFO: Pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045310052s
    Apr 18 05:51:45.538: INFO: Pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92": Phase="Pending", Reason="", readiness=false. Elapsed: 4.076214806s
    Apr 18 05:51:47.547: INFO: Pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.085266857s
    STEP: Saw pod success 04/18/23 05:51:47.547
    Apr 18 05:51:47.547: INFO: Pod "pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92" satisfied condition "Succeeded or Failed"
    Apr 18 05:51:47.610: INFO: Trying to get logs from node apps-208 pod pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92 container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 05:51:47.616
    Apr 18 05:51:47.813: INFO: Waiting for pod pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92 to disappear
    Apr 18 05:51:47.816: INFO: Pod pod-projected-configmaps-3cfa33e8-1c82-496e-8afd-3d2d40747e92 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 18 05:51:47.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7035" for this suite. 04/18/23 05:51:47.821
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:51:47.877
Apr 18 05:51:47.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 05:51:47.878
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:51:47.935
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:51:47.938
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 05:51:48.066
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:51:48.669
STEP: Deploying the webhook pod 04/18/23 05:51:48.76
STEP: Wait for the deployment to be ready 04/18/23 05:51:48.8
Apr 18 05:51:48.829: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Apr 18 05:51:50.839: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 51, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 51, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 51, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 51, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 05:51:52.843
STEP: Verifying the service has paired with the endpoint 04/18/23 05:51:52.893
Apr 18 05:51:53.894: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Apr 18 05:51:53.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9549-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 05:51:59.467
STEP: Creating a custom resource that should be mutated by the webhook 04/18/23 05:51:59.515
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:52:02.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6998" for this suite. 04/18/23 05:52:02.256
STEP: Destroying namespace "webhook-6998-markers" for this suite. 04/18/23 05:52:02.352
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":305,"skipped":5629,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.032 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:51:47.877
    Apr 18 05:51:47.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 05:51:47.878
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:51:47.935
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:51:47.938
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 05:51:48.066
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:51:48.669
    STEP: Deploying the webhook pod 04/18/23 05:51:48.76
    STEP: Wait for the deployment to be ready 04/18/23 05:51:48.8
    Apr 18 05:51:48.829: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Apr 18 05:51:50.839: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 51, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 51, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 51, 49, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 51, 48, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 05:51:52.843
    STEP: Verifying the service has paired with the endpoint 04/18/23 05:51:52.893
    Apr 18 05:51:53.894: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Apr 18 05:51:53.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9549-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 05:51:59.467
    STEP: Creating a custom resource that should be mutated by the webhook 04/18/23 05:51:59.515
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:52:02.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6998" for this suite. 04/18/23 05:52:02.256
    STEP: Destroying namespace "webhook-6998-markers" for this suite. 04/18/23 05:52:02.352
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:52:02.909
Apr 18 05:52:02.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename endpointslice 04/18/23 05:52:02.91
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:03.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:03.54
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Apr 18 05:52:03.825: INFO: Endpoints addresses: [192.168.2.107 192.168.2.108 192.168.2.109] , ports: [6443]
Apr 18 05:52:03.825: INFO: EndpointSlices addresses: [192.168.2.107 192.168.2.108 192.168.2.109] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 18 05:52:03.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9452" for this suite. 04/18/23 05:52:03.829
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":306,"skipped":5629,"failed":0}
------------------------------
â€¢ [1.090 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:52:02.909
    Apr 18 05:52:02.909: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename endpointslice 04/18/23 05:52:02.91
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:03.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:03.54
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Apr 18 05:52:03.825: INFO: Endpoints addresses: [192.168.2.107 192.168.2.108 192.168.2.109] , ports: [6443]
    Apr 18 05:52:03.825: INFO: EndpointSlices addresses: [192.168.2.107 192.168.2.108 192.168.2.109] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 18 05:52:03.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-9452" for this suite. 04/18/23 05:52:03.829
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:52:04.001
Apr 18 05:52:04.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 05:52:04.002
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:04.092
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:04.095
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 04/18/23 05:52:04.198
Apr 18 05:52:04.255: INFO: created test-pod-1
Apr 18 05:52:04.387: INFO: created test-pod-2
Apr 18 05:52:04.440: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 04/18/23 05:52:04.441
Apr 18 05:52:04.441: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-5106' to be running and ready
Apr 18 05:52:04.538: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 18 05:52:04.538: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 18 05:52:04.538: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 18 05:52:04.538: INFO: 0 / 3 pods in namespace 'pods-5106' are running and ready (0 seconds elapsed)
Apr 18 05:52:04.538: INFO: expected 0 pod replicas in namespace 'pods-5106', 0 are Running and Ready.
Apr 18 05:52:04.538: INFO: POD         NODE      PHASE    GRACE  CONDITIONS
Apr 18 05:52:04.538: INFO: test-pod-1  apps-208  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
Apr 18 05:52:04.538: INFO: test-pod-2  apps-208  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
Apr 18 05:52:04.538: INFO: test-pod-3  apps-208  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
Apr 18 05:52:04.538: INFO: 
Apr 18 05:52:06.548: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 18 05:52:06.548: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 18 05:52:06.548: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 18 05:52:06.548: INFO: 0 / 3 pods in namespace 'pods-5106' are running and ready (2 seconds elapsed)
Apr 18 05:52:06.548: INFO: expected 0 pod replicas in namespace 'pods-5106', 0 are Running and Ready.
Apr 18 05:52:06.548: INFO: POD         NODE      PHASE    GRACE  CONDITIONS
Apr 18 05:52:06.548: INFO: test-pod-1  apps-208  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
Apr 18 05:52:06.548: INFO: test-pod-2  apps-208  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
Apr 18 05:52:06.548: INFO: test-pod-3  apps-208  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
Apr 18 05:52:06.548: INFO: 
Apr 18 05:52:08.708: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 18 05:52:08.708: INFO: 2 / 3 pods in namespace 'pods-5106' are running and ready (4 seconds elapsed)
Apr 18 05:52:08.708: INFO: expected 0 pod replicas in namespace 'pods-5106', 0 are Running and Ready.
Apr 18 05:52:08.708: INFO: POD         NODE      PHASE    GRACE  CONDITIONS
Apr 18 05:52:08.708: INFO: test-pod-3  apps-208  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
Apr 18 05:52:08.708: INFO: 
Apr 18 05:52:10.614: INFO: 3 / 3 pods in namespace 'pods-5106' are running and ready (6 seconds elapsed)
Apr 18 05:52:10.614: INFO: expected 0 pod replicas in namespace 'pods-5106', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 04/18/23 05:52:10.864
Apr 18 05:52:11.160: INFO: Pod quantity 3 is different from expected quantity 0
Apr 18 05:52:12.198: INFO: Pod quantity 3 is different from expected quantity 0
Apr 18 05:52:13.164: INFO: Pod quantity 1 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 05:52:14.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5106" for this suite. 04/18/23 05:52:14.234
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":307,"skipped":5688,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.261 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:52:04.001
    Apr 18 05:52:04.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 05:52:04.002
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:04.092
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:04.095
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 04/18/23 05:52:04.198
    Apr 18 05:52:04.255: INFO: created test-pod-1
    Apr 18 05:52:04.387: INFO: created test-pod-2
    Apr 18 05:52:04.440: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 04/18/23 05:52:04.441
    Apr 18 05:52:04.441: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-5106' to be running and ready
    Apr 18 05:52:04.538: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 18 05:52:04.538: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 18 05:52:04.538: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 18 05:52:04.538: INFO: 0 / 3 pods in namespace 'pods-5106' are running and ready (0 seconds elapsed)
    Apr 18 05:52:04.538: INFO: expected 0 pod replicas in namespace 'pods-5106', 0 are Running and Ready.
    Apr 18 05:52:04.538: INFO: POD         NODE      PHASE    GRACE  CONDITIONS
    Apr 18 05:52:04.538: INFO: test-pod-1  apps-208  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
    Apr 18 05:52:04.538: INFO: test-pod-2  apps-208  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
    Apr 18 05:52:04.538: INFO: test-pod-3  apps-208  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
    Apr 18 05:52:04.538: INFO: 
    Apr 18 05:52:06.548: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 18 05:52:06.548: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 18 05:52:06.548: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 18 05:52:06.548: INFO: 0 / 3 pods in namespace 'pods-5106' are running and ready (2 seconds elapsed)
    Apr 18 05:52:06.548: INFO: expected 0 pod replicas in namespace 'pods-5106', 0 are Running and Ready.
    Apr 18 05:52:06.548: INFO: POD         NODE      PHASE    GRACE  CONDITIONS
    Apr 18 05:52:06.548: INFO: test-pod-1  apps-208  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
    Apr 18 05:52:06.548: INFO: test-pod-2  apps-208  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
    Apr 18 05:52:06.548: INFO: test-pod-3  apps-208  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
    Apr 18 05:52:06.548: INFO: 
    Apr 18 05:52:08.708: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 18 05:52:08.708: INFO: 2 / 3 pods in namespace 'pods-5106' are running and ready (4 seconds elapsed)
    Apr 18 05:52:08.708: INFO: expected 0 pod replicas in namespace 'pods-5106', 0 are Running and Ready.
    Apr 18 05:52:08.708: INFO: POD         NODE      PHASE    GRACE  CONDITIONS
    Apr 18 05:52:08.708: INFO: test-pod-3  apps-208  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-04-18 05:52:04 +0000 UTC  }]
    Apr 18 05:52:08.708: INFO: 
    Apr 18 05:52:10.614: INFO: 3 / 3 pods in namespace 'pods-5106' are running and ready (6 seconds elapsed)
    Apr 18 05:52:10.614: INFO: expected 0 pod replicas in namespace 'pods-5106', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 04/18/23 05:52:10.864
    Apr 18 05:52:11.160: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 18 05:52:12.198: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 18 05:52:13.164: INFO: Pod quantity 1 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 05:52:14.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5106" for this suite. 04/18/23 05:52:14.234
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:52:14.262
Apr 18 05:52:14.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 05:52:14.263
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:14.386
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:14.389
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 04/18/23 05:52:14.414
STEP: submitting the pod to kubernetes 04/18/23 05:52:14.414
STEP: verifying QOS class is set on the pod 04/18/23 05:52:14.436
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Apr 18 05:52:14.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5168" for this suite. 04/18/23 05:52:14.482
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":308,"skipped":5694,"failed":0}
------------------------------
â€¢ [0.291 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:52:14.262
    Apr 18 05:52:14.262: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 05:52:14.263
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:14.386
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:14.389
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 04/18/23 05:52:14.414
    STEP: submitting the pod to kubernetes 04/18/23 05:52:14.414
    STEP: verifying QOS class is set on the pod 04/18/23 05:52:14.436
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Apr 18 05:52:14.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5168" for this suite. 04/18/23 05:52:14.482
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:52:14.553
Apr 18 05:52:14.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename daemonsets 04/18/23 05:52:14.554
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:14.643
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:14.645
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 04/18/23 05:52:14.808
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 05:52:14.831
Apr 18 05:52:14.902: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:52:14.902: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:52:15.911: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:52:15.911: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:52:16.967: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:52:16.967: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:52:18.019: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 05:52:18.019: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:52:18.988: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 05:52:18.988: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 05:52:19.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 05:52:19.930: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 04/18/23 05:52:19.933
STEP: DeleteCollection of the DaemonSets 04/18/23 05:52:19.96
STEP: Verify that ReplicaSets have been deleted 04/18/23 05:52:20.156
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Apr 18 05:52:20.598: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4123297"},"items":null}

Apr 18 05:52:20.706: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4123301"},"items":[{"metadata":{"name":"daemon-set-4cwxk","generateName":"daemon-set-","namespace":"daemonsets-2921","uid":"48fed90f-87e4-4b91-8f15-782640431152","resourceVersion":"4123293","creationTimestamp":"2023-04-18T05:52:14Z","deletionTimestamp":"2023-04-18T05:52:50Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"3fefb89b2239ad271fa3926ea829c6b27fab5d7b2fd4a8a5cd1d22e550747978","cni.projectcalico.org/podIP":"172.16.100.185/32","cni.projectcalico.org/podIPs":"172.16.100.185/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"a9d66b45-426d-492c-989c-3495ee530553","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a9d66b45-426d-492c-989c-3495ee530553\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.100.185\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-gnw54","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-gnw54","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"apps-207","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["apps-207"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:15Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:19Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:19Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:15Z"}],"hostIP":"192.168.2.107","podIP":"172.16.100.185","podIPs":[{"ip":"172.16.100.185"}],"startTime":"2023-04-18T05:52:15Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T05:52:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://c95eba71eb5c5fdab9ee67f84161ce5238ae91633e63c1fa6933df54692f5359","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-57nw5","generateName":"daemon-set-","namespace":"daemonsets-2921","uid":"8f13c115-79ef-4b8a-9b8b-3d45889a961f","resourceVersion":"4123297","creationTimestamp":"2023-04-18T05:52:14Z","deletionTimestamp":"2023-04-18T05:52:50Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"aaee30ac4bc2b4f6c4c1362064cca345ea96800f721cebc8c2e350ab3563c771","cni.projectcalico.org/podIP":"172.16.125.56/32","cni.projectcalico.org/podIPs":"172.16.125.56/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"a9d66b45-426d-492c-989c-3495ee530553","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a9d66b45-426d-492c-989c-3495ee530553\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:16Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.56\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-whf4p","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-whf4p","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"apps-208","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["apps-208"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:15Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:18Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:18Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:14Z"}],"hostIP":"192.168.2.108","podIP":"172.16.125.56","podIPs":[{"ip":"172.16.125.56"}],"startTime":"2023-04-18T05:52:15Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T05:52:17Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://480a126145525db67bf643d959e998a4bfc6a78ea9609c70b85ff8a5e8a41294","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-97tj5","generateName":"daemon-set-","namespace":"daemonsets-2921","uid":"e17d739d-c369-49bd-af4b-2a32741c97b5","resourceVersion":"4123296","creationTimestamp":"2023-04-18T05:52:14Z","deletionTimestamp":"2023-04-18T05:52:50Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"8957f98e836c5ea252c729f24d1a413645e32526f701616613fc0bd5682c2778","cni.projectcalico.org/podIP":"172.16.144.25/32","cni.projectcalico.org/podIPs":"172.16.144.25/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"a9d66b45-426d-492c-989c-3495ee530553","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a9d66b45-426d-492c-989c-3495ee530553\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:16Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.144.25\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-2dxf4","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-2dxf4","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"apps-209","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["apps-209"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:15Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:18Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:18Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:14Z"}],"hostIP":"192.168.2.109","podIP":"172.16.144.25","podIPs":[{"ip":"172.16.144.25"}],"startTime":"2023-04-18T05:52:15Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T05:52:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://a0233f45e0c791c508026f8bcf415719f9695523836d0b13106fa53ae0973b7e","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:52:21.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2921" for this suite. 04/18/23 05:52:21.718
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":309,"skipped":5695,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.249 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:52:14.553
    Apr 18 05:52:14.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename daemonsets 04/18/23 05:52:14.554
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:14.643
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:14.645
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 04/18/23 05:52:14.808
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 05:52:14.831
    Apr 18 05:52:14.902: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:52:14.902: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:52:15.911: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:52:15.911: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:52:16.967: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:52:16.967: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:52:18.019: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 05:52:18.019: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:52:18.988: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 05:52:18.988: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 05:52:19.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 05:52:19.930: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 04/18/23 05:52:19.933
    STEP: DeleteCollection of the DaemonSets 04/18/23 05:52:19.96
    STEP: Verify that ReplicaSets have been deleted 04/18/23 05:52:20.156
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Apr 18 05:52:20.598: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4123297"},"items":null}

    Apr 18 05:52:20.706: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4123301"},"items":[{"metadata":{"name":"daemon-set-4cwxk","generateName":"daemon-set-","namespace":"daemonsets-2921","uid":"48fed90f-87e4-4b91-8f15-782640431152","resourceVersion":"4123293","creationTimestamp":"2023-04-18T05:52:14Z","deletionTimestamp":"2023-04-18T05:52:50Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"3fefb89b2239ad271fa3926ea829c6b27fab5d7b2fd4a8a5cd1d22e550747978","cni.projectcalico.org/podIP":"172.16.100.185/32","cni.projectcalico.org/podIPs":"172.16.100.185/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"a9d66b45-426d-492c-989c-3495ee530553","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a9d66b45-426d-492c-989c-3495ee530553\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.100.185\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-gnw54","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-gnw54","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"apps-207","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["apps-207"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:15Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:19Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:19Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:15Z"}],"hostIP":"192.168.2.107","podIP":"172.16.100.185","podIPs":[{"ip":"172.16.100.185"}],"startTime":"2023-04-18T05:52:15Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T05:52:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://c95eba71eb5c5fdab9ee67f84161ce5238ae91633e63c1fa6933df54692f5359","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-57nw5","generateName":"daemon-set-","namespace":"daemonsets-2921","uid":"8f13c115-79ef-4b8a-9b8b-3d45889a961f","resourceVersion":"4123297","creationTimestamp":"2023-04-18T05:52:14Z","deletionTimestamp":"2023-04-18T05:52:50Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"aaee30ac4bc2b4f6c4c1362064cca345ea96800f721cebc8c2e350ab3563c771","cni.projectcalico.org/podIP":"172.16.125.56/32","cni.projectcalico.org/podIPs":"172.16.125.56/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"a9d66b45-426d-492c-989c-3495ee530553","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a9d66b45-426d-492c-989c-3495ee530553\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:16Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.125.56\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-whf4p","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-whf4p","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"apps-208","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["apps-208"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:15Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:18Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:18Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:14Z"}],"hostIP":"192.168.2.108","podIP":"172.16.125.56","podIPs":[{"ip":"172.16.125.56"}],"startTime":"2023-04-18T05:52:15Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T05:52:17Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://480a126145525db67bf643d959e998a4bfc6a78ea9609c70b85ff8a5e8a41294","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-97tj5","generateName":"daemon-set-","namespace":"daemonsets-2921","uid":"e17d739d-c369-49bd-af4b-2a32741c97b5","resourceVersion":"4123296","creationTimestamp":"2023-04-18T05:52:14Z","deletionTimestamp":"2023-04-18T05:52:50Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"8957f98e836c5ea252c729f24d1a413645e32526f701616613fc0bd5682c2778","cni.projectcalico.org/podIP":"172.16.144.25/32","cni.projectcalico.org/podIPs":"172.16.144.25/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"a9d66b45-426d-492c-989c-3495ee530553","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:14Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a9d66b45-426d-492c-989c-3495ee530553\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:16Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-04-18T05:52:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"172.16.144.25\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-2dxf4","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-2dxf4","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"apps-209","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["apps-209"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:15Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:18Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:18Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-04-18T05:52:14Z"}],"hostIP":"192.168.2.109","podIP":"172.16.144.25","podIPs":[{"ip":"172.16.144.25"}],"startTime":"2023-04-18T05:52:15Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-04-18T05:52:18Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://a0233f45e0c791c508026f8bcf415719f9695523836d0b13106fa53ae0973b7e","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:52:21.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-2921" for this suite. 04/18/23 05:52:21.718
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:52:21.806
Apr 18 05:52:21.806: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 05:52:21.807
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:22.058
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:22.06
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-2884/configmap-test-5d224087-9d9b-4938-816f-f0c038232392 04/18/23 05:52:22.063
STEP: Creating a pod to test consume configMaps 04/18/23 05:52:22.136
Apr 18 05:52:22.201: INFO: Waiting up to 5m0s for pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b" in namespace "configmap-2884" to be "Succeeded or Failed"
Apr 18 05:52:22.241: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 40.20402ms
Apr 18 05:52:24.296: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.094933835s
Apr 18 05:52:26.258: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05662194s
Apr 18 05:52:28.264: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.06268633s
Apr 18 05:52:30.247: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04557696s
STEP: Saw pod success 04/18/23 05:52:30.247
Apr 18 05:52:30.247: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b" satisfied condition "Succeeded or Failed"
Apr 18 05:52:30.250: INFO: Trying to get logs from node apps-208 pod pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b container env-test: <nil>
STEP: delete the pod 04/18/23 05:52:30.256
Apr 18 05:52:30.304: INFO: Waiting for pod pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b to disappear
Apr 18 05:52:30.354: INFO: Pod pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 05:52:30.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2884" for this suite. 04/18/23 05:52:30.362
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":310,"skipped":5760,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.585 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:52:21.806
    Apr 18 05:52:21.806: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 05:52:21.807
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:22.058
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:22.06
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-2884/configmap-test-5d224087-9d9b-4938-816f-f0c038232392 04/18/23 05:52:22.063
    STEP: Creating a pod to test consume configMaps 04/18/23 05:52:22.136
    Apr 18 05:52:22.201: INFO: Waiting up to 5m0s for pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b" in namespace "configmap-2884" to be "Succeeded or Failed"
    Apr 18 05:52:22.241: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 40.20402ms
    Apr 18 05:52:24.296: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.094933835s
    Apr 18 05:52:26.258: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05662194s
    Apr 18 05:52:28.264: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.06268633s
    Apr 18 05:52:30.247: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04557696s
    STEP: Saw pod success 04/18/23 05:52:30.247
    Apr 18 05:52:30.247: INFO: Pod "pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b" satisfied condition "Succeeded or Failed"
    Apr 18 05:52:30.250: INFO: Trying to get logs from node apps-208 pod pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b container env-test: <nil>
    STEP: delete the pod 04/18/23 05:52:30.256
    Apr 18 05:52:30.304: INFO: Waiting for pod pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b to disappear
    Apr 18 05:52:30.354: INFO: Pod pod-configmaps-11aaddf1-f286-4f8e-8ddb-3f4feb9e6e1b no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 05:52:30.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2884" for this suite. 04/18/23 05:52:30.362
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:52:30.392
Apr 18 05:52:30.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 05:52:30.393
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:30.44
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:30.442
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 04/18/23 05:52:30.445
Apr 18 05:52:30.519: INFO: Waiting up to 5m0s for pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820" in namespace "emptydir-2242" to be "Succeeded or Failed"
Apr 18 05:52:30.523: INFO: Pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820": Phase="Pending", Reason="", readiness=false. Elapsed: 3.604515ms
Apr 18 05:52:32.549: INFO: Pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029551708s
Apr 18 05:52:34.529: INFO: Pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820": Phase="Running", Reason="", readiness=false. Elapsed: 4.009642177s
Apr 18 05:52:36.528: INFO: Pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008220446s
STEP: Saw pod success 04/18/23 05:52:36.528
Apr 18 05:52:36.528: INFO: Pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820" satisfied condition "Succeeded or Failed"
Apr 18 05:52:36.531: INFO: Trying to get logs from node apps-208 pod pod-0cf49b49-0d60-4821-a155-0583ad6e2820 container test-container: <nil>
STEP: delete the pod 04/18/23 05:52:36.604
Apr 18 05:52:36.784: INFO: Waiting for pod pod-0cf49b49-0d60-4821-a155-0583ad6e2820 to disappear
Apr 18 05:52:36.786: INFO: Pod pod-0cf49b49-0d60-4821-a155-0583ad6e2820 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 05:52:36.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2242" for this suite. 04/18/23 05:52:36.79
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":311,"skipped":5761,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.407 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:52:30.392
    Apr 18 05:52:30.392: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 05:52:30.393
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:30.44
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:30.442
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 04/18/23 05:52:30.445
    Apr 18 05:52:30.519: INFO: Waiting up to 5m0s for pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820" in namespace "emptydir-2242" to be "Succeeded or Failed"
    Apr 18 05:52:30.523: INFO: Pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820": Phase="Pending", Reason="", readiness=false. Elapsed: 3.604515ms
    Apr 18 05:52:32.549: INFO: Pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029551708s
    Apr 18 05:52:34.529: INFO: Pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820": Phase="Running", Reason="", readiness=false. Elapsed: 4.009642177s
    Apr 18 05:52:36.528: INFO: Pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008220446s
    STEP: Saw pod success 04/18/23 05:52:36.528
    Apr 18 05:52:36.528: INFO: Pod "pod-0cf49b49-0d60-4821-a155-0583ad6e2820" satisfied condition "Succeeded or Failed"
    Apr 18 05:52:36.531: INFO: Trying to get logs from node apps-208 pod pod-0cf49b49-0d60-4821-a155-0583ad6e2820 container test-container: <nil>
    STEP: delete the pod 04/18/23 05:52:36.604
    Apr 18 05:52:36.784: INFO: Waiting for pod pod-0cf49b49-0d60-4821-a155-0583ad6e2820 to disappear
    Apr 18 05:52:36.786: INFO: Pod pod-0cf49b49-0d60-4821-a155-0583ad6e2820 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 05:52:36.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2242" for this suite. 04/18/23 05:52:36.79
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:52:36.8
Apr 18 05:52:36.800: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename subpath 04/18/23 05:52:36.801
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:36.978
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:36.981
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/18/23 05:52:37.052
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-c624 04/18/23 05:52:37.209
STEP: Creating a pod to test atomic-volume-subpath 04/18/23 05:52:37.209
Apr 18 05:52:37.252: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-c624" in namespace "subpath-7526" to be "Succeeded or Failed"
Apr 18 05:52:37.336: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Pending", Reason="", readiness=false. Elapsed: 83.970733ms
Apr 18 05:52:39.340: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08830408s
Apr 18 05:52:41.342: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 4.089610129s
Apr 18 05:52:43.341: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 6.08878533s
Apr 18 05:52:45.340: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 8.088379538s
Apr 18 05:52:47.340: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 10.088428273s
Apr 18 05:52:49.341: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 12.088469938s
Apr 18 05:52:51.369: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 14.117312382s
Apr 18 05:52:53.340: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 16.088124907s
Apr 18 05:52:55.342: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 18.089570035s
Apr 18 05:52:57.363: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 20.111019878s
Apr 18 05:52:59.357: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 22.105163308s
Apr 18 05:53:01.341: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=false. Elapsed: 24.088724945s
Apr 18 05:53:03.342: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.089761411s
STEP: Saw pod success 04/18/23 05:53:03.342
Apr 18 05:53:03.342: INFO: Pod "pod-subpath-test-downwardapi-c624" satisfied condition "Succeeded or Failed"
Apr 18 05:53:03.345: INFO: Trying to get logs from node apps-208 pod pod-subpath-test-downwardapi-c624 container test-container-subpath-downwardapi-c624: <nil>
STEP: delete the pod 04/18/23 05:53:03.358
Apr 18 05:53:03.509: INFO: Waiting for pod pod-subpath-test-downwardapi-c624 to disappear
Apr 18 05:53:03.513: INFO: Pod pod-subpath-test-downwardapi-c624 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-c624 04/18/23 05:53:03.513
Apr 18 05:53:03.513: INFO: Deleting pod "pod-subpath-test-downwardapi-c624" in namespace "subpath-7526"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 18 05:53:03.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7526" for this suite. 04/18/23 05:53:03.521
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":312,"skipped":5765,"failed":0}
------------------------------
â€¢ [SLOW TEST] [26.735 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:52:36.8
    Apr 18 05:52:36.800: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename subpath 04/18/23 05:52:36.801
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:52:36.978
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:52:36.981
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/18/23 05:52:37.052
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-c624 04/18/23 05:52:37.209
    STEP: Creating a pod to test atomic-volume-subpath 04/18/23 05:52:37.209
    Apr 18 05:52:37.252: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-c624" in namespace "subpath-7526" to be "Succeeded or Failed"
    Apr 18 05:52:37.336: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Pending", Reason="", readiness=false. Elapsed: 83.970733ms
    Apr 18 05:52:39.340: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08830408s
    Apr 18 05:52:41.342: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 4.089610129s
    Apr 18 05:52:43.341: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 6.08878533s
    Apr 18 05:52:45.340: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 8.088379538s
    Apr 18 05:52:47.340: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 10.088428273s
    Apr 18 05:52:49.341: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 12.088469938s
    Apr 18 05:52:51.369: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 14.117312382s
    Apr 18 05:52:53.340: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 16.088124907s
    Apr 18 05:52:55.342: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 18.089570035s
    Apr 18 05:52:57.363: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 20.111019878s
    Apr 18 05:52:59.357: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=true. Elapsed: 22.105163308s
    Apr 18 05:53:01.341: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Running", Reason="", readiness=false. Elapsed: 24.088724945s
    Apr 18 05:53:03.342: INFO: Pod "pod-subpath-test-downwardapi-c624": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.089761411s
    STEP: Saw pod success 04/18/23 05:53:03.342
    Apr 18 05:53:03.342: INFO: Pod "pod-subpath-test-downwardapi-c624" satisfied condition "Succeeded or Failed"
    Apr 18 05:53:03.345: INFO: Trying to get logs from node apps-208 pod pod-subpath-test-downwardapi-c624 container test-container-subpath-downwardapi-c624: <nil>
    STEP: delete the pod 04/18/23 05:53:03.358
    Apr 18 05:53:03.509: INFO: Waiting for pod pod-subpath-test-downwardapi-c624 to disappear
    Apr 18 05:53:03.513: INFO: Pod pod-subpath-test-downwardapi-c624 no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-c624 04/18/23 05:53:03.513
    Apr 18 05:53:03.513: INFO: Deleting pod "pod-subpath-test-downwardapi-c624" in namespace "subpath-7526"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 18 05:53:03.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7526" for this suite. 04/18/23 05:53:03.521
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:53:03.535
Apr 18 05:53:03.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replicaset 04/18/23 05:53:03.536
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:53:03.643
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:53:03.645
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 04/18/23 05:53:03.655
STEP: Verify that the required pods have come up. 04/18/23 05:53:03.675
Apr 18 05:53:03.678: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 18 05:53:08.686: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 05:53:08.686
STEP: Getting /status 04/18/23 05:53:08.686
Apr 18 05:53:08.690: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 04/18/23 05:53:08.69
Apr 18 05:53:08.811: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 04/18/23 05:53:08.811
Apr 18 05:53:08.812: INFO: Observed &ReplicaSet event: ADDED
Apr 18 05:53:08.813: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 05:53:08.813: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 05:53:08.813: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 05:53:08.813: INFO: Found replicaset test-rs in namespace replicaset-6953 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 18 05:53:08.813: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 04/18/23 05:53:08.813
Apr 18 05:53:08.813: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 18 05:53:08.835: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 04/18/23 05:53:08.835
Apr 18 05:53:08.837: INFO: Observed &ReplicaSet event: ADDED
Apr 18 05:53:08.837: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 05:53:08.837: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 05:53:08.837: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 05:53:08.837: INFO: Observed replicaset test-rs in namespace replicaset-6953 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 18 05:53:08.837: INFO: Observed &ReplicaSet event: MODIFIED
Apr 18 05:53:08.842: INFO: Found replicaset test-rs in namespace replicaset-6953 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Apr 18 05:53:08.842: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 05:53:08.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6953" for this suite. 04/18/23 05:53:08.853
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":313,"skipped":5771,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.442 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:53:03.535
    Apr 18 05:53:03.535: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replicaset 04/18/23 05:53:03.536
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:53:03.643
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:53:03.645
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 04/18/23 05:53:03.655
    STEP: Verify that the required pods have come up. 04/18/23 05:53:03.675
    Apr 18 05:53:03.678: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 18 05:53:08.686: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 05:53:08.686
    STEP: Getting /status 04/18/23 05:53:08.686
    Apr 18 05:53:08.690: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 04/18/23 05:53:08.69
    Apr 18 05:53:08.811: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 04/18/23 05:53:08.811
    Apr 18 05:53:08.812: INFO: Observed &ReplicaSet event: ADDED
    Apr 18 05:53:08.813: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 05:53:08.813: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 05:53:08.813: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 05:53:08.813: INFO: Found replicaset test-rs in namespace replicaset-6953 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 18 05:53:08.813: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 04/18/23 05:53:08.813
    Apr 18 05:53:08.813: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 18 05:53:08.835: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 04/18/23 05:53:08.835
    Apr 18 05:53:08.837: INFO: Observed &ReplicaSet event: ADDED
    Apr 18 05:53:08.837: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 05:53:08.837: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 05:53:08.837: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 05:53:08.837: INFO: Observed replicaset test-rs in namespace replicaset-6953 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 18 05:53:08.837: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 18 05:53:08.842: INFO: Found replicaset test-rs in namespace replicaset-6953 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Apr 18 05:53:08.842: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 05:53:08.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6953" for this suite. 04/18/23 05:53:08.853
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:53:08.978
Apr 18 05:53:08.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename taint-multiple-pods 04/18/23 05:53:08.979
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:53:09.143
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:53:09.146
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Apr 18 05:53:09.204: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 05:54:09.260: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Apr 18 05:54:09.264: INFO: Starting informer...
STEP: Starting pods... 04/18/23 05:54:09.264
Apr 18 05:54:09.525: INFO: Pod1 is running on apps-208. Tainting Node
Apr 18 05:54:09.752: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-1075" to be "running"
Apr 18 05:54:09.763: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.944267ms
Apr 18 05:54:11.814: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061719976s
Apr 18 05:54:13.767: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.014466149s
Apr 18 05:54:13.767: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Apr 18 05:54:13.767: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-1075" to be "running"
Apr 18 05:54:13.772: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.971758ms
Apr 18 05:54:13.772: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Apr 18 05:54:13.772: INFO: Pod2 is running on apps-208. Tainting Node
STEP: Trying to apply a taint on the Node 04/18/23 05:54:13.772
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 05:54:13.815
STEP: Waiting for Pod1 and Pod2 to be deleted 04/18/23 05:54:13.818
Apr 18 05:54:20.952: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 18 05:54:40.928: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 05:54:41.029
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:54:41.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-1075" for this suite. 04/18/23 05:54:41.162
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":314,"skipped":5774,"failed":0}
------------------------------
â€¢ [SLOW TEST] [92.326 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:53:08.978
    Apr 18 05:53:08.978: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename taint-multiple-pods 04/18/23 05:53:08.979
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:53:09.143
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:53:09.146
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Apr 18 05:53:09.204: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 05:54:09.260: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Apr 18 05:54:09.264: INFO: Starting informer...
    STEP: Starting pods... 04/18/23 05:54:09.264
    Apr 18 05:54:09.525: INFO: Pod1 is running on apps-208. Tainting Node
    Apr 18 05:54:09.752: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-1075" to be "running"
    Apr 18 05:54:09.763: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.944267ms
    Apr 18 05:54:11.814: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061719976s
    Apr 18 05:54:13.767: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 4.014466149s
    Apr 18 05:54:13.767: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Apr 18 05:54:13.767: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-1075" to be "running"
    Apr 18 05:54:13.772: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.971758ms
    Apr 18 05:54:13.772: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Apr 18 05:54:13.772: INFO: Pod2 is running on apps-208. Tainting Node
    STEP: Trying to apply a taint on the Node 04/18/23 05:54:13.772
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 05:54:13.815
    STEP: Waiting for Pod1 and Pod2 to be deleted 04/18/23 05:54:13.818
    Apr 18 05:54:20.952: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Apr 18 05:54:40.928: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/18/23 05:54:41.029
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:54:41.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-1075" for this suite. 04/18/23 05:54:41.162
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:54:41.305
Apr 18 05:54:41.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 05:54:41.306
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:54:41.495
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:54:41.497
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/18/23 05:54:41.5
Apr 18 05:54:41.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
Apr 18 05:54:56.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:55:34.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5088" for this suite. 04/18/23 05:55:34.554
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":315,"skipped":5799,"failed":0}
------------------------------
â€¢ [SLOW TEST] [53.272 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:54:41.305
    Apr 18 05:54:41.305: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-publish-openapi 04/18/23 05:54:41.306
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:54:41.495
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:54:41.497
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/18/23 05:54:41.5
    Apr 18 05:54:41.501: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    Apr 18 05:54:56.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:55:34.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5088" for this suite. 04/18/23 05:55:34.554
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:55:34.577
Apr 18 05:55:34.577: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 05:55:34.578
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:55:34.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:55:34.783
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 05:55:34.867
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:55:35.269
STEP: Deploying the webhook pod 04/18/23 05:55:35.307
STEP: Wait for the deployment to be ready 04/18/23 05:55:35.559
Apr 18 05:55:35.620: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 18 05:55:37.720: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 55, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 55, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 55, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 55, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 05:55:39.724
STEP: Verifying the service has paired with the endpoint 04/18/23 05:55:39.826
Apr 18 05:55:40.826: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Apr 18 05:55:40.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8669-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 05:55:46.407
STEP: Creating a custom resource that should be mutated by the webhook 04/18/23 05:55:46.443
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:55:49.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9468" for this suite. 04/18/23 05:55:49.12
STEP: Destroying namespace "webhook-9468-markers" for this suite. 04/18/23 05:55:49.219
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":316,"skipped":5808,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.967 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:55:34.577
    Apr 18 05:55:34.577: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 05:55:34.578
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:55:34.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:55:34.783
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 05:55:34.867
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 05:55:35.269
    STEP: Deploying the webhook pod 04/18/23 05:55:35.307
    STEP: Wait for the deployment to be ready 04/18/23 05:55:35.559
    Apr 18 05:55:35.620: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 18 05:55:37.720: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 5, 55, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 55, 35, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 5, 55, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 5, 55, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 05:55:39.724
    STEP: Verifying the service has paired with the endpoint 04/18/23 05:55:39.826
    Apr 18 05:55:40.826: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Apr 18 05:55:40.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8669-crds.webhook.example.com via the AdmissionRegistration API 04/18/23 05:55:46.407
    STEP: Creating a custom resource that should be mutated by the webhook 04/18/23 05:55:46.443
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:55:49.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9468" for this suite. 04/18/23 05:55:49.12
    STEP: Destroying namespace "webhook-9468-markers" for this suite. 04/18/23 05:55:49.219
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:55:49.545
Apr 18 05:55:49.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename statefulset 04/18/23 05:55:49.547
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:55:49.713
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:55:49.716
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5867 04/18/23 05:55:49.719
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 04/18/23 05:55:49.736
STEP: Creating pod with conflicting port in namespace statefulset-5867 04/18/23 05:55:49.741
STEP: Waiting until pod test-pod will start running in namespace statefulset-5867 04/18/23 05:55:49.964
Apr 18 05:55:49.964: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-5867" to be "running"
Apr 18 05:55:49.978: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.125531ms
Apr 18 05:55:51.982: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018122357s
Apr 18 05:55:53.983: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.01880623s
Apr 18 05:55:53.983: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-5867 04/18/23 05:55:53.983
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5867 04/18/23 05:55:54.012
Apr 18 05:55:54.104: INFO: Observed stateful pod in namespace: statefulset-5867, name: ss-0, uid: e7be9cba-d2ef-4b17-afb0-0d0b900c503f, status phase: Pending. Waiting for statefulset controller to delete.
Apr 18 05:55:54.305: INFO: Observed stateful pod in namespace: statefulset-5867, name: ss-0, uid: e7be9cba-d2ef-4b17-afb0-0d0b900c503f, status phase: Failed. Waiting for statefulset controller to delete.
Apr 18 05:55:54.484: INFO: Observed stateful pod in namespace: statefulset-5867, name: ss-0, uid: e7be9cba-d2ef-4b17-afb0-0d0b900c503f, status phase: Failed. Waiting for statefulset controller to delete.
Apr 18 05:55:54.637: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5867
STEP: Removing pod with conflicting port in namespace statefulset-5867 04/18/23 05:55:54.637
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5867 and will be in running state 04/18/23 05:55:54.778
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 18 05:56:00.822: INFO: Deleting all statefulset in ns statefulset-5867
Apr 18 05:56:00.825: INFO: Scaling statefulset ss to 0
Apr 18 05:56:10.888: INFO: Waiting for statefulset status.replicas updated to 0
Apr 18 05:56:10.891: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 18 05:56:10.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5867" for this suite. 04/18/23 05:56:10.943
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":317,"skipped":5822,"failed":0}
------------------------------
â€¢ [SLOW TEST] [21.469 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:55:49.545
    Apr 18 05:55:49.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename statefulset 04/18/23 05:55:49.547
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:55:49.713
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:55:49.716
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5867 04/18/23 05:55:49.719
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 04/18/23 05:55:49.736
    STEP: Creating pod with conflicting port in namespace statefulset-5867 04/18/23 05:55:49.741
    STEP: Waiting until pod test-pod will start running in namespace statefulset-5867 04/18/23 05:55:49.964
    Apr 18 05:55:49.964: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-5867" to be "running"
    Apr 18 05:55:49.978: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.125531ms
    Apr 18 05:55:51.982: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018122357s
    Apr 18 05:55:53.983: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.01880623s
    Apr 18 05:55:53.983: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-5867 04/18/23 05:55:53.983
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5867 04/18/23 05:55:54.012
    Apr 18 05:55:54.104: INFO: Observed stateful pod in namespace: statefulset-5867, name: ss-0, uid: e7be9cba-d2ef-4b17-afb0-0d0b900c503f, status phase: Pending. Waiting for statefulset controller to delete.
    Apr 18 05:55:54.305: INFO: Observed stateful pod in namespace: statefulset-5867, name: ss-0, uid: e7be9cba-d2ef-4b17-afb0-0d0b900c503f, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 18 05:55:54.484: INFO: Observed stateful pod in namespace: statefulset-5867, name: ss-0, uid: e7be9cba-d2ef-4b17-afb0-0d0b900c503f, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 18 05:55:54.637: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5867
    STEP: Removing pod with conflicting port in namespace statefulset-5867 04/18/23 05:55:54.637
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5867 and will be in running state 04/18/23 05:55:54.778
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 18 05:56:00.822: INFO: Deleting all statefulset in ns statefulset-5867
    Apr 18 05:56:00.825: INFO: Scaling statefulset ss to 0
    Apr 18 05:56:10.888: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 18 05:56:10.891: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 18 05:56:10.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5867" for this suite. 04/18/23 05:56:10.943
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:56:11.015
Apr 18 05:56:11.016: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replication-controller 04/18/23 05:56:11.017
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:56:11.087
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:56:11.09
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 04/18/23 05:56:11.096
STEP: waiting for RC to be added 04/18/23 05:56:11.106
STEP: waiting for available Replicas 04/18/23 05:56:11.106
STEP: patching ReplicationController 04/18/23 05:56:14.096
STEP: waiting for RC to be modified 04/18/23 05:56:14.115
STEP: patching ReplicationController status 04/18/23 05:56:14.115
STEP: waiting for RC to be modified 04/18/23 05:56:14.171
STEP: waiting for available Replicas 04/18/23 05:56:14.171
STEP: fetching ReplicationController status 04/18/23 05:56:14.215
STEP: patching ReplicationController scale 04/18/23 05:56:14.252
STEP: waiting for RC to be modified 04/18/23 05:56:14.271
STEP: waiting for ReplicationController's scale to be the max amount 04/18/23 05:56:14.271
STEP: fetching ReplicationController; ensuring that it's patched 04/18/23 05:56:17.107
STEP: updating ReplicationController status 04/18/23 05:56:17.119
STEP: waiting for RC to be modified 04/18/23 05:56:17.157
STEP: listing all ReplicationControllers 04/18/23 05:56:17.157
STEP: checking that ReplicationController has expected values 04/18/23 05:56:17.24
STEP: deleting ReplicationControllers by collection 04/18/23 05:56:17.24
STEP: waiting for ReplicationController to have a DELETED watchEvent 04/18/23 05:56:17.33
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 18 05:56:17.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7779" for this suite. 04/18/23 05:56:17.613
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":318,"skipped":5838,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.624 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:56:11.015
    Apr 18 05:56:11.016: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replication-controller 04/18/23 05:56:11.017
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:56:11.087
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:56:11.09
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 04/18/23 05:56:11.096
    STEP: waiting for RC to be added 04/18/23 05:56:11.106
    STEP: waiting for available Replicas 04/18/23 05:56:11.106
    STEP: patching ReplicationController 04/18/23 05:56:14.096
    STEP: waiting for RC to be modified 04/18/23 05:56:14.115
    STEP: patching ReplicationController status 04/18/23 05:56:14.115
    STEP: waiting for RC to be modified 04/18/23 05:56:14.171
    STEP: waiting for available Replicas 04/18/23 05:56:14.171
    STEP: fetching ReplicationController status 04/18/23 05:56:14.215
    STEP: patching ReplicationController scale 04/18/23 05:56:14.252
    STEP: waiting for RC to be modified 04/18/23 05:56:14.271
    STEP: waiting for ReplicationController's scale to be the max amount 04/18/23 05:56:14.271
    STEP: fetching ReplicationController; ensuring that it's patched 04/18/23 05:56:17.107
    STEP: updating ReplicationController status 04/18/23 05:56:17.119
    STEP: waiting for RC to be modified 04/18/23 05:56:17.157
    STEP: listing all ReplicationControllers 04/18/23 05:56:17.157
    STEP: checking that ReplicationController has expected values 04/18/23 05:56:17.24
    STEP: deleting ReplicationControllers by collection 04/18/23 05:56:17.24
    STEP: waiting for ReplicationController to have a DELETED watchEvent 04/18/23 05:56:17.33
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 18 05:56:17.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7779" for this suite. 04/18/23 05:56:17.613
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:56:17.64
Apr 18 05:56:17.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 05:56:17.641
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:56:17.806
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:56:17.809
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 04/18/23 05:56:17.811
Apr 18 05:56:17.840: INFO: Waiting up to 5m0s for pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d" in namespace "emptydir-1144" to be "Succeeded or Failed"
Apr 18 05:56:17.876: INFO: Pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d": Phase="Pending", Reason="", readiness=false. Elapsed: 36.185406ms
Apr 18 05:56:19.895: INFO: Pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054412599s
Apr 18 05:56:21.920: INFO: Pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.079719432s
Apr 18 05:56:23.884: INFO: Pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043829959s
STEP: Saw pod success 04/18/23 05:56:23.884
Apr 18 05:56:23.884: INFO: Pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d" satisfied condition "Succeeded or Failed"
Apr 18 05:56:24.061: INFO: Trying to get logs from node apps-208 pod pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d container test-container: <nil>
STEP: delete the pod 04/18/23 05:56:24.075
Apr 18 05:56:24.267: INFO: Waiting for pod pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d to disappear
Apr 18 05:56:24.300: INFO: Pod pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 05:56:24.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1144" for this suite. 04/18/23 05:56:24.304
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":319,"skipped":5842,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.736 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:56:17.64
    Apr 18 05:56:17.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 05:56:17.641
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:56:17.806
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:56:17.809
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/18/23 05:56:17.811
    Apr 18 05:56:17.840: INFO: Waiting up to 5m0s for pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d" in namespace "emptydir-1144" to be "Succeeded or Failed"
    Apr 18 05:56:17.876: INFO: Pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d": Phase="Pending", Reason="", readiness=false. Elapsed: 36.185406ms
    Apr 18 05:56:19.895: INFO: Pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054412599s
    Apr 18 05:56:21.920: INFO: Pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.079719432s
    Apr 18 05:56:23.884: INFO: Pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043829959s
    STEP: Saw pod success 04/18/23 05:56:23.884
    Apr 18 05:56:23.884: INFO: Pod "pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d" satisfied condition "Succeeded or Failed"
    Apr 18 05:56:24.061: INFO: Trying to get logs from node apps-208 pod pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d container test-container: <nil>
    STEP: delete the pod 04/18/23 05:56:24.075
    Apr 18 05:56:24.267: INFO: Waiting for pod pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d to disappear
    Apr 18 05:56:24.300: INFO: Pod pod-dc99f39c-2ee3-4e04-b88a-b277e05fea6d no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 05:56:24.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1144" for this suite. 04/18/23 05:56:24.304
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:56:24.377
Apr 18 05:56:24.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 05:56:24.378
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:56:24.508
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:56:24.511
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/18/23 05:56:24.513
Apr 18 05:56:24.633: INFO: Waiting up to 5m0s for pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20" in namespace "emptydir-9377" to be "Succeeded or Failed"
Apr 18 05:56:24.636: INFO: Pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.898487ms
Apr 18 05:56:26.904: INFO: Pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.271184748s
Apr 18 05:56:28.668: INFO: Pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20": Phase="Running", Reason="", readiness=false. Elapsed: 4.034946278s
Apr 18 05:56:30.640: INFO: Pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007730237s
STEP: Saw pod success 04/18/23 05:56:30.641
Apr 18 05:56:30.641: INFO: Pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20" satisfied condition "Succeeded or Failed"
Apr 18 05:56:30.644: INFO: Trying to get logs from node apps-208 pod pod-02962f04-72e4-4d65-862a-47f06aa2cf20 container test-container: <nil>
STEP: delete the pod 04/18/23 05:56:30.735
Apr 18 05:56:30.902: INFO: Waiting for pod pod-02962f04-72e4-4d65-862a-47f06aa2cf20 to disappear
Apr 18 05:56:30.905: INFO: Pod pod-02962f04-72e4-4d65-862a-47f06aa2cf20 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 05:56:30.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9377" for this suite. 04/18/23 05:56:30.909
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":320,"skipped":5843,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.541 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:56:24.377
    Apr 18 05:56:24.377: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 05:56:24.378
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:56:24.508
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:56:24.511
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/18/23 05:56:24.513
    Apr 18 05:56:24.633: INFO: Waiting up to 5m0s for pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20" in namespace "emptydir-9377" to be "Succeeded or Failed"
    Apr 18 05:56:24.636: INFO: Pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.898487ms
    Apr 18 05:56:26.904: INFO: Pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.271184748s
    Apr 18 05:56:28.668: INFO: Pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20": Phase="Running", Reason="", readiness=false. Elapsed: 4.034946278s
    Apr 18 05:56:30.640: INFO: Pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007730237s
    STEP: Saw pod success 04/18/23 05:56:30.641
    Apr 18 05:56:30.641: INFO: Pod "pod-02962f04-72e4-4d65-862a-47f06aa2cf20" satisfied condition "Succeeded or Failed"
    Apr 18 05:56:30.644: INFO: Trying to get logs from node apps-208 pod pod-02962f04-72e4-4d65-862a-47f06aa2cf20 container test-container: <nil>
    STEP: delete the pod 04/18/23 05:56:30.735
    Apr 18 05:56:30.902: INFO: Waiting for pod pod-02962f04-72e4-4d65-862a-47f06aa2cf20 to disappear
    Apr 18 05:56:30.905: INFO: Pod pod-02962f04-72e4-4d65-862a-47f06aa2cf20 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 05:56:30.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9377" for this suite. 04/18/23 05:56:30.909
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:56:30.92
Apr 18 05:56:30.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename crd-watch 04/18/23 05:56:30.921
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:56:31.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:56:31.105
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Apr 18 05:56:31.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Creating first CR  04/18/23 05:56:38.854
Apr 18 05:56:38.919: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:38Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:56:38Z]] name:name1 resourceVersion:4124848 uid:da57cd62-e77b-411e-90e6-09e300f7010b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 04/18/23 05:56:48.921
Apr 18 05:56:48.935: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:48Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:56:48Z]] name:name2 resourceVersion:4124883 uid:252ac46b-8924-4998-a971-8f02b980ded8] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 04/18/23 05:56:58.935
Apr 18 05:56:59.002: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:38Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:56:58Z]] name:name1 resourceVersion:4124915 uid:da57cd62-e77b-411e-90e6-09e300f7010b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 04/18/23 05:57:09.003
Apr 18 05:57:09.086: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:48Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:57:09Z]] name:name2 resourceVersion:4124949 uid:252ac46b-8924-4998-a971-8f02b980ded8] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 04/18/23 05:57:19.086
Apr 18 05:57:19.111: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:38Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:56:58Z]] name:name1 resourceVersion:4124981 uid:da57cd62-e77b-411e-90e6-09e300f7010b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 04/18/23 05:57:29.114
Apr 18 05:57:29.137: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:48Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:57:09Z]] name:name2 resourceVersion:4125014 uid:252ac46b-8924-4998-a971-8f02b980ded8] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 05:57:39.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-5562" for this suite. 04/18/23 05:57:39.685
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":321,"skipped":5876,"failed":0}
------------------------------
â€¢ [SLOW TEST] [68.792 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:56:30.92
    Apr 18 05:56:30.920: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename crd-watch 04/18/23 05:56:30.921
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:56:31.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:56:31.105
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Apr 18 05:56:31.107: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Creating first CR  04/18/23 05:56:38.854
    Apr 18 05:56:38.919: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:38Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:56:38Z]] name:name1 resourceVersion:4124848 uid:da57cd62-e77b-411e-90e6-09e300f7010b] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 04/18/23 05:56:48.921
    Apr 18 05:56:48.935: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:48Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:56:48Z]] name:name2 resourceVersion:4124883 uid:252ac46b-8924-4998-a971-8f02b980ded8] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 04/18/23 05:56:58.935
    Apr 18 05:56:59.002: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:38Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:56:58Z]] name:name1 resourceVersion:4124915 uid:da57cd62-e77b-411e-90e6-09e300f7010b] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 04/18/23 05:57:09.003
    Apr 18 05:57:09.086: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:48Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:57:09Z]] name:name2 resourceVersion:4124949 uid:252ac46b-8924-4998-a971-8f02b980ded8] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 04/18/23 05:57:19.086
    Apr 18 05:57:19.111: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:38Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:56:58Z]] name:name1 resourceVersion:4124981 uid:da57cd62-e77b-411e-90e6-09e300f7010b] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 04/18/23 05:57:29.114
    Apr 18 05:57:29.137: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-04-18T05:56:48Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-04-18T05:57:09Z]] name:name2 resourceVersion:4125014 uid:252ac46b-8924-4998-a971-8f02b980ded8] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 05:57:39.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-5562" for this suite. 04/18/23 05:57:39.685
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:57:39.713
Apr 18 05:57:39.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replicaset 04/18/23 05:57:39.714
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:57:39.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:57:39.795
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 04/18/23 05:57:39.812
STEP: Verify that the required pods have come up 04/18/23 05:57:39.859
Apr 18 05:57:39.863: INFO: Pod name sample-pod: Found 0 pods out of 3
Apr 18 05:57:44.867: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 04/18/23 05:57:44.867
Apr 18 05:57:44.870: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 04/18/23 05:57:44.87
STEP: DeleteCollection of the ReplicaSets 04/18/23 05:57:44.877
STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/18/23 05:57:45
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 05:57:45.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2305" for this suite. 04/18/23 05:57:45.09
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":322,"skipped":5898,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.474 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:57:39.713
    Apr 18 05:57:39.713: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replicaset 04/18/23 05:57:39.714
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:57:39.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:57:39.795
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 04/18/23 05:57:39.812
    STEP: Verify that the required pods have come up 04/18/23 05:57:39.859
    Apr 18 05:57:39.863: INFO: Pod name sample-pod: Found 0 pods out of 3
    Apr 18 05:57:44.867: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 04/18/23 05:57:44.867
    Apr 18 05:57:44.870: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 04/18/23 05:57:44.87
    STEP: DeleteCollection of the ReplicaSets 04/18/23 05:57:44.877
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/18/23 05:57:45
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 05:57:45.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2305" for this suite. 04/18/23 05:57:45.09
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:57:45.189
Apr 18 05:57:45.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sched-preemption 04/18/23 05:57:45.19
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:57:45.36
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:57:45.363
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 18 05:57:45.915: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 18 05:58:45.991: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:58:45.994
Apr 18 05:58:45.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename sched-preemption-path 04/18/23 05:58:45.995
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:46.046
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:46.049
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Apr 18 05:58:46.167: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Apr 18 05:58:46.171: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Apr 18 05:58:46.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-1526" for this suite. 04/18/23 05:58:46.207
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 18 05:58:46.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3054" for this suite. 04/18/23 05:58:46.338
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":323,"skipped":5935,"failed":0}
------------------------------
â€¢ [SLOW TEST] [61.287 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:57:45.189
    Apr 18 05:57:45.189: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sched-preemption 04/18/23 05:57:45.19
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:57:45.36
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:57:45.363
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 18 05:57:45.915: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 18 05:58:45.991: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:58:45.994
    Apr 18 05:58:45.994: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename sched-preemption-path 04/18/23 05:58:45.995
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:46.046
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:46.049
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Apr 18 05:58:46.167: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Apr 18 05:58:46.171: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Apr 18 05:58:46.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-1526" for this suite. 04/18/23 05:58:46.207
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 05:58:46.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-3054" for this suite. 04/18/23 05:58:46.338
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:58:46.477
Apr 18 05:58:46.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename gc 04/18/23 05:58:46.478
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:46.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:46.523
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 04/18/23 05:58:46.539
STEP: Wait for the Deployment to create new ReplicaSet 04/18/23 05:58:46.6
STEP: delete the deployment 04/18/23 05:58:47.14
STEP: wait for all rs to be garbage collected 04/18/23 05:58:47.209
STEP: expected 0 rs, got 1 rs 04/18/23 05:58:47.212
STEP: expected 0 pods, got 2 pods 04/18/23 05:58:47.267
STEP: Gathering metrics 04/18/23 05:58:47.903
Apr 18 05:58:47.928: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
Apr 18 05:58:47.931: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 3.438829ms
Apr 18 05:58:47.931: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
Apr 18 05:58:47.931: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
Apr 18 05:58:48.133: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 18 05:58:48.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-630" for this suite. 04/18/23 05:58:48.138
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":324,"skipped":5963,"failed":0}
------------------------------
â€¢ [1.735 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:58:46.477
    Apr 18 05:58:46.477: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename gc 04/18/23 05:58:46.478
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:46.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:46.523
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 04/18/23 05:58:46.539
    STEP: Wait for the Deployment to create new ReplicaSet 04/18/23 05:58:46.6
    STEP: delete the deployment 04/18/23 05:58:47.14
    STEP: wait for all rs to be garbage collected 04/18/23 05:58:47.209
    STEP: expected 0 rs, got 1 rs 04/18/23 05:58:47.212
    STEP: expected 0 pods, got 2 pods 04/18/23 05:58:47.267
    STEP: Gathering metrics 04/18/23 05:58:47.903
    Apr 18 05:58:47.928: INFO: Waiting up to 5m0s for pod "kube-controller-manager-apps-209" in namespace "kube-system" to be "running and ready"
    Apr 18 05:58:47.931: INFO: Pod "kube-controller-manager-apps-209": Phase="Running", Reason="", readiness=true. Elapsed: 3.438829ms
    Apr 18 05:58:47.931: INFO: The phase of Pod kube-controller-manager-apps-209 is Running (Ready = true)
    Apr 18 05:58:47.931: INFO: Pod "kube-controller-manager-apps-209" satisfied condition "running and ready"
    Apr 18 05:58:48.133: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 18 05:58:48.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-630" for this suite. 04/18/23 05:58:48.138
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:58:48.212
Apr 18 05:58:48.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 05:58:48.213
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:48.388
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:48.391
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Apr 18 05:58:48.394: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: creating the pod 04/18/23 05:58:48.395
STEP: submitting the pod to kubernetes 04/18/23 05:58:48.395
Apr 18 05:58:48.693: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66" in namespace "pods-8109" to be "running and ready"
Apr 18 05:58:48.785: INFO: Pod "pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66": Phase="Pending", Reason="", readiness=false. Elapsed: 92.891143ms
Apr 18 05:58:48.785: INFO: The phase of Pod pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:58:50.790: INFO: Pod "pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097637001s
Apr 18 05:58:50.790: INFO: The phase of Pod pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 05:58:52.860: INFO: Pod "pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66": Phase="Running", Reason="", readiness=true. Elapsed: 4.167696903s
Apr 18 05:58:52.860: INFO: The phase of Pod pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66 is Running (Ready = true)
Apr 18 05:58:52.860: INFO: Pod "pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 05:58:52.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8109" for this suite. 04/18/23 05:58:52.982
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":325,"skipped":5975,"failed":0}
------------------------------
â€¢ [4.828 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:58:48.212
    Apr 18 05:58:48.212: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 05:58:48.213
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:48.388
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:48.391
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Apr 18 05:58:48.394: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: creating the pod 04/18/23 05:58:48.395
    STEP: submitting the pod to kubernetes 04/18/23 05:58:48.395
    Apr 18 05:58:48.693: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66" in namespace "pods-8109" to be "running and ready"
    Apr 18 05:58:48.785: INFO: Pod "pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66": Phase="Pending", Reason="", readiness=false. Elapsed: 92.891143ms
    Apr 18 05:58:48.785: INFO: The phase of Pod pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:58:50.790: INFO: Pod "pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097637001s
    Apr 18 05:58:50.790: INFO: The phase of Pod pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 05:58:52.860: INFO: Pod "pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66": Phase="Running", Reason="", readiness=true. Elapsed: 4.167696903s
    Apr 18 05:58:52.860: INFO: The phase of Pod pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66 is Running (Ready = true)
    Apr 18 05:58:52.860: INFO: Pod "pod-exec-websocket-5de38158-9f2d-49e1-9cee-f05265921e66" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 05:58:52.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8109" for this suite. 04/18/23 05:58:52.982
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:58:53.04
Apr 18 05:58:53.040: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename podtemplate 04/18/23 05:58:53.041
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:53.188
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:53.191
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 04/18/23 05:58:53.206
Apr 18 05:58:53.227: INFO: created test-podtemplate-1
Apr 18 05:58:53.321: INFO: created test-podtemplate-2
Apr 18 05:58:53.369: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 04/18/23 05:58:53.369
STEP: delete collection of pod templates 04/18/23 05:58:53.372
Apr 18 05:58:53.372: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 04/18/23 05:58:53.464
Apr 18 05:58:53.464: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 18 05:58:53.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-5256" for this suite. 04/18/23 05:58:53.485
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":326,"skipped":5976,"failed":0}
------------------------------
â€¢ [0.496 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:58:53.04
    Apr 18 05:58:53.040: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename podtemplate 04/18/23 05:58:53.041
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:53.188
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:53.191
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 04/18/23 05:58:53.206
    Apr 18 05:58:53.227: INFO: created test-podtemplate-1
    Apr 18 05:58:53.321: INFO: created test-podtemplate-2
    Apr 18 05:58:53.369: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 04/18/23 05:58:53.369
    STEP: delete collection of pod templates 04/18/23 05:58:53.372
    Apr 18 05:58:53.372: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 04/18/23 05:58:53.464
    Apr 18 05:58:53.464: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 18 05:58:53.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-5256" for this suite. 04/18/23 05:58:53.485
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:58:53.537
Apr 18 05:58:53.537: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename resourcequota 04/18/23 05:58:53.538
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:53.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:53.633
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 04/18/23 05:58:53.635
STEP: Getting a ResourceQuota 04/18/23 05:58:53.773
STEP: Listing all ResourceQuotas with LabelSelector 04/18/23 05:58:53.792
STEP: Patching the ResourceQuota 04/18/23 05:58:53.795
STEP: Deleting a Collection of ResourceQuotas 04/18/23 05:58:53.814
STEP: Verifying the deleted ResourceQuota 04/18/23 05:58:53.942
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 18 05:58:53.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3719" for this suite. 04/18/23 05:58:53.949
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":327,"skipped":5991,"failed":0}
------------------------------
â€¢ [0.432 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:58:53.537
    Apr 18 05:58:53.537: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename resourcequota 04/18/23 05:58:53.538
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:53.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:53.633
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 04/18/23 05:58:53.635
    STEP: Getting a ResourceQuota 04/18/23 05:58:53.773
    STEP: Listing all ResourceQuotas with LabelSelector 04/18/23 05:58:53.792
    STEP: Patching the ResourceQuota 04/18/23 05:58:53.795
    STEP: Deleting a Collection of ResourceQuotas 04/18/23 05:58:53.814
    STEP: Verifying the deleted ResourceQuota 04/18/23 05:58:53.942
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 18 05:58:53.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3719" for this suite. 04/18/23 05:58:53.949
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:58:53.97
Apr 18 05:58:53.970: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename watch 04/18/23 05:58:53.971
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:54.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:54.125
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 04/18/23 05:58:54.128
STEP: creating a watch on configmaps with label B 04/18/23 05:58:54.129
STEP: creating a watch on configmaps with label A or B 04/18/23 05:58:54.13
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/18/23 05:58:54.131
Apr 18 05:58:54.214: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125465 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:58:54.215: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125465 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/18/23 05:58:54.215
Apr 18 05:58:54.289: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125467 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:58:54.289: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125467 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/18/23 05:58:54.289
Apr 18 05:58:54.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125469 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:58:54.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125469 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/18/23 05:58:54.36
Apr 18 05:58:54.393: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125470 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:58:54.393: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125470 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/18/23 05:58:54.393
Apr 18 05:58:54.402: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3159  0efa4e75-35a6-4738-9f88-c20990b43934 4125472 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:58:54.402: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3159  0efa4e75-35a6-4738-9f88-c20990b43934 4125472 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/18/23 05:59:04.403
Apr 18 05:59:04.428: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3159  0efa4e75-35a6-4738-9f88-c20990b43934 4125524 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 18 05:59:04.428: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3159  0efa4e75-35a6-4738-9f88-c20990b43934 4125524 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 18 05:59:14.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3159" for this suite. 04/18/23 05:59:14.435
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":328,"skipped":5994,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.492 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:58:53.97
    Apr 18 05:58:53.970: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename watch 04/18/23 05:58:53.971
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:58:54.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:58:54.125
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 04/18/23 05:58:54.128
    STEP: creating a watch on configmaps with label B 04/18/23 05:58:54.129
    STEP: creating a watch on configmaps with label A or B 04/18/23 05:58:54.13
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/18/23 05:58:54.131
    Apr 18 05:58:54.214: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125465 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:58:54.215: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125465 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/18/23 05:58:54.215
    Apr 18 05:58:54.289: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125467 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:58:54.289: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125467 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/18/23 05:58:54.289
    Apr 18 05:58:54.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125469 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:58:54.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125469 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/18/23 05:58:54.36
    Apr 18 05:58:54.393: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125470 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:58:54.393: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3159  ff627ee0-766f-4b7f-b95d-5089d1c79d62 4125470 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/18/23 05:58:54.393
    Apr 18 05:58:54.402: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3159  0efa4e75-35a6-4738-9f88-c20990b43934 4125472 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:58:54.402: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3159  0efa4e75-35a6-4738-9f88-c20990b43934 4125472 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/18/23 05:59:04.403
    Apr 18 05:59:04.428: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3159  0efa4e75-35a6-4738-9f88-c20990b43934 4125524 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 18 05:59:04.428: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3159  0efa4e75-35a6-4738-9f88-c20990b43934 4125524 0 2023-04-18 05:58:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-04-18 05:58:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 18 05:59:14.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3159" for this suite. 04/18/23 05:59:14.435
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:59:14.462
Apr 18 05:59:14.463: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename replicaset 04/18/23 05:59:14.464
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:59:14.566
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:59:14.569
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/18/23 05:59:14.572
Apr 18 05:59:14.610: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 18 05:59:19.614: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/18/23 05:59:19.614
STEP: getting scale subresource 04/18/23 05:59:19.615
STEP: updating a scale subresource 04/18/23 05:59:19.617
STEP: verifying the replicaset Spec.Replicas was modified 04/18/23 05:59:19.638
STEP: Patch a scale subresource 04/18/23 05:59:19.784
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 18 05:59:19.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2744" for this suite. 04/18/23 05:59:20.126
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":329,"skipped":6017,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.752 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:59:14.462
    Apr 18 05:59:14.463: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename replicaset 04/18/23 05:59:14.464
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:59:14.566
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:59:14.569
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/18/23 05:59:14.572
    Apr 18 05:59:14.610: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 18 05:59:19.614: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/18/23 05:59:19.614
    STEP: getting scale subresource 04/18/23 05:59:19.615
    STEP: updating a scale subresource 04/18/23 05:59:19.617
    STEP: verifying the replicaset Spec.Replicas was modified 04/18/23 05:59:19.638
    STEP: Patch a scale subresource 04/18/23 05:59:19.784
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 18 05:59:19.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2744" for this suite. 04/18/23 05:59:20.126
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:59:20.215
Apr 18 05:59:20.215: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 05:59:20.216
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:59:20.508
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:59:20.511
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-3ab2b3b2-4cf0-4ca8-8207-0c93723a07c4 04/18/23 05:59:20.514
STEP: Creating a pod to test consume secrets 04/18/23 05:59:20.58
Apr 18 05:59:20.808: INFO: Waiting up to 5m0s for pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0" in namespace "secrets-4431" to be "Succeeded or Failed"
Apr 18 05:59:20.812: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.63243ms
Apr 18 05:59:22.816: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007802396s
Apr 18 05:59:24.816: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008369128s
Apr 18 05:59:26.899: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.091333138s
Apr 18 05:59:28.816: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.007986771s
STEP: Saw pod success 04/18/23 05:59:28.816
Apr 18 05:59:28.816: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0" satisfied condition "Succeeded or Failed"
Apr 18 05:59:28.831: INFO: Trying to get logs from node apps-208 pod pod-secrets-693c599b-be17-420b-a548-269d074968d0 container secret-volume-test: <nil>
STEP: delete the pod 04/18/23 05:59:28.853
Apr 18 05:59:28.912: INFO: Waiting for pod pod-secrets-693c599b-be17-420b-a548-269d074968d0 to disappear
Apr 18 05:59:29.049: INFO: Pod pod-secrets-693c599b-be17-420b-a548-269d074968d0 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 18 05:59:29.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4431" for this suite. 04/18/23 05:59:29.054
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":330,"skipped":6021,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.879 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:59:20.215
    Apr 18 05:59:20.215: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 05:59:20.216
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:59:20.508
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:59:20.511
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-3ab2b3b2-4cf0-4ca8-8207-0c93723a07c4 04/18/23 05:59:20.514
    STEP: Creating a pod to test consume secrets 04/18/23 05:59:20.58
    Apr 18 05:59:20.808: INFO: Waiting up to 5m0s for pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0" in namespace "secrets-4431" to be "Succeeded or Failed"
    Apr 18 05:59:20.812: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.63243ms
    Apr 18 05:59:22.816: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007802396s
    Apr 18 05:59:24.816: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008369128s
    Apr 18 05:59:26.899: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.091333138s
    Apr 18 05:59:28.816: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.007986771s
    STEP: Saw pod success 04/18/23 05:59:28.816
    Apr 18 05:59:28.816: INFO: Pod "pod-secrets-693c599b-be17-420b-a548-269d074968d0" satisfied condition "Succeeded or Failed"
    Apr 18 05:59:28.831: INFO: Trying to get logs from node apps-208 pod pod-secrets-693c599b-be17-420b-a548-269d074968d0 container secret-volume-test: <nil>
    STEP: delete the pod 04/18/23 05:59:28.853
    Apr 18 05:59:28.912: INFO: Waiting for pod pod-secrets-693c599b-be17-420b-a548-269d074968d0 to disappear
    Apr 18 05:59:29.049: INFO: Pod pod-secrets-693c599b-be17-420b-a548-269d074968d0 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 05:59:29.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4431" for this suite. 04/18/23 05:59:29.054
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:59:29.095
Apr 18 05:59:29.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 05:59:29.096
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:59:29.215
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:59:29.218
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5155 04/18/23 05:59:29.22
STEP: changing the ExternalName service to type=ClusterIP 04/18/23 05:59:29.265
STEP: creating replication controller externalname-service in namespace services-5155 04/18/23 05:59:29.401
I0418 05:59:29.516794      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5155, replica count: 2
I0418 05:59:32.568262      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 05:59:35.569314      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 05:59:35.569: INFO: Creating new exec pod
Apr 18 05:59:35.618: INFO: Waiting up to 5m0s for pod "execpodgl5j8" in namespace "services-5155" to be "running"
Apr 18 05:59:35.677: INFO: Pod "execpodgl5j8": Phase="Pending", Reason="", readiness=false. Elapsed: 58.969618ms
Apr 18 05:59:37.682: INFO: Pod "execpodgl5j8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063152599s
Apr 18 05:59:39.682: INFO: Pod "execpodgl5j8": Phase="Running", Reason="", readiness=true. Elapsed: 4.063429325s
Apr 18 05:59:39.682: INFO: Pod "execpodgl5j8" satisfied condition "running"
Apr 18 05:59:40.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5155 exec execpodgl5j8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 18 05:59:40.915: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 18 05:59:40.915: INFO: stdout: "externalname-service-whs67"
Apr 18 05:59:40.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5155 exec execpodgl5j8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.9.188 80'
Apr 18 05:59:41.070: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.9.188 80\nConnection to 10.96.9.188 80 port [tcp/http] succeeded!\n"
Apr 18 05:59:41.070: INFO: stdout: "externalname-service-qwxq2"
Apr 18 05:59:41.070: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 05:59:41.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5155" for this suite. 04/18/23 05:59:41.329
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":331,"skipped":6032,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.255 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:59:29.095
    Apr 18 05:59:29.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 05:59:29.096
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:59:29.215
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:59:29.218
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-5155 04/18/23 05:59:29.22
    STEP: changing the ExternalName service to type=ClusterIP 04/18/23 05:59:29.265
    STEP: creating replication controller externalname-service in namespace services-5155 04/18/23 05:59:29.401
    I0418 05:59:29.516794      22 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5155, replica count: 2
    I0418 05:59:32.568262      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 05:59:35.569314      22 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 05:59:35.569: INFO: Creating new exec pod
    Apr 18 05:59:35.618: INFO: Waiting up to 5m0s for pod "execpodgl5j8" in namespace "services-5155" to be "running"
    Apr 18 05:59:35.677: INFO: Pod "execpodgl5j8": Phase="Pending", Reason="", readiness=false. Elapsed: 58.969618ms
    Apr 18 05:59:37.682: INFO: Pod "execpodgl5j8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063152599s
    Apr 18 05:59:39.682: INFO: Pod "execpodgl5j8": Phase="Running", Reason="", readiness=true. Elapsed: 4.063429325s
    Apr 18 05:59:39.682: INFO: Pod "execpodgl5j8" satisfied condition "running"
    Apr 18 05:59:40.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5155 exec execpodgl5j8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 18 05:59:40.915: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 18 05:59:40.915: INFO: stdout: "externalname-service-whs67"
    Apr 18 05:59:40.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-5155 exec execpodgl5j8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.9.188 80'
    Apr 18 05:59:41.070: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.9.188 80\nConnection to 10.96.9.188 80 port [tcp/http] succeeded!\n"
    Apr 18 05:59:41.070: INFO: stdout: "externalname-service-qwxq2"
    Apr 18 05:59:41.070: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 05:59:41.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5155" for this suite. 04/18/23 05:59:41.329
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 05:59:41.35
Apr 18 05:59:41.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-probe 04/18/23 05:59:41.351
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:59:41.588
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:59:41.592
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f in namespace container-probe-3481 04/18/23 05:59:41.594
Apr 18 05:59:41.678: INFO: Waiting up to 5m0s for pod "test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f" in namespace "container-probe-3481" to be "not pending"
Apr 18 05:59:41.682: INFO: Pod "test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.179243ms
Apr 18 05:59:43.689: INFO: Pod "test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010397106s
Apr 18 05:59:45.687: INFO: Pod "test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f": Phase="Running", Reason="", readiness=true. Elapsed: 4.008133656s
Apr 18 05:59:45.687: INFO: Pod "test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f" satisfied condition "not pending"
Apr 18 05:59:45.687: INFO: Started pod test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f in namespace container-probe-3481
STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 05:59:45.687
Apr 18 05:59:45.689: INFO: Initial restart count of pod test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f is 0
STEP: deleting the pod 04/18/23 06:03:46.708
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 06:03:46.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3481" for this suite. 04/18/23 06:03:46.926
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":332,"skipped":6032,"failed":0}
------------------------------
â€¢ [SLOW TEST] [245.600 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 05:59:41.35
    Apr 18 05:59:41.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-probe 04/18/23 05:59:41.351
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 05:59:41.588
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 05:59:41.592
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f in namespace container-probe-3481 04/18/23 05:59:41.594
    Apr 18 05:59:41.678: INFO: Waiting up to 5m0s for pod "test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f" in namespace "container-probe-3481" to be "not pending"
    Apr 18 05:59:41.682: INFO: Pod "test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.179243ms
    Apr 18 05:59:43.689: INFO: Pod "test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010397106s
    Apr 18 05:59:45.687: INFO: Pod "test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f": Phase="Running", Reason="", readiness=true. Elapsed: 4.008133656s
    Apr 18 05:59:45.687: INFO: Pod "test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f" satisfied condition "not pending"
    Apr 18 05:59:45.687: INFO: Started pod test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f in namespace container-probe-3481
    STEP: checking the pod's current state and verifying that restartCount is present 04/18/23 05:59:45.687
    Apr 18 05:59:45.689: INFO: Initial restart count of pod test-webserver-4b100d5b-f3bd-4bfc-b931-297fcf165d5f is 0
    STEP: deleting the pod 04/18/23 06:03:46.708
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 06:03:46.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3481" for this suite. 04/18/23 06:03:46.926
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:03:46.951
Apr 18 06:03:46.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 06:03:46.952
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:03:47.252
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:03:47.256
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 04/18/23 06:03:47.258
Apr 18 06:03:47.501: INFO: Waiting up to 5m0s for pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018" in namespace "downward-api-4370" to be "Succeeded or Failed"
Apr 18 06:03:47.510: INFO: Pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018": Phase="Pending", Reason="", readiness=false. Elapsed: 9.321424ms
Apr 18 06:03:49.514: INFO: Pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013327881s
Apr 18 06:03:51.518: INFO: Pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016933355s
Apr 18 06:03:53.515: INFO: Pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01450421s
STEP: Saw pod success 04/18/23 06:03:53.515
Apr 18 06:03:53.515: INFO: Pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018" satisfied condition "Succeeded or Failed"
Apr 18 06:03:53.518: INFO: Trying to get logs from node apps-208 pod downward-api-edfabbbd-8821-4311-98b0-cab1f946e018 container dapi-container: <nil>
STEP: delete the pod 04/18/23 06:03:53.532
Apr 18 06:03:53.663: INFO: Waiting for pod downward-api-edfabbbd-8821-4311-98b0-cab1f946e018 to disappear
Apr 18 06:03:53.671: INFO: Pod downward-api-edfabbbd-8821-4311-98b0-cab1f946e018 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 18 06:03:53.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4370" for this suite. 04/18/23 06:03:53.676
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":333,"skipped":6047,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.749 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:03:46.951
    Apr 18 06:03:46.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 06:03:46.952
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:03:47.252
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:03:47.256
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 04/18/23 06:03:47.258
    Apr 18 06:03:47.501: INFO: Waiting up to 5m0s for pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018" in namespace "downward-api-4370" to be "Succeeded or Failed"
    Apr 18 06:03:47.510: INFO: Pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018": Phase="Pending", Reason="", readiness=false. Elapsed: 9.321424ms
    Apr 18 06:03:49.514: INFO: Pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013327881s
    Apr 18 06:03:51.518: INFO: Pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016933355s
    Apr 18 06:03:53.515: INFO: Pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01450421s
    STEP: Saw pod success 04/18/23 06:03:53.515
    Apr 18 06:03:53.515: INFO: Pod "downward-api-edfabbbd-8821-4311-98b0-cab1f946e018" satisfied condition "Succeeded or Failed"
    Apr 18 06:03:53.518: INFO: Trying to get logs from node apps-208 pod downward-api-edfabbbd-8821-4311-98b0-cab1f946e018 container dapi-container: <nil>
    STEP: delete the pod 04/18/23 06:03:53.532
    Apr 18 06:03:53.663: INFO: Waiting for pod downward-api-edfabbbd-8821-4311-98b0-cab1f946e018 to disappear
    Apr 18 06:03:53.671: INFO: Pod downward-api-edfabbbd-8821-4311-98b0-cab1f946e018 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 18 06:03:53.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4370" for this suite. 04/18/23 06:03:53.676
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:03:53.7
Apr 18 06:03:53.701: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 06:03:53.701
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:03:53.736
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:03:53.738
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Apr 18 06:03:53.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: creating the pod 04/18/23 06:03:53.741
STEP: submitting the pod to kubernetes 04/18/23 06:03:53.741
Apr 18 06:03:53.768: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45" in namespace "pods-7353" to be "running and ready"
Apr 18 06:03:53.810: INFO: Pod "pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45": Phase="Pending", Reason="", readiness=false. Elapsed: 42.417848ms
Apr 18 06:03:53.810: INFO: The phase of Pod pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 06:03:55.844: INFO: Pod "pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076454846s
Apr 18 06:03:55.845: INFO: The phase of Pod pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 06:03:57.814: INFO: Pod "pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45": Phase="Running", Reason="", readiness=true. Elapsed: 4.046339332s
Apr 18 06:03:57.814: INFO: The phase of Pod pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45 is Running (Ready = true)
Apr 18 06:03:57.814: INFO: Pod "pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 06:03:57.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7353" for this suite. 04/18/23 06:03:57.839
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":334,"skipped":6051,"failed":0}
------------------------------
â€¢ [4.167 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:03:53.7
    Apr 18 06:03:53.701: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 06:03:53.701
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:03:53.736
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:03:53.738
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Apr 18 06:03:53.741: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: creating the pod 04/18/23 06:03:53.741
    STEP: submitting the pod to kubernetes 04/18/23 06:03:53.741
    Apr 18 06:03:53.768: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45" in namespace "pods-7353" to be "running and ready"
    Apr 18 06:03:53.810: INFO: Pod "pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45": Phase="Pending", Reason="", readiness=false. Elapsed: 42.417848ms
    Apr 18 06:03:53.810: INFO: The phase of Pod pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 06:03:55.844: INFO: Pod "pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076454846s
    Apr 18 06:03:55.845: INFO: The phase of Pod pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 06:03:57.814: INFO: Pod "pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45": Phase="Running", Reason="", readiness=true. Elapsed: 4.046339332s
    Apr 18 06:03:57.814: INFO: The phase of Pod pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45 is Running (Ready = true)
    Apr 18 06:03:57.814: INFO: Pod "pod-logs-websocket-8d345700-138a-40a9-a092-5dd36ced8b45" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 06:03:57.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7353" for this suite. 04/18/23 06:03:57.839
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:03:57.869
Apr 18 06:03:57.869: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename dns 04/18/23 06:03:57.87
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:03:58.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:03:58.032
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 04/18/23 06:03:58.035
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local;sleep 1; done
 04/18/23 06:03:58.051
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local;sleep 1; done
 04/18/23 06:03:58.051
STEP: creating a pod to probe DNS 04/18/23 06:03:58.051
STEP: submitting the pod to kubernetes 04/18/23 06:03:58.051
Apr 18 06:03:58.226: INFO: Waiting up to 15m0s for pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e" in namespace "dns-7140" to be "running"
Apr 18 06:03:58.317: INFO: Pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e": Phase="Pending", Reason="", readiness=false. Elapsed: 91.018933ms
Apr 18 06:04:00.322: INFO: Pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095506287s
Apr 18 06:04:02.322: INFO: Pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.095596224s
Apr 18 06:04:04.321: INFO: Pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e": Phase="Running", Reason="", readiness=true. Elapsed: 6.095049463s
Apr 18 06:04:04.321: INFO: Pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e" satisfied condition "running"
STEP: retrieving the pod 04/18/23 06:04:04.321
STEP: looking for the results for each expected name from probers 04/18/23 06:04:04.351
Apr 18 06:04:04.355: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:04.369: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:04.373: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:04.376: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:04.379: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:04.383: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:04.386: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:04.390: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:04.390: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

Apr 18 06:04:09.395: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:09.398: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:09.401: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:09.404: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:09.407: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:09.410: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:09.413: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:09.416: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:09.416: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

Apr 18 06:04:14.509: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:14.529: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:14.533: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:14.536: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:14.540: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:14.543: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:14.547: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:14.550: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:14.550: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

Apr 18 06:04:19.395: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:19.399: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:19.402: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:19.405: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:19.408: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:19.412: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:19.414: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:19.418: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:19.418: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

Apr 18 06:04:24.398: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:24.426: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:24.428: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:24.468: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:24.472: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:24.475: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:24.478: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:24.481: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:24.481: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

Apr 18 06:04:29.397: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:29.401: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:29.405: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:29.408: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:29.412: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:29.415: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:29.418: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:29.421: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
Apr 18 06:04:29.421: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

Apr 18 06:04:34.514: INFO: DNS probes using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e succeeded

STEP: deleting the pod 04/18/23 06:04:34.514
STEP: deleting the test headless service 04/18/23 06:04:34.838
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 18 06:04:35.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7140" for this suite. 04/18/23 06:04:35.04
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":335,"skipped":6080,"failed":0}
------------------------------
â€¢ [SLOW TEST] [37.185 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:03:57.869
    Apr 18 06:03:57.869: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename dns 04/18/23 06:03:57.87
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:03:58.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:03:58.032
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 04/18/23 06:03:58.035
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local;sleep 1; done
     04/18/23 06:03:58.051
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7140.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local;sleep 1; done
     04/18/23 06:03:58.051
    STEP: creating a pod to probe DNS 04/18/23 06:03:58.051
    STEP: submitting the pod to kubernetes 04/18/23 06:03:58.051
    Apr 18 06:03:58.226: INFO: Waiting up to 15m0s for pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e" in namespace "dns-7140" to be "running"
    Apr 18 06:03:58.317: INFO: Pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e": Phase="Pending", Reason="", readiness=false. Elapsed: 91.018933ms
    Apr 18 06:04:00.322: INFO: Pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095506287s
    Apr 18 06:04:02.322: INFO: Pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.095596224s
    Apr 18 06:04:04.321: INFO: Pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e": Phase="Running", Reason="", readiness=true. Elapsed: 6.095049463s
    Apr 18 06:04:04.321: INFO: Pod "dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e" satisfied condition "running"
    STEP: retrieving the pod 04/18/23 06:04:04.321
    STEP: looking for the results for each expected name from probers 04/18/23 06:04:04.351
    Apr 18 06:04:04.355: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:04.369: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:04.373: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:04.376: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:04.379: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:04.383: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:04.386: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:04.390: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:04.390: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

    Apr 18 06:04:09.395: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:09.398: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:09.401: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:09.404: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:09.407: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:09.410: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:09.413: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:09.416: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:09.416: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

    Apr 18 06:04:14.509: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:14.529: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:14.533: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:14.536: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:14.540: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:14.543: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:14.547: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:14.550: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:14.550: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

    Apr 18 06:04:19.395: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:19.399: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:19.402: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:19.405: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:19.408: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:19.412: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:19.414: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:19.418: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:19.418: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

    Apr 18 06:04:24.398: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:24.426: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:24.428: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:24.468: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:24.472: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:24.475: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:24.478: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:24.481: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:24.481: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

    Apr 18 06:04:29.397: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:29.401: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:29.405: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:29.408: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:29.412: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:29.415: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:29.418: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:29.421: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local from pod dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e: the server could not find the requested resource (get pods dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e)
    Apr 18 06:04:29.421: INFO: Lookups using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7140.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7140.svc.cluster.local jessie_udp@dns-test-service-2.dns-7140.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7140.svc.cluster.local]

    Apr 18 06:04:34.514: INFO: DNS probes using dns-7140/dns-test-abacd1b2-3e8a-4f3e-9a01-66c30a91635e succeeded

    STEP: deleting the pod 04/18/23 06:04:34.514
    STEP: deleting the test headless service 04/18/23 06:04:34.838
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 18 06:04:35.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7140" for this suite. 04/18/23 06:04:35.04
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:04:35.056
Apr 18 06:04:35.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubelet-test 04/18/23 06:04:35.057
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:04:35.18
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:04:35.182
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 18 06:04:43.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5746" for this suite. 04/18/23 06:04:43.233
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":336,"skipped":6116,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.259 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:04:35.056
    Apr 18 06:04:35.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubelet-test 04/18/23 06:04:35.057
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:04:35.18
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:04:35.182
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 18 06:04:43.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5746" for this suite. 04/18/23 06:04:43.233
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:04:43.315
Apr 18 06:04:43.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 06:04:43.317
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:04:43.473
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:04:43.476
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 04/18/23 06:04:43.479
STEP: fetching the ConfigMap 04/18/23 06:04:43.634
STEP: patching the ConfigMap 04/18/23 06:04:43.637
STEP: listing all ConfigMaps in all namespaces with a label selector 04/18/23 06:04:43.672
STEP: deleting the ConfigMap by collection with a label selector 04/18/23 06:04:43.692
STEP: listing all ConfigMaps in test namespace 04/18/23 06:04:43.722
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 06:04:43.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9520" for this suite. 04/18/23 06:04:43.777
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":337,"skipped":6125,"failed":0}
------------------------------
â€¢ [0.483 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:04:43.315
    Apr 18 06:04:43.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 06:04:43.317
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:04:43.473
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:04:43.476
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 04/18/23 06:04:43.479
    STEP: fetching the ConfigMap 04/18/23 06:04:43.634
    STEP: patching the ConfigMap 04/18/23 06:04:43.637
    STEP: listing all ConfigMaps in all namespaces with a label selector 04/18/23 06:04:43.672
    STEP: deleting the ConfigMap by collection with a label selector 04/18/23 06:04:43.692
    STEP: listing all ConfigMaps in test namespace 04/18/23 06:04:43.722
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 06:04:43.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9520" for this suite. 04/18/23 06:04:43.777
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:04:43.799
Apr 18 06:04:43.799: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename container-probe 04/18/23 06:04:43.8
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:04:43.947
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:04:43.95
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 18 06:05:44.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9147" for this suite. 04/18/23 06:05:44.167
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":338,"skipped":6135,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.379 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:04:43.799
    Apr 18 06:04:43.799: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename container-probe 04/18/23 06:04:43.8
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:04:43.947
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:04:43.95
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 18 06:05:44.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9147" for this suite. 04/18/23 06:05:44.167
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:05:44.179
Apr 18 06:05:44.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename discovery 04/18/23 06:05:44.18
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:05:44.332
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:05:44.335
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 04/18/23 06:05:44.338
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Apr 18 06:05:44.791: INFO: Checking APIGroup: apiregistration.k8s.io
Apr 18 06:05:44.793: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Apr 18 06:05:44.793: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Apr 18 06:05:44.793: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Apr 18 06:05:44.793: INFO: Checking APIGroup: apps
Apr 18 06:05:44.794: INFO: PreferredVersion.GroupVersion: apps/v1
Apr 18 06:05:44.794: INFO: Versions found [{apps/v1 v1}]
Apr 18 06:05:44.794: INFO: apps/v1 matches apps/v1
Apr 18 06:05:44.794: INFO: Checking APIGroup: events.k8s.io
Apr 18 06:05:44.795: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Apr 18 06:05:44.795: INFO: Versions found [{events.k8s.io/v1 v1}]
Apr 18 06:05:44.795: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Apr 18 06:05:44.795: INFO: Checking APIGroup: authentication.k8s.io
Apr 18 06:05:44.796: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Apr 18 06:05:44.796: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Apr 18 06:05:44.796: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Apr 18 06:05:44.796: INFO: Checking APIGroup: authorization.k8s.io
Apr 18 06:05:44.797: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Apr 18 06:05:44.797: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Apr 18 06:05:44.797: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Apr 18 06:05:44.797: INFO: Checking APIGroup: autoscaling
Apr 18 06:05:44.798: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Apr 18 06:05:44.798: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Apr 18 06:05:44.798: INFO: autoscaling/v2 matches autoscaling/v2
Apr 18 06:05:44.798: INFO: Checking APIGroup: batch
Apr 18 06:05:44.798: INFO: PreferredVersion.GroupVersion: batch/v1
Apr 18 06:05:44.798: INFO: Versions found [{batch/v1 v1}]
Apr 18 06:05:44.798: INFO: batch/v1 matches batch/v1
Apr 18 06:05:44.798: INFO: Checking APIGroup: certificates.k8s.io
Apr 18 06:05:44.799: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Apr 18 06:05:44.799: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Apr 18 06:05:44.799: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Apr 18 06:05:44.799: INFO: Checking APIGroup: networking.k8s.io
Apr 18 06:05:44.800: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Apr 18 06:05:44.800: INFO: Versions found [{networking.k8s.io/v1 v1}]
Apr 18 06:05:44.800: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Apr 18 06:05:44.800: INFO: Checking APIGroup: policy
Apr 18 06:05:44.801: INFO: PreferredVersion.GroupVersion: policy/v1
Apr 18 06:05:44.801: INFO: Versions found [{policy/v1 v1}]
Apr 18 06:05:44.801: INFO: policy/v1 matches policy/v1
Apr 18 06:05:44.801: INFO: Checking APIGroup: rbac.authorization.k8s.io
Apr 18 06:05:44.802: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Apr 18 06:05:44.802: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Apr 18 06:05:44.802: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Apr 18 06:05:44.802: INFO: Checking APIGroup: storage.k8s.io
Apr 18 06:05:44.803: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Apr 18 06:05:44.803: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Apr 18 06:05:44.803: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Apr 18 06:05:44.803: INFO: Checking APIGroup: admissionregistration.k8s.io
Apr 18 06:05:44.804: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Apr 18 06:05:44.804: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Apr 18 06:05:44.804: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Apr 18 06:05:44.804: INFO: Checking APIGroup: apiextensions.k8s.io
Apr 18 06:05:44.805: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Apr 18 06:05:44.805: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Apr 18 06:05:44.805: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Apr 18 06:05:44.805: INFO: Checking APIGroup: scheduling.k8s.io
Apr 18 06:05:44.806: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Apr 18 06:05:44.806: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Apr 18 06:05:44.806: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Apr 18 06:05:44.806: INFO: Checking APIGroup: coordination.k8s.io
Apr 18 06:05:44.807: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Apr 18 06:05:44.807: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Apr 18 06:05:44.807: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Apr 18 06:05:44.807: INFO: Checking APIGroup: node.k8s.io
Apr 18 06:05:44.808: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Apr 18 06:05:44.808: INFO: Versions found [{node.k8s.io/v1 v1}]
Apr 18 06:05:44.808: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Apr 18 06:05:44.808: INFO: Checking APIGroup: discovery.k8s.io
Apr 18 06:05:44.809: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Apr 18 06:05:44.809: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Apr 18 06:05:44.809: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Apr 18 06:05:44.809: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Apr 18 06:05:44.810: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Apr 18 06:05:44.810: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Apr 18 06:05:44.810: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Apr 18 06:05:44.810: INFO: Checking APIGroup: crd.projectcalico.org
Apr 18 06:05:44.811: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Apr 18 06:05:44.811: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Apr 18 06:05:44.811: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Apr 18 06:05:44.811: INFO: Checking APIGroup: monitoring.coreos.com
Apr 18 06:05:44.811: INFO: PreferredVersion.GroupVersion: monitoring.coreos.com/v1
Apr 18 06:05:44.811: INFO: Versions found [{monitoring.coreos.com/v1 v1} {monitoring.coreos.com/v1alpha1 v1alpha1}]
Apr 18 06:05:44.812: INFO: monitoring.coreos.com/v1 matches monitoring.coreos.com/v1
Apr 18 06:05:44.812: INFO: Checking APIGroup: security.istio.io
Apr 18 06:05:44.812: INFO: PreferredVersion.GroupVersion: security.istio.io/v1
Apr 18 06:05:44.812: INFO: Versions found [{security.istio.io/v1 v1} {security.istio.io/v1beta1 v1beta1}]
Apr 18 06:05:44.812: INFO: security.istio.io/v1 matches security.istio.io/v1
Apr 18 06:05:44.812: INFO: Checking APIGroup: extensions.istio.io
Apr 18 06:05:44.813: INFO: PreferredVersion.GroupVersion: extensions.istio.io/v1alpha1
Apr 18 06:05:44.813: INFO: Versions found [{extensions.istio.io/v1alpha1 v1alpha1}]
Apr 18 06:05:44.813: INFO: extensions.istio.io/v1alpha1 matches extensions.istio.io/v1alpha1
Apr 18 06:05:44.813: INFO: Checking APIGroup: install.istio.io
Apr 18 06:05:44.814: INFO: PreferredVersion.GroupVersion: install.istio.io/v1alpha1
Apr 18 06:05:44.814: INFO: Versions found [{install.istio.io/v1alpha1 v1alpha1}]
Apr 18 06:05:44.814: INFO: install.istio.io/v1alpha1 matches install.istio.io/v1alpha1
Apr 18 06:05:44.814: INFO: Checking APIGroup: kafka.strimzi.io
Apr 18 06:05:44.815: INFO: PreferredVersion.GroupVersion: kafka.strimzi.io/v1beta2
Apr 18 06:05:44.815: INFO: Versions found [{kafka.strimzi.io/v1beta2 v1beta2} {kafka.strimzi.io/v1beta1 v1beta1} {kafka.strimzi.io/v1alpha1 v1alpha1}]
Apr 18 06:05:44.815: INFO: kafka.strimzi.io/v1beta2 matches kafka.strimzi.io/v1beta2
Apr 18 06:05:44.815: INFO: Checking APIGroup: telemetry.istio.io
Apr 18 06:05:44.816: INFO: PreferredVersion.GroupVersion: telemetry.istio.io/v1alpha1
Apr 18 06:05:44.816: INFO: Versions found [{telemetry.istio.io/v1alpha1 v1alpha1}]
Apr 18 06:05:44.816: INFO: telemetry.istio.io/v1alpha1 matches telemetry.istio.io/v1alpha1
Apr 18 06:05:44.816: INFO: Checking APIGroup: networking.istio.io
Apr 18 06:05:44.817: INFO: PreferredVersion.GroupVersion: networking.istio.io/v1beta1
Apr 18 06:05:44.817: INFO: Versions found [{networking.istio.io/v1beta1 v1beta1} {networking.istio.io/v1alpha3 v1alpha3}]
Apr 18 06:05:44.817: INFO: networking.istio.io/v1beta1 matches networking.istio.io/v1beta1
Apr 18 06:05:44.817: INFO: Checking APIGroup: core.strimzi.io
Apr 18 06:05:44.818: INFO: PreferredVersion.GroupVersion: core.strimzi.io/v1beta2
Apr 18 06:05:44.818: INFO: Versions found [{core.strimzi.io/v1beta2 v1beta2}]
Apr 18 06:05:44.818: INFO: core.strimzi.io/v1beta2 matches core.strimzi.io/v1beta2
Apr 18 06:05:44.818: INFO: Checking APIGroup: metrics.k8s.io
Apr 18 06:05:44.819: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Apr 18 06:05:44.819: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Apr 18 06:05:44.819: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Apr 18 06:05:44.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-167" for this suite. 04/18/23 06:05:44.824
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":339,"skipped":6180,"failed":0}
------------------------------
â€¢ [0.665 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:05:44.179
    Apr 18 06:05:44.179: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename discovery 04/18/23 06:05:44.18
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:05:44.332
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:05:44.335
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 04/18/23 06:05:44.338
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Apr 18 06:05:44.791: INFO: Checking APIGroup: apiregistration.k8s.io
    Apr 18 06:05:44.793: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Apr 18 06:05:44.793: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Apr 18 06:05:44.793: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Apr 18 06:05:44.793: INFO: Checking APIGroup: apps
    Apr 18 06:05:44.794: INFO: PreferredVersion.GroupVersion: apps/v1
    Apr 18 06:05:44.794: INFO: Versions found [{apps/v1 v1}]
    Apr 18 06:05:44.794: INFO: apps/v1 matches apps/v1
    Apr 18 06:05:44.794: INFO: Checking APIGroup: events.k8s.io
    Apr 18 06:05:44.795: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Apr 18 06:05:44.795: INFO: Versions found [{events.k8s.io/v1 v1}]
    Apr 18 06:05:44.795: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Apr 18 06:05:44.795: INFO: Checking APIGroup: authentication.k8s.io
    Apr 18 06:05:44.796: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Apr 18 06:05:44.796: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Apr 18 06:05:44.796: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Apr 18 06:05:44.796: INFO: Checking APIGroup: authorization.k8s.io
    Apr 18 06:05:44.797: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Apr 18 06:05:44.797: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Apr 18 06:05:44.797: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Apr 18 06:05:44.797: INFO: Checking APIGroup: autoscaling
    Apr 18 06:05:44.798: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Apr 18 06:05:44.798: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Apr 18 06:05:44.798: INFO: autoscaling/v2 matches autoscaling/v2
    Apr 18 06:05:44.798: INFO: Checking APIGroup: batch
    Apr 18 06:05:44.798: INFO: PreferredVersion.GroupVersion: batch/v1
    Apr 18 06:05:44.798: INFO: Versions found [{batch/v1 v1}]
    Apr 18 06:05:44.798: INFO: batch/v1 matches batch/v1
    Apr 18 06:05:44.798: INFO: Checking APIGroup: certificates.k8s.io
    Apr 18 06:05:44.799: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Apr 18 06:05:44.799: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Apr 18 06:05:44.799: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Apr 18 06:05:44.799: INFO: Checking APIGroup: networking.k8s.io
    Apr 18 06:05:44.800: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Apr 18 06:05:44.800: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Apr 18 06:05:44.800: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Apr 18 06:05:44.800: INFO: Checking APIGroup: policy
    Apr 18 06:05:44.801: INFO: PreferredVersion.GroupVersion: policy/v1
    Apr 18 06:05:44.801: INFO: Versions found [{policy/v1 v1}]
    Apr 18 06:05:44.801: INFO: policy/v1 matches policy/v1
    Apr 18 06:05:44.801: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Apr 18 06:05:44.802: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Apr 18 06:05:44.802: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Apr 18 06:05:44.802: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Apr 18 06:05:44.802: INFO: Checking APIGroup: storage.k8s.io
    Apr 18 06:05:44.803: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Apr 18 06:05:44.803: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Apr 18 06:05:44.803: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Apr 18 06:05:44.803: INFO: Checking APIGroup: admissionregistration.k8s.io
    Apr 18 06:05:44.804: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Apr 18 06:05:44.804: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Apr 18 06:05:44.804: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Apr 18 06:05:44.804: INFO: Checking APIGroup: apiextensions.k8s.io
    Apr 18 06:05:44.805: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Apr 18 06:05:44.805: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Apr 18 06:05:44.805: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Apr 18 06:05:44.805: INFO: Checking APIGroup: scheduling.k8s.io
    Apr 18 06:05:44.806: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Apr 18 06:05:44.806: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Apr 18 06:05:44.806: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Apr 18 06:05:44.806: INFO: Checking APIGroup: coordination.k8s.io
    Apr 18 06:05:44.807: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Apr 18 06:05:44.807: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Apr 18 06:05:44.807: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Apr 18 06:05:44.807: INFO: Checking APIGroup: node.k8s.io
    Apr 18 06:05:44.808: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Apr 18 06:05:44.808: INFO: Versions found [{node.k8s.io/v1 v1}]
    Apr 18 06:05:44.808: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Apr 18 06:05:44.808: INFO: Checking APIGroup: discovery.k8s.io
    Apr 18 06:05:44.809: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Apr 18 06:05:44.809: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Apr 18 06:05:44.809: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Apr 18 06:05:44.809: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Apr 18 06:05:44.810: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Apr 18 06:05:44.810: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Apr 18 06:05:44.810: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Apr 18 06:05:44.810: INFO: Checking APIGroup: crd.projectcalico.org
    Apr 18 06:05:44.811: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Apr 18 06:05:44.811: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Apr 18 06:05:44.811: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Apr 18 06:05:44.811: INFO: Checking APIGroup: monitoring.coreos.com
    Apr 18 06:05:44.811: INFO: PreferredVersion.GroupVersion: monitoring.coreos.com/v1
    Apr 18 06:05:44.811: INFO: Versions found [{monitoring.coreos.com/v1 v1} {monitoring.coreos.com/v1alpha1 v1alpha1}]
    Apr 18 06:05:44.812: INFO: monitoring.coreos.com/v1 matches monitoring.coreos.com/v1
    Apr 18 06:05:44.812: INFO: Checking APIGroup: security.istio.io
    Apr 18 06:05:44.812: INFO: PreferredVersion.GroupVersion: security.istio.io/v1
    Apr 18 06:05:44.812: INFO: Versions found [{security.istio.io/v1 v1} {security.istio.io/v1beta1 v1beta1}]
    Apr 18 06:05:44.812: INFO: security.istio.io/v1 matches security.istio.io/v1
    Apr 18 06:05:44.812: INFO: Checking APIGroup: extensions.istio.io
    Apr 18 06:05:44.813: INFO: PreferredVersion.GroupVersion: extensions.istio.io/v1alpha1
    Apr 18 06:05:44.813: INFO: Versions found [{extensions.istio.io/v1alpha1 v1alpha1}]
    Apr 18 06:05:44.813: INFO: extensions.istio.io/v1alpha1 matches extensions.istio.io/v1alpha1
    Apr 18 06:05:44.813: INFO: Checking APIGroup: install.istio.io
    Apr 18 06:05:44.814: INFO: PreferredVersion.GroupVersion: install.istio.io/v1alpha1
    Apr 18 06:05:44.814: INFO: Versions found [{install.istio.io/v1alpha1 v1alpha1}]
    Apr 18 06:05:44.814: INFO: install.istio.io/v1alpha1 matches install.istio.io/v1alpha1
    Apr 18 06:05:44.814: INFO: Checking APIGroup: kafka.strimzi.io
    Apr 18 06:05:44.815: INFO: PreferredVersion.GroupVersion: kafka.strimzi.io/v1beta2
    Apr 18 06:05:44.815: INFO: Versions found [{kafka.strimzi.io/v1beta2 v1beta2} {kafka.strimzi.io/v1beta1 v1beta1} {kafka.strimzi.io/v1alpha1 v1alpha1}]
    Apr 18 06:05:44.815: INFO: kafka.strimzi.io/v1beta2 matches kafka.strimzi.io/v1beta2
    Apr 18 06:05:44.815: INFO: Checking APIGroup: telemetry.istio.io
    Apr 18 06:05:44.816: INFO: PreferredVersion.GroupVersion: telemetry.istio.io/v1alpha1
    Apr 18 06:05:44.816: INFO: Versions found [{telemetry.istio.io/v1alpha1 v1alpha1}]
    Apr 18 06:05:44.816: INFO: telemetry.istio.io/v1alpha1 matches telemetry.istio.io/v1alpha1
    Apr 18 06:05:44.816: INFO: Checking APIGroup: networking.istio.io
    Apr 18 06:05:44.817: INFO: PreferredVersion.GroupVersion: networking.istio.io/v1beta1
    Apr 18 06:05:44.817: INFO: Versions found [{networking.istio.io/v1beta1 v1beta1} {networking.istio.io/v1alpha3 v1alpha3}]
    Apr 18 06:05:44.817: INFO: networking.istio.io/v1beta1 matches networking.istio.io/v1beta1
    Apr 18 06:05:44.817: INFO: Checking APIGroup: core.strimzi.io
    Apr 18 06:05:44.818: INFO: PreferredVersion.GroupVersion: core.strimzi.io/v1beta2
    Apr 18 06:05:44.818: INFO: Versions found [{core.strimzi.io/v1beta2 v1beta2}]
    Apr 18 06:05:44.818: INFO: core.strimzi.io/v1beta2 matches core.strimzi.io/v1beta2
    Apr 18 06:05:44.818: INFO: Checking APIGroup: metrics.k8s.io
    Apr 18 06:05:44.819: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Apr 18 06:05:44.819: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Apr 18 06:05:44.819: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Apr 18 06:05:44.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-167" for this suite. 04/18/23 06:05:44.824
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:05:44.846
Apr 18 06:05:44.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename emptydir 04/18/23 06:05:44.847
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:05:44.887
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:05:44.889
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/18/23 06:05:44.976
Apr 18 06:05:44.987: INFO: Waiting up to 5m0s for pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba" in namespace "emptydir-8896" to be "Succeeded or Failed"
Apr 18 06:05:44.990: INFO: Pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.702035ms
Apr 18 06:05:46.995: INFO: Pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008081121s
Apr 18 06:05:49.028: INFO: Pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040407155s
Apr 18 06:05:50.995: INFO: Pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00824181s
STEP: Saw pod success 04/18/23 06:05:50.995
Apr 18 06:05:50.996: INFO: Pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba" satisfied condition "Succeeded or Failed"
Apr 18 06:05:51.000: INFO: Trying to get logs from node apps-208 pod pod-5fa3065a-c291-4c6c-a477-84598bca9bba container test-container: <nil>
STEP: delete the pod 04/18/23 06:05:51.012
Apr 18 06:05:51.105: INFO: Waiting for pod pod-5fa3065a-c291-4c6c-a477-84598bca9bba to disappear
Apr 18 06:05:51.126: INFO: Pod pod-5fa3065a-c291-4c6c-a477-84598bca9bba no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 18 06:05:51.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8896" for this suite. 04/18/23 06:05:51.131
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":340,"skipped":6217,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.298 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:05:44.846
    Apr 18 06:05:44.846: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename emptydir 04/18/23 06:05:44.847
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:05:44.887
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:05:44.889
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/18/23 06:05:44.976
    Apr 18 06:05:44.987: INFO: Waiting up to 5m0s for pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba" in namespace "emptydir-8896" to be "Succeeded or Failed"
    Apr 18 06:05:44.990: INFO: Pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.702035ms
    Apr 18 06:05:46.995: INFO: Pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008081121s
    Apr 18 06:05:49.028: INFO: Pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040407155s
    Apr 18 06:05:50.995: INFO: Pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00824181s
    STEP: Saw pod success 04/18/23 06:05:50.995
    Apr 18 06:05:50.996: INFO: Pod "pod-5fa3065a-c291-4c6c-a477-84598bca9bba" satisfied condition "Succeeded or Failed"
    Apr 18 06:05:51.000: INFO: Trying to get logs from node apps-208 pod pod-5fa3065a-c291-4c6c-a477-84598bca9bba container test-container: <nil>
    STEP: delete the pod 04/18/23 06:05:51.012
    Apr 18 06:05:51.105: INFO: Waiting for pod pod-5fa3065a-c291-4c6c-a477-84598bca9bba to disappear
    Apr 18 06:05:51.126: INFO: Pod pod-5fa3065a-c291-4c6c-a477-84598bca9bba no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 18 06:05:51.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8896" for this suite. 04/18/23 06:05:51.131
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:05:51.145
Apr 18 06:05:51.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename pods 04/18/23 06:05:51.146
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:05:51.261
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:05:51.263
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 04/18/23 06:05:51.266
STEP: submitting the pod to kubernetes 04/18/23 06:05:51.266
Apr 18 06:05:51.280: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0" in namespace "pods-8344" to be "running and ready"
Apr 18 06:05:51.282: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.266804ms
Apr 18 06:05:51.282: INFO: The phase of Pod pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 06:05:53.299: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019662167s
Apr 18 06:05:53.299: INFO: The phase of Pod pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 06:05:55.287: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Running", Reason="", readiness=true. Elapsed: 4.007481676s
Apr 18 06:05:55.287: INFO: The phase of Pod pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0 is Running (Ready = true)
Apr 18 06:05:55.287: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/18/23 06:05:55.29
STEP: updating the pod 04/18/23 06:05:55.299
Apr 18 06:05:55.871: INFO: Successfully updated pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0"
Apr 18 06:05:55.871: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0" in namespace "pods-8344" to be "terminated with reason DeadlineExceeded"
Apr 18 06:05:55.874: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Running", Reason="", readiness=true. Elapsed: 2.950623ms
Apr 18 06:05:57.878: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Running", Reason="", readiness=false. Elapsed: 2.006527617s
Apr 18 06:05:59.880: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.008291159s
Apr 18 06:05:59.880: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 18 06:05:59.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8344" for this suite. 04/18/23 06:05:59.885
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":341,"skipped":6240,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.766 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:05:51.145
    Apr 18 06:05:51.145: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename pods 04/18/23 06:05:51.146
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:05:51.261
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:05:51.263
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 04/18/23 06:05:51.266
    STEP: submitting the pod to kubernetes 04/18/23 06:05:51.266
    Apr 18 06:05:51.280: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0" in namespace "pods-8344" to be "running and ready"
    Apr 18 06:05:51.282: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.266804ms
    Apr 18 06:05:51.282: INFO: The phase of Pod pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 06:05:53.299: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019662167s
    Apr 18 06:05:53.299: INFO: The phase of Pod pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 06:05:55.287: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Running", Reason="", readiness=true. Elapsed: 4.007481676s
    Apr 18 06:05:55.287: INFO: The phase of Pod pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0 is Running (Ready = true)
    Apr 18 06:05:55.287: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/18/23 06:05:55.29
    STEP: updating the pod 04/18/23 06:05:55.299
    Apr 18 06:05:55.871: INFO: Successfully updated pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0"
    Apr 18 06:05:55.871: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0" in namespace "pods-8344" to be "terminated with reason DeadlineExceeded"
    Apr 18 06:05:55.874: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Running", Reason="", readiness=true. Elapsed: 2.950623ms
    Apr 18 06:05:57.878: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Running", Reason="", readiness=false. Elapsed: 2.006527617s
    Apr 18 06:05:59.880: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.008291159s
    Apr 18 06:05:59.880: INFO: Pod "pod-update-activedeadlineseconds-86692d53-ea3d-4a44-b46f-b0530842d2d0" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 18 06:05:59.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8344" for this suite. 04/18/23 06:05:59.885
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:05:59.913
Apr 18 06:05:59.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename daemonsets 04/18/23 06:05:59.914
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:05:59.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:05:59.964
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 04/18/23 06:06:00.093
STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 06:06:00.106
Apr 18 06:06:00.122: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:06:00.122: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 06:06:01.411: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:06:01.411: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 06:06:02.568: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:06:02.568: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 06:06:03.292: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:06:03.292: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 06:06:04.132: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:06:04.132: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 06:06:05.197: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 06:06:05.197: INFO: Node apps-209 is running 0 daemon pod, expected 1
Apr 18 06:06:06.200: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 06:06:06.200: INFO: Node apps-209 is running 0 daemon pod, expected 1
Apr 18 06:06:07.131: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 06:06:07.131: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 04/18/23 06:06:07.134
Apr 18 06:06:07.137: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 04/18/23 06:06:07.137
Apr 18 06:06:07.288: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 04/18/23 06:06:07.288
Apr 18 06:06:07.290: INFO: Observed &DaemonSet event: ADDED
Apr 18 06:06:07.290: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 06:06:07.290: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 06:06:07.290: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 06:06:07.291: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 06:06:07.291: INFO: Found daemon set daemon-set in namespace daemonsets-7911 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 18 06:06:07.291: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 04/18/23 06:06:07.291
STEP: watching for the daemon set status to be patched 04/18/23 06:06:07.446
Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: ADDED
Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 06:06:07.448: INFO: Observed daemon set daemon-set in namespace daemonsets-7911 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: MODIFIED
Apr 18 06:06:07.448: INFO: Found daemon set daemon-set in namespace daemonsets-7911 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Apr 18 06:06:07.448: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 06:06:07.569
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7911, will wait for the garbage collector to delete the pods 04/18/23 06:06:07.569
Apr 18 06:06:07.682: INFO: Deleting DaemonSet.extensions daemon-set took: 59.005124ms
Apr 18 06:06:07.983: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.281135ms
Apr 18 06:06:10.515: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:06:10.515: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 06:06:10.518: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4127489"},"items":null}

Apr 18 06:06:10.521: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4127489"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 06:06:10.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7911" for this suite. 04/18/23 06:06:10.575
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":342,"skipped":6268,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.702 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:05:59.913
    Apr 18 06:05:59.913: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename daemonsets 04/18/23 06:05:59.914
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:05:59.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:05:59.964
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 04/18/23 06:06:00.093
    STEP: Check that daemon pods launch on every node of the cluster. 04/18/23 06:06:00.106
    Apr 18 06:06:00.122: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:06:00.122: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 06:06:01.411: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:06:01.411: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 06:06:02.568: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:06:02.568: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 06:06:03.292: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:06:03.292: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 06:06:04.132: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:06:04.132: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 06:06:05.197: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 06:06:05.197: INFO: Node apps-209 is running 0 daemon pod, expected 1
    Apr 18 06:06:06.200: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 06:06:06.200: INFO: Node apps-209 is running 0 daemon pod, expected 1
    Apr 18 06:06:07.131: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 06:06:07.131: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 04/18/23 06:06:07.134
    Apr 18 06:06:07.137: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 04/18/23 06:06:07.137
    Apr 18 06:06:07.288: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 04/18/23 06:06:07.288
    Apr 18 06:06:07.290: INFO: Observed &DaemonSet event: ADDED
    Apr 18 06:06:07.290: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 06:06:07.290: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 06:06:07.290: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 06:06:07.291: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 06:06:07.291: INFO: Found daemon set daemon-set in namespace daemonsets-7911 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 18 06:06:07.291: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 04/18/23 06:06:07.291
    STEP: watching for the daemon set status to be patched 04/18/23 06:06:07.446
    Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: ADDED
    Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 06:06:07.448: INFO: Observed daemon set daemon-set in namespace daemonsets-7911 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 18 06:06:07.448: INFO: Observed &DaemonSet event: MODIFIED
    Apr 18 06:06:07.448: INFO: Found daemon set daemon-set in namespace daemonsets-7911 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Apr 18 06:06:07.448: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 06:06:07.569
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7911, will wait for the garbage collector to delete the pods 04/18/23 06:06:07.569
    Apr 18 06:06:07.682: INFO: Deleting DaemonSet.extensions daemon-set took: 59.005124ms
    Apr 18 06:06:07.983: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.281135ms
    Apr 18 06:06:10.515: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:06:10.515: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 06:06:10.518: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4127489"},"items":null}

    Apr 18 06:06:10.521: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4127489"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 06:06:10.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7911" for this suite. 04/18/23 06:06:10.575
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:06:10.616
Apr 18 06:06:10.616: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename endpointslice 04/18/23 06:06:10.617
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:06:10.728
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:06:10.731
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 04/18/23 06:06:17.294
STEP: referencing matching pods with named port 04/18/23 06:06:22.308
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/18/23 06:06:27.317
STEP: recreating EndpointSlices after they've been deleted 04/18/23 06:06:32.324
Apr 18 06:06:32.455: INFO: EndpointSlice for Service endpointslice-6004/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 18 06:06:42.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6004" for this suite. 04/18/23 06:06:42.49
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":343,"skipped":6275,"failed":0}
------------------------------
â€¢ [SLOW TEST] [31.900 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:06:10.616
    Apr 18 06:06:10.616: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename endpointslice 04/18/23 06:06:10.617
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:06:10.728
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:06:10.731
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 04/18/23 06:06:17.294
    STEP: referencing matching pods with named port 04/18/23 06:06:22.308
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/18/23 06:06:27.317
    STEP: recreating EndpointSlices after they've been deleted 04/18/23 06:06:32.324
    Apr 18 06:06:32.455: INFO: EndpointSlice for Service endpointslice-6004/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 18 06:06:42.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6004" for this suite. 04/18/23 06:06:42.49
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:06:42.517
Apr 18 06:06:42.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 06:06:42.518
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:06:42.665
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:06:42.668
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 06:06:42.716
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 06:06:43.324
STEP: Deploying the webhook pod 04/18/23 06:06:43.338
STEP: Wait for the deployment to be ready 04/18/23 06:06:43.484
Apr 18 06:06:43.822: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 18 06:06:45.916: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 6, 6, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 6, 43, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 6, 6, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 6, 43, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 06:06:47.945
STEP: Verifying the service has paired with the endpoint 04/18/23 06:06:48.135
Apr 18 06:06:49.136: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Apr 18 06:06:49.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/18/23 06:06:54.729
STEP: Creating a custom resource that should be denied by the webhook 04/18/23 06:06:54.803
STEP: Creating a custom resource whose deletion would be denied by the webhook 04/18/23 06:06:56.848
STEP: Updating the custom resource with disallowed data should be denied 04/18/23 06:06:56.877
STEP: Deleting the custom resource should be denied 04/18/23 06:06:56.9
STEP: Remove the offending key and value from the custom resource data 04/18/23 06:06:56.937
STEP: Deleting the updated custom resource should be successful 04/18/23 06:06:56.975
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 06:06:57.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7400" for this suite. 04/18/23 06:06:57.748
STEP: Destroying namespace "webhook-7400-markers" for this suite. 04/18/23 06:06:57.815
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":344,"skipped":6293,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.739 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:06:42.517
    Apr 18 06:06:42.517: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 06:06:42.518
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:06:42.665
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:06:42.668
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 06:06:42.716
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 06:06:43.324
    STEP: Deploying the webhook pod 04/18/23 06:06:43.338
    STEP: Wait for the deployment to be ready 04/18/23 06:06:43.484
    Apr 18 06:06:43.822: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 18 06:06:45.916: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 6, 6, 43, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 6, 43, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 6, 6, 44, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 6, 43, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 06:06:47.945
    STEP: Verifying the service has paired with the endpoint 04/18/23 06:06:48.135
    Apr 18 06:06:49.136: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Apr 18 06:06:49.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/18/23 06:06:54.729
    STEP: Creating a custom resource that should be denied by the webhook 04/18/23 06:06:54.803
    STEP: Creating a custom resource whose deletion would be denied by the webhook 04/18/23 06:06:56.848
    STEP: Updating the custom resource with disallowed data should be denied 04/18/23 06:06:56.877
    STEP: Deleting the custom resource should be denied 04/18/23 06:06:56.9
    STEP: Remove the offending key and value from the custom resource data 04/18/23 06:06:56.937
    STEP: Deleting the updated custom resource should be successful 04/18/23 06:06:56.975
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 06:06:57.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7400" for this suite. 04/18/23 06:06:57.748
    STEP: Destroying namespace "webhook-7400-markers" for this suite. 04/18/23 06:06:57.815
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:06:58.258
Apr 18 06:06:58.258: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename configmap 04/18/23 06:06:58.259
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:06:58.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:06:58.558
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-7f795048-326e-4b7a-a43c-3ba1fbf35b8e 04/18/23 06:06:58.677
STEP: Creating a pod to test consume configMaps 04/18/23 06:06:58.694
Apr 18 06:06:58.868: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f" in namespace "configmap-7288" to be "Succeeded or Failed"
Apr 18 06:06:58.871: INFO: Pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.183611ms
Apr 18 06:07:01.048: INFO: Pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.180686317s
Apr 18 06:07:02.887: INFO: Pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f": Phase="Running", Reason="", readiness=false. Elapsed: 4.019271934s
Apr 18 06:07:04.876: INFO: Pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008708798s
STEP: Saw pod success 04/18/23 06:07:04.876
Apr 18 06:07:04.876: INFO: Pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f" satisfied condition "Succeeded or Failed"
Apr 18 06:07:05.118: INFO: Trying to get logs from node apps-208 pod pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f container agnhost-container: <nil>
STEP: delete the pod 04/18/23 06:07:05.124
Apr 18 06:07:05.254: INFO: Waiting for pod pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f to disappear
Apr 18 06:07:05.257: INFO: Pod pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 18 06:07:05.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7288" for this suite. 04/18/23 06:07:05.261
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":345,"skipped":6315,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.054 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:06:58.258
    Apr 18 06:06:58.258: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename configmap 04/18/23 06:06:58.259
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:06:58.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:06:58.558
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-7f795048-326e-4b7a-a43c-3ba1fbf35b8e 04/18/23 06:06:58.677
    STEP: Creating a pod to test consume configMaps 04/18/23 06:06:58.694
    Apr 18 06:06:58.868: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f" in namespace "configmap-7288" to be "Succeeded or Failed"
    Apr 18 06:06:58.871: INFO: Pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.183611ms
    Apr 18 06:07:01.048: INFO: Pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.180686317s
    Apr 18 06:07:02.887: INFO: Pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f": Phase="Running", Reason="", readiness=false. Elapsed: 4.019271934s
    Apr 18 06:07:04.876: INFO: Pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008708798s
    STEP: Saw pod success 04/18/23 06:07:04.876
    Apr 18 06:07:04.876: INFO: Pod "pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f" satisfied condition "Succeeded or Failed"
    Apr 18 06:07:05.118: INFO: Trying to get logs from node apps-208 pod pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f container agnhost-container: <nil>
    STEP: delete the pod 04/18/23 06:07:05.124
    Apr 18 06:07:05.254: INFO: Waiting for pod pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f to disappear
    Apr 18 06:07:05.257: INFO: Pod pod-configmaps-8ec3c3f5-bbe4-44d5-a2c6-07f7faf14d8f no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 18 06:07:05.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7288" for this suite. 04/18/23 06:07:05.261
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:07:05.312
Apr 18 06:07:05.313: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename subpath 04/18/23 06:07:05.313
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:07:05.436
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:07:05.439
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/18/23 06:07:05.449
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-gv22 04/18/23 06:07:05.545
STEP: Creating a pod to test atomic-volume-subpath 04/18/23 06:07:05.545
Apr 18 06:07:05.612: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gv22" in namespace "subpath-3387" to be "Succeeded or Failed"
Apr 18 06:07:05.615: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.798271ms
Apr 18 06:07:07.663: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050672983s
Apr 18 06:07:09.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 4.008318562s
Apr 18 06:07:11.633: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 6.020862133s
Apr 18 06:07:13.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 8.008052275s
Apr 18 06:07:15.619: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 10.006604249s
Apr 18 06:07:17.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 12.007966977s
Apr 18 06:07:19.619: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 14.007117269s
Apr 18 06:07:21.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 16.008426273s
Apr 18 06:07:23.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 18.007537321s
Apr 18 06:07:25.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 20.0077469s
Apr 18 06:07:27.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 22.008339515s
Apr 18 06:07:29.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 24.008435522s
Apr 18 06:07:31.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=false. Elapsed: 26.007819069s
Apr 18 06:07:33.619: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.007340795s
STEP: Saw pod success 04/18/23 06:07:33.619
Apr 18 06:07:33.620: INFO: Pod "pod-subpath-test-configmap-gv22" satisfied condition "Succeeded or Failed"
Apr 18 06:07:33.622: INFO: Trying to get logs from node apps-208 pod pod-subpath-test-configmap-gv22 container test-container-subpath-configmap-gv22: <nil>
STEP: delete the pod 04/18/23 06:07:33.629
Apr 18 06:07:33.697: INFO: Waiting for pod pod-subpath-test-configmap-gv22 to disappear
Apr 18 06:07:33.703: INFO: Pod pod-subpath-test-configmap-gv22 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gv22 04/18/23 06:07:33.703
Apr 18 06:07:33.703: INFO: Deleting pod "pod-subpath-test-configmap-gv22" in namespace "subpath-3387"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 18 06:07:33.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3387" for this suite. 04/18/23 06:07:33.71
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":346,"skipped":6324,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.451 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:07:05.312
    Apr 18 06:07:05.313: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename subpath 04/18/23 06:07:05.313
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:07:05.436
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:07:05.439
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/18/23 06:07:05.449
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-gv22 04/18/23 06:07:05.545
    STEP: Creating a pod to test atomic-volume-subpath 04/18/23 06:07:05.545
    Apr 18 06:07:05.612: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gv22" in namespace "subpath-3387" to be "Succeeded or Failed"
    Apr 18 06:07:05.615: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.798271ms
    Apr 18 06:07:07.663: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050672983s
    Apr 18 06:07:09.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 4.008318562s
    Apr 18 06:07:11.633: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 6.020862133s
    Apr 18 06:07:13.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 8.008052275s
    Apr 18 06:07:15.619: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 10.006604249s
    Apr 18 06:07:17.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 12.007966977s
    Apr 18 06:07:19.619: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 14.007117269s
    Apr 18 06:07:21.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 16.008426273s
    Apr 18 06:07:23.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 18.007537321s
    Apr 18 06:07:25.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 20.0077469s
    Apr 18 06:07:27.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 22.008339515s
    Apr 18 06:07:29.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=true. Elapsed: 24.008435522s
    Apr 18 06:07:31.620: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Running", Reason="", readiness=false. Elapsed: 26.007819069s
    Apr 18 06:07:33.619: INFO: Pod "pod-subpath-test-configmap-gv22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.007340795s
    STEP: Saw pod success 04/18/23 06:07:33.619
    Apr 18 06:07:33.620: INFO: Pod "pod-subpath-test-configmap-gv22" satisfied condition "Succeeded or Failed"
    Apr 18 06:07:33.622: INFO: Trying to get logs from node apps-208 pod pod-subpath-test-configmap-gv22 container test-container-subpath-configmap-gv22: <nil>
    STEP: delete the pod 04/18/23 06:07:33.629
    Apr 18 06:07:33.697: INFO: Waiting for pod pod-subpath-test-configmap-gv22 to disappear
    Apr 18 06:07:33.703: INFO: Pod pod-subpath-test-configmap-gv22 no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-gv22 04/18/23 06:07:33.703
    Apr 18 06:07:33.703: INFO: Deleting pod "pod-subpath-test-configmap-gv22" in namespace "subpath-3387"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 18 06:07:33.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-3387" for this suite. 04/18/23 06:07:33.71
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:07:33.765
Apr 18 06:07:33.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 06:07:33.766
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:07:33.858
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:07:33.861
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 06:07:33.863
Apr 18 06:07:33.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-5606 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 18 06:07:34.010: INFO: stderr: ""
Apr 18 06:07:34.010: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 04/18/23 06:07:34.01
STEP: verifying the pod e2e-test-httpd-pod was created 04/18/23 06:07:39.062
Apr 18 06:07:39.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-5606 get pod e2e-test-httpd-pod -o json'
Apr 18 06:07:39.131: INFO: stderr: ""
Apr 18 06:07:39.131: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"2110617ce3c566d768651cfd55a5cbf9e0675aeba857b34c97e6839b5d2edfcd\",\n            \"cni.projectcalico.org/podIP\": \"172.16.125.32/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.16.125.32/32\"\n        },\n        \"creationTimestamp\": \"2023-04-18T06:07:33Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5606\",\n        \"resourceVersion\": \"4128024\",\n        \"uid\": \"cc2f73e1-4403-4212-b351-6aca40c984d6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-5dg65\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"apps-208\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 30\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 30\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-5dg65\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T06:07:34Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T06:07:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T06:07:36Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T06:07:34Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://69083c3dccd4d1e5601761c4f09cd741e5b2de3be800c4a87e486e9f358c131d\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-18T06:07:36Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.2.108\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.125.32\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.16.125.32\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-18T06:07:34Z\"\n    }\n}\n"
STEP: replace the image in the pod 04/18/23 06:07:39.132
Apr 18 06:07:39.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-5606 replace -f -'
Apr 18 06:07:41.433: INFO: stderr: ""
Apr 18 06:07:41.433: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 04/18/23 06:07:41.433
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Apr 18 06:07:41.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-5606 delete pods e2e-test-httpd-pod'
Apr 18 06:07:44.059: INFO: stderr: ""
Apr 18 06:07:44.059: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 06:07:44.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5606" for this suite. 04/18/23 06:07:44.064
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":347,"skipped":6338,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.322 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:07:33.765
    Apr 18 06:07:33.765: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 06:07:33.766
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:07:33.858
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:07:33.861
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/18/23 06:07:33.863
    Apr 18 06:07:33.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-5606 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 18 06:07:34.010: INFO: stderr: ""
    Apr 18 06:07:34.010: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 04/18/23 06:07:34.01
    STEP: verifying the pod e2e-test-httpd-pod was created 04/18/23 06:07:39.062
    Apr 18 06:07:39.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-5606 get pod e2e-test-httpd-pod -o json'
    Apr 18 06:07:39.131: INFO: stderr: ""
    Apr 18 06:07:39.131: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"2110617ce3c566d768651cfd55a5cbf9e0675aeba857b34c97e6839b5d2edfcd\",\n            \"cni.projectcalico.org/podIP\": \"172.16.125.32/32\",\n            \"cni.projectcalico.org/podIPs\": \"172.16.125.32/32\"\n        },\n        \"creationTimestamp\": \"2023-04-18T06:07:33Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5606\",\n        \"resourceVersion\": \"4128024\",\n        \"uid\": \"cc2f73e1-4403-4212-b351-6aca40c984d6\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-5dg65\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"apps-208\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 30\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 30\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-5dg65\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T06:07:34Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T06:07:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T06:07:36Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-04-18T06:07:34Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://69083c3dccd4d1e5601761c4f09cd741e5b2de3be800c4a87e486e9f358c131d\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-04-18T06:07:36Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.2.108\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.16.125.32\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.16.125.32\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-04-18T06:07:34Z\"\n    }\n}\n"
    STEP: replace the image in the pod 04/18/23 06:07:39.132
    Apr 18 06:07:39.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-5606 replace -f -'
    Apr 18 06:07:41.433: INFO: stderr: ""
    Apr 18 06:07:41.433: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 04/18/23 06:07:41.433
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Apr 18 06:07:41.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-5606 delete pods e2e-test-httpd-pod'
    Apr 18 06:07:44.059: INFO: stderr: ""
    Apr 18 06:07:44.059: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 06:07:44.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5606" for this suite. 04/18/23 06:07:44.064
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:07:44.087
Apr 18 06:07:44.087: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename downward-api 04/18/23 06:07:44.088
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:07:44.168
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:07:44.171
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 04/18/23 06:07:44.173
Apr 18 06:07:44.229: INFO: Waiting up to 5m0s for pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5" in namespace "downward-api-7253" to be "running and ready"
Apr 18 06:07:44.231: INFO: Pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.664822ms
Apr 18 06:07:44.231: INFO: The phase of Pod labelsupdate2e15efe1-fa35-4936-844a-3944857940b5 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 06:07:46.235: INFO: Pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006029991s
Apr 18 06:07:46.235: INFO: The phase of Pod labelsupdate2e15efe1-fa35-4936-844a-3944857940b5 is Pending, waiting for it to be Running (with Ready = true)
Apr 18 06:07:48.236: INFO: Pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5": Phase="Running", Reason="", readiness=true. Elapsed: 4.007404777s
Apr 18 06:07:48.236: INFO: The phase of Pod labelsupdate2e15efe1-fa35-4936-844a-3944857940b5 is Running (Ready = true)
Apr 18 06:07:48.236: INFO: Pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5" satisfied condition "running and ready"
Apr 18 06:07:48.842: INFO: Successfully updated pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 18 06:07:50.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7253" for this suite. 04/18/23 06:07:50.904
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":348,"skipped":6342,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.850 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:07:44.087
    Apr 18 06:07:44.087: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename downward-api 04/18/23 06:07:44.088
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:07:44.168
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:07:44.171
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 04/18/23 06:07:44.173
    Apr 18 06:07:44.229: INFO: Waiting up to 5m0s for pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5" in namespace "downward-api-7253" to be "running and ready"
    Apr 18 06:07:44.231: INFO: Pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.664822ms
    Apr 18 06:07:44.231: INFO: The phase of Pod labelsupdate2e15efe1-fa35-4936-844a-3944857940b5 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 06:07:46.235: INFO: Pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006029991s
    Apr 18 06:07:46.235: INFO: The phase of Pod labelsupdate2e15efe1-fa35-4936-844a-3944857940b5 is Pending, waiting for it to be Running (with Ready = true)
    Apr 18 06:07:48.236: INFO: Pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5": Phase="Running", Reason="", readiness=true. Elapsed: 4.007404777s
    Apr 18 06:07:48.236: INFO: The phase of Pod labelsupdate2e15efe1-fa35-4936-844a-3944857940b5 is Running (Ready = true)
    Apr 18 06:07:48.236: INFO: Pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5" satisfied condition "running and ready"
    Apr 18 06:07:48.842: INFO: Successfully updated pod "labelsupdate2e15efe1-fa35-4936-844a-3944857940b5"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 18 06:07:50.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7253" for this suite. 04/18/23 06:07:50.904
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:07:50.938
Apr 18 06:07:50.938: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename var-expansion 04/18/23 06:07:50.939
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:07:51.077
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:07:51.08
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Apr 18 06:07:51.107: INFO: Waiting up to 2m0s for pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01" in namespace "var-expansion-8788" to be "container 0 failed with reason CreateContainerConfigError"
Apr 18 06:07:51.170: INFO: Pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01": Phase="Pending", Reason="", readiness=false. Elapsed: 63.036693ms
Apr 18 06:07:53.179: INFO: Pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072198451s
Apr 18 06:07:55.189: INFO: Pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01": Phase="Pending", Reason="", readiness=false. Elapsed: 4.08155574s
Apr 18 06:07:55.189: INFO: Pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 18 06:07:55.189: INFO: Deleting pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01" in namespace "var-expansion-8788"
Apr 18 06:07:55.279: INFO: Wait up to 5m0s for pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 18 06:07:59.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8788" for this suite. 04/18/23 06:07:59.326
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":349,"skipped":6373,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.411 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:07:50.938
    Apr 18 06:07:50.938: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename var-expansion 04/18/23 06:07:50.939
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:07:51.077
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:07:51.08
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Apr 18 06:07:51.107: INFO: Waiting up to 2m0s for pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01" in namespace "var-expansion-8788" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 18 06:07:51.170: INFO: Pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01": Phase="Pending", Reason="", readiness=false. Elapsed: 63.036693ms
    Apr 18 06:07:53.179: INFO: Pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072198451s
    Apr 18 06:07:55.189: INFO: Pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01": Phase="Pending", Reason="", readiness=false. Elapsed: 4.08155574s
    Apr 18 06:07:55.189: INFO: Pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 18 06:07:55.189: INFO: Deleting pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01" in namespace "var-expansion-8788"
    Apr 18 06:07:55.279: INFO: Wait up to 5m0s for pod "var-expansion-2f650f7b-4598-432f-aea8-77469718ea01" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 18 06:07:59.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8788" for this suite. 04/18/23 06:07:59.326
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:07:59.35
Apr 18 06:07:59.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename security-context-test 04/18/23 06:07:59.351
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:07:59.446
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:07:59.449
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Apr 18 06:07:59.491: INFO: Waiting up to 5m0s for pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180" in namespace "security-context-test-1732" to be "Succeeded or Failed"
Apr 18 06:07:59.494: INFO: Pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723766ms
Apr 18 06:08:01.557: INFO: Pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065817097s
Apr 18 06:08:03.498: INFO: Pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180": Phase="Running", Reason="", readiness=false. Elapsed: 4.006966617s
Apr 18 06:08:05.499: INFO: Pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007210874s
Apr 18 06:08:05.499: INFO: Pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 06:08:05.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1732" for this suite. 04/18/23 06:08:05.503
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":350,"skipped":6388,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.224 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:07:59.35
    Apr 18 06:07:59.350: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename security-context-test 04/18/23 06:07:59.351
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:07:59.446
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:07:59.449
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Apr 18 06:07:59.491: INFO: Waiting up to 5m0s for pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180" in namespace "security-context-test-1732" to be "Succeeded or Failed"
    Apr 18 06:07:59.494: INFO: Pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723766ms
    Apr 18 06:08:01.557: INFO: Pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065817097s
    Apr 18 06:08:03.498: INFO: Pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180": Phase="Running", Reason="", readiness=false. Elapsed: 4.006966617s
    Apr 18 06:08:05.499: INFO: Pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.007210874s
    Apr 18 06:08:05.499: INFO: Pod "busybox-user-65534-3d2fb1a1-7d50-40d2-aaa1-ac35a5c7c180" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 06:08:05.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-1732" for this suite. 04/18/23 06:08:05.503
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:08:05.576
Apr 18 06:08:05.576: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 06:08:05.577
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:05.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:05.624
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 06:08:05.657
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 06:08:06.337
STEP: Deploying the webhook pod 04/18/23 06:08:06.371
STEP: Wait for the deployment to be ready 04/18/23 06:08:06.477
Apr 18 06:08:06.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5d85dd8cdb\""}}, CollisionCount:(*int32)(nil)}
Apr 18 06:08:08.647: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 06:08:10.647
STEP: Verifying the service has paired with the endpoint 04/18/23 06:08:10.694
Apr 18 06:08:11.695: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 04/18/23 06:08:11.738
STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/18/23 06:08:11.825
STEP: Creating a configMap that should not be mutated 04/18/23 06:08:11.879
STEP: Patching a mutating webhook configuration's rules to include the create operation 04/18/23 06:08:12.234
STEP: Creating a configMap that should be mutated 04/18/23 06:08:12.255
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 06:08:12.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-964" for this suite. 04/18/23 06:08:12.59
STEP: Destroying namespace "webhook-964-markers" for this suite. 04/18/23 06:08:12.609
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":351,"skipped":6416,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.236 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:08:05.576
    Apr 18 06:08:05.576: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 06:08:05.577
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:05.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:05.624
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 06:08:05.657
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 06:08:06.337
    STEP: Deploying the webhook pod 04/18/23 06:08:06.371
    STEP: Wait for the deployment to be ready 04/18/23 06:08:06.477
    Apr 18 06:08:06.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-5d85dd8cdb\""}}, CollisionCount:(*int32)(nil)}
    Apr 18 06:08:08.647: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 8, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 06:08:10.647
    STEP: Verifying the service has paired with the endpoint 04/18/23 06:08:10.694
    Apr 18 06:08:11.695: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 04/18/23 06:08:11.738
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/18/23 06:08:11.825
    STEP: Creating a configMap that should not be mutated 04/18/23 06:08:11.879
    STEP: Patching a mutating webhook configuration's rules to include the create operation 04/18/23 06:08:12.234
    STEP: Creating a configMap that should be mutated 04/18/23 06:08:12.255
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 06:08:12.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-964" for this suite. 04/18/23 06:08:12.59
    STEP: Destroying namespace "webhook-964-markers" for this suite. 04/18/23 06:08:12.609
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:08:12.812
Apr 18 06:08:12.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename secrets 04/18/23 06:08:12.813
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:12.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:12.941
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-2197/secret-test-42f4359c-6b8a-4ec2-9b9d-756e4a419634 04/18/23 06:08:12.943
STEP: Creating a pod to test consume secrets 04/18/23 06:08:12.961
Apr 18 06:08:12.981: INFO: Waiting up to 5m0s for pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2" in namespace "secrets-2197" to be "Succeeded or Failed"
Apr 18 06:08:13.030: INFO: Pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2": Phase="Pending", Reason="", readiness=false. Elapsed: 49.658289ms
Apr 18 06:08:15.034: INFO: Pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053486853s
Apr 18 06:08:17.036: INFO: Pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055503553s
Apr 18 06:08:19.037: INFO: Pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.056601765s
STEP: Saw pod success 04/18/23 06:08:19.037
Apr 18 06:08:19.037: INFO: Pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2" satisfied condition "Succeeded or Failed"
Apr 18 06:08:19.054: INFO: Trying to get logs from node apps-208 pod pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2 container env-test: <nil>
STEP: delete the pod 04/18/23 06:08:19.06
Apr 18 06:08:19.274: INFO: Waiting for pod pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2 to disappear
Apr 18 06:08:19.296: INFO: Pod pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 18 06:08:19.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2197" for this suite. 04/18/23 06:08:19.301
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":352,"skipped":6417,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.515 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:08:12.812
    Apr 18 06:08:12.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename secrets 04/18/23 06:08:12.813
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:12.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:12.941
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-2197/secret-test-42f4359c-6b8a-4ec2-9b9d-756e4a419634 04/18/23 06:08:12.943
    STEP: Creating a pod to test consume secrets 04/18/23 06:08:12.961
    Apr 18 06:08:12.981: INFO: Waiting up to 5m0s for pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2" in namespace "secrets-2197" to be "Succeeded or Failed"
    Apr 18 06:08:13.030: INFO: Pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2": Phase="Pending", Reason="", readiness=false. Elapsed: 49.658289ms
    Apr 18 06:08:15.034: INFO: Pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053486853s
    Apr 18 06:08:17.036: INFO: Pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055503553s
    Apr 18 06:08:19.037: INFO: Pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.056601765s
    STEP: Saw pod success 04/18/23 06:08:19.037
    Apr 18 06:08:19.037: INFO: Pod "pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2" satisfied condition "Succeeded or Failed"
    Apr 18 06:08:19.054: INFO: Trying to get logs from node apps-208 pod pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2 container env-test: <nil>
    STEP: delete the pod 04/18/23 06:08:19.06
    Apr 18 06:08:19.274: INFO: Waiting for pod pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2 to disappear
    Apr 18 06:08:19.296: INFO: Pod pod-configmaps-bb59bdb2-3342-4125-afda-bf903f1488b2 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 18 06:08:19.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2197" for this suite. 04/18/23 06:08:19.301
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:08:19.327
Apr 18 06:08:19.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename events 04/18/23 06:08:19.328
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:19.378
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:19.381
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 04/18/23 06:08:19.449
STEP: get a list of Events with a label in the current namespace 04/18/23 06:08:19.513
STEP: delete a list of events 04/18/23 06:08:19.516
Apr 18 06:08:19.516: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/18/23 06:08:19.629
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Apr 18 06:08:19.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4194" for this suite. 04/18/23 06:08:19.636
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":353,"skipped":6418,"failed":0}
------------------------------
â€¢ [0.318 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:08:19.327
    Apr 18 06:08:19.327: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename events 04/18/23 06:08:19.328
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:19.378
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:19.381
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 04/18/23 06:08:19.449
    STEP: get a list of Events with a label in the current namespace 04/18/23 06:08:19.513
    STEP: delete a list of events 04/18/23 06:08:19.516
    Apr 18 06:08:19.516: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/18/23 06:08:19.629
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Apr 18 06:08:19.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-4194" for this suite. 04/18/23 06:08:19.636
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:08:19.646
Apr 18 06:08:19.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 06:08:19.647
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:19.737
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:19.74
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 06:08:19.793
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 06:08:20.346
STEP: Deploying the webhook pod 04/18/23 06:08:20.395
STEP: Wait for the deployment to be ready 04/18/23 06:08:20.468
Apr 18 06:08:20.474: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Apr 18 06:08:22.547: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 6, 8, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 8, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 6, 8, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 8, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 06:08:24.563
STEP: Verifying the service has paired with the endpoint 04/18/23 06:08:24.663
Apr 18 06:08:25.664: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 04/18/23 06:08:25.667
STEP: create a pod 04/18/23 06:08:25.731
Apr 18 06:08:25.756: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-4094" to be "running"
Apr 18 06:08:25.758: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.401409ms
Apr 18 06:08:27.764: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0076189s
Apr 18 06:08:29.799: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.042633974s
Apr 18 06:08:29.799: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 04/18/23 06:08:29.799
Apr 18 06:08:29.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=webhook-4094 attach --namespace=webhook-4094 to-be-attached-pod -i -c=container1'
Apr 18 06:08:29.888: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 06:08:29.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4094" for this suite. 04/18/23 06:08:29.918
STEP: Destroying namespace "webhook-4094-markers" for this suite. 04/18/23 06:08:29.929
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":354,"skipped":6431,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.617 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:08:19.646
    Apr 18 06:08:19.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 06:08:19.647
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:19.737
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:19.74
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 06:08:19.793
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 06:08:20.346
    STEP: Deploying the webhook pod 04/18/23 06:08:20.395
    STEP: Wait for the deployment to be ready 04/18/23 06:08:20.468
    Apr 18 06:08:20.474: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Apr 18 06:08:22.547: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 6, 8, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 8, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 6, 8, 20, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 8, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 06:08:24.563
    STEP: Verifying the service has paired with the endpoint 04/18/23 06:08:24.663
    Apr 18 06:08:25.664: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 04/18/23 06:08:25.667
    STEP: create a pod 04/18/23 06:08:25.731
    Apr 18 06:08:25.756: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-4094" to be "running"
    Apr 18 06:08:25.758: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.401409ms
    Apr 18 06:08:27.764: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0076189s
    Apr 18 06:08:29.799: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.042633974s
    Apr 18 06:08:29.799: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 04/18/23 06:08:29.799
    Apr 18 06:08:29.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=webhook-4094 attach --namespace=webhook-4094 to-be-attached-pod -i -c=container1'
    Apr 18 06:08:29.888: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 06:08:29.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4094" for this suite. 04/18/23 06:08:29.918
    STEP: Destroying namespace "webhook-4094-markers" for this suite. 04/18/23 06:08:29.929
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:08:30.264
Apr 18 06:08:30.265: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename services 04/18/23 06:08:30.265
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:30.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:30.377
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-8812 04/18/23 06:08:30.379
STEP: creating replication controller nodeport-test in namespace services-8812 04/18/23 06:08:30.633
I0418 06:08:31.006743      22 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8812, replica count: 2
I0418 06:08:34.058071      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0418 06:08:37.058271      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 18 06:08:37.058: INFO: Creating new exec pod
Apr 18 06:08:37.089: INFO: Waiting up to 5m0s for pod "execpod8phvs" in namespace "services-8812" to be "running"
Apr 18 06:08:37.140: INFO: Pod "execpod8phvs": Phase="Pending", Reason="", readiness=false. Elapsed: 50.550488ms
Apr 18 06:08:39.188: INFO: Pod "execpod8phvs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098683471s
Apr 18 06:08:41.179: INFO: Pod "execpod8phvs": Phase="Pending", Reason="", readiness=false. Elapsed: 4.090125683s
Apr 18 06:08:43.144: INFO: Pod "execpod8phvs": Phase="Running", Reason="", readiness=true. Elapsed: 6.055319875s
Apr 18 06:08:43.144: INFO: Pod "execpod8phvs" satisfied condition "running"
Apr 18 06:08:44.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8812 exec execpod8phvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Apr 18 06:08:44.329: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 18 06:08:44.329: INFO: stdout: "nodeport-test-cjphs"
Apr 18 06:08:44.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8812 exec execpod8phvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.1.219 80'
Apr 18 06:08:44.484: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.1.219 80\nConnection to 10.96.1.219 80 port [tcp/http] succeeded!\n"
Apr 18 06:08:44.484: INFO: stdout: "nodeport-test-lhc4j"
Apr 18 06:08:44.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8812 exec execpod8phvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.109 32497'
Apr 18 06:08:44.644: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.109 32497\nConnection to 192.168.2.109 32497 port [tcp/*] succeeded!\n"
Apr 18 06:08:44.644: INFO: stdout: "nodeport-test-cjphs"
Apr 18 06:08:44.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8812 exec execpod8phvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.108 32497'
Apr 18 06:08:44.839: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.108 32497\nConnection to 192.168.2.108 32497 port [tcp/*] succeeded!\n"
Apr 18 06:08:44.839: INFO: stdout: ""
Apr 18 06:08:45.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8812 exec execpod8phvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.108 32497'
Apr 18 06:08:45.993: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.108 32497\nConnection to 192.168.2.108 32497 port [tcp/*] succeeded!\n"
Apr 18 06:08:45.993: INFO: stdout: "nodeport-test-lhc4j"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 18 06:08:45.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8812" for this suite. 04/18/23 06:08:45.998
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":355,"skipped":6449,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.759 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:08:30.264
    Apr 18 06:08:30.265: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename services 04/18/23 06:08:30.265
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:30.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:30.377
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-8812 04/18/23 06:08:30.379
    STEP: creating replication controller nodeport-test in namespace services-8812 04/18/23 06:08:30.633
    I0418 06:08:31.006743      22 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8812, replica count: 2
    I0418 06:08:34.058071      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0418 06:08:37.058271      22 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 18 06:08:37.058: INFO: Creating new exec pod
    Apr 18 06:08:37.089: INFO: Waiting up to 5m0s for pod "execpod8phvs" in namespace "services-8812" to be "running"
    Apr 18 06:08:37.140: INFO: Pod "execpod8phvs": Phase="Pending", Reason="", readiness=false. Elapsed: 50.550488ms
    Apr 18 06:08:39.188: INFO: Pod "execpod8phvs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098683471s
    Apr 18 06:08:41.179: INFO: Pod "execpod8phvs": Phase="Pending", Reason="", readiness=false. Elapsed: 4.090125683s
    Apr 18 06:08:43.144: INFO: Pod "execpod8phvs": Phase="Running", Reason="", readiness=true. Elapsed: 6.055319875s
    Apr 18 06:08:43.144: INFO: Pod "execpod8phvs" satisfied condition "running"
    Apr 18 06:08:44.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8812 exec execpod8phvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Apr 18 06:08:44.329: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Apr 18 06:08:44.329: INFO: stdout: "nodeport-test-cjphs"
    Apr 18 06:08:44.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8812 exec execpod8phvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.96.1.219 80'
    Apr 18 06:08:44.484: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.96.1.219 80\nConnection to 10.96.1.219 80 port [tcp/http] succeeded!\n"
    Apr 18 06:08:44.484: INFO: stdout: "nodeport-test-lhc4j"
    Apr 18 06:08:44.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8812 exec execpod8phvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.109 32497'
    Apr 18 06:08:44.644: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.109 32497\nConnection to 192.168.2.109 32497 port [tcp/*] succeeded!\n"
    Apr 18 06:08:44.644: INFO: stdout: "nodeport-test-cjphs"
    Apr 18 06:08:44.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8812 exec execpod8phvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.108 32497'
    Apr 18 06:08:44.839: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.108 32497\nConnection to 192.168.2.108 32497 port [tcp/*] succeeded!\n"
    Apr 18 06:08:44.839: INFO: stdout: ""
    Apr 18 06:08:45.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=services-8812 exec execpod8phvs -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.2.108 32497'
    Apr 18 06:08:45.993: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.2.108 32497\nConnection to 192.168.2.108 32497 port [tcp/*] succeeded!\n"
    Apr 18 06:08:45.993: INFO: stdout: "nodeport-test-lhc4j"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 18 06:08:45.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8812" for this suite. 04/18/23 06:08:45.998
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:08:46.024
Apr 18 06:08:46.024: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 06:08:46.025
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:46.112
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:46.115
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Apr 18 06:08:46.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1829 version'
Apr 18 06:08:46.179: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Apr 18 06:08:46.179: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.6\", GitCommit:\"ff2c119726cc1f8926fb0585c74b25921e866a28\", GitTreeState:\"clean\", BuildDate:\"2023-01-18T19:22:09Z\", GoVersion:\"go1.19.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.6\", GitCommit:\"ff2c119726cc1f8926fb0585c74b25921e866a28\", GitTreeState:\"clean\", BuildDate:\"2023-01-18T19:15:26Z\", GoVersion:\"go1.19.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 06:08:46.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1829" for this suite. 04/18/23 06:08:46.186
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":356,"skipped":6466,"failed":0}
------------------------------
â€¢ [0.182 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:08:46.024
    Apr 18 06:08:46.024: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 06:08:46.025
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:46.112
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:46.115
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Apr 18 06:08:46.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-1829 version'
    Apr 18 06:08:46.179: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Apr 18 06:08:46.179: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.6\", GitCommit:\"ff2c119726cc1f8926fb0585c74b25921e866a28\", GitTreeState:\"clean\", BuildDate:\"2023-01-18T19:22:09Z\", GoVersion:\"go1.19.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.6\", GitCommit:\"ff2c119726cc1f8926fb0585c74b25921e866a28\", GitTreeState:\"clean\", BuildDate:\"2023-01-18T19:15:26Z\", GoVersion:\"go1.19.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 06:08:46.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1829" for this suite. 04/18/23 06:08:46.186
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:08:46.209
Apr 18 06:08:46.209: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename security-context 04/18/23 06:08:46.21
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:46.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:46.343
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/18/23 06:08:46.389
Apr 18 06:08:46.442: INFO: Waiting up to 5m0s for pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68" in namespace "security-context-3519" to be "Succeeded or Failed"
Apr 18 06:08:46.444: INFO: Pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.352065ms
Apr 18 06:08:48.449: INFO: Pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006640924s
Apr 18 06:08:50.471: INFO: Pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68": Phase="Running", Reason="", readiness=false. Elapsed: 4.029332485s
Apr 18 06:08:52.506: INFO: Pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.064155364s
STEP: Saw pod success 04/18/23 06:08:52.506
Apr 18 06:08:52.506: INFO: Pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68" satisfied condition "Succeeded or Failed"
Apr 18 06:08:52.538: INFO: Trying to get logs from node apps-208 pod security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68 container test-container: <nil>
STEP: delete the pod 04/18/23 06:08:52.545
Apr 18 06:08:52.900: INFO: Waiting for pod security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68 to disappear
Apr 18 06:08:52.903: INFO: Pod security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 18 06:08:52.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3519" for this suite. 04/18/23 06:08:52.908
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":357,"skipped":6517,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.774 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:08:46.209
    Apr 18 06:08:46.209: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename security-context 04/18/23 06:08:46.21
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:46.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:46.343
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/18/23 06:08:46.389
    Apr 18 06:08:46.442: INFO: Waiting up to 5m0s for pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68" in namespace "security-context-3519" to be "Succeeded or Failed"
    Apr 18 06:08:46.444: INFO: Pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.352065ms
    Apr 18 06:08:48.449: INFO: Pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006640924s
    Apr 18 06:08:50.471: INFO: Pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68": Phase="Running", Reason="", readiness=false. Elapsed: 4.029332485s
    Apr 18 06:08:52.506: INFO: Pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.064155364s
    STEP: Saw pod success 04/18/23 06:08:52.506
    Apr 18 06:08:52.506: INFO: Pod "security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68" satisfied condition "Succeeded or Failed"
    Apr 18 06:08:52.538: INFO: Trying to get logs from node apps-208 pod security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68 container test-container: <nil>
    STEP: delete the pod 04/18/23 06:08:52.545
    Apr 18 06:08:52.900: INFO: Waiting for pod security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68 to disappear
    Apr 18 06:08:52.903: INFO: Pod security-context-9bcac2e9-0d7b-457f-a824-b40b060a4a68 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 18 06:08:52.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-3519" for this suite. 04/18/23 06:08:52.908
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:08:52.985
Apr 18 06:08:52.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 06:08:52.986
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:53.057
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:53.06
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 04/18/23 06:08:53.207
Apr 18 06:08:53.207: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Apr 18 06:08:53.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
Apr 18 06:08:53.987: INFO: stderr: ""
Apr 18 06:08:53.987: INFO: stdout: "service/agnhost-replica created\n"
Apr 18 06:08:53.987: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Apr 18 06:08:53.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
Apr 18 06:08:56.583: INFO: stderr: ""
Apr 18 06:08:56.583: INFO: stdout: "service/agnhost-primary created\n"
Apr 18 06:08:56.583: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 18 06:08:56.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
Apr 18 06:08:57.049: INFO: stderr: ""
Apr 18 06:08:57.049: INFO: stdout: "service/frontend created\n"
Apr 18 06:08:57.049: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 18 06:08:57.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
Apr 18 06:08:57.447: INFO: stderr: ""
Apr 18 06:08:57.447: INFO: stdout: "deployment.apps/frontend created\n"
Apr 18 06:08:57.447: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 18 06:08:57.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
Apr 18 06:08:59.813: INFO: stderr: ""
Apr 18 06:08:59.813: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Apr 18 06:08:59.814: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 18 06:08:59.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
Apr 18 06:09:00.312: INFO: stderr: ""
Apr 18 06:09:00.312: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 04/18/23 06:09:00.312
Apr 18 06:09:00.312: INFO: Waiting for all frontend pods to be Running.
Apr 18 06:09:10.367: INFO: Waiting for frontend to serve content.
Apr 18 06:09:10.377: INFO: Trying to add a new entry to the guestbook.
Apr 18 06:09:10.387: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 04/18/23 06:09:10.396
Apr 18 06:09:10.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
Apr 18 06:09:10.599: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 06:09:10.599: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 04/18/23 06:09:10.599
Apr 18 06:09:10.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
Apr 18 06:09:10.824: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 06:09:10.824: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/18/23 06:09:10.824
Apr 18 06:09:10.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
Apr 18 06:09:11.073: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 06:09:11.073: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/18/23 06:09:11.073
Apr 18 06:09:11.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
Apr 18 06:09:11.242: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 06:09:11.242: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/18/23 06:09:11.242
Apr 18 06:09:11.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
Apr 18 06:09:12.054: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 06:09:12.055: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/18/23 06:09:12.055
Apr 18 06:09:12.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
Apr 18 06:09:12.236: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 18 06:09:12.236: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 06:09:12.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6171" for this suite. 04/18/23 06:09:12.241
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":358,"skipped":6542,"failed":0}
------------------------------
â€¢ [SLOW TEST] [19.325 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:08:52.985
    Apr 18 06:08:52.985: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 06:08:52.986
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:08:53.057
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:08:53.06
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 04/18/23 06:08:53.207
    Apr 18 06:08:53.207: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Apr 18 06:08:53.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
    Apr 18 06:08:53.987: INFO: stderr: ""
    Apr 18 06:08:53.987: INFO: stdout: "service/agnhost-replica created\n"
    Apr 18 06:08:53.987: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Apr 18 06:08:53.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
    Apr 18 06:08:56.583: INFO: stderr: ""
    Apr 18 06:08:56.583: INFO: stdout: "service/agnhost-primary created\n"
    Apr 18 06:08:56.583: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Apr 18 06:08:56.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
    Apr 18 06:08:57.049: INFO: stderr: ""
    Apr 18 06:08:57.049: INFO: stdout: "service/frontend created\n"
    Apr 18 06:08:57.049: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Apr 18 06:08:57.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
    Apr 18 06:08:57.447: INFO: stderr: ""
    Apr 18 06:08:57.447: INFO: stdout: "deployment.apps/frontend created\n"
    Apr 18 06:08:57.447: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 18 06:08:57.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
    Apr 18 06:08:59.813: INFO: stderr: ""
    Apr 18 06:08:59.813: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Apr 18 06:08:59.814: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 18 06:08:59.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 create -f -'
    Apr 18 06:09:00.312: INFO: stderr: ""
    Apr 18 06:09:00.312: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 04/18/23 06:09:00.312
    Apr 18 06:09:00.312: INFO: Waiting for all frontend pods to be Running.
    Apr 18 06:09:10.367: INFO: Waiting for frontend to serve content.
    Apr 18 06:09:10.377: INFO: Trying to add a new entry to the guestbook.
    Apr 18 06:09:10.387: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 04/18/23 06:09:10.396
    Apr 18 06:09:10.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
    Apr 18 06:09:10.599: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 06:09:10.599: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 04/18/23 06:09:10.599
    Apr 18 06:09:10.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
    Apr 18 06:09:10.824: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 06:09:10.824: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/18/23 06:09:10.824
    Apr 18 06:09:10.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
    Apr 18 06:09:11.073: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 06:09:11.073: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/18/23 06:09:11.073
    Apr 18 06:09:11.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
    Apr 18 06:09:11.242: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 06:09:11.242: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/18/23 06:09:11.242
    Apr 18 06:09:11.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
    Apr 18 06:09:12.054: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 06:09:12.055: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/18/23 06:09:12.055
    Apr 18 06:09:12.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-6171 delete --grace-period=0 --force -f -'
    Apr 18 06:09:12.236: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 18 06:09:12.236: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 06:09:12.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6171" for this suite. 04/18/23 06:09:12.241
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:09:12.316
Apr 18 06:09:12.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename webhook 04/18/23 06:09:12.317
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:09:12.77
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:09:12.775
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/18/23 06:09:13.207
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 06:09:14.076
STEP: Deploying the webhook pod 04/18/23 06:09:14.276
STEP: Wait for the deployment to be ready 04/18/23 06:09:14.451
Apr 18 06:09:14.765: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 18 06:09:16.775: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 6, 9, 14, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 9, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 6, 9, 14, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 9, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/18/23 06:09:18.784
STEP: Verifying the service has paired with the endpoint 04/18/23 06:09:18.839
Apr 18 06:09:19.839: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 04/18/23 06:09:19.845
Apr 18 06:09:19.951: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource definition that should be denied by the webhook 04/18/23 06:09:20.06
Apr 18 06:09:20.061: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 18 06:09:20.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2874" for this suite. 04/18/23 06:09:20.124
STEP: Destroying namespace "webhook-2874-markers" for this suite. 04/18/23 06:09:20.161
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":359,"skipped":6624,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.266 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:09:12.316
    Apr 18 06:09:12.316: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename webhook 04/18/23 06:09:12.317
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:09:12.77
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:09:12.775
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/18/23 06:09:13.207
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/18/23 06:09:14.076
    STEP: Deploying the webhook pod 04/18/23 06:09:14.276
    STEP: Wait for the deployment to be ready 04/18/23 06:09:14.451
    Apr 18 06:09:14.765: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Apr 18 06:09:16.775: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.April, 18, 6, 9, 14, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 9, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.April, 18, 6, 9, 14, 0, time.Local), LastTransitionTime:time.Date(2023, time.April, 18, 6, 9, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/18/23 06:09:18.784
    STEP: Verifying the service has paired with the endpoint 04/18/23 06:09:18.839
    Apr 18 06:09:19.839: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 04/18/23 06:09:19.845
    Apr 18 06:09:19.951: INFO: Waiting for webhook configuration to be ready...
    STEP: Creating a custom resource definition that should be denied by the webhook 04/18/23 06:09:20.06
    Apr 18 06:09:20.061: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 18 06:09:20.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2874" for this suite. 04/18/23 06:09:20.124
    STEP: Destroying namespace "webhook-2874-markers" for this suite. 04/18/23 06:09:20.161
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:09:20.582
Apr 18 06:09:20.582: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename kubectl 04/18/23 06:09:20.583
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:09:20.709
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:09:20.712
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 04/18/23 06:09:20.739
Apr 18 06:09:20.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-4863 create -f -'
Apr 18 06:09:21.356: INFO: stderr: ""
Apr 18 06:09:21.356: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 04/18/23 06:09:21.356
Apr 18 06:09:21.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-4863 diff -f -'
Apr 18 06:09:21.863: INFO: rc: 1
Apr 18 06:09:21.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-4863 delete -f -'
Apr 18 06:09:21.995: INFO: stderr: ""
Apr 18 06:09:21.995: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 18 06:09:21.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4863" for this suite. 04/18/23 06:09:22
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":360,"skipped":6628,"failed":0}
------------------------------
â€¢ [1.432 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:09:20.582
    Apr 18 06:09:20.582: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename kubectl 04/18/23 06:09:20.583
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:09:20.709
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:09:20.712
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 04/18/23 06:09:20.739
    Apr 18 06:09:20.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-4863 create -f -'
    Apr 18 06:09:21.356: INFO: stderr: ""
    Apr 18 06:09:21.356: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 04/18/23 06:09:21.356
    Apr 18 06:09:21.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-4863 diff -f -'
    Apr 18 06:09:21.863: INFO: rc: 1
    Apr 18 06:09:21.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2190061389 --namespace=kubectl-4863 delete -f -'
    Apr 18 06:09:21.995: INFO: stderr: ""
    Apr 18 06:09:21.995: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 18 06:09:21.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4863" for this suite. 04/18/23 06:09:22
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:09:22.016
Apr 18 06:09:22.016: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename daemonsets 04/18/23 06:09:22.017
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:09:22.23
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:09:22.233
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Apr 18 06:09:22.686: INFO: Create a RollingUpdate DaemonSet
Apr 18 06:09:22.771: INFO: Check that daemon pods launch on every node of the cluster
Apr 18 06:09:22.798: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:09:22.799: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 06:09:24.070: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:09:24.070: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 06:09:24.807: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:09:24.807: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 06:09:25.896: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:09:25.896: INFO: Node apps-207 is running 0 daemon pod, expected 1
Apr 18 06:09:26.889: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 18 06:09:26.889: INFO: Node apps-209 is running 0 daemon pod, expected 1
Apr 18 06:09:27.828: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 18 06:09:27.828: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Apr 18 06:09:27.829: INFO: Update the DaemonSet to trigger a rollout
Apr 18 06:09:27.908: INFO: Updating DaemonSet daemon-set
Apr 18 06:09:30.961: INFO: Roll back the DaemonSet before rollout is complete
Apr 18 06:09:31.005: INFO: Updating DaemonSet daemon-set
Apr 18 06:09:31.005: INFO: Make sure DaemonSet rollback is complete
Apr 18 06:09:31.025: INFO: Wrong image for pod: daemon-set-hr5xx. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Apr 18 06:09:31.025: INFO: Pod daemon-set-hr5xx is not available
Apr 18 06:09:35.062: INFO: Pod daemon-set-84876 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/18/23 06:09:35.073
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4752, will wait for the garbage collector to delete the pods 04/18/23 06:09:35.073
Apr 18 06:09:35.135: INFO: Deleting DaemonSet.extensions daemon-set took: 7.806461ms
Apr 18 06:09:35.435: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.512314ms
Apr 18 06:09:40.940: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 18 06:09:40.940: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 18 06:09:40.943: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4129384"},"items":null}

Apr 18 06:09:40.946: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4129384"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 18 06:09:40.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4752" for this suite. 04/18/23 06:09:40.998
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":361,"skipped":6674,"failed":0}
------------------------------
â€¢ [SLOW TEST] [19.018 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:09:22.016
    Apr 18 06:09:22.016: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename daemonsets 04/18/23 06:09:22.017
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:09:22.23
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:09:22.233
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Apr 18 06:09:22.686: INFO: Create a RollingUpdate DaemonSet
    Apr 18 06:09:22.771: INFO: Check that daemon pods launch on every node of the cluster
    Apr 18 06:09:22.798: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:09:22.799: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 06:09:24.070: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:09:24.070: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 06:09:24.807: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:09:24.807: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 06:09:25.896: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:09:25.896: INFO: Node apps-207 is running 0 daemon pod, expected 1
    Apr 18 06:09:26.889: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 18 06:09:26.889: INFO: Node apps-209 is running 0 daemon pod, expected 1
    Apr 18 06:09:27.828: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 18 06:09:27.828: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Apr 18 06:09:27.829: INFO: Update the DaemonSet to trigger a rollout
    Apr 18 06:09:27.908: INFO: Updating DaemonSet daemon-set
    Apr 18 06:09:30.961: INFO: Roll back the DaemonSet before rollout is complete
    Apr 18 06:09:31.005: INFO: Updating DaemonSet daemon-set
    Apr 18 06:09:31.005: INFO: Make sure DaemonSet rollback is complete
    Apr 18 06:09:31.025: INFO: Wrong image for pod: daemon-set-hr5xx. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Apr 18 06:09:31.025: INFO: Pod daemon-set-hr5xx is not available
    Apr 18 06:09:35.062: INFO: Pod daemon-set-84876 is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/18/23 06:09:35.073
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4752, will wait for the garbage collector to delete the pods 04/18/23 06:09:35.073
    Apr 18 06:09:35.135: INFO: Deleting DaemonSet.extensions daemon-set took: 7.806461ms
    Apr 18 06:09:35.435: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.512314ms
    Apr 18 06:09:40.940: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 18 06:09:40.940: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 18 06:09:40.943: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4129384"},"items":null}

    Apr 18 06:09:40.946: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4129384"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 18 06:09:40.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4752" for this suite. 04/18/23 06:09:40.998
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/18/23 06:09:41.034
Apr 18 06:09:41.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
STEP: Building a namespace api object, basename csistoragecapacity 04/18/23 06:09:41.035
STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:09:41.376
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:09:41.378
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 04/18/23 06:09:41.439
STEP: getting /apis/storage.k8s.io 04/18/23 06:09:41.441
STEP: getting /apis/storage.k8s.io/v1 04/18/23 06:09:41.442
STEP: creating 04/18/23 06:09:41.443
STEP: watching 04/18/23 06:09:41.779
Apr 18 06:09:41.779: INFO: starting watch
STEP: getting 04/18/23 06:09:41.814
STEP: listing in namespace 04/18/23 06:09:41.817
STEP: listing across namespaces 04/18/23 06:09:41.82
STEP: patching 04/18/23 06:09:41.87
STEP: updating 04/18/23 06:09:41.944
Apr 18 06:09:41.968: INFO: waiting for watch events with expected annotations in namespace
Apr 18 06:09:41.968: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 04/18/23 06:09:41.968
STEP: deleting a collection 04/18/23 06:09:42.031
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Apr 18 06:09:42.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-155" for this suite. 04/18/23 06:09:42.168
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":362,"skipped":6680,"failed":0}
------------------------------
â€¢ [1.261 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/18/23 06:09:41.034
    Apr 18 06:09:41.034: INFO: >>> kubeConfig: /tmp/kubeconfig-2190061389
    STEP: Building a namespace api object, basename csistoragecapacity 04/18/23 06:09:41.035
    STEP: Waiting for a default service account to be provisioned in namespace 04/18/23 06:09:41.376
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/18/23 06:09:41.378
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 04/18/23 06:09:41.439
    STEP: getting /apis/storage.k8s.io 04/18/23 06:09:41.441
    STEP: getting /apis/storage.k8s.io/v1 04/18/23 06:09:41.442
    STEP: creating 04/18/23 06:09:41.443
    STEP: watching 04/18/23 06:09:41.779
    Apr 18 06:09:41.779: INFO: starting watch
    STEP: getting 04/18/23 06:09:41.814
    STEP: listing in namespace 04/18/23 06:09:41.817
    STEP: listing across namespaces 04/18/23 06:09:41.82
    STEP: patching 04/18/23 06:09:41.87
    STEP: updating 04/18/23 06:09:41.944
    Apr 18 06:09:41.968: INFO: waiting for watch events with expected annotations in namespace
    Apr 18 06:09:41.968: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 04/18/23 06:09:41.968
    STEP: deleting a collection 04/18/23 06:09:42.031
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Apr 18 06:09:42.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-155" for this suite. 04/18/23 06:09:42.168
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6704,"failed":0}
Apr 18 06:09:42.297: INFO: Running AfterSuite actions on all nodes
Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Apr 18 06:09:42.297: INFO: Running AfterSuite actions on node 1
Apr 18 06:09:42.297: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Apr 18 06:09:42.297: INFO: Running AfterSuite actions on all nodes
    Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Apr 18 06:09:42.297: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Apr 18 06:09:42.297: INFO: Running AfterSuite actions on node 1
    Apr 18 06:09:42.297: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.085 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7066 Specs in 7696.330 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6704 Skipped
PASS

Ginkgo ran 1 suite in 2h8m16.626266081s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

